{"name": "w2d1t1 cnns ", "full_name": " h1 Tutorial 1 Introduction to CNNs h1 Tutorial Objectives h2 Tutorial slides h1 Setup h2 Install dependencies h2 Figure Settings h2 Helper functions h2 Plotting Functions h2 Set random seed h2 Set device GPU or CPU Execute set device h1 Section 0 Recap the Experience from Last Week h2 Video 1 Introduction to CNNs and RNNs h2 Think 0 Regularization effective number of params h3 Student Response h2 The rest of these lectures focus on another way to reduce parameters weight sharing Weight sharing is based on the idea that some sets of weights can be used at multiple points in a network We will focus mostly on CNNs today where the weight sharing is across the 2D space of an image At the end we will touch briefly on Recurrent Neural Networks RNNs which share parameters across time Both of these weight sharing techniques across space and time can reduce the number of parameters and increase a network s ability to generalize h1 Section 1 Neuroscience motivation General CNN structure h2 Video 2 Representations Visual processing in the brain h2 Think 1 What makes a representation good h3 Student Response h1 Section 2 Convolutions and Edge Detection h2 Video 3 Details about Convolution h3 Interactive Demo 2 Visualization of Convolution h4 Definitional Note h2 Coding Exercise 2 1 Convolution of a Simple Kernel h2 Coding Exercise 2 2 Convolution Output Size h2 Coding Exercise 2 3 Coding a Convolution h3 Convolution on the Chicago Skyline h2 Section 2 1 Demonstration of a CNN in PyTorch h2 Section 2 2 Padding and Edge Detection h3 Interactive Demo 2 2 Visualization of Convolution with Padding and Stride h3 Think 2 2 1 Edge Detection h4 Student Response h3 Think 2 2 2 Kernel structure h4 Student Response h1 Section 3 Pooling and Subsampling h2 Video 4 Pooling h2 Download EMNIST dataset h2 Dataset DataLoader Functions run me h2 Section 3 1 Multiple Filters h3 Think 3 1 Do you see how these filters would help recognize an X h4 Student Response h2 Section 3 2 ReLU after convolutions h2 Section 3 3 Pooling h3 Interactive Demo 3 3 The effect of the stride h3 Coding Exercise 3 3 Implement MaxPooling h2 Despite the reduction in the size of the output the important or high level features in the output still remains intact h1 Section 4 Putting it all together h2 Video 5 Putting it all together h2 Section 4 1 Number of Parameters in Convolutional vs Fully connected Models h3 Interactive Demo 4 1 Number of Parameters h4 Video 6 Implement your own CNN h3 Train Test Functions Run Me h2 Let us also test the network on an O image h1 Summary h2 Airtable Submission Link h1 Bonus 1 Write your own training loop revisited h2 Video 7 Writing your own training loop h2 Bonus 1 1 Understand the Dataset h3 Download Fashion MNIST dataset h3 Loading Fashion MNIST Data h3 Video 8 The Training Loop h2 Bonus 1 2 Backpropagation Reminder h3 Load a sample dataset EMNIST h2 Bonus 1 3 Fashion MNIST dataset h2 Coding Exercise Bonus 1 Code the training loop h2 Think Bonus 1 Overfitting h1 Bonus 2 Overfitting symptoms and cures h2 Bonus 2 1 Regularization h3 Coding Exercise Bonus 2 1 Adding Regularization h3 Think Bonus 2 1 Regularization h3 Interactive Demo Bonus 2 1 Dropout exploration h3 Coding Exercise Bonus 2 2 How much does augmentation help h4 Download Fashion MNIST if it has not been downloaded h3 Think Bonus 2 2 Data Augmentation ", "stargazers_count": 0, "forks_count": 0, "description": "Train Test Functions Run Me Double click to see the contents We download the data. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_79e1f5fb. These random weight matrices when applied as a transformation on the input gives us some output. Recall that regularization comes in several forms. We will talk more about padding in the next section. A common approach to this problem is called downsampling. Click for solution https github. Conv2d function which creates a convolutional layer that is applied to whatever image that you feed the resulting network. It should take somewhere between 10 seconds and 1 minute. We will simplify the problem further by only keeping the images that correspond to X labeled as 24 in the dataset and O labeled as 15 in the dataset. Look at the code below. Then we will train a CNN to classify an image either an X or an O. Thus A small change in the features of the underlying image won t make a huge difference to the output. If you are familiar with conventions involving flipping just assume the kernel is pre flipped. In Maxpooling we compute the maximum value of all pixels in the pooling window. 1 Regularization Coding Exercise Bonus 2. there is a boundary between left and right or whether it will detect horizontal edges where the trace of the edge is horizontal i. You were introduced to several regularization techniques such as L1 L2 Data Augmentation and Dropout. Early papers used the more common definition of convolution but not using a flip is easier to visualize and in fact the lack of flip does not impact a CNN s ability to learn. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_309474b2. py Convolution on the Chicago SkylineAfter you have finished programming the above convolution function run the below coding cell which applies two different kernels to a greyscale picture of Chicago and takes the geometric average of the results. Give it a try Change the stride and see how it affects the output shape. Video 7 Writing your own training loop Bonus 1. NOTE The comments in the train function provides many hints that will help you fill in the missing code. Tip In this animation and all the ones that follow you can hover over the parts of the code underlined in red to change them. 1 Understand the DatasetThe dataset we are going to use for this task is called Fashion MNIST. In the following cell we provide a code snippet that demonstrates setting up a convolutional network using PyTorch. Notice that here we normalize the dataset. Note in more general situations once you understand convolutions you can use functions already available in pytorch numpy to perform convolution such as scipy. begin equation textbf Kernel begin bmatrix 1 1 1 1 end bmatrix end equation Student Response Click for solution https github. However the definitions in other domains and the one we use here are slightly different. However regularization can help ANNs to better generalize. However these feature maps record the _precise_ position of features in the input. Load a sample dataset EMNIST You already coded the structure of a CNN. Parameter comparison Interactive Demo 4. How hard will it be to differentiate t shirt tops from shirts Video 8 The Training Loop Bonus 1. Note You need to run the cell to activate the sliders and again to run once changing the sliders. html Download Fashion MNIST if it has not been downloaded. Run the next cell to get the accuracy on the data Think Bonus 1 OverfittingDo you think this network is overfitting If yes what can you do to combat this Hint overfitting occurs when the training accuracy greatly exceeds the validation accuracy Click for solution https github. If there s time you can also consider how the brain s representations might differ from a learned representation inside a NN. Run this cell to enable the widget Coding Exercise 3. Here s the link to the list of transforms available in pytorch https pytorch. Since we are using PyTorch throughout the course we will use the built in functions to update the weights. Think about what this specific kernel is doing to the original image. The ReLU Rectified Linear Unit introduces non linearity into our model allowing us to learn a more complex function that can better predict the class of an image. Tip Below the function is called Conv2d because the convolutional filter is a matrix with two dimensions 2D. e for each epoch we want to to know the average loss of the batch size. Recall from the video that convolution involves sliding the kernel across the image taking the element wise product and adding those products together. com a 226927 s an discussion which talks about how ReLU is useful as an activation funciton. The stride defines how much the pooling region is moved over the input matrix to produce the next output red arrows in the animation. Today we ll be talking about other ways to simplify ANNs by making smart changes to their architecture. py Now let s run the network on the test data You should have been able to get a test accuracy of around 99 Note We are using a softmax function here which converts a real value to a value between 0 and 1 which can be interpreted as a probability. At first the outputs predictions will match the true labels only by chance. You should first have a criterion defined you can use CrossEntropyLoss here which you learned about last week so that you can calculate the loss. 1 Multiple FiltersThe following network sets up 3 filters and runs them on an image of the dataset from the X class. Tutorial 1 Introduction to CNNs Week 2 Day 1 Convnets And Recurrent Neural Networks By Neuromatch Academy __Content creators __ Dawn Estes McKnight Richard Gerum Cassidy Pirlot Rohan Saha Liam Peet Pare Saeed Najafi Alona Fyshe__Content reviewers __ Saeed Salehi Lily Cheng Yu Fang Yang Polina Turishcheva Bettina Hein Kelson Shilling Scrivo__Content editors __ Nina Kudryashova Anmol Gupta Spiros Chavlis __Production editors __ Alex Tran Van Minh Spiros Chavlis Based on material from Konrad Kording Hmrishav Bandyopadhyay Rahul Shekhar Tejas Srivastava Our 2021 Sponsors including Presenting Sponsor Facebook Reality Labs Tutorial ObjectivesAt the end of this tutorial we will be able to Define what convolution is Implement convolution as an operationIn the Bonus materials of this tutorial you will be able to train a CNN by writing your own train loop recognize the symptoms of overfitting and how to cure them Tutorial slides Setup Install dependencies Figure Settings Helper functions Plotting Functions Set random seed Executing set_seed seed seed you are setting the seed Set device GPU or CPU. Let us also test the network on an O image. That means that small changes to the position of an object in an image can result in a very different feature map. 2 Data AugmentationDid the training accuracy reduce further compared to with dropout alone Is the model still overfitting Click for solution https github. py Example output Coding Exercise 2. But a cup is a cup and an X is an X no matter where it appears in the image We need to achieve _translational invariance_. Here s some code to visualize the dataset. We will then run the same network you created in the above exercise with regularization and then plot the loss and accuracies. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_256458ee. We later provide pretrained results to give you an idea how the results would look on the whole dataset. Getting the DataLoaders Run Me Coding Exercise Bonus 1 Code the training loopNow try coding the training loop. After all that _is_ what the C in CNN stands for In this section we will define what a convolution is practice performing a convolution and implement it in code. This is because of the fact that the kernel can t produce values for the edges of the image when it slides to an end of the image and is centered on a border pixel it overlaps space outside of the image that is undefined. First we create the network and load a dataset. We first calculate how far away the predicted outputs are to the true outputs using a loss function. Recall that the input images have size 28 28. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_63a2685b. You can test your function by uncommenting the sections beneath it. py Example output The next cell contains the code for the CNN we will be using in this section. Note that unlike a convolutional layer the pooling layer contains no learned parameters Pooling just computes a pre determined summary of the input and passes that along. And just like with filters every time we apply a pooling operation we produce a single output. We have already done the same for accuracy for you. If we don t want to lose that information we will have to pad the image with some defaults such as 0s on the border. In general this kernel is just a few parameters compared to the huge number of parameters in a dense network. Video 6 Implement your own CNNin_channels 1 out_channels 32 kernel_size 3 Coding Exercise 4 Implement your own CNNLet s stack up all we have learnt. 2 Convolution Output SizeNow you have manually calculated a convolution. Therefore later dense layers will need fewer parameters. Num_Convs is the number of convolutional blocks in the network with each block containing a single kernel. py Example output Run the next cell to get the accuracy on the data Think Bonus 2. All the pieces are beginning to fit together. Below are the results from training a simple multilayer perceptron with one hidden layer b on a simple toy dataset a. py Bonus 2 Overfitting symptoms and cures Time estimate 30mins So you spent some time last week learning about regularization techniques. Download Fashion MNIST dataset Loading Fashion MNIST Data reduce_classes data to reduce Fashion MNIST Data to two categoriesIf you want to continue with the 10 class dataset skip the next cell. Start the training process by first obtaining the model output calculating the loss and finally updating the weights. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_33ecb6a5. Interactive Demo 2. py Interactive Demo Bonus 2. Section 1 Neuroscience motivation General CNN structure Time estimate 25mins Video 2 Representations Visual processing in the brain Think 1 What makes a representation good Representations have a long and storied history having been studied by the likes of Aristotle back in 300 BC Representations are not a new idea and they certainly don t exist just in neural networks. there is a boundary between top and bottom. In this section we will train a CNN using convolution layers and maxpool and then observe what the training and validation curves look like. Recall that the MNIST dataset consists of binarized images of handwritten digits. org vision stable transforms. MaxPool2d kernel_size 2 Fully Connected Layer nn. In this section we will walk through an example of training loop for a convolution net. py Consider the image below which has a black vertical stripe with white on the side. 2 Kernel structureIf the kernel were transposed i. The example below shows the result of Maxpooling within the yellow pooling windows to create the red pooling output matrix. 1 Number of Parameters Run this cell to enable the widget The difference in parameters is huge and it continues to increase as the input image size increases. But the real strength of neural networks comes from the incorporation of non linear functions. You can also try MaxPool or AvgPool. 2 How much does augmentation help Last week you also learned how data augmentation can regularize a network. Furthermore in the real world we often have learning problems where the relationship between the input and output is non linear and complex. ReLU No need to add a ReLU after the final fully connected layer. And then we call the step method on the optimizer variable to apply the gradient updates to our weight matrices. Observe the following simple kernel and discuss whether this will detect vertical edges where the trace of the edge is vertical i. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_6e9ea2ef. 1 Demonstration of a CNN in PyTorchAt this point you should have a fair idea of how to perform a convolution on an image given a kernel. The input had a size of 3 3 and the output is of size 2 2. Below is a copy of the CNN model we used previously. How did this change the shape of the output When you know the shapes of the input matrix and kernel what is the shape of the output Hint If you have problems figuring out what the output shape should look like go back to the visualisation and see how the output shape changes as you modify the image and kernel size. For our purposes no flipping is needed. Note that we are using the filters from the videos Now let s visualize the filters using the code given below. You added regularization and data augmentation in order to get a model that generalizes well. The nn module contains a plethora of functions that will make implementing a neural network easier. 1 Do you see how these filters would help recognize an X Student Response Click for solution https github. Interactive Demo 3. Don t forget to zero out the gradients. When you apply the network object to an image or anything in the form of a matrix it convolves the kernel over that image. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_7cc3340b. 1 Adding RegularizationAdd various regularization methods feel free to add any and play around Click for solution https github. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_211bbfd0. However to display the image all the pixels are normalized between 0 black and 1 white. In CNNs Max Pooling and Average Pooling are used to downsample. py We apply the filters to the images. It consists of a training set of 60 000 examples and a test set of 10 000 examples. In this article https machinelearningknowledge. py Section 3 Pooling and Subsampling Time estimate 50mins Video 4 PoolingTo visualize the various components of a CNN we will build a simple CNN step by step. Like convolutional layers pooling layers have fixed shape windows pooling windows that are systematically applied to the input. com questions 126238 what are the advantages of relu over sigmoid function in deep neural networks sfb 2 s another excellent discussion about the advantages of using ReLU. 1 Dropout explorationIf you want to try out more dropout parameter combinations but do not have the time to run them we have here precalculated some combinations you can use the sliders to explore them. Confusing but now you know Student Response Click for solution https github. In it we define a Net class that you can instantiate with a kernel to create a Neural Network object. An Example of Pooling with a kernel size of 2 Pooling gives our network translational invariance by providing a summary of the values in each pooling window. For example L1 regularization adds a term to the loss function that penalizes based on the sum of the _absolute_ magnitude of the weights. flatten x 1 in order to flatten the input at this stage. Conv2d in_channels 32 out_channels 64 kernel_size 3 Pool Layer nn. We apply the filters and relus to the images. This process is somewhat predictably called padding. Let us view the image of X and O and what the output of the filters applied to them look like. We call the backward method on our loss variable to calculate the gradients derivatives with respect to all the weight matrices and biases. Run the cell to plot the outputs You should observe the size of the output as being half of what you saw after the ReLU section which is due to the Maxpool layer. 2 Padding and Edge DetectionBefore we start in on the exercises here s a visualization to help you think about padding. Choose the correct criterion Code up the training part calculating gradients loss stepping forward Keep a track of the running loss i. There is a higher probability of belonging to class 1 i. Run this cell to enable the widget Coding Exercise Bonus 2. Finally the MaxPool2d operation reduces the output size by half to 12x12. Is the training accuracy slightly reduced from before adding regularization What accuracy were you able to reduce it to 2. SummaryIn this Tutorial we have familiarized ouselves with CNNs. Video 3 Details about ConvolutionBefore jumping into coding exercises take a moment to look at this animation that steps through the process of convolution. Student Response Click for solution https github. Now you are going to implement the training loop for a CNN. As a quick aside notice the difference in the input and output size. In Section 6 we will add regularization and data augmentation to see what effects they have on the curves and why it is important to incorporate them while training our network. Why does the validation accuracy start higher than training accuracy Click for solution https github. Let s add data augmentation to our model via transforms and see if that helps our model to better generalize In the following cell add the transforms you want in the list augmentation_transforms. Also don t forget the ReLUs use e. At the end we will touch briefly on Recurrent Neural Networks RNNs which share parameters across time. Video 1 Introduction to CNNs and RNNs Think 0 Regularization effective number of paramsLet s think back to last week when you learned about regularization. Smola _ Dive into Deep Learning http d2l. Let us view the image of X and O and what the output of the filters applied to them looks like. Despite the reduction in the size of the output the important or high level features in the output still remains intact. The network is quite confident that this image is an X Note that this is evident from the softmax output which shows the probabilities of the image belonging to each of the classes. Execute set_device Section 0 Recap the Experience from Last Week Time estimate 15mins Last week you learned a lot Recall that overparametrized ANNs are efficient universal approximators but also that ANNs can memorize our data. Linear in_features 128 out_features 2 Note As discussed in the video we would like to flatten the output from the Convolutional Layers before passing on the Linear layers thereby converting an input of shape BatchSize Channels Height Width to BatchSize Channels Height Width which in this case would be from 32 64 12 12 output of second convolution layer to 32 64 12 12 32 9216. Let s use the animation below to calculate few layer network parameters for image data of shape 32 times32 using both convolutional layers and dense layers. Interactive Demo 2 Visualization of Convolution Run this cell to enable the widget Definitional NoteIf you have a background in signal processing or math you may have already heard of convolution. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_ae125a93. Hint You could use torch. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_906c34b2. Following are the labels of the dataset 0 T shirt top 1 Trouser 2 Pullover 3 Dress 4 Coat 5 Sandal 6 Shirt 7 Sneaker 8 Bag 9 Ankle boot NOTE we will reduce the dataset to just the two categories T shirt top and Shirt to reduce the training time from about 10min to 2min. 2 Visualization of Convolution with Padding and StrideRecall that Padding adds rows and columns of zeros to the outside edge of an image Stride length adjusts the distance by which a filter is shifted after each convolution. Fully connected ModelsConvolutional networks encourage weight sharing by learning a single kernel that is repeated over the entire input image. correlate2d or scipy. Consider the below image and kernel begin align textbf Image begin bmatrix 0 200 200 0 0 200 0 0 0 end bmatrix textbf Kernel begin bmatrix frac 1 4 frac 1 4 frac 1 4 frac 1 4 end bmatrix end align Perform by hand the operations needed to convolve the kernel and image above. Edge detecting filters are usually learned by the first layers in a CNN. Below that are two graphics that show the effect of regularization on both the number of non zero weights d and on the network s accuracy c. As with filters we can change the shape of the window and the size of the stride. Each example is a 28 28 gray scale image associated with a label from 10 classes. 3 The effect of the strideThe following animation depicts how changing the stride changes the output. Airtable Submission Link Bonus 1 Write your own training loop revisited Time estimate 20mins In the last section we coded up a CNN but trained it with some predefined functions. We should also stop to think about how we get the output of the pooling layer to be 12x12. Pooling performs a kind of information compression that provides summary statistics for a _neighborhood_ of the input. py Coding Exercise 2. 1 Edge DetectionOne of the simpler tasks performed by a convolutional layer is edge detection that is finding a place in the image where there is a large and abrupt change in color. If you re up for a challenge you can try methods other than dropout as well. Exercise Fill in the missing lines of code. Now we want you to add some dropout regularization and check if that helps reduce overfitting. We have leaned how the convolution operation works and be applied in various images. These operations shrink the size of the hidden layers and produce features that are more translationally invariant which can be better leveraged by subsequent layers. Download EMNIST dataset Dataset DataLoader Functions run me Let s view a couple samples from the dataset. Also we have learned to implement our own CNN. 2 Backpropagation Reminder_Feel free to skip if you ve got a good handle on Backpropagation_We know that we multiply the input data tensors with weight matrices to obtain some output. This time we will use the EMNIST letters dataset which consists of binarized images of handwritten characters A. Here https stats. We look at the nn module in PyTorch. This is in contrast to the convolutional layer where there are filters to be learned. The 1 means it flattens dimensions starting with dimensions 1 in order to exclude the batch dimension from the flattening. Based on the loss function we change the values of our weight matrices using the gradients of the error with respect to the weight matrices. In particular we will look at the nn. Create a CNN with the following structure. And pytorch calls them linear layers. 2 ReLU after convolutionsUp until now we ve talked about the convolution operation which is linear. What do you notice Note Dense layers are the same as fully connected layers. The reduced parameter set not only brings down memory usage by huge chunks but it also allows the model to generalize better. It is because first the two Conv2d with a kernel_size 3 operations cause the image to be reduced to 26x26 and the second Conv2d reduces it to 24x24. 1 Number of Parameters in Convolutional vs. Use a kernel of size 2 and stride of 2 for the MaxPooling layer. The CNN parameter size however is invariant of the image size as irrespective of the input that it gets it keeps sliding the same learnable filter over the images. In the next Tutorial we will go deeper in the training of CNNs Next we will talk about RNNs which parameter share over time. Next you should to put everything together. The Rectified Linear Unit ReLU Activation Function Now let us incorporate ReLU into our previous model and visualize the output. While pooling does not reduce the number of parameters for a subsequent convolutional layer it does decreases the image size. We further divide the test set into a validation set and a test set 8000 and 2000 resp. Initially we don t know what the actual weight matrices are so we initialize them with some random values. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_3ef24bd7. py Great In this section you trained what may have been your very first CNN. ai animated explanation of feed forward neural network architecture you can find more animations Let s first see a sample training loop. Change the padding and stride and see how this affects the shape of the output. 1 Convolution of a Simple KernelAt its core convolution is just repeatedly multiplying a matrix known as a _kernel_ or _filter_ with some other larger matrix in our case the pixels of an image. The ReLU function is shown below. Here s an animation of backpropagation works. Make sure you remove all print statements from your convolution2d implementation or this will run for a _very_ long time. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_4df59f95. py Your network produced the correct output. the columns become rows and the rows become columns what would the kernel detect What would be produced by running this kernel on the vertical edge image above Student Response Click for solution https github. 3 PoolingConvolutional layers create feature maps that summarize the presence of particular features e. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_67c8514b. py Section 2 Convolutions and Edge Detection Time estimate 25mins Fundamental to CNNs are convolutions. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_82e644f4. Afterwards enter your results in the solution section in the code below. Note you must run the cell before you can use the sliders. This is like a very zoomed in vertical edge within an image As you can see this kernel detects vertical edges the black stripe corresponds to a highly positive result while the white stripe corresponds to a highly negative result. 3 Coding a ConvolutionHere we have the skeleton of a function that performs convolution using the provided image and kernel matrices. The more common definition involves flipping the kernel horizontally and vertically before sliding. ai chapter_convolutional neural networks conv layer. It is alwasy image kernel 1 Click for solution https github. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_ecc74cf8. very low output patterns. Both of these weight sharing techniques across space and time can reduce the number of parameters and increase a network s ability to generalize. The Num_Dense in this exercise is the number of dense layers we use in the network with each dense layer having the same input and output dimensions. Weight sharing is based on the idea that some sets of weights can be used at multiple points in a network. Execute this cell to view the filtered images Discuss with your pod how the ReLU activations help strengthen the features necessary to detect an X. In Avgpooling we compute the average value of all pixels in the pooling window. The kernel size is the length and width of this kernel. Pay special attention to the areas with very high vs. py Coming Up The rest of these lectures focus on another way to reduce parameters weight sharing. Load images run me Pretty cool right We will go into more detail on what s happening in the next section. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_a728d667. Take a minute with your pod and talk about which classes you think would be most confusable. Section 4 Putting it all together Time estimate 33mins Video 5 Putting it all together Section 4. In more general usage the no flip operation that we call convolution is known as _cross correlation_ hence the usage of scipy. Then we look at the training loop. Downsampling creates a lower resolution version of an image retaining the large structural elements and removing some of the fine detail that may be less relevant to the task. 3 Fashion MNIST datasetNow Let us train on the actual Fashion MNIST dataset. Conv2d in_channels 1 out_channels 32 kernel_size 3 Convolution nn. Linear in_features 9216 out_features 128 Fully Connected layer nn. 3 Implement MaxPooling Let us now implement MaxPooling in PyTorch and observe the effects of Pooling on the dimension of the input image. How does the padding need to be configured to maintain the shape of the input Run this cell to enable the widget Think 2. Larger images require that the linear layer use a matrix that can be directly multiplied with the input pixels. To improve performance we need to change the weight matrices so that the predicted outputs are similar to the true outputs labels. We will focus mostly on CNNs today where the weight sharing is across the 2D space of an image. This will give you a solid understanding of the different steps involved in the training loop. correlate2d in the next exercise. Take a moment with your pod to discuss what would make a good representation and how that might differ depending on the task you train your CNN to do. There are also 1D and 3D convolutions but we won t talk about them today. ", "id": "joseguzman/w2d1t1-cnns", "size": "34871", "language": "python", "html_url": "https://www.kaggle.com/code/joseguzman/w2d1t1-cnns", "git_url": "https://www.kaggle.com/code/joseguzman/w2d1t1-cnns", "script": "torch.optim torch.utils.data make_plots __init__ display seed_worker interactive make_grid IFrame ipywidgets plot_loss_accuracy on_button_clicked addBox Net(nn.Module) AirtableForm train plot DataLoader YouTubeVideo ImageFolder IPython FMNIST_Net2(nn.Module) correlate2d forward torch.nn numpy BiliVideo(IFrame) get_augmentation_transforms do_plot trange convolve2d download_data calculate_output_shape conv_check PIL check_conv_function interactive_output test EMNIST_Net(nn.Module) Image matplotlib.pyplot torchvision.datasets get_data_loaders tqdm.notebook interact interact_manual FMNIST_Net1(nn.Module) check_pooling_net Net2(nn.Module) set_seed check_shape_function widgets get_Xvs0_dataset display as IPyDisplay tqdm convolution2d display_image_from_greyscale_array torch.nn.functional plot_func evaltools.airtable fixed scipy.signal transforms_custom emnist_net(nn.Module) get_fashion_mnist_dataset TensorDataset Net3(nn.Module) set_device torchvision.utils reduce_classes IPython.display torchvision.transforms ", "entities": "(('you', 'manually convolution'), 'calculate') (('regularization', 'several forms'), 'recall') (('you', 'them'), 'Tip') (('You', 'L1 L2 Data such Augmentation'), 'introduce') (('output', 'size'), 'have') (('s', 'sample training first loop'), 'ai') (('pooling how much region', 'animation'), 'define') (('core convolution', 'image'), 'Convolution') (('example', '10 classes'), 'be') (('that', 'neural network'), 'contain') (('we', 'same input dimensions'), 'be') (('it', 'image'), 'convolve') (('equation textbf Kernel', 'solution https github'), 'begin') (('that', 'convolution'), 'take') (('input images', 'size'), 'recall') (('Now you', 'CNN'), 'go') (('you', 'list augmentation_transforms'), 'let') (('you', 'seed'), 'introduction') (('that', 'input directly pixels'), 'require') (('Now s', 'code'), 'note') (('We', '8000 resp'), 'divide') (('s', '32 convolutional layers'), 'let') (('it', 'images'), 'be') (('you', 'CNN'), 'take') (('that', 'systematically input'), 'fix') (('It', 'somewhere between 10 seconds'), 'take') (('real strength', 'linear non functions'), 'come') (('how changing', 'output'), '3') (('predicted outputs', 'outputs true labels'), 'improve') (('we', 'border'), 'want') (('Here code', 'dataset'), 's') (('pixels', '0'), 'display') (('why it', 'network'), 'add') (('that', 'PyTorch'), 'provide') (('now you', 'solution https github'), 'confusing') (('you', 'already convolution'), 'Run') (('you', 'Neural Network object'), 'define') (('You', 'CNN'), 'code') (('it', 'flattening'), 'mean') (('what', 'next section'), 'run') (('that', 'less task'), 'create') (('applied', 'them'), 'let') (('we', 'convolution net'), 'walk') (('CNNs Max Pooling', 'Average downsample'), 'use') (('T', '2min'), 'be') (('specific kernel', 'original image'), 'think') (('we', 'task'), 'Understand') (('what', 'section'), 'py') (('you', 'next cell'), 'dataset') (('we', 'pooling window'), 'compute') (('This', 'convolutional layer'), 'be') (('you', 'pod'), 'take') (('Edge detecting filters', 'CNN'), 'learn') (('which', 'results'), 'py') (('we', 'batch size'), 'want') (('MNIST dataset', 'handwritten digits'), 'recall') (('don certainly t', 'just neural networks'), 'estimate') (('that', 'model'), 'add') (('Detection 25mins Fundamental', 'CNNs'), 'estimate') (('We', 'next section'), 'talk') (('output shape how you', 'image size'), 'change') (('weight today where sharing', 'image'), 'focus') (('First we', 'dataset'), 'create') (('we', 'step'), 'visualize') (('efficient universal also ANNs', 'data'), 'Section') (('which', 'probability'), 'py') (('common approach', 'problem'), 'call') (('which', 'handwritten characters'), 'use') (('Therefore later dense layers', 'fewer parameters'), 'need') (('white stripe', 'highly negative result'), 'edge') (('convolution', 'products'), 'recall') (('lack', 'ability'), 'use') (('convolution', 'code'), 'be') (('which', '32'), 'in_features') (('that', 'where large color'), 'edge') (('sets', 'network'), 'base') (('data also how augmentation', 'network'), 'learn') (('Smola _ Dive', 'd2l'), 'http') (('NeuromatchAcademy course dl content tree main tutorials', 'solutions W2D1_Tutorial1_Solution_ae125a93'), 'com') (('kernel size', 'kernel'), 'be') (('output', 'pooling layer'), 'stop') (('bmatrix', 'kernel'), 'consider') (('this', '_'), 'make') (('where trace', 'edge'), 'observe') (('that', 'provided image matrices'), 'have') (('Here link', 'pytorch https available pytorch'), 's') (('py', 'parameters weight sharing'), 'focus') (('It', 'image solution https alwasy 1 github'), 'be') (('it', 'input image size increases'), 'run') (('you', '2'), 'be') (('where trace', 'edge'), 'be') (('NeuromatchAcademy course dl content tree main tutorials', 'solutions'), 'com') (('here you', 'padding'), 'Padding') (('which', 'convolution operation'), 'talk') (('ReLU how activations', 'necessary X.'), 'strengthen') (('Next you', 'everything'), 'should') (('Section', 'together Section'), 'put') (('it', 'image size'), 'reduce') (('MaxPool2d Finally operation', 'half to 12x12'), 'reduce') (('s', 'dataset'), 'run') (('convolutional filter', 'two dimensions'), 'call') (('point you', 'kernel'), 'have') (('you', 'such scipy'), 'numpy') (('we', 'CNN model'), 'be') (('weight random matrices', 'output'), 'give') (('which', 'Maxpool layer'), 'run') (('we', 'CNNs'), 'SummaryIn') (('training 1 loopNow', 'training loop'), 'get') (('how ReLU', 'activation funciton'), 'com') (('we', 'weights'), 'use') (('small changes', 'feature very different map'), 'mean') (('output', 'data'), 'run') (('second Conv2d', '24x24'), 'be') (('filter', 'convolution'), 'adjust') (('This', 'training loop'), 'give') (('that', 'features e.'), 'create') (('Here animation', 'backpropagation works'), 's') (('you', 'them'), 'want') (('we', 'single output'), 'produce') (('Note Dense layers', 'fully connected layers'), 'notice') (('us', 'input image'), 'let') (('more common definition', 'kernel'), 'involve') (('that', 'input entire image'), 'encourage') (('Now us', 'output'), 'let') (('It', 'test 10 000 examples'), 'consist') (('us', 'O image'), 'let') (('Video', 'training 7 own loop'), 'write') (('how it', 'output shape'), 'give') (('level important features', 'output'), 'despite') (('Below results', 'toy dataset simple a.'), 'be') (('we', 'weight matrices'), 'change') (('how filters', 'solution https github'), 'see') (('Today we', 'architecture'), 'talk') (('you', 'sliders'), 'note') (('we', 'stride'), 'change') (('Thus small change', 'output'), 'win') (('We', 'data'), 'function') (('parameter', 'time'), 'go') (('we', 'output'), 'know') (('You', 'again once sliders'), 'note') (('training when accuracy', 'solution https github'), 'run') (('which', 'side'), 'consider') (('probabilities', 'classes'), 'be') (('gradients', 'weight matrices'), 'call') (('NeuromatchAcademy course dl content tree main tutorials', 'solutions W2D1_Tutorial1_Solution_4df59f95'), 'com') (('we', 'section'), 'py') (('training curves', 'then what'), 'train') (('Also we', 'own CNN'), 'learn') (('general kernel', 'dense network'), 'be') (('you', 'resulting network'), 'function') (('Run', 'widget'), 'need') (('We', '_ invariance translational _'), 'be') (('you', 'then loss'), 'run') (('that', 'input'), 'perform') (('we', 'all'), 'implement') (('where relationship', 'input'), 'have') (('also 1D we', 'them'), 'be') (('What', 'solution https github'), 'become') (('NeuromatchAcademy course dl content tree main tutorials', 'solutions W2D1_Tutorial1_Solution_906c34b2'), 'com') (('also model', 'huge chunks'), 'bring') (('sfb', 'ReLU'), 'question') (('how results', 'whole dataset'), 'provide') (('block', 'single kernel'), 'be') (('we', 'scipy'), 'know') (('here we', 'dataset'), 'notice') (('so we', 'random values'), 'know') (('us', 'Fashion MNIST actual dataset'), 'let') (('Then we', 'X'), 'train') (('which', 'time'), 'touch') (('alone model', 'solution https github'), '2') (('two that', 'accuracy c.'), 'be') (('Example', 'pooling window'), 'give') (('py network', 'correct output'), 'produce') (('you', 'other dropout'), 're') (('So you', 'regularization last week techniques'), 'py') (('that', 'dataset'), 'simplify') (('then we', 'weight matrices'), 'call') (('Both', 'ability'), 'reduce') (('correct criterion', 'running loss i.'), 'choose') (('we', 'other domains'), 'be') (('You', 'it'), 'test') (('when you', 'regularization'), 'introduction') (('How it', 'shirts Video'), 'be') (('first how far away predicted outputs', 'loss function'), 'calculate') (('that', 'image'), 'introduce') (('just kernel', 'flipping'), 'assume') (('you', 'missing code'), 'NOTE') (('that', 'image'), 'be') (('that', 'weights'), 'add') (('We', 'images'), 'apply') (('validation Why accuracy', 'solution https github'), 'start') (('that', 'overfitting'), 'want') (('convolution how operation', 'various images'), 'lean') (('you', 'loss'), 'have') (('also how representations', 'NN'), 'consider') (('outputs predictions', 'only chance'), 'match') (('pooling layer', 'that'), 'note') (('example', 'pooling output red matrix'), 'show') (('more translationally which', 'better subsequent layers'), 'shrink') (('We', 'you'), 'do') (('how this', 'output'), 'change') (('regularization RegularizationAdd various methods', 'solution https github'), '1') (('applied', 'them'), 'look') (('we', 'predefined functions'), 'write') ", "extra": "['negative result', 'test', 'bag']"}
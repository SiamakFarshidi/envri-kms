{"name": "ieee cancer detection ", "full_name": " h1 Import the necessary libraries and load the data h1 Load the data and explore a few images ", "stargazers_count": 0, "forks_count": 0, "description": "Image type convert PIL. linear algebra data processing CSV file I O e. At the end I run the outputs through a fully connected layer to get the probabilities. Image type to 3D tensor with shape 150 150 3 convert 3D tensor to 4D tensor with shape 1 150 150 3 and return 4D tensor. Now I ll run the CNN itself. read_csv deal with paths deal with paths deal with images read images from files make plots pretty plots P get unique cell types get the first row containing an image of cell_type cell list containing one image of each type create the subplots show the images and label them loads RGB image as PIL. The architecture will be 3 Conv2D Dropout Maxpooling 4 times followed by a global maxpooling. Import the necessary libraries and load the data Load the data and explore a few imagesThis step was done using Kevin s notebook https www. com kmader histology mnist loading and processing data methods. ", "id": "ibrahimshamma/ieee-cancer-detection", "size": "437", "language": "python", "html_url": "https://www.kaggle.com/code/ibrahimshamma/ieee-cancer-detection", "git_url": "https://www.kaggle.com/code/ibrahimshamma/ieee-cancer-detection", "script": "Flatten glob randint LabelBinarizer keras.layers keras.callbacks GlobalAveragePooling2D random np_utils Dropout EarlyStopping Sequential Conv2D seaborn numpy paths_to_tensor PIL ModelCheckpoint sklearn.model_selection imread #read images from files image matplotlib.pyplot ImageFile path_to_tensor Dense keras.utils tensorflow pandas GlobalMaxPooling2D set_random_seed tqdm glob #deal with paths keras.preprocessing MaxPooling2D sklearn.preprocessing keras.models train_test_split get_first_cell_images skimage.io ", "entities": "(('subplots', 'PIL'), 'deal') (('Image type', '1 150 150 3 4D tensor'), 'convert') (('architecture', 'Dropout 4 times global maxpooling'), 'be') (('I', 'probabilities'), 'run') (('a few step', 'notebook https www'), 'import') ", "extra": "[]"}
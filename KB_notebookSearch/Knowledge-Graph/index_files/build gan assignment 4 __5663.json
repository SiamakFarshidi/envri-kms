{"name": "build gan assignment 4 ", "full_name": " h1 Build a Conditional GAN h3 Goals h3 Learning Objectives h2 Getting Started h4 Packages and Visualization h4 Generator and Noise h4 Discriminator h2 Class Input h2 Training h2 Exploration h4 Changing the Class Vector h4 Changing the Noise Vector ", "stargazers_count": 0, "forks_count": 0, "description": "TrainingNow you can start to put it all together First you will define some new parameters mnist_shape the number of pixels in each MNIST image which has dimensions 28 x 28 and one channel because it s black and white so 1 x 28 x 28 n_classes the number of classes in MNIST 10 since there are the digits from 0 to 9 And you also include the same parameters from previous assignments criterion the loss function n_epochs the number of times you iterate through the entire dataset when training z_dim the dimension of the noise vector display_step how often to display visualize the images batch_size the number of images per forward backward pass lr the learning rate device the device typeThen you can initialize your generator discriminator and optimizers. Packages and Visualization Generator and Noise Discriminator Class InputIn conditional GANs the input vector for the generator will also need to include the class information. Optional hints for combine_vectors1. one_hot https pytorch. Optional hints for get_one_hot_labels1. You ll then do some exploration of the generated images to visualize what the noise and class vectors mean. If the discriminator is told it should be looking at a 1 but sees something that s clearly an 8 it can guess that it s probably fakeThere are no explicit unit tests here if this block of code runs and you don t change any of the other variables then you ve done it correctly ExplorationYou can do a bit of exploration now Changing the Class VectorYou can generate some numbers with your new model You can add interpolation as well to make it more interesting. For the discriminator you need to add a channel for every class. Set for our testing purposes please do not change Build the neural network UNQ_C1 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED FUNCTION get_one_hot_labels UNQ_C2 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED FUNCTION combine_vectors Note Make sure this function outputs a float no matter what inputs it receives UNQ_C3 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED FUNCTION get_input_dimensions UNQ_C4 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL UNIT TEST NOTE Initializations needed for grading Dataloader returns the batches and the labels Flatten the batch of real images from the dataset Zero out the discriminator gradients Get noise corresponding to the current batch_size Now you can get the images from the generator Steps 1 Combine the noise vectors and the one hot labels for the generator 2 Generate the conditioned fake images Make sure that enough images were generated Now you can get the predictions from the discriminator Steps 1 Create the input for the discriminator a Combine the fake images with image_one_hot_labels remember to detach the generator. You will begin by importing the necessary libraries and building the generator and discriminator. The class is represented using a one hot encoded vector where its length is the number of classes and each index represents a class. Your re basically morphing one image into another. The vector is all 0 s and a 1 on the chosen class. Changing the Noise VectorNow what happens if you hold the class constant but instead you change the noise vector You can also interpolate the noise vector and generate an image at each step. The generator will no longer take z_dim as an argument but input_dim instead since you need to pass in both the noise and class vectors. Given the labels of multiple images e. So starting from a image you will produce intermediate images that look more and more like the ending image until you get to the final image. The documentation for torch. This code can be done in one line. one_hot may be helpful. Understand the distinction between the class and noise vector in a conditional GAN. To do this you will need to update the input dimensions for both models. Tell that to the discriminator so that it knows it should be looking at a 1. Specifically you might want to look at what the dim argument of torch. You will also need to do this when adding the class channels to the discriminator. Remember that you need to ensure that the vectors are the same type floats. Build a Conditional GAN GoalsIn this notebook you re going to make a conditional GAN in order to generate hand written images of digits conditioned on the digit to be generated the class vector. Again you can look to the PyTorch library for help. Note that this assignment requires no changes to the architectures of the generator or discriminator only changes to the data passed to both. Tell that to the generator so that it knows it should be generating a 1 2. from a batch and number of classes please create one hot vectors for each label. To do this you will need to write a function that combines two vectors. detach so you do not backpropagate through it b Combine the real images with image_one_hot_labels 2 Get the discriminator s prediction on the fakes as disc_fake_pred 3 Get the discriminator s prediction on the reals as disc_real_pred Make sure that enough predictions were made Make sure that the inputs are different Keep track of the average discriminator loss Zero out the generator gradients This will error if you didn t concatenate your labels to your image correctly Keep track of the generator losses Before you explore you should put the generator in eval mode both in general and so that batch norm doesn t cause you issues and is using its eval statistics Choose the interpolation how many intermediate images you want 2 for the start and end image Calculate the interpolation vector between the two labels Combine the noise and the labels Choose the start digit Choose the end digit How many intermediate images you want 2 for the start and end image This time you re interpolating between the noise instead of the labels This time you re interpolating between the noise instead of the labels Combine the noise and the labels again Generate noise vectors to interpolate between Choose the number of noise examples in the grid. This will let you choose what digit you want to generate. Next you need to be able to concatenate the one hot class vector to the noise vector before giving it to the generator. The documentation for F. This code can also be written in one line. In addition to good variable naming this also means that you can use the generator and discriminator code you have previously written with different parameters. Now to train you would like both your generator and your discriminator to know what class of image should be generated. For the generator you will need to calculate the size of the input vector recall that for conditional GANs the generator s input is the noise vector concatenated with the class vector. There is a class within the PyTorch functional library that can help you. Getting StartedFor this assignment you will be using the MNIST dataset again but there s nothing stopping you from applying this generator code to produce images of animals conditioned on the species or pictures of faces conditioned on facial characteristics. For example if you re generating a picture of the number 1 you would need to 1. Learn the technical difference between a conditional and unconditional GAN. You can choose what these two images will be using your conditional GAN. There are a few locations where you will need to implement code. Learning Objectives1. org docs master generated torch. ", "id": "amoghjrules/build-gan-assignment-4", "size": "5663", "language": "python", "html_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-4", "git_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-4", "script": "torch.utils.data __init__ torch make_grid Discriminator(nn.Module) tqdm.auto show_tensor_images DataLoader interpolate_noise interpolate_class forward test_input_dims torchvision nn combine_vectors matplotlib.pyplot torchvision.datasets get_noise make_disc_block MNIST tqdm Generator(nn.Module) weights_init torch.nn.functional get_one_hot_labels transforms torchvision.utils make_gen_block get_input_dimensions ", "entities": "(('you', 'models'), 'need') (('that', 'you'), 'be') (('you', 'digit'), 'let') (('you', 'final image'), 'produce') (('that', 'two vectors'), 'need') (('index', 'class'), 'represent') (('code', 'also one line'), 'write') (('Your', 'another'), 'morph') (('class', 'image'), 'train') (('input', 'noise class vector'), 'need') (('Packages', 'class also information'), 'need') (('vector', 'all 0 chosen class'), 'be') (('Combine', 'generator'), 'change') (('Specifically you', 'torch'), 'want') (('you', 'class'), 'need') (('you', 'previously different parameters'), 'mean') (('Again you', 'help'), 'look') (('it', '1'), 'tell') (('noise', 'what'), 'do') (('as well it', 'interpolation'), 'guess') (('instead you', 'noise'), 'take') (('You', 'step'), 'change') (('Next you', 'generator'), 'need') (('two images', 'conditional GAN'), 'choose') (('1 you', '1'), 'need') (('it', '1 2'), 'tell') (('instead time you', 'grid'), 'detach') (('assignment you', 'facial characteristics'), 'get') (('You', 'discriminator'), 'need') (('assignment', 'both'), 'note') (('You', 'generator'), 'begin') (('you', 'class vector'), 'build') (('typeThen you', 'generator discriminator'), 'start') (('a few where you', 'code'), 'be') ", "extra": "['test']"}
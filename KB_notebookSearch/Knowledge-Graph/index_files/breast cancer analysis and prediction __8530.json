{"name": "breast cancer analysis and prediction ", "full_name": " h1 Breast Cancer Analysis and Prediction h1 1 Load libraries and read the data h2 1 1 Load libraries h2 1 2 Read the data h2 1 3 Missing values h2 1 4 Reassign target and drop useless features h1 2 Exploratory Data Analysis EDA h2 2 1 Head and describe h2 2 2 Target distribution number and h2 2 3 Features distribution hue diagnosis h2 2 4 Correlation matrix h2 2 5 Positive correlated features h2 2 6 Uncorrelated features h2 2 7 Negative correlated features h1 3 Principal Component Analysis h2 3 1 Compute PCA h2 3 2 PCA pie plot with 6 components 88 8 h2 3 3 PCA scatter plot with 2 components 63 3 h2 3 4 PCA scatter plot with 3 components 72 7 h1 4 Define functions h2 4 1 Confusion matrix and show metrics h2 4 2 Precision Recall curve h2 4 3 ROC curve h2 4 4 Learning curve h1 5 Prepare dataset h2 5 1 Define X y h2 5 2 Standard scaler X h2 5 3 Train test split h2 6 1 Logistic Regression and GridSearch CV to optimise hyperparameters accuracy h2 6 2 RFE Recursive features elimination 30 features 15 features h2 6 3 Compare learning curves and cross validation scores h2 6 4 Select threshold for a recall 100 all malignant tumors detected h2 6 5 Predicting with recall 100 h2 7 1 Logistic Regression and GridSearch CV to optimise hyperparameters recall h2 7 2 Voting classifier log log2 h2 7 4 Voting classifier predicting with recall 100 precision 92 h2 7 5 Models performance plot accuracy precision recall ", "stargazers_count": 0, "forks_count": 0, "description": "Uncorrelated features 2. Correlation matrix 2. Logistic Regression and GridSearch CV to optimise hyperparameters recall 7. ROC curveThe ROC curve is created by plotting the true positive rate TPR against the false positive rate FPR at various threshold settings. RFE Recursive features elimination 30 features 15 features Recursive feature elimination RFE is a feature selection method that fits a model and removes the weakest feature or features until the specified number of features is reached. 4 with a standard deviation of 0. Predicting with recall 100 With 2 models we can increase the precision while keeping a recall 100 7. Prepare dataset 5. Predictive model Logistic Regression 6. ID number Diagnosis M malignant B benign Ten real valued features are computed for each cell nucleus radius mean of distances from center to points on the perimeter texture standard deviation of gray scale values perimeter area smoothness local variation in radius lengths compactness perimeter 2 area 1. Compare learning curves and cross validation scores With only 15 features and 5 folds we got an accuracy of 97. 5 plot_distribution concave points_mean. edu ml datasets Breast Cancer Wisconsin 28Diagnostic 29 Features are computed from a digitized image of a fine needle aspirate FNA of a breast mass. They describe characteristics of the cell nuclei present in the image. Missing values 1. Select threshold for a recall 100 all malignant tumors detected 6. Correlation matrixLet s check the correlation between few features by pair 2. Learning curve 4. 5 plot_distribution symmetry_mean. Voting classifier predicting with recall 100 precision 92 7. PCA scatter plot with 3 components 72. Standard scaler X Why do you need to standardize your data For example a variable that ranges between 0 and 100 will outweigh a variable that ranges between 0 and 1. 5 plot_distribution concavity_mean. ROC curve Precision recall curve. Missing valuesAll features are complete only Unnamed 32 is completely null probably an error in the dataset we drop it in below 1. Features distribution hue diagnosis Bellow you can remove the to show all features distribution except the first line 2. Cross validation metrics 5. Define functionsThis part is essential to measure the performance of a model roc cross validation learning curve. Exploratory Data Analysis EDA 2. Train test split 6. Compare learning curves and cross validation scores 6. Breast Cancer Analysis and Prediction Recall 1. Define X y 5. Logistic Regression and GridSearch CV to optimise hyperparameters accuracy 6. Precision Recall curveThe precision recall curve shows the tradeoff between precision and recall for different threshold 4. To follow we don t use the selector the log cfl is most performant but the code is here for you 6. PCA scatter plot with 2 components 63. Cross validation metricsCross validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model and a test set to evaluate it. Positive correlated features 2. Read the data 1. Precision Recall curve 4. Confusion matrix and show metrics 4. Models performance plot accuracy precision recall Thank you all Merci \u00e0 tous Python libraries ignore warning messages Read data Drop useless variables Reassign target Head describe 2 datasets COUNT PERCENTAGE plot distribution mean plot_distribution compactness_mean. Features are ranked by the model s coef_ or feature_importances_ 6. Load libraries and read the data 1. com gpreda for sharing his incredible knowledge Special note 2 Thanks Pavan Raj https www. RFE Recursive features elimination 30 features 15 features 6. Head and describe 2. Target distribution number and 2. Predictive model 2 Ensemble Classifier to maximise precision and detect all malignant tumors 7. Predicting with recall 100 7. 5 plot distribution se plot distribution worst tick labels convert to array seaborn version Plot seaborn version seaborn version To make a PCA normalize data is essential SUM AND DROP COMP 7 30 Confusion matrix Show metrics Precision recall curve ROC curve plt. Load libraries 1. Voting classifier log log2 7. 0 concavity severity of concave portions of the contour concave points number of concave portions of the contour symmetry fractal dimension coastline approximation 1 Special note Thanks Gabriel Preda https www. Define X y y diagnosis target X features radius_mean area_se. Reassign target and drop useless features 2. Learning curveThe Learning curve determines cross validated training and test scores. Logistic Regression and GridSearch CV to optimise hyperparameters recall Grid search CV accuracy penalty l2 Grid search CV recall penalty l1 7. Find the best parameters recall Log w best hyperparameters recall Confusion maxtrix metrics Cross val log2 Voting Classifier Confusion maxtrix Cross val score voting Learning curve Voting Threshold Ensemble recall 1. Models performance plot accuracy precision recall Information here https archive. Confusion matrix and show metricsThe confusion matrix also known as the error matrix allows visualization of the performance of an algorithm true positive TP Malignant tumour correctly identified as malignant true negative TN Benign tumour correctly identified as benign false positive FP Benign tumour incorrectly identified as malignant false negative FN Malignant tumour incorrectly identified as benignMetrics Accuracy TP TN TP TN FP FN Precision TP TP FP Recall TP TP FN 4. Using these variables without standardization in effect gives the variable with the larger range a bigger weight in the analysis 5. Define functions 4. Select threshold for a recall 100 all malignant tumors detected For this study the most important is to detect all malignants tumours. 971 Vincent Lugat September 2018 1. Features distribution hue diagnosis 2. PCA pie plot with 6 components 88. Negative correlated features 3. Standard scaler X 5. Voting classifier select threshold recall 100 7. com pavanraj159 the plotly master 1. 05 Learning curve Cross val metric Def X and Y Normalization Train_test split Find best hyperparameters accuracy Log with best hyperparameters Confusion maxtrix metrics ROC curve Logistic regression with RFE Confusion maxtrix metrics ROC curve support and ranking RFE Learning curve Log with best hyperpara Learning curve Log with RFE Cross val Log Cross val Log with RFE Threshold Recall 1. 5 plot_distribution fractal_dimension_mean. Principal Component Analysis 3. ", "id": "vincentlugat/breast-cancer-analysis-and-prediction", "size": "8530", "language": "python", "html_url": "https://www.kaggle.com/code/vincentlugat/breast-cancer-analysis-and-prediction", "git_url": "https://www.kaggle.com/code/vincentlugat/breast-cancer-analysis-and-prediction", "script": "sklearn.metrics PCA cross_val_score plotly.offline plot_roc chain plot_learning_curve recall_score precision_score itertools cross_val_metrics plot_feat1_feat2 show_metrics seaborn numpy plotly.graph_objs plot_confusion_matrix learning_curve sklearn.decomposition plot_precision_recall VotingClassifier sklearn.ensemble sklearn.model_selection confusion_matrix plotly.tools pca_scatter matplotlib.pyplot RFE pandas StandardScaler LogisticRegression accuracy_score sklearn.feature_selection plot_distribution precision_recall_curve GridSearchCV sklearn.linear_model sklearn.preprocessing roc_curve train_test_split plotly.figure_factory ", "entities": "(('RFE Recursive', '15 features'), 'feature') (('Precision Recall curveThe precision recall curve', 'different threshold'), 'show') (('Logistic Regression', 'GridSearch optimise 7'), 'recall') (('we', '100 7'), 'predict') (('Features', 'coef _'), 'rank') (('determines', 'validated training'), 'cross') (('5 we', '97'), 'get') (('Define y diagnosis X', 'radius_mean area_se'), 'y') (('plot_distribution compactness_mean', 'Reassign 2 datasets'), 'thank') (('Voting classifier', 'threshold recall'), 'select') (('100 malignant tumors', '6'), 'threshold') (('metricsThe confusion matrix', 'benignMetrics Accuracy TP TN TP TN FP FN Precision TP TP FP Recall TP TP incorrectly FN'), 'allow') (('ROC curveThe ROC curve', 'threshold various settings'), 'create') (('most important', 'study'), 'threshold') (('we', '1'), 'be') (('concavity 0 severity', 'fractal dimension coastline contour symmetry approximation'), 'note') (('specified number', 'features'), 'feature') (('Voting Classifier Confusion maxtrix val Cross score', 'Learning Voting Threshold'), 'find') (('Using', 'bigger analysis'), 'give') (('They', 'present image'), 'describe') (('curve Logistic regression', 'RFE Threshold Recall'), '05') (('that', '0'), 'scaler') (('Correlation matrixLet', 'pair'), 'check') (('Cross validation metricsCross validation', 'it'), 'be') (('PCA normalize data', 'version Plot seaborn seaborn version'), 'convert') (('part', 'roc cross validation learning model curve'), 'be') (('most code', 'here you'), 'use') (('Diagnosis malignant B benign Ten real valued features', 'radius lengths'), 'compute') (('all', 'first line'), 'remove') (('Logistic Regression', 'Grid CV accuracy search penalty'), 'recall') (('28Diagnostic 29 Features', 'breast mass'), 'dataset') ", "extra": "['biopsy of the greater curvature', 'test', 'diagnosis']"}
{"name": "qa integrated biomedical ner classifier for pico ", "full_name": " h1 Intro h2 My previous work as basis for this notebook h2 Contribution to CORD 19 h3 TL DR Merge existing NER biomedical and reading comprehension general topic data Get a high performing specialised population health condition and outcome classifier with general reading comprehension ability Also aim is to present data interactively and in a meaningful way h1 Teaser Results h2 Example for an interactive plot on diseases and symptoms connected with COVID 19 h2 Example 2 for an interactive plot on medical care h1 Methods h1 The training data h1 Aim h1 Creating the training testing and prediction data h3 Step 1 Familiarise myself with the SQuAD data format json file and adapt the corpus h1 Fine tune a Question answering model on the newly created training data h1 Convert the CORD 19 data into a format that we can feed to the network h1 Predict on CORD data ", "stargazers_count": 0, "forks_count": 0, "description": "Integrated existing corpora of annotated biomedical entities 5000 abstracts annotated with data of interest to many CORD 19 challenges 2. Since 2005 a significant amount of research already focused on mining this type of information. Above we can see that the raw results from the data mining are not a bad starting point. When sorted by frequency count pneumonia comes up as the top health condition which is sadly also true in the real world. This is how systematic reviewing works and what medical researchers are going to expect if they ever use a tool like this one. Described a process of enriching NER data through the Squad corpus and to describe how this boosts the results Contribution to CORD 19 1. N amount of Original SQuAD domains eg 200 are randomly selected and shuffeled in between my adapted ebm nlp training data. Get a high performing specialised population health condition and outcome classifier with general reading comprehension ability. The resulting top 5 health conditions show for example that cancer and lung cancer have been grouped All in all this step reduces 566 unique descriptions of health conditions to 291 clusters and in the resulting data frame we see that for example pneumonia ncp and severe covid 19 pneumonia get grouped and that type 2 diabetes is now part of the diabetes cluster. NB of course I don t use any additional SQuAD domains in the evaluation data because I want my results to be comparable with other architectures trained on the basis of the same data. ipynbAs this is a bit resource intensive all fine tuned weights are aviailable here TODO upload to kaggle Convert the CORD 19 data into a format that we can feed to the network Predict on CORD dataThis is essentially a repetition ofthe fine tuning step just that one now removes the do train parameter in the colab file and selects a previous trained model as input to compute the predictions There are cells in the COLAB file that do and explain this and I hope to acutally include the colab script in this Kaggle notebook once I figure out how to do this Each CORD task will have its own notebook where I will go more into detail and show more data and more visualisations. Also aim is to present data interactively and in a meaningful way. The plot is interactive and on hover shows some more detailled information about the mined health problem as well as the cluster it was assigned to More detailed explanation of the code will be added in each single task submission. com annotations About merging it with SquAD I did not even use the whole SQuAD data because its just too much training data and my GPU access is limited image. After fine tuning all tuned weights will be saved in the outputs folder. But there are a lot of duplicates here. io SQuAD explorer 3 https huggingface. NB I will use my own fork of this repo but I still download the pretrained models from them. The Colab script can be found here https github. I did not even train models on most tasks But it is possible with the code in this notebook my GIT The corpus has age group samle size pharma vs non pharma and outcome types such as mortality or different adverse events annotated https ebm nlp. png Teaser Results Example for an interactive plot on diseases and symptoms connected with COVID 19 Question for each epidemiological study Patients with which medical conditions were included This is a small teaser showing mined medical conditions and probable corona related diseases in the dataset. And even more obvious I use the ebm nlp expert annotated held out abstracts for evaluation. png attachment image. 2 data for general reading comprehension in question answering we will use random parts of the corpus at most 200 domains 2. Methods The training data 1 5000 entity annotated abstracts of medical clinical trials 1. Example 2 for an interactive plot on medical care Question for each epidemiological study What was the intervention given to the participants This is another small teaser showing my mined medical interventions in the dataset. com annotations 2 https rajpurkar. The plot is interactive and on hover shows some more detailled information about the mined procedure as well as the cluster it was assigned to More detailed explanation of the code will be added in each task submission. Creating the training testing and prediction data Step 1 Familiarise myself with the SQuAD data format json file and adapt the corpus SQuAD consists of domains namely a whole Wikipedia article as one domain PURPLE in the picture below Each domain has some question contexts something like a paragraph of text YELLOW Questions about the text potentially multiple questions about the same paragraph BLUE Span annotations of where the labelled answer is OR if there is no answer a boolean to indicate that GREENWhen I adapt the ebm nlp corpus abstracts become domains purple sentences become question contexts yellow entity types become questions I created a list of questions that aim to comprehensively ask for entity types examples below sentences with labelled entities become proper span answers and sentences without entity become impossible answers NB depending on entity type it is worth considering under sampling some of the impossible answers in order to boost recall I am a systematic reviewer turned data scientist so I really care about recall most ie retrieving ALL entities and F1 second. 3 Jumping on the Transformer train we can use basically any pre trained architecture capable of performing the SQuAD task implemented by Huggingface s Transformers 3. com L ENA CORD19scripts blob master CORD_mining. co ultimately it d be great to use any other NER dataset in the following architecture Aim We will harness BERTs or XL Net or ANY transformers power of domain adaptation and transfer learning to extract entities from any epidemiological study on COVID. Transformed the baseline task of extracting entities into a Question Answering task in order to utilise further general reading comprehension data from the SQuAD corpus I did evaluated published these models early February. Below I am doing some post processing and clustering on the data. Trying to provide a framework that allows to integrate all available training data over time TL DR Merge existing NER biomedical and reading comprehension general topic data. When doing this one simply needs to upload their training and evaluation files created in the previous step save them in a google drive and point the script to the right folder. My previous work as basis for this notebook 1. This will be explained in more detail in my task specific submissions. png Intro Population Intervention Comparator and Outcomes PICO are key parts of medical systematic or rapid reviews of literature. PNG attachment SquadArchi. PNG eg asking for study population I compiled these options quests Who was treated What were the criteria for enrollment What were the inclusion criteria Who was enrolled in the study What were participants diagnosed with Which participants took part in the study Fine tune a Question answering model on the newly created training dataThen I use the Transformers library mentioned above and to fine tune my own Frankenstein NER QA modelsWith a bit of work on my own fork of Transformers I can display evaluation results as needed e. Using some pre Covid 19 training data and fine tuned neural networks I will show how my system can be used now in order to support evidence synthesis. Applying the aforementioned models to abstracts in the CORD dataset2. Processing the results deriving interactive plots trends between different versions of the dataset word clouds. Following is a short overview and some code on how to merge the datasets and what the final architecture looks like on a super high level. per class recall scores in order to adjust undersampling rate of my training dataFor fine tuning itself I use Googe Colab whith the GPU option enabled. ", "id": "lenaschmidt0493/qa-integrated-biomedical-ner-classifier-for-pico", "size": "8466", "language": "python", "html_url": "https://www.kaggle.com/code/lenaschmidt0493/qa-integrated-biomedical-ner-classifier-for-pico", "git_url": "https://www.kaggle.com/code/lenaschmidt0493/qa-integrated-biomedical-ner-classifier-for-pico", "script": "defaultdict glob display collections nltk.tokenize numpy make_train_test interactive_plots CORD19scripts pandas covid_input sent_tokenize Counter tqdm IPython.display HTML ", "entities": "(('we', 'most 200 domains'), 'use') (('how this', 'CORD'), 'describe') (('corpus', 'outcome such mortality'), 'train') (('how system', 'evidence synthesis'), 'use') (('amount', 'nlp training 200 randomly adapted ebm data'), 'select') (('fine tuned weights', 'outputs folder'), 'save') (('Colab script', 'https here github'), 'find') (('we', 'Huggingface Transformers'), 'use') (('png Intro Population Intervention Comparator', 'literature'), 'be') (('it', 'task single submission'), 'be') (('training just too much data', 'SQuAD even whole data'), 'com') (('results', 'same data'), 'use') (('that', 'time'), 'try') (('raw results', 'data mining'), 'see') (('it', 'task submission'), 'be') (('GPU option', 'Googe Colab'), 'per') (('significant amount', 'information'), 'focus') (('This', 'dataset'), 'example') (('I', 'needed e.'), 'ask') (('type 2 diabetes', 'diabetes now cluster'), 'reduce') (('This', 'probable corona related dataset'), 'result') (('training data', 'medical clinical trials'), 'method') (('Also aim', 'interactively meaningful way'), 'be') (('I', 'them'), 'use') (('data systematic so I', 'most ie entities'), 'consist') (('Aim We', 'COVID'), 'be') (('Below I', 'data'), 'do') (('even more I', 'evaluation'), 'use') (('which', 'sadly also real world'), 'come') (('I', 'models'), 'publish') (('where I', 'more data'), 'ipynbas') (('This', 'task specific submissions'), 'explain') (('final architecture', 'super high level'), 'be') (('they', 'one'), 'be') ", "extra": "['annotation', 'disease', 'outcome', 'patient', 'test', 'lung', 'lung cancer', 'procedure']"}
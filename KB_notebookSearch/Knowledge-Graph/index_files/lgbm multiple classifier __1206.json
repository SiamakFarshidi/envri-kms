{"name": "lgbm multiple classifier ", "full_name": " h3 v12 fix bug h3 v11 drop more features based on feature importances h3 v10 drop some features based on feature importances h3 v9 add feature importance plot h3 v8 add comments h3 v7 0 01387 h2 Feature engineering h2 categorical h2 Dense h2 Divide features into groups h2 Model h2 Prediction ", "stargazers_count": 0, "forks_count": 0, "description": "01387I simply replace my neural network model with lgbm model from https www. For example 1 2 3 4 5 label 1 6 7 8 9 10 label 2 etc. And I slide the smoothing window and train each LGBMClassifier. sort_values by X. v12 fix bug v11 drop more features based on feature importances v10 drop some features based on feature importances v9 add feature importance plot v8 add comments v7 0. astype object train Week_ob train Week. hstack test_dense_game test_dense dense_player_features test_dense IsRusher 0 test_cat_game np. Third model 3 4 5 6 7 label 1 8 9 10 11 12 label 2 etc. Finaly I calculate the ensemble of predictions of these multiple LGBMClassifiers. hstack train_cat_game train_cat cat_player_features train_dense IsRusher 0 with rusher player feature print print test have unseen label col print not nan in train col print nan seen in train col test_dense_game np. Target Yard of lgbm is smoothened and fed to LGBMClassifier. astype object train TimeDelta_ob train TimeDelta. Feature engineering categorical Dense Divide features into groups Model Prediction train train 2200 https www. Second model 2 3 4 5 6 label 1 7 8 9 10 11 label 2 etc. hstack test_cat_game test_cat cat_player_features test_dense IsRusher 0. reset_index drop True drop_cols DefensePersonnel OffensePersonnel train_dense_game np. com mrkmakr neural network with mae objective 0 01385Some feature engineerings standerize categorical version of numeric feature used in this kernel are not suitable to lgbm. For example First model 1 2 3 4 5 label 1 6 7 8 9 10 label 2 etc. sort_values by Dis. astype object train train. com rooshroosh fork of neural networks different architecture train DefendersInTheBox_ob train DefendersInTheBox. hstack train_dense_game train_dense dense_player_features train_dense IsRusher 0 with rusher player feature train_cat_game np. sort_values by PlayId Team IsRusher. I just use almost the same features used in the above kernelIn this kernel I use the multiple LGBMClassifiers. ", "id": "mrkmakr/lgbm-multiple-classifier", "size": "1206", "language": "python", "html_url": "https://www.kaggle.com/code/mrkmakr/lgbm-multiple-classifier", "git_url": "https://www.kaggle.com/code/mrkmakr/lgbm-multiple-classifier", "script": "__init__ lightgbm tqdm_notebook predict OffensePersonnelSplit preprocess kaggle.competitions seaborn numpy RandomForestRegressor return_step _get_pred199 sklearn.ensemble orientation_to_cat sklearn.model_selection LabelEncoder KFold strtoseconds DefensePersonnelSplit matplotlib.pyplot pandas map_weather make_pred strtofloat StandardScaler LGBMClassifier fit tqdm MultiLGBMClassifier() nflrush get_pred199 matplotlib sklearn.preprocessing drop train_test_split ", "entities": "(('Feature categorical Dense engineering Divide', 'Model Prediction train train'), 'feature') (('architecture different DefendersInTheBox_ob', 'neural networks'), 'com') (('01387I', 'https www'), 'replace') (('Second model', '10 2 3 4 6 1 7 11 2 etc'), 'label') (('Target Yard', 'LGBMClassifier'), 'smoothen') (('kernel I', 'multiple LGBMClassifiers'), 'use') (('I', 'LGBMClassifier'), 'slide') (('1 2', '9 3 5 1 6 label 2 etc'), 'label') (('nan', 'train col'), 'train_cat_game') (('v8', 'comments v7'), 'drop') (('Finaly I', 'multiple LGBMClassifiers'), 'calculate') (('feature 0 engineerings', 'lgbm'), 'standerize') ", "extra": "['test']"}
{"name": "cervix eda model selection ", "full_name": " h1 Cervix EDA h2 Image types h2 Image dimensions h1 TSNE embedding h3 3D t SNE with cervix indicators h1 Image clustering with TSNE embedding h1 Clustering of pairwise image distances h1 Image neighbourhood h1 Model Selection h2 Confusion matrix h2 Confusion matrix on training set ", "stargazers_count": 0, "forks_count": 0, "description": "In this notebook we will be looking at basic dataset stats like number of samples per class image sizes different embeddings of RGB image space pairwise distances and a clustermap of images in RGB space linear model selection with basic multi class evaluation metrics. Let us first see how many images there are for each cervix type and which file types they have. The yellow somewhat clustered area tells us there are a few images that have relatively high distance to all other images in the sample of our training images we read. Per default each image will now keep its RGB information and therefore will be transformed to a 100 100 3 30. Also we are giving only very few images per class that TSNE can work with to find a good distance preserving embedding. Image neighbourhoodGiven the pool of cervix images and the similarity matrix above we will now plot the extrem cases of the similarity matrix. normalize each uint8 image to the value interval 0 1 as float image rgb to gray downsample image to rescaled_dim X rescaled_dim L2 norm of each sample 1 pca translate each sample to its color upper triangle of matrix set to np. All files are in JPG format and Type 2 is the most common one with a little bit more than 50 in the training data in total Type 1 on the other hand has a little bit less than 20 in the training data. To be able to cope with that we ll most likely end up using L1 regularization. Confusion matrixThe confusion matrix is a standard analysis tool in binary and multi class classification where in each entry C_ i j corresponds to the number of samples that have true class label i and are predicted as j. Image clustering with TSNE embeddingLet us now use the compressed images and the distance preserving transformation of TSNE to get an understanding of what image clusters there are. The original images have as we have seen earlier quite a high resolution so scaling them down to 100 x 100 is resulting in a great loss of information so the embedding to two dimensions is likely not going to have a good structure where we can separate visually by cervical cancer types. fit_transform gray_imgs_mat. I think it is a good representation of maximally dissimilar. Now lets build a barplot to get an idea of the distribution of image dimensions by cervix type. Image dimensionsNow in order to get an idea of how many different shapes of images by class there are lets have a look at. This decision is very important for the healthcare provider and critical for the patient. Identifying the transformation zones is not an easy task for the healthcare providers therefore an algorithm aided decision will significantly improve the quality and efficiency of cervical cancer screening for these patients. To do that we find the image that has maximal distance on average compared to the all other images minimal distance on average compared to the all other imagesand compare both candidates to the mean image from out set of images. It is quite important to understand that we only have read a few training instances 108 and have thousands of dimensions. For that we will use matplotlib to replace the previously red green and blue points with the actual images that were input to the TSNE transformation. These different types of cervix in our data set are all considered normal not cancerous but since the transformation zones aren t always visible some of the patients require further testing while some don t. The submission format is asking for a probability for each of the three different cervix types. Lets first count them for each class. Confusion matrix on training setLooking at the train confusion matrix we can see that we almost only predict class 1. From the data description In this competition you will develop algorithms to correctly classify cervix types based on cervical images. For that we ll use scipy s pdist method. All of the images in our sample have three channels we can ignore this information for now. This will result in a matrix where each row are all flattened pixel for the grayscale images. Image typesNow that we have the data in a handy dataframe we can do a few aggregations on the data. We can see that our models have a great problem with confusing class zero with class two. The images seem to vary alot in they formats the first two samples have only a circular area with the actual image the last sample has the image in a rectangle. The image on the left has quite a lot of blue in it which I would not expect to be present in the majority of samples. 000 dimensional vector. Clustering of pairwise image distancesTo get a different view of how images relate to each other from a purely numerical point of view lets now look at pairwise distances. nan maximally dissimilar image maximally similar image now compute the mean image no need for normalizing we already did this earlier Normalizer. On the left and top of the clustermap we find one of three colors for each row and column this color indicates the type of cervix. If you like this kernel please give an upvote thanks We are given training images for each of cervix types. Cervix EDAIn this competition we have a multi class classification problem with three classes. For the multi class problem we are faced with here we ll use standard approach of OVR one vs rest meaning we will train three models where each of them is designed to distinguish class 1 2 and 3 from the others respectively. TSNE embeddingWe will now take all of the sample images rescale them convert them to grayscale. Model SelectionNow that we ve established a basic idea about the data let s do the most straightforward approach where we take the resized color images and labels and train a most likely quite heavily regularized linear model like logistic regression on it. We can clearly see that there is a big heterogeneous cluster and a few quite distant outliers. Now lets read the files for each type to get an idea about how the images look like. We are asked given an image to identify the cervix type. I ve added the option to choose to convert them to grayscale before passing them to TSNE. 3D t SNE with cervix indicatorsNow let s project the 100x100x3 images to three dimensions to check for low dimensional patterns. Type 1 Red Type 2 Green Type 3 BlueHere is the unclustered distance matrix. To reduce runtime take only a subsample per class. ", "id": "philschmidt/cervix-eda-model-selection", "size": "6145", "language": "python", "html_url": "https://www.kaggle.com/code/philschmidt/cervix-eda-model-selection", "git_url": "https://www.kaggle.com/code/philschmidt/cervix-eda-model-selection", "script": "sklearn.metrics glob AnnotationBbox plotly.offline defaultdict imread Normalizer TSNE collections seaborn numpy plotly.graph_objs squareform matplotlib.offsetbox preprocessing sklearn sklearn.model_selection confusion_matrix LabelEncoder plotly.tools matplotlib.pyplot sklearn.manifold pandas subprocess LogisticRegression check_output OffsetImage imshow scipy.spatial.distance pdist transform_image imscatter GridSearchCV sklearn.linear_model sklearn.preprocessing train_test_split skimage.io ", "entities": "(('color', 'cervix'), 'find') (('we', 'class evaluation basic multi metrics'), 'look') (('how images', 'pairwise now distances'), 'get') (('image', 'therefore 100 100 3 30'), 'keep') (('submission format', 'cervix three different types'), 'ask') (('where we', 'cancer visually cervical types'), 'have') (('similarity we', 'similarity matrix'), 'neighbourhoodgiven') (('where each', '1 2 others'), 'use') (('you', 'cervical images'), 'develop') (('where row', 'grayscale images'), 'result') (('We', 'cervix type'), 'ask') (('us', 'understanding'), 'use') (('that', 'j.'), 'be') (('s', 'low dimensional patterns'), 'let') (('2 most common one', 'training data'), 'be') (('We', 'cervix types'), 'give') (('we', 'almost only class'), 'matrix') (('decision', 'patient'), 'be') (('we', 'data'), 'typesNow') (('I', 'samples'), 'have') (('always some', 'further testing'), 'consider') (('that', 'images'), 'find') (('that', 'TSNE transformation'), 'use') (('therefore algorithm aided decision', 'patients'), 'be') (('images', 'how'), 'read') (('reduce', 'class'), 'take') (('we', 'information'), 'have') (('last sample', 'rectangle'), 'seem') (('TSNE', 'embedding'), 'give') (('we', 'already earlier Normalizer'), 'compute') (('now all', 'grayscale'), 'take') (('lets', 'look'), 'dimensionsnow') (('we', 'training images'), 'tell') (('Now lets', 'cervix type'), 'build') (('quite we', 'dimensions'), 'be') (('models', 'class'), 'see') (('competition we', 'three classes'), 'cervix') (('they', 'file types'), 'let') (('where we', 'it'), 'SelectionNow') (('I', 'TSNE'), 'add') (('it', 'good maximally dissimilar'), 'think') (('we', 'L1 most likely regularization'), 'end') ", "extra": "['patient', 'test', 'cervical cancer']"}
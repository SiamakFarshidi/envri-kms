{"name": "learn2reg tutorial ", "full_name": " h2 Introduction h2 The whole picture h2 Importing provided helper functions h2 Registration using pretrained CNNs h2 Training a CNN for registration h2 Explanatory Details h3 2 Correlation layer implementation Basic steps h4 CNN Convolution operation h4 Correlation layer h3 3 Min Convolution h3 4 Spatial Transform ", "stargazers_count": 0, "forks_count": 0, "description": "Importing provided helper functionsuse Add Data Search by URL and type kaggle. To achieve this per spatial position we combine weighted contributions of every possible displacement based on its cost determined by the correlation layer. Firstly the subvoxel accuracy determination of the minimum SSD position inside the search region will be computed by a weighted averaging. In addition to every slice we provide organ segmentations that will be used for registration evaluation purposes Dice scores as well as for the weakly supervised training of the feature extraction load TCIA data show an example patient slice Uncomment to use pretrained MIND net to extract features Now we prepare our train test dataset. view operation to transform the moving tensor 1 C H W to C 1 H x W. In essence we change tensors 1 C H W to C 1 H W. to crnt_dev 2 perform the SSD cost calculation based on the correlation layer. This lower envelope is not directly differentiable but we can obtain a very accurate approximation using first a min pooling with stride 1 that finds local minima in the SSD tensor followed by two average pooling operations with stride 1 that provide a quadratic smoothing. the extraction of image patch sequences into a matrix multiplication. Here a 1 1 3 3 Image Tensor batch_sz channels heigth width is convolved with a 2x2 kernel without padding etc. The main idea is to incorporate learnable CNNs as feature extractors into an optimization pipeline that is inspired by a well studied discrete registration approach. Correlation layerThis unfolding operation comes in very handy to implement the correlation layer where we need to perform a similar operation. In order to compute the correlation values for every voxel in the moving image for all discrete displacement steps in its corresponding search region in the fixed image we perform the following steps for an efficient implementation We use the. This cell imports all requires packages and provides namespace aliases insert at 1 0 is the script path or in REPL Here we import the image data and perform some preprocessing on the grayvalue images. html highlight unfold torch. the red T inside the discretized neighbourhood yellow rectangle. feat_mov 1 24 80 78 24 feature channels spatial HW dims feat_mov_unfold 24 121 6240 mind chans 11 11 121 displ steps 6240 80 78 spatial positions F. IntroductionIn this tutorial on discrete registration we will explore the implementation of the correlation layer used e. compute the displacements using the meanfield function3. Secondly these values are subsequently also averaged along the spatial image dimensions to result in a smooth displacement field. While during a convolution we use the unfold operation to extract image patches __regions__ to be multiplied with a kernel for the correlation layer we also need to extract regions for our __similarity search__ on a predefined discrete neighbourhood grid. The whole pictureExtracted from the MICCAI submission https arxiv. After having processed our registration image pair by a __CNN whose weights will be adjusted __ we try to find corresponding image contents cf. view operation to swap the batch and channel dimensions. Specifying the search region by r_sz r_sz with r_sz being the size of the region we use the unfold operation to obtain the unfolded tensor of dimension C r_sz x r_sz H x W. Here the idea is to transfer the regularized cost tensor from above into a displacement field. Relying on the implicit broadcasting along the first dimension when computing m f 2 we sum along the 0th dimension to obtain the SSD values for every spatial position in a tensor of dimension r_sz x r_sz H x W. to crnt_dev generate the unfolded version of the moving encoding that will result in the shifted versions per channel according to the corresponding discrete displacement pair forward path pass both images through the network so that the weights appear in the computation graph and will be updated compute the cost tensor using the correlation layer compute the MIN convolution probabilistic output with the given function loss computation compute the weighted sum of the shifted moving label versions compute the loss as sum of squared differences between the fixed label representation and the warped labels perform the backpropagation and weight updates every grad_accum iterations backpropagate the accumulated gradients Validate patient 17 pat17 1 compute the feature representations. 10931 the figure above illustrates the registration approach that will be implemented below. The image below illustrates this for an image that is convolved with a 2x2 kernel consecutively the red green yellow and blue patch are multiplied by the kernel to gain convolution output. In order to compute a reasonable displacement field a two fold regularisation strategy is employed. transpose 1 0 displace_range displace_range padding disp_hw feat_fixed 24 1 6240 compute scalarproduct along feature dimension per broadcast sum along 0 and reshape to 1 121 80 78 reshape the 4D tensor back to spatial dimensions. PyTorch documentation for the unfold operation https pytorch. Here we perform an average filtering along the spatial dimensions to get the final cost tensor. Now we are able to compute the sum of squared differences SSD values for every spatial position between the moving feature representation m and its corresponding search region feature representations in the fixed image f. The method is demonstrated on slices of abomdinal CT scans from the TCIA pancreas dataset. 10931 and focus on the practical implementation details below. Pushing the channel into the batch dimension allows to leave the feature channels untouched while constructing the search region patches along the first dimension with the unfold operation functionality. In order to obtain a reasonable displacement field this next step is the mean field inference. to crnt_dev The network defined here has the same architecture as the pretrained network above and we will train it from scratch on the given image data. For the subvoxel displacement parameter estimation per spatial position we pursue the following strategy Starting with the SSD tensor of size r_sz x r_sz H x W computed in the last step above we first perform the difussion regularisation using min convolutions with a lower envelope of parabolas rooted at the displacement offsets with heights equalling the SSD values. Based on the kernel size the patches are arranged into the unfolded matrix according to their position during the sweeping process of the convolution. Now we visualize a pair of images fixed moving showing their grayvalue images annotations and feature representations. 4 Spatial TransformPerforming 1 step of the discrete registration approach to check whether so far the implementation is working. The refinement of the learnable feature CNN weights will be performed further down. com mattiaspaul learn2reg to load the provided dataset aside images and segmentations it contains the functions warp_and_evaluate which is used to visualise your results and meanfield which is required to regularise the probabilistic displacements Registration using pretrained CNNsIn the next cell we load pretrained network that computes features based on the input images fixed and moving. Without padding we have 4 valid patches to apply the 2x2 kernel therefore the unfolded matrix is of dimensionality 4x4. applying the displacement field on the moving image with the warp_and_evaluate function Training a CNN for registrationNext we will start implementing our own correlation layer and start training a network for discrete image registrationNext we want to evaluate our network that we trained from scratch on the held out test data Explanatory Details 2 Correlation layer implementation Basic steps CNN Convolution operationIn order to move a filter kernel across an image behind the scenes an __ unfold __ operation is used to transfer this operation i. For the sake of clarity we process only one pair at a time. py tensor dimensionalities in comments are for an arbitrary choice of displace_range 11 feat sizes of 1 24 80 78 they clearly depend on the actual choice and only serve as numerical examples here. unfold 3 Min ConvolutionThe finding of the displacement pair yielding the smallest SSD value corresponds to the idea of finding the feature representations that correlate the most. In essence applying the softmax function along the negatively weighted displacement dimension provides the weighting scheme for each displacement and their summation results in a smooth and continuous displacement per position. In the example below the 3x3 search region is defined by discrete voxel displacement pairs in 1 0 1 x 1 0 1 on the current resolution and 1 1 ideally yields the position with the highest correlation. Since this process tends to be unstable due to noise or ambiguities in the following we introduce our two fold regularisation strategy. resulting in a 1 1 2 2 output. In the next part for this image pair we demonstrate the basic registration workflow after having defined the discrete search region size 1. in FlowNet to compute a dissimilarity map for a range of discrete displacement. For more theoretical insights we refer you again to https arxiv. TODO IMPLEMENT THE CORRELATION LAYER or find the solution in learn2reg_discrete. compute the cost tensor using the correlation layer2. ", "id": "mattiaspaul/learn2reg-tutorial", "size": "7562", "language": "python", "html_url": "https://www.kaggle.com/code/mattiaspaul/learn2reg-tutorial", "git_url": "https://www.kaggle.com/code/mattiaspaul/learn2reg-tutorial", "script": "torch.nn.functional torch.optim torch.nn learn2reg_discrete numpy matplotlib.pyplot my_correlation_layer ", "entities": "(('1 that', 'quadratic smoothing'), 'be') (('that', 'most'), 'correspond') (('we', 'search region discrete size'), 'demonstrate') (('_ _ we', 'image contents corresponding cf'), 'after') (('we', 'dimension'), 'specify') (('that', 'registration above approach'), 'illustrate') (('we', 'dimension'), 'sum') (('width', 'etc'), 'heigth') (('Now we', 'train test dataset'), 'show') (('that', 'registration well studied discrete approach'), 'be') (('We', 'the'), 'perform') (('Here we', 'cost final tensor'), 'perform') (('above we', 'image given data'), 'to') (('we', 'https again arxiv'), 'refer') (('we', 'H 1 W.'), 'change') (('we', 'correlation layer'), 'combine') (('accuracy Firstly subvoxel determination', 'weighted averaging'), 'compute') (('we', 'e.'), 'introductionin') (('Here we', 'grayvalue images'), 'require') (('patches', 'convolution'), 'arrange') (('so far implementation', 'registration 4 Spatial TransformPerforming 1 discrete approach'), 'step') (('crnt_dev', 'correlation layer'), 'perform') (('refinement', 'feature CNN learnable weights'), 'perform') (('Secondly values', 'displacement smooth field'), 'average') (('grad_accum iterations', 'feature 17 pat17 1 representations'), 'generate') (('_ _ unfold _ _ operation', 'operation'), 'start') (('Now we', 'search region feature image corresponding fixed f.'), 'be') (('Now we', 'grayvalue images annotations'), 'visualize') (('computes', 'input images'), 'learn2reg') (('method', 'TCIA pancreas dataset'), 'demonstrate') (('we', 'time'), 'process') (('1 1', 'highest correlation'), 'define') (('we', 'SSD values'), 'pursue') (('whole', 'MICCAI submission https arxiv'), 'pictureextracte') (('therefore unfolded matrix', 'dimensionality 4x4'), 'have') (('we', 'neighbourhood predefined discrete grid'), 'use') (('summation', 'position'), 'provide') (('where we', 'similar operation'), 'come') (('TODO', 'learn2reg_discrete'), 'implement') (('regularisation two fold strategy', 'displacement reasonable field'), 'in') (('Here idea', 'displacement field'), 'be') (('we', 'regularisation two fold strategy'), 'introduce') (('78 feature HW feat_mov 1 24 80 24 channels spatial 24 121 6240 mind', '11 displ 11 121 steps'), 'dim') (('consecutively red green yellow', 'convolution output'), 'illustrate') (('Pushing', 'operation unfold functionality'), 'allow') (('80 78 they', 'only numerical examples'), 'be') (('Importing', 'Add Data type URL kaggle'), 'provide') ", "extra": "['annotation', 'biopsy of the greater curvature', 'patient', 'test']"}
{"name": "fine tuning bert text classification ", "full_name": " h1 Fine Tune BERT for Text Classification with TensorFlow h2 Prerequisites h2 Initial Set Up h3 Install TensorFlow and TensorFlow Model Garden h2 Some Initial Imports and Checks h4 Logging into wandb h2 Lets Get the Dataset h3 Get to Know your data Some Basic EDA h1 Taming the Data h2 Lets BERT Get the Pre trained BERT Model from TensorFlow Hub h3 Checking out some of the training samples and their tokenized ids h2 Lets Get That Data Ready Tokenize and Preprocess Text for BERT h3 Wrapping the Python Function into a TensorFlow op for Eager Execution h2 Let the Data Flow Creating the final input pipeline using tf data h1 Lets Model Our Way to Glory h2 Create The Model h2 Let Us Train h4 W B Experiment Tracking h3 Lets Evaluate h3 Lets Look at some Graphs h3 Saving the models and model Versioning h4 W B Artifacts h3 Quick Sneak Peek into the W B Dashboard h3 References ", "stargazers_count": 0, "forks_count": 0, "description": "io annotated 20paper BERT References W B usage and intro https www. Since we just trained for a very limited data and less epoch these graphs generated here are not as represenetative so leaving this here more interms of a place holder for the reader to experiment with. Add your model file to the Artifact with wandb. In graph mode you can only use TensorFlow Ops and functions. the dictionary have keys which should obv match Now we will simply apply the transformation to our train and test datasets train valid train data spec we can finally see the input datapoint is now converted to the BERT specific input tensor valid data spec Building the model input BERT Layer Classification Head for classification we only care about the pooled output at this point we can play around with the classification head based on the downstream tasks and its complexity inputs coming from the function Calling the create model function to get the keras based functional model using adam with a lr of 2 10 5 loss as binary cross entropy as only 2 classes and similarly binary accuracy Update CONFIG dict with the name of the model. ai authorize and add it to kaggle s secret key for hassle free authentication. Let us decompress and read the data into a pandas DataFrame. You can check out and get the entire code as a notebook and run it on colab from this Github Repo https github. ai guides integrations kerasYes Its as simple as adding a callback D Lets EvaluateLet us do an evaluation on the validation set and log the scores using weights and biases. It looks like a good train test split so far. csv from that competition https archive. Create an empty Artifact with wandb. Reports we can create reports on experiments and project levels. Quick Sneak Peek into the W B Dashboard Things to note Grouping of experiments and runs. For this kernel we will be looking into Weights and Biases https wandb. org download quora_dataset_train. Visualizations of all training logs and metrics. init It initializes the run with basic project informationparameters project The project name this will create a new project tab where all the experiments for this project will be tracked config A dictionary of all parameters and hyper parameters we wish to track group optional but would help us to group by different parameters later on job_type to describe the job type it would help in grouping different experiments later. Let Us Train One drawback of the tf hub is that we import the entire module as a layer in keras as a result of which we dont see the parameters and layers in the model summary. UPDATE BERT Annotated Paper and Beyond. Even the distribution of question length in words and characters is very similar. For the classification task we are only concerned with the pooled_output. Here we will pass the evaluation dictionary as it is and log it. Artifacts Storing Datasets models and other files for version tracking. Data preprocessing consists of transforming text to BERT input features input_word_ids input_mask segment_ids input_type_ids Input Word Ids Output of our tokenizer converting each sentence into a set of token ids. log Finish the run Save model Initialize a new W B run for saving the model changing the job_type Save model as Model Artifact Finish W B run. Lets Look at some GraphsThese Graphs will mainly be useful when we are training for more epochs and more data. b lets us clone a specific branch only. com ayuraj experiment tracking with weights and biases install requirements to use tensorflow models repository you may have to restart the runtime afterwards also ignore any ERRORS popping up at this step TO LOAD DATA FROM ARCHIVE LINK import numpy as np import pandas as pd from sklearn. zip compression zip low_memory False print df. Only realtokens are attended to. Artifacts Model versioning and storage. More details about Kaggle s Secret key feature on https www. Hopefully this was useful for you and by now you have a small kickstart on training and utilizing BERT for a variety of downstream tasks like classification Named Entity Recognition Sentence filling and many more. Visualizations for system metrics could be useful when training on cloud instances or physical GPU machines Hyperparmeter tracking in the tabular form. To still give out a method to generate graphs explicitly here is some very basic code. ai akshayuppal12 Finetune BERT Text Classification artifacts model BERT_EN_UNCASED 48ffa3e14aba242a5113 Model versioning and more. Bert was trained on two tasks fill in randomly masked words from a sentence. Input Masks Since we are padding all the sequences to 128 max sequence length it is important that we create some sort of mask to make sure those paddings do not interfere with the actual text tokens. The mask has 1 for real tokens and 0 for padding tokens. given two sentences which sentence came first. Saving the models and model Versioning W B ArtifactsFor saving the models and making it easier to track different experiments I will be using wandb. org api_docs python tf keras Model fit Lets Model Our Way to Glory Create The ModelThere are two outputs from the BERT Layer A pooled_output of shape batch_size 768 with representations for the entire input sequences. ai akshayuppal12 Finetune BERT Text Classification runs 29thnm00 workspace user akshayuppal12 created for this run. W B Artifacts are a way to save your datasets and models. We will be looking into Experiment Trancking and Artifacts Logging into wandb. Taming the Data Lets BERT Get the Pre trained BERT Model from TensorFlow HubWe will be using the uncased BERT present in the tfhub. Graph tensors do not have a value. The official tfhub page states that All parameters in the module are trainable and fine tuning all parameters is the recommended practice. log_artifact to save the Artifact Artifact dashboard https wandb. Datasets return features labels pairs as expected by keras. model_selection import train_test_split df pd. com au1206 Fine_Tuning_BERT. com product feedback 114053 Lets Get the Dataset The data we will use is the dataset provided on the Quora Insincere Questions Classification competition on Kaggle https www. data The resulting tf. Coming up Next BERT Annotated Paper Write up on Transformers and its workings For some annotated reader friendly research papers on advanced concepts and tutorials like these please visit https au1206. py_function https www. Prerequisites Willingness to learn Growth Mindset is all you need Some basic idea about Tensorflow Keras Some Python to follow along with the code Initial Set Up Install TensorFlow and TensorFlow Model GardenCloning the Github Repo for tensorflow models depth 1 during cloning Git will only get the latest copy of the relevant files. org api_docs python tf py_function will pass regular tensors with a value and a. shape TO LOAD DATA FROM KAGGLE label 0 non toxic label 1 toxic Since the dataset is very imbalanced we will keep the same distribution in both train and test set by stratifying it based on the labels using small portions of the data as the over all dataset would take ages to train feel free to include more data by changing train_size TRAIN SET VALIDATION SET TRAIN SET VALIDATION SET we want the dataset to be created and processed on the cpu lets look at 3 samples from train set Setting some parameters Label categories maximum length of token input sequences Get BERT layer and tokenizer All details here https tfhub. Setting all parameters in form of a dictionary so any changes if needed can be made here Checking out some of the training samples and their tokenized ids Lets Get That Data Ready Tokenize and Preprocess Text for BERTEach line of the dataset is composed of the review text and its label. Please match it with your tensorflow 2. com c quora insincere questions classification data. org api_docs python tf data Dataset map to apply this function to each element of the dataset. Here are Four main things that W B offers Experiment Tracking Tracking ML Experiments and logging various parameters and metrics on a clean dashboard. Please feel free to download the train set from kaggle or use the link below to download the train. First things first we need to create a free account on W B https wandb. If you made it this far please consider leaving feedback so I can improve and also if you liked it consider upvoting. Within a run there are three steps for creating and saving a model Artifact. All these graphs are actually directly logged on the wandb dashboard https wandb. Wrapping the Python Function into a TensorFlow op for Eager Execution Let the Data Flow Creating the final input pipeline using tf. The tokenizer here is present as a model asset and will do uncasing for us as well. Segment Ids For out task of text classification since there is only one sequence the segment_ids input_type_ids is essentially just a vector of 0s. log Log a dict of scalars metrics like accuracy and loss and any other type of wandb object. org api_docs python tf py_function. Initialize W B run Train model setting low epochs as It starts to overfit with this limited data please feel free to change Initialize a new run for the evaluation job Model Evaluation on validation set Log scores using wandb. map this function directly You need to wrap it in a tf. Sweeps Hyper parameter tuning. numpy method to access it to the wrapped python function. If this was helpful consider sharing it with more people so they can also learn about it. csv quora_dataset_train. It can save you a lot of space and time. A sequence_output of shape batch_size max_seq_length 768 with representations for each input token in context. eg train evaluate etcIn order to Log all the different metrics we will use a simple callback provided by W B WandCallback https docs. dev tensorflow bert_en_uncased_L 12_H 768_A 12 2 checks if the bert layer we are using is uncased or not This provides a function to convert row to input features and label this uses the classifier_data_lib which is a class defined in the tensorflow model garden we installed earlier since we only have 1 sentence for classification purpose textr_b is None since only 1 example the index 0 py_func doesn t set the shape of the returned tensors. org api_docs python tf data Dataset map runs in graph mode. ai site for experiment tracking. ai site Then let us access our authorization API key https wandb. Fine Tune BERT for Text Classification with TensorFlow Figure 1 BERT Classification ModelWe will be using GPU accelerated Kernel for this tutorial as we would require a GPU to fine tune BERT. You can run multiple experiments with different hyper parameters and track them. read_csv https archive. In order to prepare the text to be given to the BERT layer we need to first tokenize our words. Therefore we need a generate input mask blocking the paddings. You want to use Dataset. Therefore we will go ahead and train teh entire model without freezing anything W B Experiment TrackingIn order to start the expirment tracking we will be creating runs on W B wandb. Get to Know your data Some Basic EDASo it looks like the train and validation set are similar in terms of class imbalance and the various lengths in the question texts. NOTE ANYTHING BEFORE THIS CELL SHOULD ONLY BE RUN ONCE ONLY DURING THE INITIAL SETUP Some Initial Imports and ChecksA Healthy practice for any ML practioner is to do a clean experiment tracking such that reasults are reproducable and trackable. Note After installing the required Python packages you ll need to restart the Colab Runtime Engine Run Restart and clear all cell outputs. the final datapoint passed to the model is of the format a dictionary as x and labels. ", "id": "au1206/fine-tuning-bert-text-classification", "size": "10124", "language": "python", "html_url": "https://www.kaggle.com/code/au1206/fine-tuning-bert-text-classification", "git_url": "https://www.kaggle.com/code/au1206/fine-tuning-bert-text-classification", "script": "create_feature official.nlp.bert UserSecretsClient optimization tokenization seaborn numpy create_model sklearn.model_selection matplotlib.pyplot kaggle_secrets tensorflow WandbCallback official.nlp.data pandas create_graphs wandb.keras tensorflow_hub train_test_split official.nlp create_feature_map classifier_data_lib ", "entities": "(('I', 'wandb'), 'save') (('you', 'cell outputs'), 'note') (('it', 'it'), 'pass') (('BERT Text Classification', 'run'), 'ai') (('it', 'different experiments'), 'init') (('it', 'far feedback'), 'improve') (('mask', 'tokens'), 'have') (('Therefore we', 'paddings'), 'need') (('keras', 'model'), 'have') (('train set', 'question various texts'), 'get') (('EvaluateLet us', 'weights'), 'guide') (('we', 'Kaggle https www'), 'feedback') (('You', 'Github Repo https github'), 'check') (('paddings', 'text actual tokens'), 'Masks') (('Data Ready Tokenize', 'review text'), 'make') (('Data Flow', 'tf'), 'let') (('log_artifact', 'https wandb'), 'dashboard') (('org api_docs', 'graph mode'), 'python') (('we', 'https Weights wandb'), 'look') (('org api_docs', 'dataset'), 'python') (('tokenizer', 'us'), 'be') (('parameters', 'module'), 'state') (('we', 'model summary'), 'let') (('It', 'wandb'), 'run') (('Visualizations', 'tabular form'), 'be') (('sentence', 'two sentences'), 'give') (('First things first we', 'W B https wandb'), 'need') (('such reasults', 'experiment clean tracking'), 'NOTE') (('Label maximum length', 'BERT layer'), 'take') (('io', 'References W B 20paper BERT usage'), 'annotate') (('characters', 'words'), 'be') (('we', 'only pooled_output'), 'be') (('mainly when we', 'more epochs data'), 'be') (('It', 'train good test'), 'look') (('we', 'experiments'), 'report') (('0 py_func doesn', 'returned tensors'), 'bert_en_uncased_L') (('You', 'them'), 'run') (('you', 'classification Named Entity Recognition Sentence filling'), 'be') (('ModelThere', 'input entire sequences'), 'python') (('org api_docs python', 'value'), 'pass') (('segment_ids only one input_type_ids', 'essentially just 0s'), 'Ids') (('Datasets return features', 'labels keras'), 'pair') (('still give', 'graphs'), 'be') (('ai', 'hassle free authentication'), 'authorize') (('we', 'W B wandb'), 'go') (('you', 'TensorFlow only Ops'), 'use') (('Bert', 'sentence'), 'train') (('us', 'pandas'), 'let') (('We', 'wandb'), 'look') (('Model Artifact Finish W B', 'job_type Save model'), 'log') (('Pre', 'present tfhub'), 'use') (('graphs', 'wandb dashboard https actually directly wandb'), 'log') (('directly You', 'tf'), 'map') (('we', 'W B WandCallback https docs'), 'evaluate') (('ai Then us', 'authorization https API key wandb'), 'site') (('final datapoint', 'dictionary x'), 'pass') (('reader', 'place holder'), 'be') (('workings', 'https au1206'), 'come') (('W B', 'clean dashboard'), 'be') (('Artifacts', 'version other tracking'), 'Datasets') (('Data', 'token ids'), 'feature') (('W B Artifacts', 'datasets'), 'be') (('we', 'tune fine BERT'), 'use') (('we', 'first words'), 'in') (('np', 'sklearn'), 'install') (('TensorFlow GardenCloning', 'relevant files'), 'be') (('they', 'also it'), 'consider') (('log', 'other wandb'), 'log') ", "extra": "['test']"}
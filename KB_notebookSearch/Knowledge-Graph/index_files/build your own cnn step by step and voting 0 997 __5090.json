{"name": "build your own cnn step by step and voting 0 997 ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "It is recommended that no GPU students do not train you can take a look then use the final model and the weight file I provided. The result of training observation is that the pool layer is added after the last convolution layer or the pool layer is added after the countdown first and second convolution layer. Those who are interested can continue to explore higher scores. I have obtained some excellent models. com s 1T31ToVXSC7KWsSdcBjYkgQ C2 A0 list path 2F extraction code ltu5 load weight and Prediction Voting function did not find the kind of direct vote on the forecast I do not know if there is I wrote one of my own. Module Imports Load Data Data preprocessing Data augmentation Perform rotation on the picture move up and down left and right and other operations to increase the amount of data. First select the first layer filters parameter Observe the cross validation score of the training output and select the better parameters. Choose the fifth way to add that is add droupout after the second and third modules Select the parameters of the first dropout dropout parameter selection training using the loop may encounter some problems you can manually modify the parameter values training observation. 99728 which should be top10. This is also my final choice of the model. Padding parameter selection Same seems a little better but it doesn t make much difference. You can add BN to each convolution layer or you can add some without adding some. Combine predict In this way I can get a score of 0. 7 all seem good choose 0. Weights file can be downloaded from here https pan. Of course by combining different models I may be able to achieve a higher score. In digit recognizer I initially learned to construct my own CNN model step by step and finally used multi model voting to get a good score. 5 is better choose 0. 4 Select the parameters for the second dropout 0. Select the number of convolution layers 3 4 5 are optional. A module count of 2 appears to be valid. Normalization and one hot Normalizetion Take a look at the data at will. Of course the selection of full connection parameters and other operations also can be done but after training observation found that the current model has a good effect the subsequent attempt is no longer need you can try it yourself. Now take a model combination with a final score of 0. My result was 32 or 64 and I chose 32 to continue building. Select the first layer kernel_size parameter 3 4 5 6 7 all look good I chose 5 to continue to build. Choose how to add pool layer starting with the last convolution layer and adding a pool layer up to each convolution layer. Finally I chose to add BN to each convolution layer. I chose to add the pooling layer to the bottom one or two layers that is the last two layers. These models can help us raise the score to 0. This article has a lot of training and my GPU is not very good 1050ti which takes a lot of time. Data augmentation is very effective. Select pooling layer pool_size parameter 2 3 4 all look good. For the convenience of commit all steps are trained for only one epoch. The following parameters are the version used by most people but you can also explore parameters that are more effective for your own model. With the two convolution pooling modules of the current model and the final fully connected module a total of three modules are selected to add dropout. If you are Chinese you can check out my blog https blog. net qq_33758867 article details 90047240. Build your own CNN step by step. Save model weights and load model weights The model combination using the simple voting method using the model prediction of three scores of 0. 99785 through a variety of combinations. I have a maximum score of 0. Decided to use 5 layers of convolution pool_size 3 continues to build. To achieve good results you should train at least 20 epochs. Based on the model that has been built that is the five layers of convolution layer plus the last two layers are pooled into a module and the number of modules required is selected. 996 basically can get the score of 0. Each module is added separately three modules are added and any two modules are added in a total of 7 ways. Model compilation 3. 5 Similarly there are many ways to add batch normalization. I tried some ways and the results were all good. You can save the weights of these models. Parameters such as rotation_range zoom_range width_shift_range and height_shift_range can be modified. predict and submit Usually after 80 epochs of training there will be some models that can make the score reach 0. Selection of filter parameters for convolution layer of New Module Choose 64 Selection of kernel_size parameters for convolution layer of New Module It feels like 3 4 5 6 are all the same continue to use 5 Pool_size Parameter selection of New Module pool layer Still use 3. ", "id": "firstbloody/build-your-own-cnn-step-by-step-and-voting-0-997", "size": "5090", "language": "python", "html_url": "https://www.kaggle.com/code/firstbloody/build-your-own-cnn-step-by-step-and-voting-0-997", "git_url": "https://www.kaggle.com/code/firstbloody/build-your-own-cnn-step-by-step-and-voting-0-997", "script": "Flatten keras.preprocessing.image keras.layers keras.callbacks train_test_split GlobalAveragePooling2D Dropout Sequential Conv2D AveragePooling2D seaborn numpy Input ReduceLROnPlateau combine_model keras.backend preprocessing sklearn sklearn.model_selection ImageDataGenerator matplotlib.pyplot RMSprop Activation Dense pandas keras.optimizers GlobalMaxPooling2D OneHotEncoder BatchNormalization keras.initializers Model layers MaxPooling2D Add sklearn.preprocessing LearningRateScheduler keras glorot_uniform keras.models ZeroPadding2D ", "entities": "(('you', 'parameter values training manually observation'), 'choose') (('longer you', 'it'), 'do') (('weight I', 'then final model'), 'recommend') (('I', '32'), 'be') (('you', 'at least 20 epochs'), 'achieve') (('convolution last layer', 'pool convolution countdown first layer'), 'be') (('number', 'modules'), 'be') (('little it', 'much difference'), 'seem') (('I', '0'), 'predict') (('I', 'good score'), 'learn') (('I', 'own'), 'com') (('us', '0'), 'help') (('you', 'blog https blog'), 'check') (('two modules', '7 ways'), 'add') (('Parameters', 'rotation_range zoom_range such width_shift_range'), 'modify') (('that', 'bottom one layers'), 'choose') (('3 4 5', 'convolution layers'), 'be') (('very good which', 'time'), 'have') (('Pool_size Parameter 4 5 6 all 5 selection', 'Still 3'), 'Choose') (('who', 'higher scores'), 'continue') (('you', 'some'), 'add') (('Finally I', 'convolution layer'), 'choose') (('This', 'also final model'), 'be') (('that', 'more own model'), 'be') (('score', '0'), 'be') (('Normalization', 'will'), 'take') (('Weights file', 'https pan'), 'download') (('I', 'higher score'), 'by') (('Module Imports Load Data Data', 'data'), 'perform') (('results', 'ways'), 'try') (('all I', '5'), 'select') (('You', 'models'), 'save') ", "extra": "[]"}
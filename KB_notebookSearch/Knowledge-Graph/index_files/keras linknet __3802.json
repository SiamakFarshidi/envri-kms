{"name": "keras linknet ", "full_name": " h1 Intro h1 Get the data h1 Create our Keras metric h1 Build and train our neural network h1 Make predictions h1 Encode and submit our results ", "stargazers_count": 0, "forks_count": 0, "description": "03718 which is very common for image segmentation problems such as this. I ll just train for 10 epochs which takes around 10 minutes in the Kaggle kernel with the current parameters. Seems good Create our Keras metricNow we try to define the mean average precision at different intersection over union IoU thresholds metric in Keras. The architecture used is the so called LinkNet https arxiv. post processing Fit model Predict on train val and test Threshold predictions Create list of upsampled test masks Perform a sanity check on some random training samples Perform a sanity check on some random validation samples Run length encoding stolen from https www. I downsample both the training and test images to keep things light and manageable but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run length encodings later on. 277 LB Set some parameters Get train and test IDs Get and resize train images and masks Get and resize test images Check if training data looks all right Define IoU metric Build U Net model pre processing Expand channels of shortcut to match residual. Stride appropriately to match residual width height Should be int if network architecture is correctly configured. It also seems to just increase over time no matter what when you train. Next we fit the model on the training data using a validation split of 0. com rakhlin fast run length encoding python excellent implementation of run length encoding. All right looks good Loss seems to be a bit erratic though. How about the validation data Not too shabby Definitely needs some more training and tweaking. TensorFlow has a mean IoU metric but it doesn t have any native support for the mean over multiple thresholds so I tried to implement this. and then finally create our submission This scored 0. Remember to load the best saved model if you ve used early stopping and checkpointing. The model is at least able to fit to the training data Certainly a lot of room for improvement even here but a decent start. I ll leave it to you to improve the model architecture and parameters Make predictionsLet s make predictions both on the test set the val set and the train set as a sanity check. We use a small batch size because we have so little data. Encode and submit our resultsNow it s time to submit our results. That was with version 2 of this notebook be aware that the results from the neural network are extremely erratic and vary greatly from run to run version 3 is significantly worse for example. Let s iterate over the test IDs and generate run length encodings for each seperate mask identified by skimage. I ve stolen this https www. com rakhlin fast run length encoding python Create submission DataFrame. 277 You should easily be able to stabilize and improve the results just by changing a few parameters tweaking the architecture a little bit and training longer with early stopping. There are definitely better ways to handle this but it works fine for now Let s see if things look all right by drawing some random images and their associated masks. Get the dataLet s first import all the images and associated masks. They also have a tendency to work quite well even on small datasets. Build and train our neural networkNext we build our model loosely based on LinkNet https arxiv. 1 X 1 conv if shape is different. Update Added early stopping and checkpointing and increased to 30 epochs. 03718 Update Changed to ELU units added dropout. I m by no means certain that this implementation is correct though Any assistance in verifying this would be most welcome Update This implementation is most definitely not correct due to the very large discrepancy between the results reported here and the LB results. I recommend using checkpointing and early stopping when training your model. IntroBasically a fork of the U Net starter where U Net is replaced with LinkNet. The success of LinkNet for Carvana http slides. Have fun LB score history Version 7 0. com vladimiriglovikov kaggle deep learning to create a model for binary segmentation of car images and presentation by Vladimir Iglovikov made me think it might be worth a try for segmenting nuclei. I won t do it here to make things a bit more reproducible although it s very likely that your results will be different anyway. ", "id": "kmader/keras-linknet", "size": "3802", "language": "python", "html_url": "https://www.kaggle.com/code/kmader/keras-linknet", "git_url": "https://www.kaggle.com/code/kmader/keras-linknet", "script": "skimage.transform keras.regularizers keras.layers keras.callbacks Deconv2D keras.layers.core dec_block mean_iou EarlyStopping Dropout chain skimage.morphology MaxPool2D itertools imread Conv2D numpy keras.metrics Input imread_collection Conv2DTranspose AvgPool2D ModelCheckpoint keras.layers.convolutional bce_dice block_func matplotlib.pyplot label Activation tensorflow l2 pandas Lambda _shortcut dice_coef resize tqdm imshow BatchNormalization enc_block load_model rle_encoding Model concatenate MaxPooling2D prob_to_rles backend binary_crossentropy backend as K keras.layers.pooling keras add concatenate_images keras.models keras.layers.merge skimage.io ", "entities": "(('Update', '30 epochs'), 'add') (('you', 'early stopping'), 'remember') (('Next we', '0'), 'fit') (('so I', 'this'), 'have') (('model', 'improvement'), 'be') (('s', 'skimage'), 'let') (('we', 'metric Keras'), 'seem') (('com rakhlin', 'length encoding python Create submission fast DataFrame'), 'run') (('it', 'results'), 'Encode') (('too shabby', 'Definitely more training'), 'about') (('which', 'such this'), '03718') (('network height architecture', 'appropriately residual width'), 'be') (('I', 'early when model'), 'recommend') (('com rakhlin', 'length run encoding'), 'run') (('U where Net', 'LinkNet'), 'fork') (('Threshold predictions', 'https www'), 'post') (('This', '0'), 'create') (('They', 'quite well even small datasets'), 'have') (('we', 'so little data'), 'use') (('things', 'all random images'), 'be') (('it', 'try nuclei'), 'vladimiriglovikov') (('we', 'length correct run encodings'), 'downsample') (('train', 'sanity check'), 'leave') (('most implementation', 'results'), 'm') (('results', '3 significantly example'), 'be') (('very results', 'it'), 'win') (('when you', 'matter what'), 'seem') (('we', 'LinkNet https loosely arxiv'), 'build') (('03718 Update', 'dropout'), 'add') (('training data', 'residual'), 'get') (('success', 'slides'), 'http') (('You', 'little bit longer early stopping'), '277') (('which', 'current parameters'), 'train') ", "extra": "['test']"}
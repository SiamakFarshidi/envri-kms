{"name": "birdclef2021 model training ", "full_name": " h1 Model training h1 1 Settings and imports h1 2 Data preparation h1 3 Extract training samples h1 4 Load training samples h1 5 Build a simple model h1 6 Soundscape analysis ", "stargazers_count": 0, "forks_count": 0, "description": "Next we need to specify an optimzer initial learning rate a loss function and a metric. But for now loading samples from disk and combining them into a large NumPy array is fine. Ok that leaves us with 27 species and 8 548 audio files. So we keep it simple and build our own model. In this tutorial we ll use a very simplistic AlexNet like design with four convolutional layers and three dense layers. This is not a bad selection to start experimenting. We ll have to check ourselves luckily we have some validation soundscapes. This function needs to load a file with Librosa we only use the first 15 seconds in this tutorial extract mel spectrograms and save each spectrogram as PNG image in a working directory for later access. Model trainingIn this notebook we will train our first model and apply this model to a soundscape. Build a simple modelAlright our dataset is ready now we need to define a model architecture. Nice These are good samples. Load training samplesFor now our spectrograms reside in a working directory. Load metadata file Limit the number of training samples and classes First only use high quality samples Second assume that birds with the most training samples are also the most common A species needs at least 200 recordings with a rating above 4 to be considered common Let s see how many species and samples we have left Shuffle the training data and limit the number of audio files to MAX_AUDIO_FILES Define a function that splits an audio file extracts spectrograms and saves them in a working directory Open the file with librosa limited to the first 15 seconds Split signal into five second chunks End of signal Extract mel spectrograms for each audio chunk Normalize Save as image file Parse audio files and extract training samples Plot the first 12 spectrograms of TRAIN_SPECS Parse all samples and add spectrograms into train data primary_labels into label data Open image Convert to numpy array Normalize between 0. That s something you should always double check Add channel axis to 2D array Add new dimension for batch size Predict Get highest scoring species Prepare submission entry Decide if it s a nocall or a species by applying a threshold Add the confidence score as well Make a new data frame Merge with ground truth so we can inspect Let s look at the first 50 entries. Notice how some of them only contain a fraction of a bird call That s an issue we won t deal with in this tutorial. 0 and exclude samples with nan Add channel axis to 2D array Add new dimension for batch size Add to train data Add to label data Make sure your experiments are reproducible Build a simple model as a sequence of convolutional blocks. The last layer is our classification layer and is softmax activated. Now it s your turn to find better strategies to cope with this shift in acoustic domains. It might make sense to choose an off the shelve TF model that was pre trained on audio data but we would need to adjust the inputs i. ogg seems to contain a lot of Song Sparrow sonspa vocalizations let s try this one then. Settings and importsLet s begin with imports and a few basic settings. the resolution of our spectrograms to fit the external model. We also didn t detect the Northern Cardinal norcar and Red winged Blackbird rewbla even though we had them in our training data. Well and we missed others. This is a good example for the difficulties we re facing when analyzing soundscapes. This is not a huge CNN it only has 200 000 parameters. We ll use 20 of our training data for validation and we ll stop after 25 epochs. The scores might not tell us much about how well we will perform on soundscape data. We will simply ignore the fact that samples might not contain any bird sounds. Yet with potentially hundreds of thousands of extracted spectrograms an in memory dataset is not a good idea. The species list includes very common species like the House Sparrow houspa Blue Jay blujay or Song Sparrow sonspa. Yet we also only have a very small dataset with just 27 classes. Remember this is only a sample implementation feel free to explore your own workflow. Not too bad we got into the 60s of our validation accuracy. It s the easiest way to use these data for training with Keras. Ok that s not too bad. Well it s a multi label task so sigmoid might actually be a better choice First conv block Second conv block Third conv block Fourth conv block Global pooling instead of flatten Dense block Classification layer Compile the model and specify optimizer loss and metric Add callbacks to reduce the learning rate if needed early stopping and checkpoint saving Let s train the model for a few epochs Load the best checkpoint Pick a soundscape Open it with librosa Store results so that we can analyze them later Split signal into 5 second chunks Just like we did before well this could actually be a seperate function End of signal Get the spectrograms and run inference on each of them This should be the exact same process as we used to generate training samples Keep track of the end time of each chunk Get the spectrogram Normalize to match the value range we used during training. Ok we have 1 500 audio files that cover 27 species let s extract spectrograms this might take a while. And again we have to load a file with Librosa extract spectrograms for 5 second chunks pass each chunk through the model and eventually assign a label to the 5 second audio chunk. Callbacks make our life easier the three that we re adding will take care of saving the best checkpoint they will reduce the learning rate whenever the training process stalls and they will stop the training if the model is overfitting. Here we go everything is in place let s train a model. We actually got some of these Song Sparrow sonspa vocalizations. Each block has the sequence CONV RELU BNORM MAXPOOL. Finally perform global average pooling and add 2 dense layers. Please don t hesitate to leave a comment or start a new forum thread if you have any questions. Ok we found a few bird species with a score above the threshold. That s way too much for this tutorial so we will limit our species selection to species that have at least 200 recordings with a rating of 4 or better. Global vars seconds height x width Code adapted from https www. We will keep the amount of training samples species and soundscapes to a minimum to keep the execution time as short as possible. com frlemarchand bird song classification using an efficientnet Make sure to check out the entire notebook. If we want to train a model we have to load them into memory. The file 28933_SSW_20170408. These are the steps that we will cover select audio files we want to use for training extract spectrograms from those files and save them in a working directory load selected samples into a large in memory dataset build a simple beginners CNN train the model apply the model to a selected soundscape and look at the results 1. Soundscape analysisIn this tutorial we will simply pick a soundscape from the training data but the overall process can easily be automated and then applied to all soundscape files. Let s look at the results and see how well we re actually doing. Data preparationThe training data for this competition contains tens of thousands of audio files for 397 species. Extract training samplesWe need to define a function that extracts spectrograms for a given audio file. But remember we re training on focal recordings and validate on focal recordings. Alright we got 4 157 training spectrograms. That s roughly 150 for each species which is not too bad. Let s make sure the spectrograms look right and show the first 12. Let s use a soundscape that actually contains some of the species that we trained our model for. Focal recordings as training data can be misleading and soundscapes have much higher noise levels and also contain very faint bird calls. ", "id": "stefankahl/birdclef2021-model-training", "size": "5253", "language": "python", "html_url": "https://www.kaggle.com/code/stefankahl/birdclef2021-model-training", "git_url": "https://www.kaggle.com/code/stefankahl/birdclef2021-model-training", "script": "tensorflow matplotlib.pyplot PIL shuffle Image sklearn.utils get_spectrograms pandas tqdm numpy ", "entities": "(('Data training preparationThe data', '397 species'), 'contain') (('s', 'one'), 'seem') (('We', 'Song Sparrow sonspa vocalizations'), 'get') (('we', '25 epochs'), 'use') (('too we', 'validation accuracy'), 'get') (('overall process', 'soundscape easily then files'), 'pick') (('that', 'given audio file'), 'need') (('experiments', 'convolutional blocks'), 'exclude') (('sample only implementation', 'own workflow'), 'remember') (('we', 'four convolutional layers'), 'use') (('we', 'inputs'), 'make') (('we', 'training'), 's') (('we', 'memory'), 'want') (('spectrograms', 'first 12'), 'let') (('It', 'Keras'), 's') (('Next we', 'loss function'), 'need') (('we', 'tutorial'), 'notice') (('Settings', 'imports'), 'begin') (('that', '27 species'), 'leave') (('luckily we', 'validation soundscapes'), 'have') (('huge it', '200 only 000 parameters'), 'have') (('we', 'just 27 classes'), 'have') (('again we', 'audio 5 second chunk'), 'have') (('that', '4'), 's') (('now spectrograms', 'working directory'), 'samplesFor') (('you', 'questions'), 'hesitate') (('model', 'training'), 'make') (('this', 'while'), 'have') (('soundscapes', 'bird also very faint calls'), 'be') (('that', '0'), 'limit') (('trainingIn notebook we', 'soundscape'), 'model') (('how well we', 'soundscape data'), 'tell') (('we', 'focal recordings'), 'remember') (('now we', 'model architecture'), 'need') (('Now it', 'acoustic domains'), 's') (('we', 'threshold'), 'find') (('we', 'model'), 'let') (('So we', 'own model'), 'keep') (('model', 'results'), 'be') (('samples', 'bird sounds'), 'ignore') (('we', 'later access'), 'use') (('s', 'first 50 entries'), 's') (('height width Code', 'https www'), 'second') (('block', 'sequence'), 'have') (('We', 'execution time'), 'keep') (('we', 'when soundscapes'), 'be') (('loading samples', 'NumPy large array'), 'be') (('species list', 'House Sparrow houspa Blue Jay blujay'), 'include') (('an', 'memory dataset'), 'be') (('s', 'model'), 'go') (('we', 'training 4 157 spectrograms'), 'get') (('com frlemarchand bird song classification', 'entire notebook'), 'make') (('even we', 'training data'), 'detect') (('which', 'roughly species'), 's') (('how well we', 'results'), 'let') "}
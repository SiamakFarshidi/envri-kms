{"name": "titanic top 3 cluster analysis ", "full_name": " h1 Titanic Top 3 now is maybe 6 cluster analysis attempts for imrovement the solution Titanic Top 3 one line of the prediction code with LB 0 83253 h1 Preparing to prediction including FE h3 Preparing to prediction including FE h1 Clustering h2 Tuning model h3 Plot tree h3 Prediction h3 Saving the result h2 Residues of train dataset view ", "stargazers_count": 0, "forks_count": 0, "description": "The restriction to only pairs of features is due to the desire to provide a high quality visualization of the clustering process by analogy with the kernel https scikit learn. com vbmokin titanic top 3 one line of the prediction code The one line of the code for prediction LB 0. 83253 Titanic Top 3 Saving the result FE Thanks to https www. 83253Early I developed kernels https www. com erinsweet simpledetect Thanks to https www. After that the optimal decision tree DecisionTreeClassifier is built by the criterion of max_depth optimization method GridSearchCV. com kpacocha top 6 titanic machine learning from disaster Embarked Thanks to https www. Code from the my kernel Titanic Top 3 one line of the prediction code https www. org wikipedia commons 6 6e St C3 B6wer_Titanic. com mauricef titanic https scikit learn. 744107744107744 Saving the result LB 0. com erinsweet simpledetect Preparing to prediction including FE Preparing to prediction including FE Clustering Tuning model Plot tree Prediction Saving the result Residues of train dataset viewI hope you find this kernel useful and enjoyable. 4719653701687156 LB 0. com vbmokin titanic top 3 one line of the prediction code. html sphx glr auto examples cluster plot cluster comparison pyMy attempts to find a solution giving accuracy above LB 0. com vbmokin three lines of code for titanic top 15 which had three lines of code based on 3 and 4 statements and provides an LB of at least 80 and 85 of teams Titanic Top 20 and 15 respectively. 3349282296650718 Std 0. If this criterion for the optimal method exceeds a threshold limit_opt then a new feature is synthesized by this method in the train and test datasets. Your comments and feedback are most welcome. com kpacocha top 6 titanic machine learning from disaster Thanks to https www. 83253 have not yet been successful. If a solution is found I will post it. com mauricef titanic https www. com vbmokin titanic top 3 one line of the prediction codeI try to improve the result by using the clustering of different features relative to those that were selected in solution Titanic Top3. html sphx glr auto examples cluster plot cluster comparison py Set up cluster parameters update parameters with dataset specific values normalize dataset for easier parameter selection catch warnings related to kneighbors_graph determine the optimal clustering method clustering data by the optimal method synthesis of a new feature add black color for outliers if any Survived Tuning the DecisionTreeClassifier by the GridSearchCV plot tree Prediction by the DecisionTreeClassifier Mean 0. org stable auto_examples cluster plot_cluster_comparison. later I improved the result Titanic Top 3 I will give code with forecasting not in the context of the classes of cabins and ports but in the context of the surnames of passengers Thanks to https www. I will also give new features FE FC. com vbmokin three lines of code for titanic top 20 and https www. Thanks to https www. com kpacocha top 6 titanic machine learning from disaster https www. com vbmokin three lines of code for titanic top 20 https www. html sphx glr auto examples cluster plot cluster comparison py Features list for clustering x1 x2 as string name of features from dataframe df t 1 with train_y t 0 without its train dataset test dataset Thanks to https scikit learn. The kernel allows trying to improve the accuracy of the kernel Titanic Top 3 one line of the prediction code https www. com vbmokin three lines of code for titanic top 15 https www. com erinsweet simpledetect Fare Thanks to https www. com erinsweet simpledetect Family_Size The minimal percentage of similarity of the clustered feature with Survived for inclusion in the final dataset number of clusters Thanks to https scikit learn. The kernel allows to apply different clustering methods they can be easily added into clustering_algorithms to pairs of features feature_first by default WomanOrBoySurvived and a feature from the list clustered_features. html sphx glr auto examples cluster plot cluster comparison py https www. The optimal method determined for each pair of features automatically by the criterion of the maximum cosine similarity with the target feature Survived in the training dataset complete similarity is 1. html sphx glr auto examples cluster plot cluster comparison py generate clustering algorithms estimate bandwidth for mean shift connectivity matrix for structured Ward make connectivity symmetric Create cluster objects Thanks to https scikit learn. com kpacocha top 6 titanic machine learning from disaster Cabin Deck Thanks to https www. The kernel is devoted to an overview of clustering methods and attempts to create new features that will improve the solution in one line of code to prediction them. jpg Titanic Top 3 now is maybe 6 cluster analysis attempts for imrovement the solution Titanic Top 3 one line of the prediction code with LB 0. The given number of clusters n_clusters_opt is used for classification methods. ", "id": "vbmokin/titanic-top-3-cluster-analysis", "size": "3418", "language": "python", "html_url": "https://www.kaggle.com/code/vbmokin/titanic-top-3-cluster-analysis", "git_url": "https://www.kaggle.com/code/vbmokin/titanic-top-3-cluster-analysis", "script": "mixture cycle StandardScaler numpy cluster islice sklearn.neighbors datasets sklearn.tree generate_data sklearn scipy.spatial.distance matplotlib.pyplot DecisionTreeClassifier sklearn.model_selection pandas kneighbors_graph export_graphviz generate_clustering_algorithms LabelEncoder GridSearchCV cosine itertools sklearn.preprocessing ", "entities": "(('that', 'solution Titanic Top3'), 'line') (('com kpacocha', 'https www'), 'top') (('15 which', 'teams'), 'vbmokin') (('com', 'https titanic top 15 www'), 'vbmokin') (('they', 'list clustered_features'), 'allow') (('given number', 'classification methods'), 'use') (('Titanic Top 3 I', 'https Thanks www'), 'improve') (('jpg Titanic Top', 'LB'), 'be') (('com kpacocha', 'disaster https www'), 'top') (('pyMy', 'LB'), 'attempt') (('com vbmokin titanic', 'prediction code'), 'top') (('com', 'titanic top 20'), 'vbmokin') (('83253Early I', 'kernels https www'), 'develop') (('com', 'https Thanks www'), 'erinsweet') (('kernel https scikit', 'learn'), 'be') (('decision tree optimal DecisionTreeClassifier', 'max_depth optimization method GridSearchCV'), 'build') (('com', 'https titanic top 20 www'), 'vbmokin') (('then new feature', 'train datasets'), 'synthesize') (('minimal percentage', 'https Thanks scikit'), 'erinsweet') (('com kpacocha', 'Embarked https www'), 'top') (('kernel', 'train dataset viewI'), 'erinsweet') (('Thanks', 'https scikit'), 'comparison') (('erinsweet Fare Thanks', 'https www'), 'simpledetect') (('Survived', 'DecisionTreeClassifier'), 'comparison') (('kernel', 'Titanic prediction code https 3 one www'), 'allow') (('that', 'them'), 'be') (('complete similarity', 'training dataset'), 'determine') (('com vbmokin titanic', 'prediction LB'), 'line') "}
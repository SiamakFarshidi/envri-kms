{"name": "dfdc yuming yao ", "full_name": " h1 1 Introduction h1 2 Related Work h2 Load Data h1 3 Problem Formulation h1 Initialize BlazeFace h1 Initialize Yolo h1 Initialize MTCNN h1 Initialize MobilenetFace h1 Ability to Detect Face h1 Accuracy Comparison h1 Cropped Images h1 BlazeFace h1 MTCNN h1 Mobilenet h1 YOLO h1 Extra Comparisons h1 4 Methods h1 5 Experiments and Results h1 MesoNet h1 Resnext Model h1 Xception h1 6 Conclusion and Future Works h1 7 Bibliography ", "stargazers_count": 0, "forks_count": 0, "description": "you have to enable this manually calculate the fpr and tpr for all thresholds of the classification method I plt Remove original output layer new updated Find the faces for N frames in the video. Finally we chose the shortest use time FaceBlaze was used to extract faces and then we used a ResNet model similar to CNN for training and verification but our method did not perform well. Because traditional image forensics technology is usually not suitable for video and compression will seriously reduce the quality of the data. Unlike Inception v4 ResNext does not require manual design of complex Inception structural details but each branch uses the same topology. One of its most influential applications DeepFake is very advanced. Therefore it is very necessary to do some work to identify these fake content generated by algorithms through technical means which is a crucial part of solving the problems caused by deepfake described above. The reason for this is that residual learning is easier than direct learning of original features. It does not completely assign each channel to an independent convolution kernel or the entire Feature Map. YOLO did not show the process of obtaining the region proposal. The above work has achieved quite good results but deepfake is also making progress. Then a framework for using deep learning methods to detect these deepfake videos is proposed a convolutional neural network architecture is trained on the face database extracted from the FaceForensics and DeepFakeDetection datasets. Private test set This data set is private outside the Kaggle platform and is used to calculate private rankings. Of course you can also build a deeper network. I did this intentionally because the model can t get most of the private validation set right based on LB Find the faces for N frames in the video. Related WorkSince the development of deepfake even the detection of deepfake has long become a hot research topic. Conclusion and Future WorksIn the whole work we first tried to segment the video data set and divide the data set into pictures. The architecture of DeepfakeStack includes two or more basic learners called level 0 models and a meta learner called level 1 model which combines the predictions of these level 0 models. Our work is also based on deep learning. After the features are input to the three convolutional layers of the result the network uses a face classifier to determine whether the region is a face and uses border regression and a face key point. Both YOLO training and detection are performed in a separate network. Optionally a fully connected layer can be inserted before the logistic regression layer. Initialize MTCNNMTCNN Multi task convolutional neural network is a multi task neural network model for face detection tasks proposed by Shenzhen Research Institute of Chinese Academy of Sciences in 2016. Yuming Yao 2032754Dataset https www. Its basic structure is a convolutional neural network. used the Resnet model for training and prediction and at the same time using Resnetx and Xception pre trained models to perform predictions. 65 and the AUC can reach 1. The difference is that what we do has the following characteristics. This is a user named Deepfakes in a community who grafted the face of Wonder Woman Gal Gadot to the heroine of an adult movie and uploaded the video to the website. Because regression and machine learning are both based on mathematical function methods when categorical data appears in the data set we want to analyze the data at this time is not ideal because we cannot process them mathematically. It can not only ensure the accuracy of detection but also the fast reasoning speed can reach the sub millisecond level in the general mobile phone CPU. Petersburg and Moscow Russia 2020 pp. It is a more complex convolutional network with more input features. Obviously we need further research to combat deepfake. Why it can have such high performance One is the design of the backbone network which uses the depthwise convolution of the large receptive field and 1x1 convolution kernel to speed up the features and uses the nested single blaze method to increase the expression of the model ability the second is because of the design of the detection regression. It achieved 5 first results in ILSVRC and COCO 2015. The second is Xception which is another improvement to Inception v3 proposed by Google after Inception. com kaggle docker python For example here s several helpful packages to load linear algebra data processing CSV file I O e. We intercept a certain frame or a few frames in each video as input for training and detection as shown in the following figureNext we show the photos in the training setIn the selection of extraction methods we have chosen four face extraction methods BlazeFace MTCNN MobileNet and YOLO. First identify the false content and then we can better prevent warn and punish. are analyzing the following methods two convolutional neural network CNN architectures namely Meso 4 and MesoInception 4 Convolutional LSTM network the former extracts frame level features the latter performs sequence processing and sends the dense layer and finally determines whether the video is real or fake. Depth level separable convolution is actually a factorized convolutions which can be decomposed into two smaller operations depthwise convolution and pointwise convolution. Compared with Inception V3 in terms of classification performance Xception has a smaller lead on ImageNet but is much ahead of JFT in terms of parameters and speed Xception has fewer parameters than Inception but is faster. At that time DeepFake made its first appearance in the adult exchange community of the American social news website Reddit and it caused a lot of shock. Based on a single end to end network complete the input from the original image to the output of the object position and category. First look at Resnet. Grouped convolution is a compromise between the depth of the ordinary convolution kernel and the separable convolution. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python Docker image https github. We changed the model chose the pre trained Rest and Xception and we got the best results on Rest. BlazeFace only cascades 2 scale features for face detection and each point uses only two anchors under 16x16 features and each point uses 6 anchors under 8x8 features. Load DataFirst we need to declare the path of training and test samples and metadata files this is just a small part of it more training data we will show later View the number of samples in the test and training set Load metadataAnalyze the number of true and false videos in the training set and describe them with pie charts and histograms respectivelyIn this histogram we find that only 19 of the samples are real videosThe training samples have two resolutions 1080x1920 and 1920x1080. Video data analysis 3. Public test set This data set is completely rejected and the Kaggle platform calculates the public ranking. Ivanenko Combining Deep Learning and Super Resolution Algorithms for Deep Fake Detection 2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering EIConRus St. This part will eventually output a lot of face areas that may have faces and input these areas into R Net for further processing. A comparison of several ways of extracting faces such as MTCNN BlazeFace YOLO etc. The full name of R Net is Refine Network. The complete training set exceeds 470GB. The proposal of the Deep Residual Network ResNet is a milestone event in the history of CNN images. The input of the predictor is the data set provided by the DFDC challenge and the Resnext and Xception neural network algorithms are used to detect real and fake faces. Due to its large size it must be accessed through the GCS bucket. Only look at one face per frame. In addition the model has been tested on various interpretable artificial intelligence technologies such as LRP and LIME to provide a clear visualization of the salient areas of the image focused by the model 4. This model mainly uses three cascaded networks and uses the idea of candidate box plus the classifier is to perform fast and efficient face detection. Therefore it is necessary to combine other technologies to study and solve the deepfake problem. Corresponds to an input channel so depthwise convolution is a depth level operation. YOLO solves object detection as a regression problem. What I want to do this time is to detect the fake faces generated by deepfake. In the end we found that BlazeFace has the fastest detection speed and the Resnetx model AUC can reach 0. At the end of the network structure there is also a larger 256 fully connected layer which retains more image features and at the same time performs face discrimination and human face area border regression and face feature positioning and finally output the coordinates of the upper left corner and the lower right corner of the face area and the five feature points of the face area. Public verification set The submitted file output generation will be based on a small set of 400 videos id included in this public verification set. In studying the problem of image classification the basis of convolution will follow the logistic regression layer. Sung DeepfakeStack A Deep Ensemble based Learning Technique for Deepfake Detection 2020 7th IEEE International Conference on Cyber Security and Cloud Computing CSCloud 2020 6th IEEE International Conference on Edge Computing and Scalable Cloud EdgeCom New York NY USA 2020 pp. Obviously from the perspective of frame resolution this challenge will require a lot of resources. We show the effect of our work by drawing the ROC curve. Initialize BlazeFaceFirst look at BlazeFace. Training set This data set contains target labels which can be downloaded outside of Kaggle for competitors to build their models. YOLO model training is divided into two steps one is pre training using data to train the first 20 convolutional layers of the YOLO network 1 average pooling layer 1 fully connected layer. pyplot glob cv2 torch and tensorflow in python. It contains videos of similar format and nature to the training and public verification test sets but real organic videos with or without deepfakes. First we need to create a variable encoder_x for encoding and then when the program is executed these Fake and Real category data are converted into values 0 and 1. Compared with R Net there is one more convolutional layer. The output of this layer is used as the final network model output. For example when processing Fake or Real data we replace them with 0 and 1 and then analyze. Derakhshani Eyebrow Recognition for Identifying Deepfake Videos 2020 International Conference of the Biometrics Special Interest Group BIOSIG Darmstadt Germany 2020 pp. proposed an automatic and efficient method for detecting face tampering in videos based on DeepFake and Face2Face which can generate fake videos that cannot be distinguished by the human eyes. There are 4 data sets related to this competition. The pointwise convolution is actually an ordinary convolution but it uses a 1x1 convolution kernel. The area under the ROC curve is the value of AUC. read_csv Input data files are available in the read only. Another difference from Inception v4 is that ResNeXt first performs 1 1 convolution and then performs unit addition. On the other hand this problem is considered to be more complex and requires other connections beyond vision 1. Compared with ordinary networks ResNet adds a short circuit mechanism between every two layers which forms residual learning. With the continuous improvement of the deepfake algorithm one can expect that the altered image artifacts will disappear. It is not clear whether the private test will be the same release. O Net is called Output Network. In order to improve the image accuracy when training the detection model the input image resolution is resized to 448x448. The running speed of ResNeXt of similar structure should be better than Inception V4 because the design of the branch of the same topology of ResNeXt is more in line with GPU hardware design principles. The difference is that YOLO does not use the inception module but uses 1x1 convolutional layer here 1x1 convolutional layer exists for cross channel information integration 3x3 convolutional layer simple replacement. When training and testing the number of frames of each video is 297 299 and 298 299 of which 299 is the most frequent. The Xception architecture has 36 convolutional layers which form the basis of the feature extraction of the network. Changing faces is never perfect. Although ResNet wins by depth there are tricks in its architecture which makes the depth of the network play a role. Use the same convolution kernel. 1109 CSCloud EdgeCom49738. Then analyze the residual unit ResNet uses two residual units shallow network and deep network. The idea of grouped convolution is derived from Inception. Compared with the first layer of P Net a fully connected layer is added so the input data will be more stringent. Collect training image size View the first frame of the first 10 videos Sample size distribution \u8bfb\u53d6\u89c6\u9891 \u83b7\u53d6\u6807\u7b7e \u83b7\u53d6\u7b2c\u4e00\u5e27 u3000\u5c55\u793a\u7b2c\u4e00\u5e27\u89c6\u9891 \u63d0\u53d6\u8138\u90e8\u56fe\u7247 That constant describe pieces for 16 9 images fast less accurate slower more accurate 9 16 respectively Face Detection The value below are both the number of frames Frame rate Resolution Width Resolution Height Total number of frames Duration unit s import keras. We keep the aspect ratio intact and add zero padding if necessary. This is why the first data sets containing generated fake videos appeared. In principle it can turn the protagonist of the video into anyone. When the network is deeper it performs residual learning between three layers three layer volume The product cores are 1x1 3x3 and 1x1. Its first appearance at the end of 2017 caused a sensation. com c deepfake detection challenge 1. zip on the Kaggle data page. After uploading this fake video to this website it caused a lot of discomfort. Make a prediction then take the average. Resize to the model s required input size. In order to balance performance and accuracy MTCNN avoids the huge performance consumption caused by traditional ideas such as sliding window plus classifier first use a small model to generate a certain possibility of target area candidate frame then use more complex models for fine classification and higher precision area box regression and let this step be executed recursively this idea forms a three layer network namely P Net R Net and O Net to achieve fast and efficient face detection. It is worth noting that the number of feature maps in the hidden layer is relatively small and it is 1 4 of the number of output feature maps. pyplot glob cv2 torch tensorflow\u7b49package 6. In the training data whether the video is forged by deepfake is determined by the string REAL or FAKE in the label column. The YOLO network draws on the GoogLeNet classification network structure. Echizen MesoNet a Compact Facial Video Forgery Detection Network 2018 IEEE International Workshop on Information Forensics and Security WIFS Hong Kong Hong Kong 2018 pp. Usually the solution approach uses visible artifacts which is common in most deepfakes. Finally combined with the residual network the final ResNext is obtained. The above three algorithms are the algorithms used in this work. DeepfakeStack 5 is a deep ensemble learning technology that combines a series of the latest classification models based on deep learning and creates an improved combined classifier. ResNeXt does have fewer hyperparameters than Inception V4 but it does not seem to be very reasonable to directly abolish Inception s characteristics of including different receptive fields. But when the dimensions are inconsistent corresponding to double the dimensions this cannot be added directly. This is a very efficient and lightweight face detector. The difference between the effect of O Net and R Net is that this layer of structure will recognize the area of the face through more supervision and will regress the facial feature points of the person and finally output five facial feature points. Unlike Inception which requires manual design of each branch the topology of each branch of ResNeXt is the same. The most used research on this type of problem is directly based on machine learning and deep learning for recognition and detection but recently integrated learning has been proposed to further improve the recognition accuracy. In fact this structure has been used in the Inception model before. In the next work we will try to do some work similar to the DeepfakeStack deep integration learning algorithm to achieve better recognition results and find the optimal integration strategy. LabelEncoder is a function in the scikit learn package. Another is ResNext which is a combination of ResNet and Inception. When you submit the competition from the output file of the submitted notebook containing the competition data set your code will rerun in the background and when the retest is completed the score will be posted on the public leaderboard. For depthwise separable convolution it first uses depthwise convolution to convolve different input channels separately and then uses pointwise convolution to combine the above outputs so that the overall effect is similar to a standard convolution but it will greatly reduce the calculation quantity and model parameter quantity. The above described depthwise separable convolution which is the basic component of MobileNet but batchnorm will be added to the real application and the ReLU activation function will be used. Next let s look at the work that has made some research progress in this area. NOTE When running on the CPU the batch size must be fixed or else memory usage will blow up. Experiments and Results MesoNet\u73b0\u5728\u6211\u4eec\u4f7f\u7528MesoNet\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3 \u5728\u8fd9\u4e4b\u524d\u6211\u4eec\u505a\u4e86\u6570\u636e\u96c6\u7684\u4e00\u4e9b\u5206\u6790 \u53d1\u73b0\u8fd9\u5e76\u4e0d\u662f\u4e00\u4e2a\u5747\u8861\u7684\u6570\u636e\u96c6 \u4e3a\u6b64\u6211\u4eec\u91c7\u7528\u4e86\u4e0b\u91c7\u6837\u7684\u65b9\u5f0f\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u5904\u7406 \u901a\u8fc7K 5\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65b9\u5f0f\u8fdb\u884c \u5e76\u901a\u8fc7log_loss\u4f5c\u4e3a\u8bad\u7ec3\u7ed3\u679c\u8bc4\u4f30\u7684\u6807\u51c6 \u51c6\u786e\u7387\u5728\u6d4b\u8bd5\u96c6\u4e0a\u5927\u7ea6\u670960 \u4ee5\u4e0a\u7684\u6b63\u786e\u7387 \u6211\u4eec\u53d1\u73b0\u81ea\u5df1\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u6548\u679c\u5e76\u4e0d\u51fa\u8272 \u6211\u60f3\u8fd9\u4e0e\u6211\u4eec\u6570\u636e\u96c6\u7684\u4f7f\u7528\u4e0d\u591f\u79d1\u5b66\u6709\u5173 \u4e3a\u6b64\u6211\u4eec\u5c1d\u8bd5\u4e86\u5176\u4ed6\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u9884\u6d4b \u901a\u8fc7\u5b9e\u9a8c\u53ef\u4ee5\u8868\u660e \u76f8\u5bf9\u6bd4MesoNet Xception\u548cResnext Resnext\u7684\u8868\u73b0\u7ed3\u679c\u662f\u6700\u597d\u7684 \u5728\u8fd9\u4e4b\u524d\u6211\u4eec\u4e5f\u5df2\u7ecf\u4ecb\u7ecd\u4e86Resnext\u548cXception\u7684\u7f51\u7edc \u4e0b\u9762\u6211\u4eec\u4f1a\u901a\u8fc7\u5bf9\u8fd9\u4e24\u4e2a\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u9884\u6d4b \u5e76\u901a\u8fc7AUC\u8fdb\u884c\u8bc4\u4f30 Resnext ModelWhen using regression models and machine learning models all the survey data are numerical values to make it easier to get good results. This network will filter out a large number of candidate frames with poor results and finally perform Bounding Box Regression and NMS on the selected candidate boxes to further optimize the prediction results. For a stacked layer structure several layers stacked when the input is x the learned feature is recorded as H x and now I hope it can learn the residual F x H x x so the original learning feature is F x x. Using high level libraries such as Keras or TensorFlow Slim only requires 30 to 40 lines of code which is different from architectures such as VGG 16 but is much more complicated to define than architectures such as Inception V2 or V3. The structure of Xception is based on ResNet but the convolutional layer is replaced with Separable Convolution. MethodsIn this part we will introduce the related algorithms used in this work mainly Resnet Xception and ResNext. Here are the main columns filename the file name of the video label whether the video is real or fake original if the video of the training set is fake the original video is listed here split this is always equal to training. The change is mainly reflected in ResNet directly using stride 2 convolution for downsampling and replacing the fully connected layer with the global average pool layer. We use AUC ROC Area Under Curve to measure the quality of machine learning models. The level 1 model is trained based on the predictions made by the basic model of out of sample data. backend as K This is not a bug. For the image pyramid constructed in the previous step an FCN is used to perform preliminary feature extraction and frame calibration and perform the Bounding Box Regression adjustment window and NMS to filter most of the windows. AUC ROC is a commonly used evaluation index for classifiers in machine learning. The 36 convolutional layers are constructed into 14 modules all of which have linear residual connections around them except for the first and last modules. Here is another introduction to the training set. There is also grouped convolution. Resize the training image resolution to 224x224 then use the first 20 convolutional layer network parameters obtained in step 1 to initialize the network parameters of the first 20 convolutional layers of the YOLO model and then use the VOC 20 type of annotation data for YOLO model training. This is one of the earlier work done in deepfake detection. The essence of ResNeXt is Group Convolution which controls the number of groups by variable cardinality. Test time augmentation horizontal flips. Based on training meta learners on top of pre trained basic learners and provide an interface to adapt meta learners according to the predictions of basic learners and show how the integrated technology performs classification tasks. You can use the pooling with strde 2 so that no parameters will be added 2 Use a new mapping projection shortcut Generally a 1x1 convolution is used which will increase the parameters and increase the amount of calculation. The full name of P Net is Proposal Network and its basic structure is a fully convolutional network. We send all the prediction windows to R Net. This work is to protect people s personal rights safeguard the people s legitimate interests and maintain the stable development of society which is extremely beneficial. P Net is a region suggestion network for the face region. The basic structure is a more complicated convolutional neural network. O Net has more characteristic input and more complex network structure and also has better performance. When the residual is 0 the stacked layer only does the identity mapping at this time at least the network performance will not decrease in fact the residual will not be 0 which will also make the stacked layer learn new features based on the input features for better performance. The official has provided 50 small data sets after segmentation. The three cascaded networks are P Net for quickly generating candidate windows R Net for filtering and selecting high precision candidate windows and O Net for generating final bounding boxes and face key points. In this work we use LabelEncoder to implement the above conversion process. The specific diagram will be given in detail in the next part. calculate the fpr and tpr for all thresholds of the classification method I plt. Xception\u4ee5\u4e0a\u4e09\u79cd\u7b97\u6cd5\u5c31\u662f\u672c\u6b21\u5de5\u4f5c\u4e2d\u7528\u5230\u7684\u7b97\u6cd5 \u6211\u4eec\u4f7f\u7528AUC ROC Area Under Curve \u6765\u8861\u91cf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8d28\u91cf\u7684\u6307\u6807 AUC ROC\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u5e38\u7528\u7684\u4e00\u4e2a\u5206\u7c7b\u5668\u8bc4\u4ef7\u6307\u6807 \u5176\u89c4\u5219\u7528\u4e00\u53e5\u8bdd\u6982\u62ec\u5c31\u662f \u4e00\u4e2a\u6b63\u4f8b \u4e00\u4e2a\u8d1f\u4f8b \u9884\u6d4b\u4e3a\u6b63\u7684\u6982\u7387\u503c\u6bd4\u9884\u6d4b\u4e3a\u8d1f\u7684\u6982\u7387\u503c\u8fd8\u8981\u5927\u7684\u53ef\u80fd\u6027 \u6211\u4eec\u901a\u8fc7\u7ed8\u5236ROC\u66f2\u7ebf\u6765\u4f53\u73b0\u6211\u4eec\u7684\u5de5\u4f5c\u6548\u679c ROC\u66f2\u7ebf\u4e0b\u9762\u7684\u9762\u79ef\u5c31\u662fAUC\u7684\u503c \u5177\u4f53\u56fe\u793a\u4f1a\u5728\u4e0b\u4e00\u90e8\u5206\u8be6\u7ec6\u7ed9\u51fa \u5bf9\u4e8e\u4e0a\u9762\u63d0\u5230\u7684\u6a21\u578b\u7684\u8bad\u7ec3 \u6211\u4eec\u4f7f\u7528\u4e86python\u4e2d\u7684numpy pandas matplotlib. Because of this situation we need a way to digitize text to preprocess the training data. In order to find a solution to this problem relevant researchers have actively explored relevant research strategies and made many attempts. input directory For example running this by clicking run or pressing Shift Enter will list all files under the input directory You can write up to 20GB to the current directory kaggle working that gets preserved as output when you create a version using Save Run All You can also write temporary files to kaggle temp but they won t be saved outside of the current session \u52a0\u8f7d\u8bad\u7ec3\u89c6\u9891\u7684\u6587\u4ef6\u540d \u52a0\u8f7d\u6d4b\u8bd5\u89c6\u9891\u7684\u6587\u4ef6\u540d Equal aspect ratio ensures that pie is drawn as a circle. In fact ResNet solved the deep CNN model. 0 can get good results. Its rules are summarized in one sentence a positive example a negative example the probability that the prediction is positive is greater than the probability that the prediction is negative. If it is allowed to continue the consequences will be disastrous. The accuracy of DeepfakeStack can reach 99. Kazi Explainable Deep Fake Detection Using Visual Interpretability Methods 2020 3rd International Conference on Information and Computer Technologies ICICT San Jose CA USA 2020 pp. The current work is based on machine learning deep learning and deep integrated learning to identify and detect deepfakes. 98 which is a good data. Compared with the 1x1x32 feature of P Net using full convolution output R Net uses a 128 fully connected layer after the last convolution layer which retains more image features and the accuracy performance is also better than P Net. The use of exchanged face resolution mismatches and affine transformations leads to the existence of fake images a CNN is trained to capture these features and match. Inception V4 performs splicing and then performs 1 1 convolution. It is divided into 50 files for easy access and download. This trick is Residual Learning. IntroductionThe continuous development of science and technology enables deep learning DL models to be applied to a variety of applications. Therefore this paper follows the method of deep learning and proposes two networks both with fewer layers to focus on the mesoscopic properties of the image 2. For short circuit connection when the input and output dimensions are the same the input can be directly added to the output. There are two strategies 1 Use zero padding to increase the dimension. In this case the researchers decided to find a method of deepfake detection to protect people from this huge danger. This makes the architecture very easy to define and modify. Obvious distortions and blurring of the surrounding facial areas usually expose them. In principle DeepFake uses one of the most well known deep learning algorithms GANs. Further other researchers can add other parts to this work to enhance the recognition effect. It performs very well in face detection tasks in close up frontal scenes. Since the main task of the algorithm is the detection of positive faces in most cases the anchor with a ratio of 1. First let s look at some related work directly based on machine learning and deep learning. In the case of uncomplicated data distribution both it can solve problems and increase the speed of network reasoning which makes BlazeFace efficient and lightweight Initialize YoloYOLO its full name is You Only Look Once which basically summarizes the characteristics of YOLO completely that is only one CNN operation is required. Ability to Detect Face Accuracy ComparisonBlue BlazeFaceRed MobilenetGreen MTCNNPurple YOLO Cropped Images BlazeFace MTCNN Mobilenet YOLO Extra Comparisons 4. In addition to directly using identity mapping for short circuit connections of course projection shortcuts can be used. Bug in PyTorch If we found any faces prepare them for the model. In general ResNeXt proposes a strategy of separable convolution between the depth of the ordinary convolution kernel grouped convolution which achieves a balance between the two strategies by controlling the number of groups base. Of course this is only one of many bad influences and there are many evil or illegal ways to use these fake content in propaganda political campaigns cyber crime blackmail etc. Such artifacts provide good accuracy for deepfakes to a large extent especially for relatively older fakes. The ResNet network is based on the VGG19 network modified on the basis of it and added a residual unit through a short circuit mechanism. Compared with a single machine learning and deep learning model deep ensemble learning shows better results in deepfake detection. In short the Xception architecture is a linear stack of deeply separable convolutional layers with residual connections. For the training of the model mentioned above we use packages such as numpy pandas matplotlib. Use residual learning to solve the degradation problem. At this time a downsamp is generally required. TODO not sure yet if this helps or not Preprocess the images. The problem of difficulty in training 14 years of VGG has only 19 layers and 15 years of ResNet has as many as 152 layers which is not an order of magnitude in network depth. For example Generative Adversarial Networks GAN models can produce super realistic images languages and even videos. Then we used 4 face detection methods and compared its running time. Therefore the biometrics of the exchange components may be more preferable than marking forged images. The convolution machine is a compromise between ordinary convolution and depth separable convolution that is the number of channels of the Feature Map generated by each branch is n n 1. Initialize MobilenetFaceMobileNet which is a small and efficient CNN model proposed by Google has a compromise between accuracy and latency. That is to say the data not used for training the basic model is provided to the basic model to make predictions and these predictions and the expected output provide input and output pairs of the training data set used to fit the meta model. Because the output of P Net is only a possible face area with a certain degree of credibility in this network the input will be refined and selected and most of the wrong input will be discarded and again use the border regression and facial key point locator to carry out the border regression and key point positioning of the face area and finally outputs a more credible face area for O Net. We do it on the original video data set. x i x i 255. In 3 they focused on the problem of detecting fake faces by matching falsely replaced face components specifically by matching the eyebrow region to detect fake phenomena. For 18 layer and 34 layer ResNet it performs residual learning between two layers. It is found that Inception V4 is better than ResNeXt in more environments. The most successful method is based on blinking eyes mismatched color profiles and facial distortion artifacts. For example the so called deep forgeries made by GANs Generative Adversarial Networks manipulating audio or video clips are too close to real content to be distinguished from real images in human perception. An important design principle of ResNet is when the size of the feature map is reduced by half the number of feature maps doubles which maintains the complexity of the network layer. Problem FormulationIn this work the data set we selected is a competition on Kaggle Deepfake Detection Challenge DFDC which is the data set provided by the Deepfake synthetic face detection competition. The locator is used to make the initial proposal of the face area. After the picture passes through the P Net many prediction windows will be left. Depthwise convolution is different from standard convolution. Reddit officially banned the face changing video produced and uploaded by Deepfakes for inappropriate content and infringed on the privacy of others. In general its core is the use of decomposable depthwise separable convolution which can not only reduce the computational complexity of the model but also greatly reduce the model size. It was at that time that offensive deepfakes and defensive detection methods began to compete. The basic unit of MobileNet is depthwise separable convolution. For standard convolution the convolution kernel is used on all input channels while depthwise convolution uses different convolution kernels for each input channel that is a convolution kernel. In general YOLO has the characteristics of fast speed low background false detection rate and strong versatility. ", "id": "fangxina/dfdc-yuming-yao", "size": "30551", "language": "python", "html_url": "https://www.kaggle.com/code/fangxina/dfdc-yuming-yao", "git_url": "https://www.kaggle.com/code/fangxina/dfdc-yuming-yao", "script": "MobileNetV2 albumentations keras.layers BlazeFace Lambda make_square_image get_yolo_face predict_on_video_set predict_on_video get_boxes_points tqdm_notebook keras.callbacks larger_range FaceExtractor matplotlib.pyplot check_answers VideoReader get_label Model get_blaze_boxes torch.nn.functional get_frame torchvision.models get_mtcnn_face keras Pooling(nn.Module) get_blazeface_face crop_image tensorflow.keras.models process_file correct_precentile torch.nn FuncAnimation non_max_suppression blazeface tensorflow schedule get_model transpose_shots pandas gather_info detect visualize_frame torchvision.transforms isotropically_resize_image prediction_pipline ZeroPadding2D InceptionLayer = tf.compat.v1.GraphDef Head(torch.nn.Module) FCN(torch.nn.Module) union_suppression read_img tqdm_notebook as tqdm numpy func matplotlib.animation get_original_filename keras.backend ThreadPoolExecutor mtcnn load_mobilenetv2_224_075_detector keras.optimizers shuffle read_video_1 tqdm.notebook Conv2D ArtistAnimation FaceDetector() MyResNeXt(models.resnet.ResNet) face_extract_1 LabelEncoder sklearn.metrics train_test_split tensorflow.keras.applications.mobilenet_v2 get_path MTCNN tensorflow.keras.layers LearningRateScheduler define_model seaborn Dense sigmoid concurrent.futures tqdm get_mobilenet_face Sequential Normalize forward sklearn.model_selection annotate_image Input pytorchcv.model_provider scale_boxes __init__ log_loss sklearn.preprocessing ", "entities": "(('locator', 'face area'), 'use') (('AUC ROC', 'machine learning'), 'be') (('CNN only one operation', 'YOLO'), 'solve') (('ResNet', 'CNN deep model'), 'solve') (('most', 'O Net'), 'refine') (('Reddit', 'others'), 'ban') (('which', 'model also greatly size'), 'be') (('ResNet', 'two residual units'), 'analyze') (('F H learning residual so original feature', 'H x'), 'stack') (('actually ordinary it', 'convolution 1x1 kernel'), 'be') (('YOLO model training', 'pooling YOLO network 1 average layer'), 'divide') (('pyplot', 'cv2 torch tensorflow\u7b49package'), 'glob') (('output', 'network model final output'), 'use') (('CNN', 'features'), 'lead') (('DL deep learning models', 'applications'), 'enable') (('first appearance', 'sensation'), 'cause') (('principle DeepFake', 'algorithms most well known deep learning GANs'), 'use') (('point', '8x8 features'), 'cascade') (('that', 'area'), 'let') (('Here introduction', 'training set'), 'be') (('official', 'segmentation'), 'provide') (('I', 'classification method'), 'calculate') (('Derakhshani Eyebrow Recognition', 'Biometrics Special Interest Group BIOSIG Darmstadt Germany'), 'pp') (('Inception V4', 'then 1 1 convolution'), 'perform') (('video', 'label column'), 'determine') (('Group which', 'variable cardinality'), 'be') (('we', 'pandas such numpy matplotlib'), 'use') (('then we', 'better warn'), 'identify') (('Generative Adversarial Networks GAN models', 'images super realistic languages'), 'produce') (('it', 'different receptive fields'), 'have') (('We', 'zero padding'), 'keep') (('value', 'Resolution Width Height frames Duration import Total keras'), 'collect') (('also stacked layer', 'better performance'), 'be') (('we', '0'), 'replace') (('second', 'detection regression'), 'have') (('Further other researchers', 'recognition effect'), 'add') (('0 meta 1 which', 'level 0 models'), 'include') (('input', 'directly output'), 'for') (('neural network convolutional architecture', 'FaceForensics datasets'), 'propose') (('Such artifacts', 'especially relatively older fakes'), 'provide') (('we', 'training data'), 'need') (('which', 'data face detection Deepfake synthetic competition'), 'FormulationIn') (('layer product three cores', 'three layers'), 'perform') (('input data', 'P Net'), 'add') (('which', 'Inception such V2'), 'require') (('We', 'ROC curve'), 'show') (('It', 'convolution independent kernel'), 'assign') (('competitors', 'models'), 'set') (('which', 'network'), 'have') (('level 1 model', 'sample data'), 'train') (('main task', '1'), 'be') (('t', 'video'), 'do') (('YOLO network', 'GoogLeNet classification network structure'), 'draw') (('most successful method', 'color profiles'), 'base') (('layer', 'feature finally five facial points'), 'be') (('specific diagram', 'next part'), 'give') (('Initialize MTCNNMTCNN Multi neural task convolutional network', '2016'), 'be') (('region', 'border regression'), 'be') (('design', 'GPU hardware design principles'), 'be') (('numerical it', 'good results'), 'Experiments') (('which', 'ResNet'), 'be') (('full name', 'P Net'), 'be') (('challenge', 'resources'), 'require') (('we', 'them'), 'want') (('how integrated technology', 'classification tasks'), 'base') (('Initialize BlazeFaceFirst', 'BlazeFace'), 'look') (('it', 'shock'), 'make') (('read_csv Input data files', 'read'), 'be') (('relatively it', 'output feature maps'), 'be') (('which', 'network depth'), 'have') (('separable that', 'branch'), 'be') (('We', 'machine learning models'), 'use') (('Obviously we', 'deepfake'), 'need') (('they', 'fake phenomena'), 'focus') (('data why first sets', 'generated fake videos'), 'be') (('final ResNext', 'Finally residual network'), 'obtain') (('Net', 'network more complex also better performance'), 'have') (('basis', 'regression logistic layer'), 'follow') (('Grouped convolution', 'convolution ordinary kernel'), 'be') (('learning 5 deep ensemble that', 'improved combined classifier'), 'be') (('we', 'face extraction four methods'), 'intercept') (('idea', 'Inception'), 'derive') (('It', 'ILSVRC'), 'achieve') (('that', 'input channel'), 'use') (('finally video', 'dense layer'), 'analyze') (('new updated', 'video'), 'have') (('ResNeXt', 'unit then addition'), 'be') (('Xception short architecture', 'residual connections'), 'be') (('which', 'deepfake'), 'be') (('depthwise convolution', 'input channel'), 'correspond') (('ResNet network', 'circuit short mechanism'), 'base') (('batchnorm', 'real application'), 'describe') (('Inception V4', 'more environments'), 'find') (('DeepFake', 'most influential applications'), 'one') (('depth', 'role'), 'be') (('34 it', 'two layers'), 'for') (('whole we', 'pictures'), 'conclusion') (('who', 'website'), 'be') (('downsamp', 'time'), 'require') (('which', 'network layer'), 'be') (('First s', 'machine directly learning'), 'let') (('residual learning', 'original features'), 'be') (('which', 'Inception'), 'be') (('researchers', 'huge danger'), 'decide') (('actually factorized which', 'convolution'), 'be') (('reasoning also fast speed', 'mobile phone general CPU'), 'ensure') (('data set', 'neural network Resnext real faces'), 'be') (('which', 'calculation'), 'use') (('learning deep deep ensemble learning', 'deepfake detection'), 'show') (('This', 'deepfake detection'), 'be') (('LabelEncoder', 'package'), 'be') (('it', 'GCS bucket'), 'access') (('it', 'anyone'), 'turn') (('i', 'verification public set'), 'set') (('Then we', 'running time'), 'use') (('prediction', 'probability'), 'summarize') (('image altered artifacts', 'deepfake algorithm'), 'expect') (('It', 'kaggle python Docker image https github'), 'come') (('MethodsIn part we', 'work'), 'introduce') (('convolutional layer', 'Separable Convolution'), 'base') (('which', 'accuracy'), 'have') (('Private test', 'private rankings'), 'set') (('Of course this', 'propaganda political campaigns'), 'be') (('current work', 'deep integrated deepfakes'), 'base') (('here 1x1 convolutional layer', 'channel information cross integration 3x3 convolutional layer simple replacement'), 'be') (('We', 'R Net'), 'send') (('method', 'training'), 'choose') (('structure', 'Inception model'), 'use') (('Ability', 'Face Accuracy ComparisonBlue'), 'BlazeFaceRed') (('offensive deepfakes', 'time'), 'be') (('which', 'society'), 'be') (('YOLO', 'region proposal'), 'show') (('we', 'integration optimal strategy'), 'try') (('all', 'first modules'), 'construct') (('predictions', 'meta model'), 'be') (('category Fake data', 'values'), 'need') (('BlazeFace', 'Resnetx 0'), 'find') (('so called deep forgeries', 'human perception'), 'be') (('which', 'groups base'), 'propose') (('YOLO', 'regression problem'), 'solve') (('input image resolution', '448x448'), 'resize') (('which', 'most deepfakes'), 'use') (('Therefore it', 'deepfake problem'), 'be') (('problem', 'vision'), 'consider') (('Related development', 'even deepfake'), 'WorkSince') (('yet this', 'images'), 'sure') (('accuracy', '99'), 'reach') (('YOLO training', 'separate network'), 'perform') (('topology', 'ResNeXt'), 'be') (('basic unit', 'separable convolution'), 'be') (('usually video', 'data'), 'reduce') (('network', 'prediction further results'), 'filter') (('three cascaded networks', 'key points'), 'be') (('Therefore paper', 'image'), 'follow') (('do', 'following characteristics'), 'be') (('Of course you', 'also deeper network'), 'build') (('recursively idea', 'P Net R face namely fast detection'), 'avoid') (('accuracy performance', 'P also Net'), 'use') (('we', 'Rest'), 'change') (('which', 'residual learning'), 'add') (('it', 'consequences'), 'be') (('projection shortcuts', 'course'), 'use') (('here this', 'always training'), 'be') (('deepfake', 'also progress'), 'achieve') (('this', 'inconsistent dimensions'), 'be') (('Therefore biometrics', 'more forged images'), 'be') (('model', 'face fast detection'), 'use') (('Depthwise convolution', 'standard convolution'), 'be') (('It', 'close frontal scenes'), 'perform') (('Kaggle completely platform', 'public ranking'), 'set') (('want', 'deepfake'), 'be') (('It', 'verification test public real organic deepfakes'), 'contain') (('299', '298 299 which'), 'be') (('also larger 256 fully connected which', 'feature face five area'), 'be') (('FCN', 'windows'), 'use') (('it', 'discomfort'), 'cause') (('It', 'input more complex convolutional more features'), 'be') (('memory usage', 'When CPU'), 'fix') (('picture', 'prediction P Net many windows'), 'leave') (('above three algorithms', 'work'), 'be') (('AUC ROC\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u5e38\u7528\u7684\u4e00\u4e2a\u5206\u7c7b\u5668\u8bc4\u4ef7\u6307\u6807', '\u4e00\u4e2a\u6b63\u4f8b \u4e00\u4e2a\u8d1f\u4f8b \u9884\u6d4b\u4e3a\u6b63\u7684\u6982\u7387\u503c\u6bd4\u9884\u6d4b\u4e3a\u8d1f\u7684\u6982\u7387\u503c\u8fd8\u8981\u5927\u7684\u53ef\u80fd\u6027 \u6211\u4eec\u901a\u8fc7\u7ed8\u5236ROC\u66f2\u7ebf\u6765\u4f53\u73b0\u6211\u4eec\u7684\u5de5\u4f5c\u6548\u679c \u5bf9\u4e8e\u4e0a\u9762\u63d0\u5230\u7684\u6a21\u578b\u7684\u8bad\u7ec3 pandas ROC\u66f2\u7ebf\u4e0b\u9762\u7684\u9762\u79ef\u5c31\u662fAUC\u7684\u503c \u5177\u4f53\u56fe\u793a\u4f1a\u5728\u4e0b\u4e00\u90e8\u5206\u8be6\u7ec6\u7ed9\u51fa \u6211\u4eec\u4f7f\u7528\u4e86python\u4e2d\u7684numpy matplotlib'), 'Area') (('full name', 'R Net'), 'be') (('P Net', 'region suggestion face region'), 'be') (('faces', 'model'), 'bug') (('pie', 'circle'), 'list') (('relevant researchers', 'many attempts'), 'explore') (('we', 'conversion above process'), 'use') (('It', 'easy access'), 'divide') (('score', 'public leaderboard'), 'rerun') (('videosThe training real samples', 'two resolutions'), 'need') (('recently integrated learning', 'recognition further accuracy'), 'base') (('proposal', 'CNN images'), 'be') (('Optionally fully connected layer', 'regression logistic layer'), 'insert') (('Obvious distortions', 'usually them'), 'expose') (('it', 'calculation greatly quantity'), 'use') (('pyplot', 'python'), 'glob') (('branch', 'same topology'), 'require') (('model', 'model'), 'test') (('that', 'human eyes'), 'propose') (('that', 'further processing'), 'output') (('area', 'AUC'), 'be') (('change', 'pool global average layer'), 'reflect') "}
{"name": "pokemon images autoencoder and gan in tensorflow ", "full_name": " h1 Pokemon Images Autoencoder and GAN h1 Importing the data as an array h1 Creating a supervised learning problem out of an unlabeled dataset h1 Convolutional Autoencoder h1 Application to image denoising h1 GANs h2 Define and Train the Discriminator Model h2 Create generator to generate real samples h2 Create generator to generate fake samples h2 Training the Generator Model h2 Evaluating GAN Model Performance ", "stargazers_count": 0, "forks_count": 0, "description": "Then I m going to feed those images through a convolutional autoencoder to train it. The other neural network called the discriminator evaluates them for authenticity Define and Train the Discriminator ModelFirst I m going to create a neural network that can discriminate between the real images and the fake images. I ll be doing this via the train_discriminator function and then the train_gan function. Importing the data as an arrayFirst I set up the base directory and find the number of pictures that I have. Below I m going to create a dataset of images with gaussian noise. Then it is reconstructed back to its original sizeFor this first autoencoder I m using a series of dense layers to encode and decode the images. Due to the adversarial nature of the training process the generator is changing after every batch. Finally I m going to test how well the autoencoder performed. I m going to do this by creating a new model that combines the generator and discriminator models. This is a binary classification task so the output layer will be composed of a single neuron with a sigmoid activation function. It will also return class labels for the sample specifically a class label of 1 to indicate real images. I will do this with the generate_latent_points functionNext I will define a generate_fake_samples function that returns both the generated samples and the associated class labelsI can then plot the generated samples by calling the imshow function. Below I can see the original images compared with the images fed through the autoencoder. The images are fuzzy and some of the color has been removed but the autoencoder is able to pick up on the main features. I m going to use convolutions because they perform better. Also I m going to use dropout for regularization. The discriminator model is updated once per batch by combining one half of a batch of fake and real examples into a single batch. Then I iterate through all of the images open them resize them to be 64x64x3 divide the pixel density by 255 so every pixel is in the range of 0 1 add them to an array of arrays and then split into the training and test set. Creating a supervised learning problem out of an unlabeled datasetI can take an unlabeled dataset and frame it as a supervised learning problem tasked with outputting x a reconstruction of the original input x. Since the model is not trained the generated images are complately random pixel values Training the Generator ModelThe weights in the generator model are updated based on the performance of the discriminator model. Therefore when the generator is trained as part of the GAN model I will mark the generated samples as real class 1 Here I can see the model expects the pokemon images as input and predicts a single value as output Evaluating GAN Model PerformanceCurrently there are no objective ways to evaluate the performance of a GAN model so the images must be subjectively evaluated for quality by a human operator. So I cannot know when to stop training without looking at examples of generated images. In order to handle this complex training situation I will periodically evaluate the classification accuracy of the discriminator on real and fake imagesperiodically generate many images and save them for subjective reviewperiodically save the generator modelFirst I will update the discriminator model with real and fake samples then update the generator via the composite model. After that I build and train a GAN. So once good enough images can be generated the subjective quality of the images may then begin to vary improve or degrade with subsequent updates. Therefore autoencoders are good at removing noise from images. I m setting the input shape as 64 64 3 so I will need to reshape my x_train and x_test back to a shape of 64 64 3. In order to improve the quality of the reconstructed I m going to use a slightly different model with more filters per layer GANsA Generative Adversarial Network GAN is an algorithmic architecture that uses two neural networks putting one against the other in order to generate new synthetic instances of data that can pass for real data. These fake samples will be createdThe generator model is responsible for creating new fake but plausible images by taking a point from the latent space as input and outputting a square grayscale image. When the discriminator model is good at detecting fake samples teh generator is updated more and when the discriminator model is relatively poor or confused when detecting fake samples the generator model is updated less. The first step is to generate new points in the latent space. When training the generator in this GAN model I want the discriminator to think that the samples output by the generator are real not fake. Below I can see that in this case the loss remains stable over the course of training. The latent space is an arbitrarily defined vector space of Gaussian distributed values. The array of random numbers can then be reshaped into samples which is n rows with 100 elements per row. A bottleneck constrains the amount of information that can traverse the full network forcing a learned compression of the input data. The generator model is only concerned with the discriminator s performance on fake samples. randn for generating arrays of random numbers drawn from a standard Gaussian. In this case the image which contains 12288 is fed through a bottleneck which contains only 32 neurons. This network can be trained by minimizing the reconstruction error L x x which measures the differences between the original input and the consequent reconstruction. Create generator to generate fake samplesNext I want to write a function that will generate fake samples. The reason for this is that a crash in the discriminator loss indicates that the generator model has started generating bad examples that the discriminator can easily discriminate. Finally I will report the loss each batch so I can keep an eye on the loss over batches. The generator model is not compiled and does not specify a loss function or optimization algorithm. Pokemon Images Autoencoder and GANIn this project I experiment with creating autoencoders using dense layers and convolutional pooling layers. The discriminator is only concerned with distinguishing between real and fake samples so it can be trained in a standalone manner on examples of each. I ll do this by stacking the generator and discriminator so that the generator receives as input random points in the latent space and generates samples that are fed into the discriminator model directly and then are classified and the output of this larger model can be used to update the model weights of the generator. Create generator to generate real samplesNow I m going to write a function that will take the training dataset as an argument and will select a random subsample of images. Next I m going to fit the model. One neural network called the generator generates new data instances. This can be done by calling np. Feed the test images which have never been seen before through the autoencoder. Then I use the autoencoder in order to remove gaussian noise from images. Then I use two Conv2D UpSampling2D layers to decode the image back to its original size. In order to compare different runs I m going to use tensorboard and the tensorboard_callback. Application to image denoisingSince the aim of an autoencoder is to learn a representation for a set of data the autoencoder needs to focus on the main features of the data. It has no meaning but by drawing points from this space randomly and providing them to the generator model during training the generator model will assign meaning to the latent points until at the end of training the latent vector space represents a compressed representation of the output space of pokemon images that only the generator knows how to turn into plausible pokemon images. Therefore I will mark all of the layers in the discriminator as not trainable when it is part of the GAN model so that they can not be updated and overtrained on fake examples. This is because the generator is not trained directly. The input is x_train and the output is also x_train since the goal is for the autoencoder to encode the images feed them through a bottleneck and then decode them to be as close as possible to the original image. I feed the original image through two Conv2D MaxPooling2D layers in order to encode the image down to 32 neurons. This will take the 64 64 3 images and feed them through a neural network. Convolutional AutoencoderNext I m going to test how a convolutional autoencoder will perform. ", "id": "lukemonington/pokemon-images-autoencoder-and-gan-in-tensorflow", "size": "8789", "language": "python", "html_url": "https://www.kaggle.com/code/lukemonington/pokemon-images-autoencoder-and-gan-in-tensorflow", "git_url": "https://www.kaggle.com/code/lukemonington/pokemon-images-autoencoder-and-gan-in-tensorflow", "script": "matplotlib.image pyplot keras define_generator define_gan train_gan Image generate_fake_samples numpy ImageOps train regularizers summarize_performance tensorflow train_discriminator matplotlib.pyplot generate_real_samples generate_latent_points PIL pandas define_discriminator tensorflow.keras ", "entities": "(('that', 'images'), 'create') (('classification output binary layer', 'activation sigmoid function'), 'be') (('pixel complately random Training', 'discriminator model'), 'be') (('directly then output', 'generator'), 'do') (('which', 'before autoencoder'), 'feed') (('generated samples', 'imshow function'), 'do') (('It', 'real images'), 'return') (('I', '64 64 3'), 'm') (('so I', 'batches'), 'report') (('m', 'gaussian noise'), 'go') (('that', 'input data'), 'constrain') (('loss', 'training'), 'see') (('I', 'train_discriminator function'), 'do') (('Below I', 'autoencoder'), 'see') (('autoencoder', 'main features'), 'be') (('I', 'composite model'), 'evaluate') (('This', 'neural network'), 'take') (('Then I', 'back original size'), 'use') (('I', 'dense layers'), 'Images') (('generator model', 'loss function'), 'compile') (('latent space', 'vector arbitrarily defined Gaussian distributed values'), 'be') (('that', 'generator models'), 'm') (('autoencoder', 'as possible original image'), 'be') (('One neural network', 'data new instances'), 'generate') (('autoencoder', 'data'), 'application') (('I', '32 neurons'), 'feed') (('generator model', 'relatively when fake samples'), 'update') (('they', 'convolutions'), 'm') (('first step', 'latent space'), 'be') (('which', 'only 32 neurons'), 'feed') (('that', 'fake samples'), 'want') (('subjective quality', 'subsequent updates'), 'generate') (('it', 'each'), 'be') (('they', 'fake examples'), 'mark') (('Also I', 'regularization'), 'm') (('I', 'that'), 'import') (('So I', 'generated images'), 'know') (('discriminator', 'that'), 'be') (('which', 'row'), 'reshape') (('discriminator model', 'single batch'), 'update') (('only generator', 'pokemon how plausible images'), 'have') (('samples output', 'generator'), 'want') (('Therefore autoencoders', 'images'), 'be') (('Then I', 'images'), 'use') (('that', 'real images'), 'call') (('that', 'real data'), 'be') (('Then I', 'it'), 'go') (('generator model', 'fake samples'), 'be') (('Creating', 'original input'), 'take') (('L which', 'original input'), 'train') (('createdThe generator model', 'grayscale square image'), 'be') (('generator', 'batch'), 'due') (('so pixel', 'then training'), 'iterate') (('images', 'human operator'), 'mark') (('first I', 'images'), 'reconstruct') "}
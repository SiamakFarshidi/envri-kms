{"name": "build your own cnn step by step and voting 0 997 ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "Choose how to add pool layer starting with the last convolution layer and adding a pool layer up to each convolution layer. Normalization and one hot Normalizetion Take a look at the data at will. 996 basically can get the score of 0. Now take a model combination with a final score of 0. Build your own CNN step by step. Parameters such as rotation_range zoom_range width_shift_range and height_shift_range can be modified. Model compilation 3. 4 Select the parameters for the second dropout 0. With the two convolution pooling modules of the current model and the final fully connected module a total of three modules are selected to add dropout. I have obtained some excellent models. 7 all seem good choose 0. Combine predict In this way I can get a score of 0. The following parameters are the version used by most people but you can also explore parameters that are more effective for your own model. Based on the model that has been built that is the five layers of convolution layer plus the last two layers are pooled into a module and the number of modules required is selected. Decided to use 5 layers of convolution pool_size 3 continues to build. Padding parameter selection Same seems a little better but it doesn t make much difference. These models can help us raise the score to 0. 5 is better choose 0. Of course by combining different models I may be able to achieve a higher score. Selection of filter parameters for convolution layer of New Module Choose 64 Selection of kernel_size parameters for convolution layer of New Module It feels like 3 4 5 6 are all the same continue to use 5 Pool_size Parameter selection of New Module pool layer Still use 3. Choose the fifth way to add that is add droupout after the second and third modules Select the parameters of the first dropout dropout parameter selection training using the loop may encounter some problems you can manually modify the parameter values training observation. 5 Similarly there are many ways to add batch normalization. I tried some ways and the results were all good. The result of training observation is that the pool layer is added after the last convolution layer or the pool layer is added after the countdown first and second convolution layer. This article has a lot of training and my GPU is not very good 1050ti which takes a lot of time. Each module is added separately three modules are added and any two modules are added in a total of 7 ways. 99728 which should be top10. predict and submit Usually after 80 epochs of training there will be some models that can make the score reach 0. 99785 through a variety of combinations. To achieve good results you should train at least 20 epochs. Select pooling layer pool_size parameter 2 3 4 all look good. com s 1T31ToVXSC7KWsSdcBjYkgQ C2 A0 list path 2F extraction code ltu5 load weight and Prediction Voting function did not find the kind of direct vote on the forecast I do not know if there is I wrote one of my own. You can add BN to each convolution layer or you can add some without adding some. Weights file can be downloaded from here https pan. For the convenience of commit all steps are trained for only one epoch. This is also my final choice of the model. In digit recognizer I initially learned to construct my own CNN model step by step and finally used multi model voting to get a good score. Data augmentation is very effective. I chose to add the pooling layer to the bottom one or two layers that is the last two layers. You can save the weights of these models. Save model weights and load model weights The model combination using the simple voting method using the model prediction of three scores of 0. Module Imports Load Data Data preprocessing Data augmentation Perform rotation on the picture move up and down left and right and other operations to increase the amount of data. Those who are interested can continue to explore higher scores. net qq_33758867 article details 90047240. Of course the selection of full connection parameters and other operations also can be done but after training observation found that the current model has a good effect the subsequent attempt is no longer need you can try it yourself. Select the first layer kernel_size parameter 3 4 5 6 7 all look good I chose 5 to continue to build. Select the number of convolution layers 3 4 5 are optional. I have a maximum score of 0. It is recommended that no GPU students do not train you can take a look then use the final model and the weight file I provided. First select the first layer filters parameter Observe the cross validation score of the training output and select the better parameters. Finally I chose to add BN to each convolution layer. If you are Chinese you can check out my blog https blog. A module count of 2 appears to be valid. My result was 32 or 64 and I chose 32 to continue building. ", "id": "firstbloody/build-your-own-cnn-step-by-step-and-voting-0-997", "size": "5090", "language": "python", "html_url": "https://www.kaggle.com/code/firstbloody/build-your-own-cnn-step-by-step-and-voting-0-997", "git_url": "https://www.kaggle.com/code/firstbloody/build-your-own-cnn-step-by-step-and-voting-0-997", "script": "OneHotEncoder ZeroPadding2D AveragePooling2D keras.layers Activation keras.models train_test_split keras LearningRateScheduler keras.preprocessing.image numpy MaxPooling2D seaborn Dropout preprocessing ImageDataGenerator BatchNormalization Dense combine_model GlobalAveragePooling2D glorot_uniform layers keras.callbacks keras.backend keras.initializers RMSprop keras.optimizers sklearn ReduceLROnPlateau Add matplotlib.pyplot GlobalMaxPooling2D Sequential sklearn.model_selection pandas Conv2D Model Input Flatten sklearn.preprocessing ", "entities": "(('Weights file', 'https pan'), 'download') (('number', 'modules'), 'be') (('us', '0'), 'help') (('Parameters', 'rotation_range zoom_range such width_shift_range'), 'modify') (('I', 'higher score'), 'by') (('Finally I', 'convolution layer'), 'choose') (('This', 'also final model'), 'be') (('weight I', 'then final model'), 'recommend') (('Module Imports Load Data Data', 'data'), 'perform') (('very good which', 'time'), 'have') (('Pool_size Parameter 4 5 6 all 5 selection', 'Still 3'), 'Choose') (('who', 'higher scores'), 'continue') (('you', 'blog https blog'), 'check') (('that', 'bottom one layers'), 'choose') (('longer you', 'it'), 'do') (('score', '0'), 'be') (('two modules', '7 ways'), 'add') (('that', 'more own model'), 'be') (('You', 'models'), 'save') (('Normalization', 'will'), 'take') (('you', 'parameter values training manually observation'), 'choose') (('I', '0'), 'predict') (('3 4 5', 'convolution layers'), 'be') (('I', 'own'), 'com') (('you', 'at least 20 epochs'), 'achieve') (('results', 'ways'), 'try') (('you', 'some'), 'add') (('little it', 'much difference'), 'seem') (('all I', '5'), 'select') (('convolution last layer', 'pool convolution countdown first layer'), 'be') (('I', 'good score'), 'learn') (('I', '32'), 'be') "}
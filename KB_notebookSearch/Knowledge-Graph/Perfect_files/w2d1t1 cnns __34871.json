{"name": "w2d1t1 cnns ", "full_name": " h1 Tutorial 1 Introduction to CNNs h1 Tutorial Objectives h2 Tutorial slides h1 Setup h2 Install dependencies h2 Figure Settings h2 Helper functions h2 Plotting Functions h2 Set random seed h2 Set device GPU or CPU Execute set device h1 Section 0 Recap the Experience from Last Week h2 Video 1 Introduction to CNNs and RNNs h2 Think 0 Regularization effective number of params h3 Student Response h2 The rest of these lectures focus on another way to reduce parameters weight sharing Weight sharing is based on the idea that some sets of weights can be used at multiple points in a network We will focus mostly on CNNs today where the weight sharing is across the 2D space of an image At the end we will touch briefly on Recurrent Neural Networks RNNs which share parameters across time Both of these weight sharing techniques across space and time can reduce the number of parameters and increase a network s ability to generalize h1 Section 1 Neuroscience motivation General CNN structure h2 Video 2 Representations Visual processing in the brain h2 Think 1 What makes a representation good h3 Student Response h1 Section 2 Convolutions and Edge Detection h2 Video 3 Details about Convolution h3 Interactive Demo 2 Visualization of Convolution h4 Definitional Note h2 Coding Exercise 2 1 Convolution of a Simple Kernel h2 Coding Exercise 2 2 Convolution Output Size h2 Coding Exercise 2 3 Coding a Convolution h3 Convolution on the Chicago Skyline h2 Section 2 1 Demonstration of a CNN in PyTorch h2 Section 2 2 Padding and Edge Detection h3 Interactive Demo 2 2 Visualization of Convolution with Padding and Stride h3 Think 2 2 1 Edge Detection h4 Student Response h3 Think 2 2 2 Kernel structure h4 Student Response h1 Section 3 Pooling and Subsampling h2 Video 4 Pooling h2 Download EMNIST dataset h2 Dataset DataLoader Functions run me h2 Section 3 1 Multiple Filters h3 Think 3 1 Do you see how these filters would help recognize an X h4 Student Response h2 Section 3 2 ReLU after convolutions h2 Section 3 3 Pooling h3 Interactive Demo 3 3 The effect of the stride h3 Coding Exercise 3 3 Implement MaxPooling h2 Despite the reduction in the size of the output the important or high level features in the output still remains intact h1 Section 4 Putting it all together h2 Video 5 Putting it all together h2 Section 4 1 Number of Parameters in Convolutional vs Fully connected Models h3 Interactive Demo 4 1 Number of Parameters h4 Video 6 Implement your own CNN h3 Train Test Functions Run Me h2 Let us also test the network on an O image h1 Summary h2 Airtable Submission Link h1 Bonus 1 Write your own training loop revisited h2 Video 7 Writing your own training loop h2 Bonus 1 1 Understand the Dataset h3 Download Fashion MNIST dataset h3 Loading Fashion MNIST Data h3 Video 8 The Training Loop h2 Bonus 1 2 Backpropagation Reminder h3 Load a sample dataset EMNIST h2 Bonus 1 3 Fashion MNIST dataset h2 Coding Exercise Bonus 1 Code the training loop h2 Think Bonus 1 Overfitting h1 Bonus 2 Overfitting symptoms and cures h2 Bonus 2 1 Regularization h3 Coding Exercise Bonus 2 1 Adding Regularization h3 Think Bonus 2 1 Regularization h3 Interactive Demo Bonus 2 1 Dropout exploration h3 Coding Exercise Bonus 2 2 How much does augmentation help h4 Download Fashion MNIST if it has not been downloaded h3 Think Bonus 2 2 Data Augmentation ", "stargazers_count": 0, "forks_count": 0, "description": "3 Implement MaxPooling Let us now implement MaxPooling in PyTorch and observe the effects of Pooling on the dimension of the input image. In more general usage the no flip operation that we call convolution is known as _cross correlation_ hence the usage of scipy. The input had a size of 3 3 and the output is of size 2 2. As with filters we can change the shape of the window and the size of the stride. The network is quite confident that this image is an X Note that this is evident from the softmax output which shows the probabilities of the image belonging to each of the classes. Next you should to put everything together. py Your network produced the correct output. Here https stats. py Interactive Demo Bonus 2. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_3ef24bd7. Both of these weight sharing techniques across space and time can reduce the number of parameters and increase a network s ability to generalize. flatten x 1 in order to flatten the input at this stage. Getting the DataLoaders Run Me Coding Exercise Bonus 1 Code the training loopNow try coding the training loop. Also don t forget the ReLUs use e. py Convolution on the Chicago SkylineAfter you have finished programming the above convolution function run the below coding cell which applies two different kernels to a greyscale picture of Chicago and takes the geometric average of the results. py Consider the image below which has a black vertical stripe with white on the side. py Now let s run the network on the test data You should have been able to get a test accuracy of around 99 Note We are using a softmax function here which converts a real value to a value between 0 and 1 which can be interpreted as a probability. Load images run me Pretty cool right We will go into more detail on what s happening in the next section. Load a sample dataset EMNIST You already coded the structure of a CNN. A common approach to this problem is called downsampling. Interactive Demo 2. Let us view the image of X and O and what the output of the filters applied to them look like. Train Test Functions Run Me Double click to see the contents We download the data. If you re up for a challenge you can try methods other than dropout as well. In it we define a Net class that you can instantiate with a kernel to create a Neural Network object. py Great In this section you trained what may have been your very first CNN. Despite the reduction in the size of the output the important or high level features in the output still remains intact. the columns become rows and the rows become columns what would the kernel detect What would be produced by running this kernel on the vertical edge image above Student Response Click for solution https github. there is a boundary between top and bottom. 2 Convolution Output SizeNow you have manually calculated a convolution. To improve performance we need to change the weight matrices so that the predicted outputs are similar to the true outputs labels. py Example output The next cell contains the code for the CNN we will be using in this section. Note that we are using the filters from the videos Now let s visualize the filters using the code given below. 1 Adding RegularizationAdd various regularization methods feel free to add any and play around Click for solution https github. In the next Tutorial we will go deeper in the training of CNNs Next we will talk about RNNs which parameter share over time. Exercise Fill in the missing lines of code. Furthermore in the real world we often have learning problems where the relationship between the input and output is non linear and complex. If you are familiar with conventions involving flipping just assume the kernel is pre flipped. First we create the network and load a dataset. And pytorch calls them linear layers. Is the training accuracy slightly reduced from before adding regularization What accuracy were you able to reduce it to 2. Look at the code below. The nn module contains a plethora of functions that will make implementing a neural network easier. If there s time you can also consider how the brain s representations might differ from a learned representation inside a NN. Note that unlike a convolutional layer the pooling layer contains no learned parameters Pooling just computes a pre determined summary of the input and passes that along. Run this cell to enable the widget Coding Exercise 3. Following are the labels of the dataset 0 T shirt top 1 Trouser 2 Pullover 3 Dress 4 Coat 5 Sandal 6 Shirt 7 Sneaker 8 Bag 9 Ankle boot NOTE we will reduce the dataset to just the two categories T shirt top and Shirt to reduce the training time from about 10min to 2min. You added regularization and data augmentation in order to get a model that generalizes well. Recall that regularization comes in several forms. Weight sharing is based on the idea that some sets of weights can be used at multiple points in a network. Here s an animation of backpropagation works. 3 PoolingConvolutional layers create feature maps that summarize the presence of particular features e. It should take somewhere between 10 seconds and 1 minute. Why does the validation accuracy start higher than training accuracy Click for solution https github. The 1 means it flattens dimensions starting with dimensions 1 in order to exclude the batch dimension from the flattening. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_211bbfd0. 1 Understand the DatasetThe dataset we are going to use for this task is called Fashion MNIST. ai animated explanation of feed forward neural network architecture you can find more animations Let s first see a sample training loop. We have already done the same for accuracy for you. Change the padding and stride and see how this affects the shape of the output. Note in more general situations once you understand convolutions you can use functions already available in pytorch numpy to perform convolution such as scipy. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_82e644f4. How hard will it be to differentiate t shirt tops from shirts Video 8 The Training Loop Bonus 1. Create a CNN with the following structure. Conv2d in_channels 1 out_channels 32 kernel_size 3 Convolution nn. Then we will train a CNN to classify an image either an X or an O. html Download Fashion MNIST if it has not been downloaded. There are also 1D and 3D convolutions but we won t talk about them today. The ReLU Rectified Linear Unit introduces non linearity into our model allowing us to learn a more complex function that can better predict the class of an image. com questions 126238 what are the advantages of relu over sigmoid function in deep neural networks sfb 2 s another excellent discussion about the advantages of using ReLU. Recall that the MNIST dataset consists of binarized images of handwritten digits. This time we will use the EMNIST letters dataset which consists of binarized images of handwritten characters A. 2 ReLU after convolutionsUp until now we ve talked about the convolution operation which is linear. Give it a try Change the stride and see how it affects the output shape. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_7cc3340b. Observe the following simple kernel and discuss whether this will detect vertical edges where the trace of the edge is vertical i. Smola _ Dive into Deep Learning http d2l. Video 1 Introduction to CNNs and RNNs Think 0 Regularization effective number of paramsLet s think back to last week when you learned about regularization. Video 7 Writing your own training loop Bonus 1. The stride defines how much the pooling region is moved over the input matrix to produce the next output red arrows in the animation. there is a boundary between left and right or whether it will detect horizontal edges where the trace of the edge is horizontal i. Now we want you to add some dropout regularization and check if that helps reduce overfitting. That means that small changes to the position of an object in an image can result in a very different feature map. These random weight matrices when applied as a transformation on the input gives us some output. It consists of a training set of 60 000 examples and a test set of 10 000 examples. When you apply the network object to an image or anything in the form of a matrix it convolves the kernel over that image. Section 4 Putting it all together Time estimate 33mins Video 5 Putting it all together Section 4. Make sure you remove all print statements from your convolution2d implementation or this will run for a _very_ long time. It is alwasy image kernel 1 Click for solution https github. correlate2d in the next exercise. In this article https machinelearningknowledge. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_ecc74cf8. In particular we will look at the nn. Therefore later dense layers will need fewer parameters. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_309474b2. An Example of Pooling with a kernel size of 2 Pooling gives our network translational invariance by providing a summary of the values in each pooling window. Thus A small change in the features of the underlying image won t make a huge difference to the output. com a 226927 s an discussion which talks about how ReLU is useful as an activation funciton. How did this change the shape of the output When you know the shapes of the input matrix and kernel what is the shape of the output Hint If you have problems figuring out what the output shape should look like go back to the visualisation and see how the output shape changes as you modify the image and kernel size. Since we are using PyTorch throughout the course we will use the built in functions to update the weights. NOTE The comments in the train function provides many hints that will help you fill in the missing code. For our purposes no flipping is needed. However to display the image all the pixels are normalized between 0 black and 1 white. In Avgpooling we compute the average value of all pixels in the pooling window. Parameter comparison Interactive Demo 4. The CNN parameter size however is invariant of the image size as irrespective of the input that it gets it keeps sliding the same learnable filter over the images. In this section we will walk through an example of training loop for a convolution net. The kernel size is the length and width of this kernel. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_906c34b2. For example L1 regularization adds a term to the loss function that penalizes based on the sum of the _absolute_ magnitude of the weights. How does the padding need to be configured to maintain the shape of the input Run this cell to enable the widget Think 2. Like convolutional layers pooling layers have fixed shape windows pooling windows that are systematically applied to the input. Here s some code to visualize the dataset. At the end we will touch briefly on Recurrent Neural Networks RNNs which share parameters across time. py Coding Exercise 2. Tip Below the function is called Conv2d because the convolutional filter is a matrix with two dimensions 2D. You can test your function by uncommenting the sections beneath it. However these feature maps record the _precise_ position of features in the input. The reduced parameter set not only brings down memory usage by huge chunks but it also allows the model to generalize better. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_33ecb6a5. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_a728d667. We should also stop to think about how we get the output of the pooling layer to be 12x12. Student Response Click for solution https github. Download EMNIST dataset Dataset DataLoader Functions run me Let s view a couple samples from the dataset. Also we have learned to implement our own CNN. In Maxpooling we compute the maximum value of all pixels in the pooling window. Hint You could use torch. Here s the link to the list of transforms available in pytorch https pytorch. 2 Kernel structureIf the kernel were transposed i. 2 Backpropagation Reminder_Feel free to skip if you ve got a good handle on Backpropagation_We know that we multiply the input data tensors with weight matrices to obtain some output. Click for solution https github. Larger images require that the linear layer use a matrix that can be directly multiplied with the input pixels. We have leaned how the convolution operation works and be applied in various images. We look at the nn module in PyTorch. And then we call the step method on the optimizer variable to apply the gradient updates to our weight matrices. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_ae125a93. While pooling does not reduce the number of parameters for a subsequent convolutional layer it does decreases the image size. SummaryIn this Tutorial we have familiarized ouselves with CNNs. However regularization can help ANNs to better generalize. Fully connected ModelsConvolutional networks encourage weight sharing by learning a single kernel that is repeated over the entire input image. Don t forget to zero out the gradients. org vision stable transforms. Let us also test the network on an O image. Num_Convs is the number of convolutional blocks in the network with each block containing a single kernel. In the following cell we provide a code snippet that demonstrates setting up a convolutional network using PyTorch. Execute set_device Section 0 Recap the Experience from Last Week Time estimate 15mins Last week you learned a lot Recall that overparametrized ANNs are efficient universal approximators but also that ANNs can memorize our data. 1 Demonstration of a CNN in PyTorchAt this point you should have a fair idea of how to perform a convolution on an image given a kernel. You should first have a criterion defined you can use CrossEntropyLoss here which you learned about last week so that you can calculate the loss. 1 Multiple FiltersThe following network sets up 3 filters and runs them on an image of the dataset from the X class. correlate2d or scipy. 1 Do you see how these filters would help recognize an X Student Response Click for solution https github. Start the training process by first obtaining the model output calculating the loss and finally updating the weights. 2 Visualization of Convolution with Padding and StrideRecall that Padding adds rows and columns of zeros to the outside edge of an image Stride length adjusts the distance by which a filter is shifted after each convolution. The ReLU function is shown below. The Num_Dense in this exercise is the number of dense layers we use in the network with each dense layer having the same input and output dimensions. What do you notice Note Dense layers are the same as fully connected layers. py Section 2 Convolutions and Edge Detection Time estimate 25mins Fundamental to CNNs are convolutions. ai chapter_convolutional neural networks conv layer. 1 Number of Parameters in Convolutional vs. Then we look at the training loop. This will give you a solid understanding of the different steps involved in the training loop. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_6e9ea2ef. The example below shows the result of Maxpooling within the yellow pooling windows to create the red pooling output matrix. Each example is a 28 28 gray scale image associated with a label from 10 classes. Let s add data augmentation to our model via transforms and see if that helps our model to better generalize In the following cell add the transforms you want in the list augmentation_transforms. We will then run the same network you created in the above exercise with regularization and then plot the loss and accuracies. We will talk more about padding in the next section. Confusing but now you know Student Response Click for solution https github. Note You need to run the cell to activate the sliders and again to run once changing the sliders. But a cup is a cup and an X is an X no matter where it appears in the image We need to achieve _translational invariance_. py Example output Coding Exercise 2. Think about what this specific kernel is doing to the original image. Afterwards enter your results in the solution section in the code below. 1 Convolution of a Simple KernelAt its core convolution is just repeatedly multiplying a matrix known as a _kernel_ or _filter_ with some other larger matrix in our case the pixels of an image. Interactive Demo 2 Visualization of Convolution Run this cell to enable the widget Definitional NoteIf you have a background in signal processing or math you may have already heard of convolution. Use a kernel of size 2 and stride of 2 for the MaxPooling layer. Linear in_features 9216 out_features 128 Fully Connected layer nn. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_4df59f95. The more common definition involves flipping the kernel horizontally and vertically before sliding. 1 Number of Parameters Run this cell to enable the widget The difference in parameters is huge and it continues to increase as the input image size increases. Video 3 Details about ConvolutionBefore jumping into coding exercises take a moment to look at this animation that steps through the process of convolution. But the real strength of neural networks comes from the incorporation of non linear functions. All the pieces are beginning to fit together. Early papers used the more common definition of convolution but not using a flip is easier to visualize and in fact the lack of flip does not impact a CNN s ability to learn. You can also try MaxPool or AvgPool. Initially we don t know what the actual weight matrices are so we initialize them with some random values. py Coming Up The rest of these lectures focus on another way to reduce parameters weight sharing. If we don t want to lose that information we will have to pad the image with some defaults such as 0s on the border. These operations shrink the size of the hidden layers and produce features that are more translationally invariant which can be better leveraged by subsequent layers. Pooling performs a kind of information compression that provides summary statistics for a _neighborhood_ of the input. 3 Fashion MNIST datasetNow Let us train on the actual Fashion MNIST dataset. Tip In this animation and all the ones that follow you can hover over the parts of the code underlined in red to change them. We will simplify the problem further by only keeping the images that correspond to X labeled as 24 in the dataset and O labeled as 15 in the dataset. Download Fashion MNIST dataset Loading Fashion MNIST Data reduce_classes data to reduce Fashion MNIST Data to two categoriesIf you want to continue with the 10 class dataset skip the next cell. Pay special attention to the areas with very high vs. You were introduced to several regularization techniques such as L1 L2 Data Augmentation and Dropout. Below that are two graphics that show the effect of regularization on both the number of non zero weights d and on the network s accuracy c. Choose the correct criterion Code up the training part calculating gradients loss stepping forward Keep a track of the running loss i. At first the outputs predictions will match the true labels only by chance. Section 1 Neuroscience motivation General CNN structure Time estimate 25mins Video 2 Representations Visual processing in the brain Think 1 What makes a representation good Representations have a long and storied history having been studied by the likes of Aristotle back in 300 BC Representations are not a new idea and they certainly don t exist just in neural networks. There is a higher probability of belonging to class 1 i. MaxPool2d kernel_size 2 Fully Connected Layer nn. However the definitions in other domains and the one we use here are slightly different. We further divide the test set into a validation set and a test set 8000 and 2000 resp. Based on the loss function we change the values of our weight matrices using the gradients of the error with respect to the weight matrices. Take a moment with your pod to discuss what would make a good representation and how that might differ depending on the task you train your CNN to do. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_63a2685b. In this section we will train a CNN using convolution layers and maxpool and then observe what the training and validation curves look like. We later provide pretrained results to give you an idea how the results would look on the whole dataset. very low output patterns. And just like with filters every time we apply a pooling operation we produce a single output. In general this kernel is just a few parameters compared to the huge number of parameters in a dense network. Let s use the animation below to calculate few layer network parameters for image data of shape 32 times32 using both convolutional layers and dense layers. It is because first the two Conv2d with a kernel_size 3 operations cause the image to be reduced to 26x26 and the second Conv2d reduces it to 24x24. The Rectified Linear Unit ReLU Activation Function Now let us incorporate ReLU into our previous model and visualize the output. Edge detecting filters are usually learned by the first layers in a CNN. Conv2d function which creates a convolutional layer that is applied to whatever image that you feed the resulting network. Below are the results from training a simple multilayer perceptron with one hidden layer b on a simple toy dataset a. 3 Coding a ConvolutionHere we have the skeleton of a function that performs convolution using the provided image and kernel matrices. Tutorial 1 Introduction to CNNs Week 2 Day 1 Convnets And Recurrent Neural Networks By Neuromatch Academy __Content creators __ Dawn Estes McKnight Richard Gerum Cassidy Pirlot Rohan Saha Liam Peet Pare Saeed Najafi Alona Fyshe__Content reviewers __ Saeed Salehi Lily Cheng Yu Fang Yang Polina Turishcheva Bettina Hein Kelson Shilling Scrivo__Content editors __ Nina Kudryashova Anmol Gupta Spiros Chavlis __Production editors __ Alex Tran Van Minh Spiros Chavlis Based on material from Konrad Kording Hmrishav Bandyopadhyay Rahul Shekhar Tejas Srivastava Our 2021 Sponsors including Presenting Sponsor Facebook Reality Labs Tutorial ObjectivesAt the end of this tutorial we will be able to Define what convolution is Implement convolution as an operationIn the Bonus materials of this tutorial you will be able to train a CNN by writing your own train loop recognize the symptoms of overfitting and how to cure them Tutorial slides Setup Install dependencies Figure Settings Helper functions Plotting Functions Set random seed Executing set_seed seed seed you are setting the seed Set device GPU or CPU. Run the next cell to get the accuracy on the data Think Bonus 1 OverfittingDo you think this network is overfitting If yes what can you do to combat this Hint overfitting occurs when the training accuracy greatly exceeds the validation accuracy Click for solution https github. Run the cell to plot the outputs You should observe the size of the output as being half of what you saw after the ReLU section which is due to the Maxpool layer. Run this cell to enable the widget Coding Exercise Bonus 2. Today we ll be talking about other ways to simplify ANNs by making smart changes to their architecture. Airtable Submission Link Bonus 1 Write your own training loop revisited Time estimate 20mins In the last section we coded up a CNN but trained it with some predefined functions. Video 6 Implement your own CNNin_channels 1 out_channels 32 kernel_size 3 Coding Exercise 4 Implement your own CNNLet s stack up all we have learnt. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_256458ee. Interactive Demo 3. Take a minute with your pod and talk about which classes you think would be most confusable. py Section 3 Pooling and Subsampling Time estimate 50mins Video 4 PoolingTo visualize the various components of a CNN we will build a simple CNN step by step. 1 Dropout explorationIf you want to try out more dropout parameter combinations but do not have the time to run them we have here precalculated some combinations you can use the sliders to explore them. 2 Padding and Edge DetectionBefore we start in on the exercises here s a visualization to help you think about padding. This process is somewhat predictably called padding. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_79e1f5fb. As a quick aside notice the difference in the input and output size. py We apply the filters to the images. We apply the filters and relus to the images. Recall that the input images have size 28 28. 2 How much does augmentation help Last week you also learned how data augmentation can regularize a network. Note you must run the cell before you can use the sliders. Execute this cell to view the filtered images Discuss with your pod how the ReLU activations help strengthen the features necessary to detect an X. This is because of the fact that the kernel can t produce values for the edges of the image when it slides to an end of the image and is centered on a border pixel it overlaps space outside of the image that is undefined. In Section 6 we will add regularization and data augmentation to see what effects they have on the curves and why it is important to incorporate them while training our network. py Bonus 2 Overfitting symptoms and cures Time estimate 30mins So you spent some time last week learning about regularization techniques. Downsampling creates a lower resolution version of an image retaining the large structural elements and removing some of the fine detail that may be less relevant to the task. com NeuromatchAcademy course content dl tree main tutorials W2D1_ConvnetsAndRecurrentNeuralNetworks solutions W2D1_Tutorial1_Solution_67c8514b. Below is a copy of the CNN model we used previously. Notice that here we normalize the dataset. We call the backward method on our loss variable to calculate the gradients derivatives with respect to all the weight matrices and biases. py Example output Run the next cell to get the accuracy on the data Think Bonus 2. ReLU No need to add a ReLU after the final fully connected layer. begin equation textbf Kernel begin bmatrix 1 1 1 1 end bmatrix end equation Student Response Click for solution https github. 1 Regularization Coding Exercise Bonus 2. After all that _is_ what the C in CNN stands for In this section we will define what a convolution is practice performing a convolution and implement it in code. Now you are going to implement the training loop for a CNN. 1 Edge DetectionOne of the simpler tasks performed by a convolutional layer is edge detection that is finding a place in the image where there is a large and abrupt change in color. 3 The effect of the strideThe following animation depicts how changing the stride changes the output. Finally the MaxPool2d operation reduces the output size by half to 12x12. 2 Data AugmentationDid the training accuracy reduce further compared to with dropout alone Is the model still overfitting Click for solution https github. Conv2d in_channels 32 out_channels 64 kernel_size 3 Pool Layer nn. We will focus mostly on CNNs today where the weight sharing is across the 2D space of an image. In CNNs Max Pooling and Average Pooling are used to downsample. This is in contrast to the convolutional layer where there are filters to be learned. This is like a very zoomed in vertical edge within an image As you can see this kernel detects vertical edges the black stripe corresponds to a highly positive result while the white stripe corresponds to a highly negative result. Let us view the image of X and O and what the output of the filters applied to them looks like. Consider the below image and kernel begin align textbf Image begin bmatrix 0 200 200 0 0 200 0 0 0 end bmatrix textbf Kernel begin bmatrix frac 1 4 frac 1 4 frac 1 4 frac 1 4 end bmatrix end align Perform by hand the operations needed to convolve the kernel and image above. Recall from the video that convolution involves sliding the kernel across the image taking the element wise product and adding those products together. e for each epoch we want to to know the average loss of the batch size. Linear in_features 128 out_features 2 Note As discussed in the video we would like to flatten the output from the Convolutional Layers before passing on the Linear layers thereby converting an input of shape BatchSize Channels Height Width to BatchSize Channels Height Width which in this case would be from 32 64 12 12 output of second convolution layer to 32 64 12 12 32 9216. We first calculate how far away the predicted outputs are to the true outputs using a loss function. ", "id": "joseguzman/w2d1t1-cnns", "size": "34871", "language": "python", "html_url": "https://www.kaggle.com/code/joseguzman/w2d1t1-cnns", "git_url": "https://www.kaggle.com/code/joseguzman/w2d1t1-cnns", "script": "torch.nn.functional convolve2d torchvision.transforms set_device display as IPyDisplay DataLoader check_pooling_net interact_manual IPython.display get_Xvs0_dataset seed_worker make_plots numpy Image TensorDataset check_shape_function Net3(nn.Module) interactive train download_data convolution2d set_seed addBox plot_func EMNIST_Net(nn.Module) get_fashion_mnist_dataset Net(nn.Module) BiliVideo(IFrame) on_button_clicked torch.nn IPython evaltools.airtable tqdm AirtableForm plot_loss_accuracy YouTubeVideo interact calculate_output_shape interactive_output Net2(nn.Module) matplotlib.pyplot make_grid conv_check IFrame ImageFolder PIL check_conv_function forward correlate2d emnist_net(nn.Module) FMNIST_Net1(nn.Module) plot get_augmentation_transforms tqdm.notebook trange scipy.signal transforms_custom ipywidgets reduce_classes torch.optim test torch.utils.data display widgets __init__ do_plot FMNIST_Net2(nn.Module) torchvision.datasets display_image_from_greyscale_array get_data_loaders torchvision.utils fixed ", "entities": "(('Today we', 'architecture'), 'talk') (('what', 'next section'), 'run') (('Here code', 'dataset'), 's') (('T', '2min'), 'be') (('ReLU how activations', 'necessary X.'), 'strengthen') (('that', 'image'), 'introduce') (('predicted outputs', 'outputs true labels'), 'improve') (('alone model', 'solution https github'), '2') (('it', 'image size'), 'reduce') (('which', 'convolution operation'), 'talk') (('We', 'images'), 'apply') (('First we', 'dataset'), 'create') (('also how representations', 'NN'), 'consider') (('We', 'next section'), 'talk') (('we', 'border'), 'want') (('input images', 'size'), 'recall') (('py network', 'correct output'), 'produce') (('pooling how much region', 'animation'), 'define') (('It', 'test 10 000 examples'), 'consist') (('you', 'manually convolution'), 'calculate') (('You', 'CNN'), 'code') (('how results', 'whole dataset'), 'provide') (('we', 'single output'), 'produce') (('that', 'systematically input'), 'fix') (('filter', 'convolution'), 'adjust') (('we', 'scipy'), 'know') (('where trace', 'edge'), 'be') (('core convolution', 'image'), 'Convolution') (('we', 'other domains'), 'be') (('Also we', 'own CNN'), 'learn') (('you', 'pod'), 'take') (('us', 'Fashion MNIST actual dataset'), 'let') (('you', 'such scipy'), 'numpy') (('also model', 'huge chunks'), 'bring') (('you', 'CNN'), 'take') (('you', 'seed'), 'introduction') (('gradients', 'weight matrices'), 'call') (('also 1D we', 'them'), 'be') (('us', 'input image'), 'let') (('that', 'dataset'), 'simplify') (('Next you', 'everything'), 'should') (('Video', 'training 7 own loop'), 'write') (('You', 'again once sliders'), 'note') (('so we', 'random values'), 'know') (('common approach', 'problem'), 'call') (('you', 'other dropout'), 're') (('Detection 25mins Fundamental', 'CNNs'), 'estimate') (('level important features', 'output'), 'despite') (('correct criterion', 'running loss i.'), 'choose') (('It', 'image solution https alwasy 1 github'), 'be') (('how changing', 'output'), '3') (('We', 'data'), 'function') (('more translationally which', 'better subsequent layers'), 'shrink') (('NeuromatchAcademy course dl content tree main tutorials', 'solutions W2D1_Tutorial1_Solution_ae125a93'), 'com') (('parameter', 'time'), 'go') (('just kernel', 'flipping'), 'assume') (('This', 'training loop'), 'give') (('that', 'input'), 'perform') (('Here animation', 'backpropagation works'), 's') (('convolution', 'products'), 'recall') (('which', 'time'), 'touch') (('Now us', 'output'), 'let') (('how filters', 'solution https github'), 'see') (('when you', 'regularization'), 'introduction') (('sfb', 'ReLU'), 'question') (('that', 'overfitting'), 'want') (('Then we', 'X'), 'train') (('what', 'section'), 'py') (('NeuromatchAcademy course dl content tree main tutorials', 'solutions'), 'com') (('s', 'sample training first loop'), 'ai') (('you', 'missing code'), 'NOTE') (('it', 'images'), 'be') (('that', 'input entire image'), 'encourage') (('that', 'less task'), 'create') (('we', 'CNNs'), 'SummaryIn') (('that', 'neural network'), 'contain') (('Here link', 'pytorch https available pytorch'), 's') (('you', 'them'), 'Tip') (('You', 'it'), 'test') (('we', 'same input dimensions'), 'be') (('white stripe', 'highly negative result'), 'edge') (('which', 'results'), 'py') (('Now s', 'code'), 'note') (('we', 'weight matrices'), 'change') (('training curves', 'then what'), 'train') (('this', '_'), 'make') (('training when accuracy', 'solution https github'), 'run') (('It', 'somewhere between 10 seconds'), 'take') (('block', 'single kernel'), 'be') (('that', 'provided image matrices'), 'have') (('that', 'where large color'), 'edge') (('This', 'convolutional layer'), 'be') (('s', 'dataset'), 'run') (('outputs predictions', 'only chance'), 'match') (('You', 'L1 L2 Data such Augmentation'), 'introduce') (('you', 'next cell'), 'dataset') (('So you', 'regularization last week techniques'), 'py') (('you', '2'), 'be') (('We', 'you'), 'do') (('which', 'probability'), 'py') (('small changes', 'feature very different map'), 'mean') (('you', 'list augmentation_transforms'), 'let') (('regularization', 'several forms'), 'recall') (('that', 'convolution'), 'take') (('it', 'image'), 'convolve') (('equation textbf Kernel', 'solution https github'), 'begin') (('general kernel', 'dense network'), 'be') (('applied', 'them'), 'let') (('Smola _ Dive', 'd2l'), 'http') (('second Conv2d', '24x24'), 'be') (('NeuromatchAcademy course dl content tree main tutorials', 'solutions W2D1_Tutorial1_Solution_906c34b2'), 'com') (('Now you', 'CNN'), 'go') (('we', 'batch size'), 'want') (('here we', 'dataset'), 'notice') (('that', 'features e.'), 'create') (('we', 'pooling window'), 'compute') (('don certainly t', 'just neural networks'), 'estimate') (('then we', 'weight matrices'), 'call') (('py', 'parameters weight sharing'), 'focus') (('here you', 'padding'), 'Padding') (('point you', 'kernel'), 'have') (('Below results', 'toy dataset simple a.'), 'be') (('training 1 loopNow', 'training loop'), 'get') (('we', 'convolution net'), 'walk') (('What', 'solution https github'), 'become') (('more common definition', 'kernel'), 'involve') (('example', '10 classes'), 'be') (('you', 'then loss'), 'run') (('applied', 'them'), 'look') (('convolution how operation', 'various images'), 'lean') (('that', 'input directly pixels'), 'require') (('which', '32'), 'in_features') (('which', 'handwritten characters'), 'use') (('we', 'predefined functions'), 'write') (('NeuromatchAcademy course dl content tree main tutorials', 'solutions W2D1_Tutorial1_Solution_4df59f95'), 'com') (('two that', 'accuracy c.'), 'be') (('you', 'Neural Network object'), 'define') (('data also how augmentation', 'network'), 'learn') (('pooling layer', 'that'), 'note') (('probabilities', 'classes'), 'be') (('how this', 'output'), 'change') (('convolutional filter', 'two dimensions'), 'call') (('why it', 'network'), 'add') (('we', 'task'), 'Understand') (('that', 'model'), 'add') (('efficient universal also ANNs', 'data'), 'Section') (('which', 'Maxpool layer'), 'run') (('MNIST dataset', 'handwritten digits'), 'recall') (('you', 'already convolution'), 'Run') (('bmatrix', 'kernel'), 'consider') (('us', 'O image'), 'let') (('How it', 'shirts Video'), 'be') (('regularization RegularizationAdd various methods', 'solution https github'), '1') (('we', 'stride'), 'change') (('we', 'section'), 'py') (('Run', 'widget'), 'need') (('s', '32 convolutional layers'), 'let') (('We', '8000 resp'), 'divide') (('output', 'pooling layer'), 'stop') (('Example', 'pooling window'), 'give') (('real strength', 'linear non functions'), 'come') (('we', 'step'), 'visualize') (('now you', 'solution https github'), 'confusing') (('that', 'weights'), 'add') (('kernel size', 'kernel'), 'be') (('Edge detecting filters', 'CNN'), 'learn') (('where trace', 'edge'), 'observe') (('example', 'pooling output red matrix'), 'show') (('how ReLU', 'activation funciton'), 'com') (('weight today where sharing', 'image'), 'focus') (('output', 'data'), 'run') (('that', 'image'), 'be') (('weight random matrices', 'output'), 'give') (('output', 'size'), 'have') (('you', 'sliders'), 'note') (('MaxPool2d Finally operation', 'half to 12x12'), 'reduce') (('validation Why accuracy', 'solution https github'), 'start') (('pixels', '0'), 'display') (('you', 'resulting network'), 'function') (('We', '_ invariance translational _'), 'be') (('that', 'PyTorch'), 'provide') (('convolution', 'code'), 'be') (('you', 'loss'), 'have') (('Thus small change', 'output'), 'win') (('how it', 'output shape'), 'give') (('we', 'all'), 'implement') (('you', 'them'), 'want') (('CNNs Max Pooling', 'Average downsample'), 'use') (('sets', 'network'), 'base') (('Both', 'ability'), 'reduce') (('first how far away predicted outputs', 'loss function'), 'calculate') (('lack', 'ability'), 'use') (('output shape how you', 'image size'), 'change') (('specific kernel', 'original image'), 'think') (('where relationship', 'input'), 'have') (('which', 'side'), 'consider') (('we', 'weights'), 'use') (('Therefore later dense layers', 'fewer parameters'), 'need') (('we', 'output'), 'know') (('we', 'CNN model'), 'be') (('it', 'input image size increases'), 'run') (('it', 'flattening'), 'mean') (('Section', 'together Section'), 'put') (('Note Dense layers', 'fully connected layers'), 'notice') "}
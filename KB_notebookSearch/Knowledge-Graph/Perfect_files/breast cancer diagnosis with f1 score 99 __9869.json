{"name": "breast cancer diagnosis with f1 score 99 ", "full_name": " h1 Breast Cancer h2 A Problem Understanding h2 B Data Understanding h4 1 Data Description h4 2 Load The Data h4 3 Data Types h1 C Data Exploration h1 D Data Preprocessing h4 1 Data Selection h4 2 Preprocess Data h4 3 Data Transformation h1 E Data Modelling h4 1 Random Forest h4 2 KNN h4 3 SVM h1 F Evaluation ", "stargazers_count": 0, "forks_count": 0, "description": "91204 RejectedAs on the previous test we need to keep some features and remove the other features that are unnecessary. The predictive model using SVM does very well. 3 To increase the F1 score we have applied hyperparameter tuning using RandomizedSearch and obtain F1 score of Optmized Random Forest model 94. women will be diagnosed with breast cancer and 3. The available data can includes independent variables and dependent variables. FP is the most important indicator. Ten features are computed for each nucleus area radius perimeter symmetry number and size of concavities fractal dimension of the boundary compactness smootimess local variation of radial seg ments and texture variance of gray levels inside the boundary. EvaluationOverall the model perform well to predict the class of cancer with F1 score 94 even not using hyperparameter optimization F1 score of Random Forest model 94. Ten real valued features are computed for each cell nucleus radius mean of distances from center to points on the perimeter texture standard deviation of gray scale values perimeter area smoothness local variation in radius lengths compactness perimeter 2 area 1. It is very dangerous because the patient will have the serious treatment consume a high dose drug category or have a serious surgery that is actually not appropriate for such patient. After the diagnosis for each patient with breast cancer we classify the severity of cancers as malignant or benign in order to give them special treatments. K Nearest Neighbours3. Let me remind you what does it mean. Data Preprocessing 1. 91016 Rejected texture_worst is highly correlated with texture_mean \u03c1 0. 0 F1 score of SVM model 99. Data ExplorationOn the data exploration we will see the distribution of each variable using a histogram. Preprocess DataAfter we know what features to be excluded let s make the sample data for analysis or the data that we want to work with. 7 F1 score of KNN model 97. The model we used are 1. Support Vector Machine SVM 1. This outpatient procedure involves using a small gauge needle to take the fluid known as a fine needle aspirate FNA directly from a breast lump or mass thelump having been previously detected by self examination and or mammoaphy. This is helpful to speed up our correlation test. Data TransformationWe need to check the boundaries minimum and maximum values of each features. For a typical image containing between 10 and 40 nuclei the image analysis process takes approximately two to five minutes. So we can also include the target to the correlation test because the correlation test can process only numerical data. 97758 Rejected perimeter_mean is highly correlated with radius_mean \u03c1 0. 99371 Rejected radius_worst is highly correlated with area_mean \u03c1 0. In contrast a value in FN is the number of malignant patient who are predicted as benign. The boundaries are initialized by an operator using a mouse pointer. It is better to scale the numeric data because every feature has different scale. We also consider to remove unnecessary data that is clearly not required. From concave points_mean concavity_mean and concave points_worst we choose concave points_mean From texture_mean and texture_worse we choose texture_mean At this step we keep variables concave points_mean and texture_mean and will exclude 3 other variables in group_2 concavity_mean concave points_worst and texture_worse 2. Before go to correlation test we need to change the target of classification in the column of diagnosis to be numerical. Data SelectionNow we need to select the data based on the question that we want to address which is classification of the cancer. False positives FP We predicted yes but they don t actually have the malignant cancer. We create 3 basic models and then optimze each models using Hyperparameter Search technique. largest or worst value biggest size most irregular shape and standard error of each of these cellular features are com puted for each image resulting in a total of 30 real valued features. If two variables have a correlation coefficient then the two variables are numerical variables while the remainder are categorical variables. From the histograms below we can see the distributions are normal. 92139 Rejected concave points_worst is highly correlated with concave points_mean \u03c1 0. 0 concavity severity of concave portions of the contour concave points number of concave portions of the contour symmetry fractal dimension coastline approximation 1 Note Mean Etandard Error SE and Worst mean of the three largest values of these features are obtained from each image resulting in 30 features. It is also important to binarized our target because it is need to convert to 0 and 1 to calculate F1 score of our model evaluation. What we need is to ensure the inputs include all independent varibales and each feature doesn t make a high correlation with the target or with other input s we can identify them by evaluating through correlation test. Data Description data. False negatives FN We predicted no but they actually do have the malignant cancer. 96275 RejectedFirst we will choose one out of three variables that are higly correlated From radius_mean perimeter_mean and area_mean we choose radius_mean From radius_se perimeter_se and area_se we choose radius_se From radius_worst perimeter_worst and area_worst we choose radius_worst Second due to the high correlation of the radius features radius_mean and radius_worst we need to choose one let s take the radius_mean At this step we keep 2 variables radius_mean and radius_se and will exclude 7 other variables in group_1 perimeter_mean area_mean perimeter_se area_se radius_worst perimeter_worst area_worst Group 2 Features in concave points texture and concavity Look at the pandas profile report we can witness concave points_mean is highly correlated with concavity_mean \u03c1 0. 98651 Rejected area_se is highly correlated with perimeter_se \u03c1 0. 97279 Rejected perimeter_worst is highly correlated with radius_worst \u03c1 0. From the Pandas Profiling thare are 14 warnings 4 are due to zero values. Clearly this not severe as the opposite situation. 3 We can conclude that SVM is the best model to classify the breast cancer with the optimum F1 score of 99. The annual mortality rate of approximately 28 deaths per 100 000 women has remained nearly constant over the past 20 years. There is a time to re assess the patient in order to provide better treatment. 99786 Rejected perimeter_se is highly correlated with radius_se \u03c1 0. Problem UnderstandingDespite a great deal of public awareness and scientific research breast cancer continues to be the most common cancer and the second largest cause of cancer deaths among women. 9 F1 score of Optmized KNN model 97. In this case because the data are obtained using real image we assume zero values are possible and not human error so we can t exclude that. Diagnosis M malignant B benign 3. SVMFor the above confusion matrix we can see that the false positive 0 and the false negative 1. Even though the available data are seems to be relevant we need to conduct the correlation test to make sure we used the features that are must be included. The fluid from the FNA is placedon a glass slide and stained to highlight the nuclei of the constituent cells. If the cancer is identified as malignant there is a sort amount of time or even no time to re evaluate the patient and the wrong treatment will be taken by the doctor and make the patient in danger. Data UnderstandingFirst a sample of fluid is taken from the patient s breast. To illustrate if there is a value in FP it means that the patient with benign cancer predicted as malignant cancer. Approximately 12 of U. An image from the FNA is transferredto a workstation by a video camera mounted on a microscope. There are 31 features now including the target Next let s explore all variables using Pandas Proiling Report. A breast cancer victim s chances for long term survival are improved by early detection of the disease and early detection is in turn enhanced by an accurate diagnosis. From the above warning we can see that there are 10 warning regarding the correlation of the features we can group them as 2 groups of correlation test Group 1 Features in Radius Perimeter and Area Take a look at the pandas profile report area_mean is highly correlated with perimeter_mean \u03c1 0. 93766 Rejected area_worst is highly correlated with perimeter_worst \u03c1 0. For example the third column is Mean Radius column 13 is Radius SE column 23 is Worst Radius. If the data are highly correlated we then exlude it. All feature values are stored with four significant numbers. The correlation test is used to evaluate the relationship between two numerical variables. For example the patient ID and other blank features. Data ModellingLet s prapare our input and output using tran test split before we create models. The mean value extreme value i. Xcyt uses a curve fitting program to determine the exact boundaries of the nuclei. Because the FP is zero and NP is very small 1. 7 F1 score of Optmized SVM model 99. In the histogram the horizontal axis is the data of the feature while the vertical axis is the frequency of occurrence. ", "id": "busthon/breast-cancer-diagnosis-with-f1-score-99", "size": "9869", "language": "python", "html_url": "https://www.kaggle.com/code/busthon/breast-cancer-diagnosis-with-f1-score-99", "git_url": "https://www.kaggle.com/code/busthon/breast-cancer-diagnosis-with-f1-score-99", "script": "train_test_split confusion_matrix sklearn.svm numpy seaborn evaluate preprocessing f1_score SVC sklearn.neighbors sklearn matplotlib.pyplot sklearn.model_selection pandas RandomForestClassifier RandomizedSearchCV KNeighborsClassifier sklearn.metrics sklearn.ensemble StandardScaler sklearn.preprocessing ", "entities": "(('This', 'correlation test'), 'be') (('EvaluationOverall model', 'Random Forest model'), 'perform') (('it', 'model evaluation'), 'be') (('that', 'features'), 'seem') (('distribution', 'histogram'), 'ExplorationOn') (('vertical axis', 'occurrence'), 'be') (('highly we', 'then it'), 'exlude') (('who', 'malignant patient'), 'be') (('concave 92139 Rejected points_worst', 'points_mean 0'), 'correlate') (('Next s', 'Pandas Proiling Report'), 'be') (('feature values', 'four significant numbers'), 'store') (('human we', 't that'), 'assume') (('Ten features', 'boundary'), 'compute') (('we', 'special treatments'), 'classify') (('which', 'cancer'), 'SelectionNow') (('numerical remainder', 'correlation coefficient'), 'be') (('Ten real valued features', 'radius lengths'), 'compute') (('97758 Rejected perimeter_mean', '0'), 'correlate') (('Rejected texture_worst', '0'), '91016') (('correlation test', 'two numerical variables'), 'use') (('that', 'also unnecessary data'), 'consider') (('third column', 'example'), 'be') (('fluid', 'constituent cells'), 'be') (('patient', 'malignant cancer'), 'illustrate') (('women', 'breast cancer'), 'diagnose') (('largest biggest size', '30 real valued features'), 'put') (('we', 'confusion above matrix'), 'see') (('that', 'actually such patient'), 'be') (('Xcyt', 'nuclei'), 'use') (('image analysis process', 'approximately two to five minutes'), 'take') (('they', 'actually malignant cancer'), 'fn') (('correlation test', 'only numerical data'), 'include') (('we', 'that'), 'DataAfter') (('we', 'points_worst'), 'choose') (('Problem UnderstandingDespite', 'women'), 'continue') (('area_mean', 'perimeter_mean highly \u03c1'), 'see') (('feature', 'different scale'), 'be') (('Rejected perimeter_worst', '0'), '97279') (('Rejected area_worst', '0'), '93766') (('boundaries', 'mouse pointer'), 'initialize') (('Data TransformationWe', 'features'), 'need') (('Rejected radius_worst', 'area_mean highly \u03c1'), '99371') (('t', 'actually malignant cancer'), 'positive') (('mortality annual rate', 'nearly past 20 years'), 'remain') (('that', 'other features'), 'need') (('predictive model', 'SVM'), 'do') (('Rejected perimeter_se', 'highly \u03c1'), '99786') (('sort malignant amount', 'danger'), 'be') (('we', 'correlation test'), 'be') (('concave points_mean', '0'), 'choose') (('SVM', '99'), 'conclude') (('early detection', 'accurate diagnosis'), 's') (('Clearly this', 'opposite situation'), 'severe') (('distributions', 'histograms'), 'see') (('we', 'diagnosis'), 'need') (('available data', 'independent variables'), 'include') (('We', 'Hyperparameter Search technique'), 'create') (('we', 'Random Forest Optmized model'), '3') (('fluid', 'mass self previously examination'), 'involve') (('sample', 'breast'), 'take') (('Rejected area_se', 'highly \u03c1'), '98651') (('Worst mean', '30 features'), 'severity') (('tran test we', 'models'), 'prapare') (('image', 'microscope'), 'be') "}
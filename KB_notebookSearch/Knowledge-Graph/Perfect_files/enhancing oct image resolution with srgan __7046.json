{"name": "enhancing oct image resolution with srgan ", "full_name": " h2 Enhancing OCT image resolution with SRGANs h4 Keywords unsupervised super resolution SRGAN VGG19 h2 I Introduction h2 II Imports and globals h2 III Data h2 IV Utility functions h3 IV A Metrics h4 1 PSNR Peak Signal to Noise ratio h4 2 SSIM Structural Similarity Index h3 IV B Loss Functions h4 Plot loss function h3 IV C Sampling saving images h2 V SRGAN VGG19 h3 V 1 Generator h3 V 2 Discriminator h3 V 3 VGG19 Feature Extractor h2 VI Training h2 VII References and further reading ", "stargazers_count": 0, "forks_count": 0, "description": "References and further reading 1 Goodfellow et al. l_ Gen SR sum limits_ n 1 N log D_ theta _D G_ theta _G I LR l_ Gen SR generative loss D discriminator function D_ theta _D discriminator function parametrized with theta _D D_ theta _D G_ theta _G I LR probability that the reconstructed image G_ theta _G I LR is a natural HR image Plot loss function IV C. l_ VGG i j SR 1 over W_ i j H_ i j sum limits_ x 1 W_ i j sum limits_ y 1 H_ i j phi _ i j I HR _ x y phi _ i j G_ theta _G I LR _ x y 2 l_ VGG i j SR VGG loss phi _ i j the feature map obtained by the j th convolution after activation before the i th maxpooling layer within the VGG19 network 2. Adversarial Loss This is calculated based on probabilities provided by Discriminator. pdf install an older version of tensorflow the implementation may not work with the most recent TensorFlow release data path batch size equals to 8 due to RAM limits define the shape of low resolution image LR define the shape of high resolution image HR optimizer for discriminator generator use seed for reproducible results get min max image sizes image_list is the list of all images ransom sample a batch of images change the size do a random horizontal flip convert lists into numpy ndarrays X 1 2 to scale back from 1 1 to 0 1 use 16 residual blocks in generator input LR dimension 4x downsample of HR input for the generator pre residual block conv layer before residual blocks add 16 residual blocks post residual block conv and batch norm layer after residual blocks take the sum of pre residual block gen1 and post residual block gen2 upsampling upsampling conv layer at the output model define hyperparameters the input is the HR shape input layer for discriminator 8 convolutional layers with batch normalization fully connected layer last fully connected layer for classification input layer for high resolution images input layer for low resolution images generate high resolution images from low resolution images extract feature maps from generated images make a discriminator non trainable discriminator will give us a probability estimation for the generated high resolution images create and compile initialize training loop normalize the images generate high resolution images from low resolution images generate a batch of true and fake labels calculate total loss of discriminator as average loss on true and fake labels sample a batch of images normalize the images extract feature maps for true high resolution images train the generator calculate the psnr calculate the ssim normalize the images comment this line to display all the images plots post training save model weights. This network will serve as a baseline for further experiments with upscaling choice of feature extractor etcetera. ESRGAN Enhanced Super Resolution Generative Adversarial Networks https arxiv. The perceptual loss by contrast has a content loss component that computes pixel wise differences in feature space not pixel space and this results in an SR image that is closer to the subjective evaluation of human observers. IntroductionOptical coherence tomography OCT scans of the retina are used to produce high resolution cross sectional images of the retina. Utility functionsQuantitative metrics for image quality Loss functions Plots Image processing sampling and saving images IV A. Discriminator V 3. Discriminator network 3. We downsample HR OCT images by 4x to synthetically create LR training data. Both losses are defined below Pixel wise MSE loss is the mean squared error between each pixel in the original HR image and a the corresponding pixel in the generated SR image. The SRGAN model uses a deep neural network built with residual blocks and optimized using perceptual loss in a GAN framework. PSNR Peak Signal to Noise ratioPSNR is the ratio between maximum possible power of signal and power of corrupting noise Wikipedia. Here the authors used a perceptual loss instead of a pixel wise Mean Squared Error MSE loss. The generator follows the architecture outlined in 2. The computational enhancement of image resolution is known as super resolution. Imports and globals III. com PacktPublishing Generative Adversarial Networks Projects 4 Saeed Anwar et al. A Deep Journey into Super resolution A Survey https arxiv. Adversarial framework V 1. 04802 3 Kailash Ahirwar. VGG19 Feature Extractor VI. Code The code is based on the SRGAN paper 2 and Kailash Ahirwar s code 3. The SRGAN introduced in 2016 addressed the issue of reconstructing high resolution HR images from low resolution LR images such that fine texture detail in the reconstructed super resolution SR images was not lost. pdf 5 Xintao Wang et al. Generative Adversarial Networks GANs 1 are one of newer methods that have been applied to super resolution and in this notebook we use a Super Resolution GAN SRGAN 2 to enhance subsampled OCT scans. In this exercise we use an SRGAN design which is faithful to the original SRGAN 2. l SR l_X SR 10 3 l_ Gen SR l SR perceptual loss l_X SR content loss l_ Gen SR adversarial loss 1. org wiki Structural_similarity. Generative Adversarial Nets https arxiv. OCT imaging is the now the standard of care in opthalmologyand there is interest in applying AI methods to enhance conventional OCT images from commercial systems. GeneratorThere are 16 residual blocks and 2 upsampling blocks. Sampling saving images V. A VGG 19 network is used for feature extraction this allows us to compute the feature distance between the original and generated images sent through the feature extractor. PSNR 10 log_ 10 left MAX_I 2 over MSE right MAX_I maximum possible power of a signal of image I MSE mean squared error pixel by pixel 2. Generative Adversarial Networks Projects https github. MSE loss approaches give a high Peak Signal to Noise PSNR value but they also tend to produce overly smooth images with insufficient high frequency details. SSIM Structural Similarity IndexSSIM measures the perceptual difference between two similar images see Wikipedia https en. SSIM x y 2 mu_x mu_y c_1 2 sigma_ xy c_2 over mu_x 2 mu_y 2 c_1 sigma_x 2 sigma_y 2 c_2 mu_x mu_y average value for image x y sigma_x sigma_y standard deviation for image x y sigma_ xy covariance of x and y c_1 c_2 coefficients IV B. Evaluation The visual quality of generated images will be observed. Perceptual Loss is a weighted sum of the content loss and adversarial loss. Content Loss The SRGAN replaced the MSE loss with a VGG loss. The Generator upsamples LR images by 4x and will be trained to generate SR images. It has been applied to the DIV2K CelebA and other natural image datasets and here we want to see how it performs on OCT data. The discriminator will be trained to distinguish between HR SR images the GAN loss is backpropagated to the discriminator and the generator. SRGAN VGG19The SRGAN has the following code components 1. VGG loss is the euclidean distance between the feature maps of the generated SR image and the original HR image. Enhancing OCT image resolution with SRGANs Keywords unsupervised super resolution SRGAN VGG19 I. This architecture used a pre trained VGG 19 feature extractor and gave photorealistic results on large 4x upsampled low resolution images. The feature maps are the activation layers of the pre trained VGG 19 network. The SRGAN is implemented as follows Training 1. Photo Realistic Single Image Super Resolution Using a Generative Adversarial Network https arxiv. DataLoad data process data EDA IV. In addition standard quantitative metrics Peak Signal to Noise Ratio and Structural Similarity Index PSNR SSIM will be used to assess the results. Loss FunctionsThe most important contribution of the SRGAN paper was the use of a perceptual loss function. Feature extractor using the VGG19 network 4. This gives us pairs of HR and LR images for the training data set. ", "id": "shir0mani/enhancing-oct-image-resolution-with-srgan", "size": "7046", "language": "python", "html_url": "https://www.kaggle.com/code/shir0mani/enhancing-oct-image-resolution-with-srgan", "git_url": "https://www.kaggle.com/code/shir0mani/enhancing-oct-image-resolution-with-srgan", "script": "skimage.transform repeat keras.layers Activation keras.models keras compute_ssim plot_loss save_images build_VGG19 numpy Image compute_psnr Adam VGG19 BatchNormalization keras.applications Dense imageio LeakyReLU keras.callbacks imread sample_images plot_psnr build_generator keras.optimizers tensorflow build_discriminator Add matplotlib.pyplot build_adversarial_model PIL resize pandas TensorBoard Conv2D find_img_dims plot_ssim residual_block Model resize as imresize UpSampling2D Input asarray get_train_images itertools ", "entities": "(('Enhancing', 'super resolution'), 'unsupervise') (('Wikipedia https', 'two similar images'), 'measure') (('j _ _ LR _ _ j SR VGG loss phi 2 i', 'VGG19 network'), 'VGG') (('VGG loss', 'SR generated image'), 'be') (('SRGAN VGG19The SRGAN', 'code following components'), 'have') (('OCT imaging', 'commercial systems'), 'be') (('PSNR Peak Signal', 'noise Wikipedia'), 'be') (('computational enhancement', 'super resolution'), 'know') (('reconstructed image', 'G _ _ I HR image Plot loss IV natural C.'), 'limit') (('losses', 'SR corresponding generated image'), 'define') (('GAN loss', 'discriminator'), 'train') (('code', 'SRGAN paper'), 'Code') (('coherence tomography OCT IntroductionOptical scans', 'retina'), 'use') (('architecture', 'resolution upsampled low images'), 'use') (('us', 'feature extractor'), 'use') (('PacktPublishing Generative Adversarial Networks', 'Saeed Anwar et 4 al'), 'com') (('feature maps', 'activation trained VGG 19 network'), 'be') (('I MSE', 'pixel'), 'leave') (('which', 'original SRGAN'), 'use') (('Perceptual Loss', 'content weighted loss'), 'be') (('SRGAN model', 'GAN framework'), 'use') (('generator', '2'), 'follow') (('Content SRGAN', 'VGG loss'), 'Loss') (('Structural Similarity Index PSNR SSIM', 'results'), 'in') (('that', 'human observers'), 'have') (('plots', 'training save model weights'), 'install') (('we', 'OCT 2 subsampled scans'), 'be') (('issue', 'resolution SR reconstructed super images'), 'address') (('We', 'LR training synthetically data'), 'downsample') (('upsamples LR images', 'SR images'), 'train') (('network', 'feature extractor etcetera'), 'serve') (('Loss most important contribution', 'loss perceptual function'), 'be') (('Adversarial This', 'Discriminator'), 'Loss') (('they', 'frequency insufficient high details'), 'give') (('Here authors', 'perceptual loss'), 'use') (('how it', 'OCT data'), 'apply') (('This', 'training data set'), 'give') (('visual quality', 'generated images'), 'observe') (('Generative Adversarial Networks', 'https github'), 'Projects') "}
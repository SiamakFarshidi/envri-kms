{"name": "eda regression with statsmodels and scikit learn ", "full_name": " h1 Workflow h1 1 Load relevant libraries h1 2 Problem definition h1 3 Data Acquisition h1 4 Target variable inspection h1 5 Feature inspection h2 5 1 Feature Explanation h3 5 1 1 Cut h3 5 1 2 Color h3 5 1 3 Clarity h3 5 1 4 Carat h3 5 1 5 Depth and Table h4 5 1 5 1 Depth h4 5 1 5 2 Table h3 5 1 6 x y and z h3 What we learn h2 5 2 Data cleaning h3 Nulls h3 Data types h2 5 3 Feature engineering h1 6 Exploratory Data Analysis EDA h2 6 1 Univariate h3 Carat Weight h3 Cut h3 Color h3 Clarity h3 Depth h3 Table h3 Depth Table ratio h3 Valuable diamonds are they distributed differently h3 Conclusions What we ve learned h2 6 2 Multivariate h2 Cut vs Clarity h2 Cut vs Color h2 Clarity vs Color h2 Depth vs Cut h2 Table vs Cut h2 Depth vs Table vs Cut h2 Fixed carat how is price related to other features h3 Cut vs Color h3 Cut vs Clarity h3 Color vs Clarity h3 Conclusions what to expect from the models h1 7 Modelling h2 7 1 Statsmodels h3 7 1 1 First Model price carat h3 7 1 2 Second model log price carat h3 7 1 3 3rd model price carat carat 2 carat 3 carat 4 h3 7 1 4 4th model log price carat carat 2 carat 3 carat 4 h3 7 1 5 5th model log price ALL features h3 7 1 6 6th model log price ALL features depth table h3 7 1 7 7th model log price ALL features depth table cut h3 Statsmodels Conclusions h2 7 2 Scikit Learn h3 7 2 1 Get the data h3 7 2 2 Ridge Regression L2 norm penalization h3 7 2 3 Lasso Regression L1 norm penalization h3 7 2 4 Elastic Net Ridge Lasso h4 Coefficient comparison Ridge and Lasso h3 Scikit Learn Conclusions ", "stargazers_count": 0, "forks_count": 0, "description": "The value of a finished diamond is based on this combination. set up and perform GridSearchCV3. Data cleaningThis step is crucial. Seems to confirm that high quality grades increase price. Clarity clarity_grading https cdn. Machine Learning algorithms don t work with NaNs how missing values are encoded in pandas and numpy and some are very sensitive to outliers and absurd values. Depth Continuous numerical variable check for missing values absurd values scale and possible errors. It is relavant to dig a little deeper here and understanding why might it be that these entries are encoded as strings 1. 985 one indication that depth and table didn t help much Coefficient estimates are all significant F statistic s p value suggests there is high relationship between predictors and response Omnibus and JarqueBera still high but we ll see from residuals that theyare better behaved Skew is very close to zero suggesting more symmetrical residuals Kurtosis is somewhat large indicating more concentration of residuals around zero mean Condition Number got reduced and warning is now gone indicating that collinearity is not a huge issue now would need to see VIF statistic ti be sure but for simplicity won t do that now. Next both approach are put to work together. When they re put together using FeatureUnion the final output is coerced to an array. Residuals still ehxibit highly non linear pattern and heteroscadacity wasn t really taken care for. info performed at the beginning of the cleaning stage we know there are no missign entries but if we didn t remember that Values highly concentrated between 50 and 65. html __ y Xw 2_2 alpha w 2_2 This additional term penalizes large coefficients. Hope to be contributing to the Data Science community. 983 one indication that cut didn t help much Coefficient estimates are all significant F statistic s p value suggests there is high relationship between predictors and response Omnibus and JarqueBera still high but we ll see from residuals that theyare better behaved Skew is very close to zero suggesting more symmetrical residuals Kurtosis is somewhat large indicating more concentration of residuals around zero meanResiduals plot behaves similarly but now we see a few more high studentized residuals appearing. are they text data 2. From this we learn that cut may help estimate depth and table but the other way around is not true. Exploratory Data Analysis 6. R 2 achieved of 0. org page diamondcolor __ of a diamond actually refers to the lack of color in a diamond with perfectly colorless diamonds considered the highest quality with the highest value and brown or yellow diamonds being the lowest quality. What we ve done used Statsmodels to build some less complex models for the price task regression evaluated some statistical aspects of each model developed some knowledge about the importane of the features got an R 2 of about 0. Coefficient comparison Ridge and LassoNotice that even with a very low alpha Lasso shrinks the coefficients even more. NullsNo values missing or encoded as NaN. 3 for the maximum number of diamonds with same carat. Is there a relationship between the predictors and price 2. Below I summarize the entries on each column to see unique values. clarity_grading https cdn. Clarity vs Color Color seems to matter more for low cut grades. As a consequence Lasso is sometimes used to perform feature selection least important are left out. Visualizaing What we ve learned so far overall higher the weight higher the price relationship between mean price and carat bin is not linear first three bins mean value increases far more than the proportional increase in carat diamonds between 2 and 3 carats and between 3 and 4 carats apporximately same mean price diamonds heavier than 3 carats the price still goes up with carat but the increase is more moderate there are lighter diamonds that were highly valued why For the last observation let s check highly priced diamonds with small carat weight. On the other hand a depth of 65 percent for a round diamond would be excessive and be detrimental to its beauty. 2 could be solved using a non linear transformation on price such as sqrt price or log price. For simplicity and to prevent high collinearity from affecteing the coefficient estimates of the model I ll drop x y z since carat seem toSince depth_table_ratio doesn t add information will also drop alongside epth and table bins. TableAnalog to depth doesn t seem to help predicting price. Can we predict price with the predictors available 3. How is it distributed over the range of values Does it seem to follow a particular distribution We begin by taking a look at some 10 random observations Checking the data type and some statistics. x y and z Continuous numerical variable check for missing values absurd values scale and possible errors. png The ideal depth percentage varies with the shape of the diamond. Let s try turning to bins discretizing Depth values balanced across bins. Color color_grading https cdn. ColorOn the basis purely of color higher grades seem to decrease the value. in their book Introduction to Statistical Learning. No data type errors or typos. Since we have confirmed that x y I propose a set of steps to deal with absurd dimension values in the following order 1. Are there absurd values i. org resource resmgr images GemsJewelry 164901433526626. As explained Dataset page depth here is the depth percentage which can be approximated by depth z average x y 100. When y is available but x is absurd 15 or 0. jpg Large diamonds are rarer than smaller ones and as the carat weight increases the value of the diamond increases as well. Clarity grade is determined on a scale of decreasing clarity from the highest clarity Flawless or FL to the lowest clarity Included 3 or I3. Set up GridSearchCV find best parameter s 3. A depth percentage that may be too much for one shape might be essential for another. In order to leave the whole functionality in just one cell I reproduce the complete pipeline below Now we use this union pipeline alongside other functionalities. color_grading https cdn. Depth percentage https beyond4cs. This is largely due to these dimensions being highly correlated with carat and between themselves. Both are suggested by Hastie T. Although some preliminary analysis found no missing values NaNs it seems that 0. In the case 3 it might be that we ll need to perform some more cleaning steps. Only three rows present values above 12. org resource resmgr images GemsJewelry 135781409756963. What we do next use some powerful tools like Cross Validation in Scikit Learn to evaluate other models evaluate the generalization capacity of each model on the test set 7. Inspect coefficients visually As observed before the L1 penalty term in this particular dataset makes the alpha go very low almost turning off the regularization. 5 meaning it became non significant. Depth and TableFrom a different __ reference https beyond4cs. Data AcquisitionI separate a DataFrame data so that the changes I perform are recorded on it but there s still one version of the data untouched. Features inspection6. Carat With larger diamonds come higher prices. Carat Continuous numerical variable then it s good to check for missing values absurd values scale and possible errors. Chaging data type is good practice here for visualization and data analysis. Later I go from what I ve learned and build on top of that with Scikit Learn API as it s to me more friendly and more flexible. Predict and print metrics on test set 6. Data typesThree variables with object data type. Table appear to have a negative correlation with price 6. When turned to bins table seems to display a positive correlation with price except for depths greater than 65. Cut vs ColorInterpretation Table 10. com grading depth and table values __ I got information about depth and table. Taking a look at some summary statistics The. In doing so the coefficient estimate for table got a p value 0. The alpha term controls the regularization strength higher alpha stronger regularization smaller coefficients 1. If so how strong it this relationship 3. Also I ll use some of the Scikit Learn s funcionalities to speed the preprocessing steps. Clarity No clear difference in distributions on the basis of clarity. Feature inspection 5. Hope you ve enjoyed and that you feel like contributing commenting and upvoting basic libraries for data acquisition handling and visualization libraries for modelling check fror null values on target variable turn to categorical data type and order turn to categorical data type and order create Boolean mask to subset DataFrame compute mean value of x substitute on the dataFrame find rows where z is absurd define function to calculate z apply on dataframe create bins create column for bins create bin list create column for bins create bins list create columns for bins build polynomial carats exclude cons take quality features concatenate carat and quality features get responde DataFrame train model take quality features concatenate carat and quality features train_y_df remains as used in the previous example train model remove cut columns from DataFrame train_y_df is the same as used for the previous model train model as DataFrame as DataFrame create identifiers for polynomial features and linear features create the functions to get each subset of the data display polynomial features after transformation display first few lines of linear features in this case no other operation is performed join both pipelines into one display final resulting array s first 5 rows create identifiers for polynomial features and linear features create the functions to get each subset of the data join both pipelines into one create the regressor pipeline perform first fit and use as starting point set up grid of alphas to search set up GridSearch object to select best alpha and fit to data fit to data and print best scores and parameters predictions and actual values as arrays create the regressor pipeline perform first fit and use as starting point set up grid of alphas to search set up GridSearch object to select best alpha and fit to data fit to data and print best scores and parameters get prediction and actual values as arrays create alphas space for search prepare GridSearch arguments get prediction and actual values as arrays. However being inside this range does not guarantee a good cut. Here different than what has been seen previously both color and clarity grades seem to increase price very clearly. Looking at the count of diamonds below. Next let s look at the other end low values. Cut Not really good to see as there are way less highly priced diamonds. 9 above Very Good seems to be negatively related to price Here a non expected behavior appears. One way to solve it would be a non linear transformation on carat. 936 a very significant increase Coefficient estimates still significant F statistic display there is high relationship between predictors and response still Omnibus and JarqueBera suggest residuals are still far from normal Skew is very close to zero suggesting more symmetrical residuals Kurtosis is somewhat large indicating more concentration of residuals around zero meanUp until now I ve only looked at the residuals plot but now we take a look at the Studentized Residuals as well the Residuals divied Residuals plot displays that variance of error terms around 0 got more or less constant LOWESS line is almost a straight line Studentized Residuals Plot display there are high residuals 7. Expect to see majority of low prices because majority of diamonds are are light. 0 encodes missing values in this dataset. Carat weight has positive correlation with price and relationship seems highly non linear carat distribution is different between more valuable and less valuable diamonds. Feel free to make on this Kernel better as well by comenting and suggesting. The modern clarity scale was invented in the 1950s by a former president of GIA Richard T. Table is high or low probrably due to shape of cut. Table vs CutHere a very similar finding to that of table higher cut grades tend to be found around specific table values. html __ 1 2 n_ samples y Xw 2_2 alpha w _1 This additional term penalizes large coefficients but different from Ridge it actually shrinks smaller coefficients down to zero sparsity. Let s try using a table normalization and some colors In the case of the top 3 cut grades Highly priced diamonds don t seem to present a different distribution across cut grades both have majority of diamonds on high grades pprobably because overall there are more good grades than bad ones. Residuals should be equally scattered around zero line for all fitted values constant variance of residuals or homoscedacity the plot displays a non equally distributed behavior i. Residuals plot displays that variance of error terms around 0 got more or less constant Studentized Residuals Plot display there are still high residuals 7. negative zero strings data type problems etc. Are there missing values 2. The consequence is that smaller coefficients tend to produce smaller penalties and the coefficients are shrinked. UnivariateHow is each predictor alone related to price Carat WeightPartiotining carat into multiple bins for visualization shows carat is positively related to price relationship seems non linearLooking at how carat changes with price seems to hint yet again that log transforming price might be a good idea because of the shape of the relationship. Using a master set of diamonds specifically chosen based on their range of color a grader picks up the diamond and places it next to the individual diamonds in the master set. How many Depth 65 around 835 diamonds values of x y and z don t particularly stand out z just seems to be close to them probrably due to the shape of the cutDepth 58 around 581 diamonds values of x y and z don t particularly stand out z just seems to be far from them probrably due to the shape of the cutNo reason to cut out points outside Inter Quartile Range of boxplot but it s probably a good thing to verify how cut and depth interact in Exploratory Data Analysis. inspect coefficients5. This is as far as my expertise of both APIs go for now so I stop here. predict on test set6. com wp content uploads 2013 02 depthpercentagesofdiamond. Diamond clarity is the presence or absence of characteristics called inclusions in the diamond. cut is receiving bad reputation for something it may be not responsible for. All predictors when used solely have large and small priced diamonds over the entire range of their values categories. Domain and historical knowledge would be useful here but in the absence of any I ll simplify. 5 alpha 1 l1_ ratio w 2_2 Since two parameters are going to be tested nw we use RandomizedSearchCV to reduce the workload instead of testing 6 x 9 54 combinations it sample a number of them and return the best results. After this transformation the distribution of values allows for better statistical analysis and seems to improve models performances. org page diamondclarity __ is the state of being clear or transparent. Fixed carat how is price related to other features How quality features fare for a fixed carat does increase in quality mean increase in price So we select carat 0. Next when y is absurd 15 or 0. It is not to be confused with the shape like emerald or round or facet arrangement like brilliant or step cut but is instead a reference to the craftsmanship of the diamond and how it factors into the diamond s brilliance. Drawing a pair plot in order to visualize as scatter plots The same kind of relationship found between price and carat is reproduced between price and the dimensional features x y and z. for a given carat and color higher cut grade doesn t necessarily mean increase in price. Inspect coefficients visually As we have observed the GridSearchCV actually dound the best value for alpha to be very low. Table Continuous numerical variable check for missing values absurd values scale and possible errors. In case we forgot that Values highly concentrated between 58 and 65 but there are observations above and below. Carat is highly related to price in a non linear fashion log transforming price adding polynomial terms improved the fit visually2. By default uses alpha 1 and l1_ratio 0. Regarding statistical metrics R 2 got smaller and no improvement is found. Color In the case of color highly priced diamonds seem to appear more often alongdside bad color grades than with good color grades. About the distribution highly skewed to the right 1 4 of the diamonds below 950 50 of the diamonds below 2 400 1 4 of the diamonds between 2 400 and 5 300 50 of the diamonds between 950 and 5 300Given the skewness of the distribution I ve seen in a lot of kernel authors perfoming a log transformation on the target variable. jpg No null entries as observed with the. For the remaining observations when x is absurd 15 or 0. 5 Inter Quartile Range but there are too many to be outliers probrably are highly priced diamonds therefore can t lose this information. Depth Aside from having less points outside the box and whiskers the distributions seem analogous. org page diamondcut __ of a diamond refers to how well the diamond s facets interact with light the proportions of the diamond and the overall finish of the diamond. Also majority of diamonds have low carat weight. In short inclusions are the internal or external flaws of the diamond. Depth no very clear relationship with price 7. Define cmap for bivariate visualization Cut vs ClarityHow does the interaction between cut and clarity affect the mean price In Table 1 for a given value of cut higher mean prices are more associated with lower clarity grades. Statsmodels ConclusionsWell that s pretty much as far as my knowledge in Linear Regression Statistics and Statsmodels go. As expected from the feature explanation section these entries are categories written in the form of text. To reduce collinearity and increase the accuracy of the coefficient estimates we ll try next removing depth and table. Although polynomial terms tend to be somewhat collinear this value wasn t so high when only the carat terms were used Looking back at the pairplot we see that depth and table are fairly collinear. Of highly priced diamonds Three highest prices maximum grades for clarity and color Fourth highest price maximum grades for cut and color 2nd highest for clarity Between diamonds close in carat exceptionally good quality drives price up. 0 replace with the mean x value over the entire dataset3. Get the dataInstead of preparing a different complete DataFrame as I did for Statsmodels I ll use FunctionTransformer and FeatureUnion functionalities to transform the data on the fly for each model. Questions we may want to answer 1. print and store metrics R 2 Explained Variance RSME MAE7. Target variable inspection5. The numeric descriptors for the Diamond Cut Grade follow the American Gem Society s standards for how well a diamond is cut. AGS 3 or 4 VS have minor inclusions. Valuable diamonds are they distributed differently As all boxplots displaying price display a large number of diamonds outside Inter Quartile Range I investigate a little further highly priced diamonds. However when we look at Tables 2 and 3 we verify that the mean price is driven mainly by mean carat weight. Weight does not always enhance the value of a diamond either. First Model price caratAs a first model I start with the simplest possible as a starting point. org resource resmgr images GemsJewelry 79661461782004. CutAbout cut 87. Fit w best parameter s 4. ClarityAgain same overall pattern majority of cases receving low price lower grades with higher mean prices DepthAlone doesn t help predicting price. Exploratory Data Analysis EDA 6. Again similar behavior. How many Values of x y and z don t particularly stand out. for a given carat and clarity higher cut grade doesn t necessarily mean increase in price. 1 When y is availabele but x is absurd 2 When x is absurd but y is not availableFor simplicity as this only seems to happen when both are zero I do 3 Where x is available but y is absurd 4 When z is absurd Now all values seem to be fine 5. So a 60 percent table means that the table is 60 percent wide as the diamond s outline. We then try the polynomial approach on carat. Second model log price caratFirst just the log transformation of the response. Alone not a good predictor of price. This is my first practice Kernel in Data Science. AGS 1 or 2 VVS has minute inclusions that are difficult for a skilled grader to see under 10x magnification. Below I extract the features of interest for polynomial transformation and separately the feaures to go untouched in this case. The main purpose of the table facet is to refract light rays entering the diamond and to allow reflected light rays from the pavilion facets back into the observer s eye. fit model with best paramater s 4. Thefere the next model presents only the version where I removed both depth and table. Next we do indeed create a partition in carat weight but we split by 1. On a grading report there are normally two measurements of depth the first is the actual depth measurement in millimeters and the second is the depth percentage which shows how deep the diamond is in relation to its width. What we learn From the basic reserach of the literature we expect carat clarity color and cut to play a big role diamond price depth and table are also important but not clearly how x y and z are important as they help determine carat and depth but seem to be of secondary importanceI won t assume an order of importance between the 4 Cs since for me it isn t quite clear from the previous explanations which order this should be. Load relevant libraries 2. org stable modules generated sklearn. On the other hand I don t expect to any of the dimensions to be largely relevant as other variables already capture their importanca with them. Why would higher cut grades have lower prices Hypotheses Majority of diamonds have good cut grade. Since many inclusions and blemishes are very small and can be difficult to see with the naked eye they are graded at 10x magnification. JPG No null entries as observed with the. Scikit Learn ConclusionsAfter using Statsmodels to investigate linear models non linear transformation and analyse some easily available statistics we ve used Scikit Learn s API to build Pipelines to create polynomial terms on th fly and grid search for the best parameters perform regularized regressions with Ridge and Lasso investigate results on test setsBoth API s are great tools to fit and analyse models with some differences on outputs and capabilities. Again we trun to discretization for better visualization. My main goal was to use some basic Statsmodels API to evaluate some simple regression models. Notice the ouput of lin_pl pipeline is a DataFrame whereas the output of poly_pl pipeline is an array. Seemingly high number of high values above 1. Depth vs CutInteresting result it seems that high cut grades tend to be found more often around 60 and 65 more concentrated. When used together they describe the quality of a finished diamond. Cut vs ClarityInterpretation Table 13. 4th model log price carat carat 2 carat 3 carat 4 R 2 increased to 0. In practice this means regularization is almost absent. MultivariateFirst it s better to encode quality categorical variables so they get visible. 1 was expected since we saw visually that price and carat relationship was not linear. At the lower clarities may have an effect on the diamond s durability. Feature ExplanationAs I know absilutely nothing about diamonds beforehand checking some literature is always a good idead. 8 very weird when maximum x is about 10. This is the data type of strings text in Python. Depth vs Table vs CutAs observed better cuts tend to be more restrictive in terms of the range of depth and table values. 5 5th model log price ALL featuresThis time will use data as DataFrame for better interpretation of results. CutThe __ cut https www. z is the absolute value of depth and should be coherent with the depth x and y values. Regarding the best model Model 5 log price polynomial carat presented the best behavior in terms of residuals. Is there any particular pattern for the other variables Let s arbitrarily look at diamonds above 10 000. 200 grams or 1 5 gram and is subdivided into 100 points. In fact the Table for price seems a combination of the effects of carat and count of diamonds. Carat__ Carat https www. Cut vs ColorSimilar behavior to the observed for cut vs clarity price is mainly affected by carat but the count of diamonds shifts towards higher grades. Now looking at y vs carat. Inspect residuals As observed in the Statsmodels models although there are some very high residuals there are some good aspects to this Residuals plot Residusl resemble normality kind of Residuals seem to be equally dispersed around zero mean for all fitted values homoscedacity 7. x y and z x length in mm y width in mm z depth in mmThose are simply the dimensions of the diamonds. png No null entries as observed with the. for a given carat and cut higher clarity grade related to increase in price. Model didn t suffer much R 2 dropped to 0. Conclusions What we ve learned1. DepthThe depth of a diamond is its height in millimeters measured from the culet to the table. Like for depth let s try discretizing and check for patterns. 985 on the training set a few statistics pointed out that the model used might not be the best one however the ease of interpretation is in favor of the model built. Create pipelines to extract and treat differently each subset of the data. Let s check the potentially absurd values. Residuals plot displays that variance of error terms around 0 got more or less constant Studentized Residuals Plot display there are some very high residuals even higher then before 7. We ll see with Statsmodels that this will in fact improve the model and why it is so but for now I won t do that. Problem definitionWe want to predict diamond price continuous numerical based on certain measurements features using use prices already available. From the heatmap we see that carat x y and z are highly correlated with price and between themselves. png AGS 0 Flawless or Internally Flawless no inclusions or blemishes visible under 10x Internally Flawless diamonds have no inclusions visible under 10x but can have very minor blemishes marks and features confined to the surface only. Indeed log transforming seems to bring the data closer to fit with the help of a third order polynomial. 06 weight more than 3 carats. build pipeline to transform the data and apply a grid search for best parameters2. 3rd model price carat carat 2 carat 3 carat 4Now the U shaped is practically gone suggesting a better fit but heteroscedacity is still present. Specifically it seems to be between 55 and 63. Therefore I won t start with a simple model here and build it up rather I ll use Ridge and Lasso regressors from Scikit Learn regularized regression on the model with all features and see if I come to similar conclusions regarding feature importance and prediction capability. Which predictors seem to have greater impact 4. Depth Table ratioLike depth and table doesn t seem to be correlate with price. 7 7th model log price ALL features depth table cutOne last model now I will try removing cut since it seemed to display a low effect on price in the multivariate analysis cross tables want to check. org resource resmgr images GemsJewelry 116161409755629. No particular relationship. Cut cut_grading https cdn. However the increase in value is not proportionate to the size increase. are they categories written as text 3. com wp content uploads 2013 02 tableandtablepercentagesofdiamond. For example a 1 carat diamond will cost more than twice that of a \u00bd carat diamond assuming Color Clarity and Cut grade are the same. 985 a very significant increase Coefficient estimates are all significant F statistic s p value suggests there is high relationship between predictors and response Omnibus and JarqueBera suggest residuals are far from normal Skew is very close to zero suggesting more symmetrical residuals Kurtosis is somewhat large indicating more concentration of residuals around zero mean Condition Number is very high indicating high collinearity between terms. The following quote from the Gemological Institute of America summarizes the __ diamond quality factors https www. AGS 5 6 or 7 SI have noticeable inclusions that are fairly easy to see under 10x magnification sometimes these inclusions can be visible to the unaided eye. for a given carat and cut higher color grade related to increase in price. It s a Supervised Regression task. LOWESS Locally WEighted Scatterplot Smoothing curve shows a U shape suggesting a non linear relationship is present2. A few points we may want to check 1. org page diamondcarat __ is the unit of measurement for the physical weight of diamonds. Cut Color and Clarity given a carat value we expect them to increase price as the grade is higher but Color and clarity clearly displayed that increase when combined for a fixed carat value Cut from previous literature is expected to increase price but we couldn t see it so clearly other aspects may be affecting 3. Lasso Regression L1 norm penalizationOn top of the Ordinary Least Squares Lasso Regression adds a penalty term that is proportional to the absolute magnitude of the coefficients of the regression. However by including categorical features like clarity and color model 7 seemed to outperform model 5 in terms of prediction as measured by the R 2 although there are high studentized residuals for all fitted values. Inspect coefficients visually And the result is very similar to the that obtained with Statsmodels carat has the biggest average weight on price followed by the 2nd order term of carat depth table and cut have very low weight on price the quality features have increasing weight with increasing quality grade as expected. No null entries as observed with the. Next turn into category and set an order of importance. Cut Color Clarity appear to have negative correlation with mean price apart from Color frequency of diamonds is very similar across all grades. info method helps analysing a lot on information regarding data preparation. 5 weight 2 carats or less. It also happens to be the largest facet on a diamond and plays a vital role on brilliance and light performance of a stone. Ridge Regression L2 norm penalizationOn top of the Ordinary Least Squares Ridge Regression adds a penalty term that is proportional to the square of the coefficients from the regression. As most diamonds are approximately round shaped we expect x y. ColorThe __ color https www. dtype is float64 so only numeric entries. For instance a princess cut with a 75 or 77 percent depth would still be considered acceptable and can yield an attractive diamond. Finally when z is absurd 15 or 0. Clarity__ Clarity https www. AGS has a proprietary numeric and verbal descriptors for cut. What about the values themselves Some very low and some very high. Table from univariate analysis increase in table is related to decrease in price expect to see negative coefficient4. The verbal descriptors are AGS Ideal Excellent Very Good Good Fair and Poor. 9 very weird when maximum x is about 10. The diamond grader then decides the color grade based on the saturation of the color compared to the master set. TableThe table refers to the flat facet of the diamond which can be seen when the stone is face up. 6 weight 1 carat or less. In the American Gem Society there s a comprehensive explanation of the __ 4 C s of diamonds https www. Table_percentage https beyond4cs. 850 good for a starting value Coefficients are significant as p values are low F test for regression states there is a correlation between predictors and response residuals are non normal form Omnibus and Jarque Bera Proceeding to examine residuals 1. From the plot in fact the coefficients resemble those of Ridge regression. Depth don t seem to have any clear relationsip with price4. cut_grading https cdn. are they numeric that due to errors got coerced into object It s important to differentiate case 2 from case 1 as there s a specific category data type in Python that saves memory and allows for ordering which helps in data analysis tasks. edu diamond quality factor __ Diamonds with certain qualities are more rare and more valuable than diamonds that lack them. The size and severity of these flaws determines the grade. AGS 7 8 9 or 10 I have inclusions that are obvious at 10x magnification sometimes they can be seen with the naked eye. carat_ags https cdn. 7Visually inspecting Setting the axes limits between 0 and 15 reveals that the hypotheses that x is approximately equal to y was somewhat accurate. Minimizes 1 2 n_ samples y Xw 2_2 alpha l1_ ratio w _1 0. Are there outliers 4. Also approximating a diamond for a prism we should expect carat to be proportional to x y z. For simplicity I ll arbitrarily establish that above 15 is absurd. Scikit LearnThrough Statsmodels we ve already tried out a few models and using its statistical API came to a few conclusions regarding important features. Mean price seems to decrease as depth to table ratio increases. most of the diamonds carat 1 on average small price most of the diamonds Ideal cutBy association Ideal cut small pricesIt should be true then that cut only drives up the price when comparing same carat diamonds when alongside other distinctive quality factorsOn Bivariate Multivariate analysis predictors relationships between themselves we wnat to check that. AS a result the coefficients are not shrinked and feature selection is not performed. Table Very similar distributions as well. Two diamonds of equal weight may be unequal in value depending upon other determining factors such as Cut Color and Clarity. Moreover Data Cleaning focuses on removing problematic data entries whenever possible be it for computational and or statistical reasons. These are known as the 4Cs. With minor modifications it has been the universal standard ever since using verbal descriptors most are now familiar with Flawless Internally Flawless VVS1 VVS2 VS1 VS2 SI1 SI2 I1 I2 and I3. Need to look at combination between color and other quality factors and how they affect diamond prices. Conclusions what to expect from the models1. org page 4cs __ which is presented below very summarized. For better understanding it s good to go step by step. The equation below is taken from Scikit Learn s __ documentation https scikit learn. Inspect residuals Residuals plot resembles that of Ridge Regression as well. Hypothesis Like with cut the overall behvior is possibly being adversily affected by the majority of diamonds being light. png In a grading report table percentage is calculated based on the size of the table divided by the average girdle diameter of the diamond. AGS grades cut on a scale from 0 to 10 with 0 being Ideal and 10 being Poor. Target variable inspectionIt s a continuous variable. Color vs ClarityInterpretation Table 16. describe method reveals that there are at least three suposedly absurd situations x 0 no sense in a diamond with zero length y 58. Below we look at the count of diamonds once again. Load relevant libraries2. 0 aproximate using depth z average x y 100 showed in the Feature Explanation. We follow with a visual inspection on the distribution of prices. Feature engineeringI am not very skilled in this aspect but one idea comes to mind since cut is related to depth and table I combine depth and table into one variable. As in Ridge alpha term controls the regularization strength higher alpha stronger regularization smaller coefficients 1. Apparently large values above 4 are not absurds but big diamonds. It just lazily treats the data on demand for the algorithms and makes it easier to change the polynomial features degree. inspect residuals 7. We ve visually tested both so we ll now model them to see the results. 4 Elastic Net Ridge Lasso Combines the concepts of L1 and L2 regularizations by letting one chose the weight of each through the l1_ratio parameter. 6 6th model log price ALL features depth tableFor this model I tried first removing depth since it has weaker relationship with price. Taking a quick glance at the distribution As expected higher carat weights linked to greater dimensions of diamonds. ", "id": "alvaroacapelo/eda-regression-with-statsmodels-and-scikit-learn", "size": "38500", "language": "python", "html_url": "https://www.kaggle.com/code/alvaroacapelo/eda-regression-with-statsmodels-and-scikit-learn", "git_url": "https://www.kaggle.com/code/alvaroacapelo/eda-regression-with-statsmodels-and-scikit-learn", "script": "FeatureUnion train_test_split Ridge cross_val_score numpy seaborn cross_validate mean_absolute_error sklearn.linear_model FunctionTransformer explained_variance_score matplotlib.pyplot statsmodels.api sklearn.model_selection pandas r2_score sklearn.pipeline ElasticNet PolynomialFeatures mean_squared_error RandomizedSearchCV Pipeline LabelEncoder GridSearchCV sklearn.metrics Lasso StandardScaler sklearn.preprocessing ", "entities": "(('that', 'another'), 'be') (('coefficient so estimate', 'p value'), 'get') (('p values', 'Jarque Bera residuals'), 'good') (('Here non expected behavior', 'negatively price'), 'seem') (('com grading table _ I', 'depth'), 'depth') (('L2 one', 'l1_ratio parameter'), 'combine') (('where I', 'depth'), 'present') (('We', 'data type'), 'distribute') (('table', '60 percent outline'), 'mean') (('I', 'arbitrarily 15'), 'establish') (('pattern ClarityAgain same overall majority', 'DepthAlone doesn t price'), 'help') (('Mean price', 'table ratio increases'), 'seem') (('it', 'Flawless Internally Flawless VVS1 VVS2 VS1 VS2 SI1 SI2 I1 most now I2'), 'be') (('z', 'depth values'), 'be') (('we', 'more cleaning steps'), 'be') (('much R', '0'), 'suffer') (('200 grams', '1 5 100 points'), 'subdivide') (('It', 'light stone'), 'happen') (('sometimes they', 'naked eye'), 'AGS') (('2', 'sqrt such price'), 'solve') (('t', 'price'), 'seem') (('carat', 'z.'), 'approximate') (('Inspect residuals Residuals plot', 'Ridge Regression'), 'resemble') (('s', 'potentially absurd values'), 'let') (('size', 'grade'), 'determine') (('we', 'next depth'), 'reduce') (('This', 'Data first Science'), 'be') (('how it', 'brilliance'), 'be') (('So we', 'carat'), 'increase') (('Inter Quartile 5 too probrably highly priced therefore t', 'information'), 'Range') (('depth', 'table'), 'be') (('output', 'poly_pl pipeline'), 'notice') (('cut', 'still attractive diamond'), 'consider') (('largely dimensions', 'themselves'), 'be') (('it', 'features polynomial degree'), 'treat') (('grader', 'master set'), 'pick') (('whenever it', 'computational reasons'), 'focus') (('Apparently large values', '4'), 'be') (('I', 'one variable'), 'be') (('largely other variables', 'them'), 'expect') (('Residuals plot variance', 'very high even higher then 7'), 'display') (('model log 5 5th time', 'results'), 'price') (('skilled grader', '10x magnification'), 'have') (('doesn t', 'price'), 'table') (('Clarity', 'low cut grades'), 'seem') (('feature selection', 'result'), 'shrinked') (('so I', 'that'), 'see') (('Scikit LearnThrough Statsmodels we', 'important features'), 'try') (('we', 'that'), 'be') (('that', 'approximately y'), '7visually') (('Residuals plot variance', 'Studentized Residuals Plot more constant display'), 'display') (('linear non relationship', 'U shape'), 'show') (('diamond grader', 'master set'), 'decide') (('we', '1'), 'create') (('log Model 5 price polynomial carat', 'residuals'), 'present') (('Hypothesis overall behvior', 'diamonds'), 'affect') (('We', 'prices'), 'follow') (('setsBoth API', 'outputs'), 'perform') (('Also I', 'preprocessing steps'), 'use') (('quality high grades', 'price'), 'seem') (('However being', 'good cut'), 'guarantee') (('it', 'Exploratory Data Analysis'), 'stand') (('clarity modern scale', 'GIA Richard T.'), 'invent') (('regularization', 'practice'), 'mean') (('alpha term', 'regularization strength higher alpha stronger regularization smaller coefficients'), 'control') (('This', 'Python'), 'be') (('Below I', 'unique values'), 'summarize') (('main goal', 'regression simple models'), 'be') (('html _ _ Xw w 2_2 2_2 additional term', 'large coefficients'), 'y') (('alpha', 'actually best value'), 'dound') (('pretty much as far knowledge', 'Linear Regression Statistics'), 'ConclusionsWell') (('LOWESS more constant line', '0'), 'estimate') (('Below I', 'separately case'), 'extract') (('Hypotheses Majority', 'cut good grade'), 'have') (('log Indeed transforming', 'third order'), 'seem') (('basis', 'value'), 'seem') (('equation', 'Scikit _ _ documentation https below scikit'), 'learn') (('carat weight', 'diamond increases'), 'be') (('Now values', '3'), '1') (('Cut', 'higher grades'), 'affect') (('quality features', 'quality increasing grade'), 'have') (('Lasso', 'coefficients'), 'Ridge') (('Lasso', 'feature sometimes selection'), 'leave') (('Carat', 'higher prices'), 'come') (('Chaging', 'good here visualization'), 'be') (('better cuts', 'depth values'), 'observe') (('I', 'still one data'), 'separate') (('previously color grades', 'price'), 'seem') (('when x', 'remaining observations'), 'for') (('Condition Number', 'very high indicating high terms'), 'suggest') (('Next s', 'other end low values'), 'let') (('Now we', 'other functionalities'), 'reproduce') (('log transforming yet again price', 'relationship'), 'relate') (('they', 'quality categorical variables'), 's') (('I', 'target variable'), 'skewness') (('sometimes inclusions', 'unaided eye'), 'have') (('value', 'combination'), 'base') (('best however ease', 'model'), 'set') (('Table', 'cut'), 'be') (('which', 'this'), 'be') (('heteroscedacity', 'practically better fit'), 'carat') (('following quote', '_ _ diamond quality factors https www'), 'summarize') (('Diamond clarity', 'diamond'), 'be') (('depth here which', 'depth'), 'be') (('quality exceptionally good drives', 'close carat'), 'price') (('We', 'carat'), 'try') (('that', 'regression'), 'norm') (('s', 'carat small weight'), 'visualizae') (('When together they', 'finished diamond'), 'describe') (('I', 'model'), 'get') (('it', 'multivariate analysis cross tables'), 'feature') (('Two diamonds', 'Cut such Color'), 'be') (('com wp content', '2013 02 depthpercentagesofdiamond'), 'upload') (('how well facets', 'overall diamond'), 'refer') (('highest quality', 'highest value'), 'refer') (('GridSearch arguments', 'actual arrays'), 'create') (('Clarity grade', '3'), 'determine') (('they', '10x magnification'), 'grade') (('majority', 'diamonds'), 'expect') (('continuous numerical', 'use prices'), 'want') (('which', 'data analysis tasks'), 'be') (('it', 'zero sparsity'), '_') (('cut high grades', 'Depth CutInteresting'), 'result') (('Table', 'diamonds'), 'seem') (('it', 'values missing NaNs'), 'find') (('Carat Continuous numerical then it', 'missing values'), 'variable') (('a few more high studentized residuals', 'zero meanResiduals'), 'help') (('Carat', 'fit visually2'), 'be') (('Depth don t', 'price4'), 'seem') (('depth', 'beauty'), 'be') (('it', 'best results'), '2_2') (('Specifically it', '55'), 'seem') (('coefficients', 'smaller penalties'), 'be') (('Weight', 'diamond'), 'enhance') (('s', '10 000'), 'be') (('both', 'pprobably overall more good bad ones'), 'let') (('entries', 'strings'), 'be') (('Table', 'negative coefficient4'), 'relate') (('2 improvement', 'metrics statistical R'), 'get') (('some', 'very outliers'), 'work') (('Ridge alpha term', 'regularization strength higher alpha stronger regularization smaller coefficients'), 'control') (('distribution', 'models performances'), 'allow') (('Residusl normality resemble kind', 'values fitted homoscedacity'), 'be') (('However increase', 'size increase'), 'be') (('how diamond', 'width'), 'be') (('ti', 'that'), 'suggest') (('how well diamond', 'American Gem standards'), 'follow') (('don t', 'y'), 'stand') (('Again we', 'better visualization'), 'trun') (('z x y 100', 'Feature Explanation'), 'aproximate') (('model log price 4th carat', '2 3 4 2 0'), 'increase') (('it', 'me'), 'go') (('carat highly non linear distribution', 'more valuable less diamonds'), 'have') (('given carat', 'price'), 'mean') (('interaction', 'clarity more lower grades'), 'affect') (('Cut Color Clarity', 'very grades'), 'appear') (('Flawless Internally diamonds', 'surface'), 'AGS') (('Values', 'highly 58'), 'forget') (('when stone', 'diamond'), 'refer') (('Model price First first I', 'starting point'), 'carata') (('add', 'also epth bins'), 'for') (('AGS grades', '0'), 'cut') (('Table', 'price'), 'appear') (('Below we', 'diamonds'), 'look') (('carat x y', 'themselves'), 'see') (('predictors', 'greater impact'), 'seem') (('com wp content', '2013 02 tableandtablepercentagesofdiamond'), 'upload') (('distributions', 'box'), 'seem') (('same kind', 'price'), 'reproduce') (('AGS', 'verbal cut'), 'have') (('y width', 'simply diamonds'), 'be') (('absilutely nothing', 'beforehand literature'), 'ExplanationAs') (('s', 'bins'), 'let') (('other way', 'depth'), 'learn') (('Also majority', 'carat low weight'), 'have') (('coefficients', 'Ridge regression'), 'resemble') (('info method', 'data preparation'), 'help') (('I', 'any'), 'be') (('so clearly other aspects', '3'), 'expect') (('we', 'test'), 'use') (('mean price', 'carat mainly mean weight'), 'verify') (('main purpose', 'back eye'), 'be') (('more than twice that', 'Color Clarity'), 'cost') (('it', 'price'), 'feature') (('depth', 'back pairplot'), 'tend') (('s', 'patterns'), 'let') (('alpha', 'very low almost regularization'), 'inspect') (('now so I', 'APIs'), 'be') (('statistical aspects', '2 about 0'), 'use') (('it', 'step step'), 's') (('One way', 'non linear carat'), 'be') (('I', 'little further highly priced diamonds'), 'distribute') (('depth ideal percentage', 'diamond'), 'png') (('didn Values', 'highly 50'), 'info') (('so we', 'results'), 'test') (('grading report table percentage', 'diamond'), 'png') (('I', 'feature importance'), 'win') (('plot', 'residuals'), 'scatter') (('org page diamondcarat _ _', 'diamonds'), 'be') (('it', 'something'), 'receive') (('final output', 'array'), 'put') (('entries', 'text'), 'be') (('quality other how they', 'diamond prices'), 'need') (('Residuals', 'heteroscadacity wasn really care'), 'ehxibit') (('I', 'following order'), 'confirm') (('we', 'predictors'), 'predict') (('that', 'them'), 'be') "}
{"name": "santander ml explainability ", "full_name": " h3 CLEAR DATA MADE MODEL h2 Notebook Content h2 1 Introduction h2 2 A Data Science Workflow for Santander h2 2 1 Import h2 2 2 Setup h2 2 3 Version h2 3 Problem Definition h3 3 1 Problem Feature h3 3 2 Aim h3 3 3 Variables h2 3 4 evaluation h2 4 Exploratory Data Analysis EDA h2 4 1 Data Collection h1 Reducing memory size by 50 h2 4 1 1Data set fields h2 4 2 2 numerical values Describe h2 4 2 Visualization h2 4 2 1 hist h2 4 2 2 Mean Frequency h2 4 2 3 countplot h2 4 2 4 hist h2 4 2 6 distplot h2 4 2 7 violinplot h2 4 3 Data Preprocessing h2 4 3 1 Check missing data for test train h2 4 3 2 Binary Classification h2 4 3 3 Is data set imbalance h2 4 3 4 skewness and kurtosis h1 5 Machine Learning Explainability for Santander h2 5 1 Permutation Importance h3 Prepare our data for our model h3 Create a sample model to calculate which feature are more important h2 5 2 How to calculate and show importances h3 Here is how to calculate and show importances with the eli5 library h2 5 3 What can be inferred from the above h2 5 4 Partial Dependence Plots h2 5 5 Partial Dependence Plot h2 5 6 Chart analysis h2 5 7 SHAP Values h1 6 Model Development h2 6 1 lightgbm h2 6 2 RandomForestClassifier h2 6 3 DecisionTreeClassifier h2 6 4 CatBoostClassifier h2 6 5 Funny Combine h1 7 References credits ", "stargazers_count": 0, "forks_count": 0, "description": "3 4 evaluation Submissions are evaluated on area under the ROC curve http en. The most important feature was Var_110. 5 4 Partial Dependence PlotsWhile feature importance shows what variables most affect predictions partial dependence plots show how a feature affects predictions. CatBoostClassifier 64 1. 3 2 AimIn this competition The task is to predict the value of target column in the test set. but certainly the importance of each one is different 1. Permutation Importance 51 1. KernelExplainer works with all models though it is slower than other Explainers and it offers an approximation rather than exact Shap values. TreeExplainer my_model. com dansbecker partial plots 1. SHAP connects game theory with local explanations uniting several previous methods 1 7 and representing the only possible consistent and locally accurate additive feature attribution method based on expectations see the SHAP NIPS paper for details. com their mission is to help people and businesses prosper. com artgor how to not overfit1. com miklgr500 catboost with gridsearch cv 1. DecisionTreeClassifier 63 1. CatBoostClassifier 6 1 lightgbm 6 2 RandomForestClassifier 6 3 DecisionTreeClassifier 6 4 CatBoostClassifierNow you can change your model and submit the results of other models. 6 7 and partial dependence plots are calculated after a model has been fit. 300 MB before Reducing1. com c porto seguro safe driver prediction 4 3 1 Check missing data for test train 4 3 2 Binary Classification 4 3 3 Is data set imbalance A large part of the data is unbalanced but how can we solve it 1. All features are senseless named. com arjanso reducing dataframe memory size by 65 1. com arjanso reducing dataframe memory size by 65 Keeps track of columns that have missing values filled in. com dansbecker shap values https www. com dansbecker shap values 1. The features that are shown in white indicate that they have no effect on our prediction1. Imbalanced dataset is relevant primarily in the context of supervised machine learning involving two or more classes. com dansbecker partial plots For the sake of explanation I use a Decision Tree which you can see below. com mjbahmani 10 steps to become a data scientist Kaggle https www. Data Preprocessing 43 1. 5 6 Chart analysis1. io en latest library 5 3 What can be inferred from the above 1. com en us azure machine learning studio algorithm choice 1. com learn machine learning explainability in Kaggle. DeepExplainer works with Deep Learning models. Variables 33 1. how to extract insights from models Prepare our data for our model Create a sample model to calculate which feature are more important. csv a sample submission file in the correct format. What can be inferred from the above 53 1. The data provided for this competition has the same structure as the real data we have available to solve this problem. last update 10 03 2019You can Fork code and Follow me on GitHub https github. image credits https github. 5 2 How to calculate and show importances Here is how to calculate and show importances with the eli5 https eli5. com mjbahmani Kaggle https www. RandomForestClassifier1. org wiki Receiver_operating_characteristic between the predicted probability and the observed target. The features shown in red indicate that they have a negative impact on our prediction1. 5 1 Permutation Importance In this section we will answer following question 1. DecisionTreeClassifier1. Imbalance means that the number of data points available for different the classes is different Image source http api. they are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals. com slundberg shap Note Shap can answer to this qeustion how the model works for an individual prediction If you look carefully at the code where we created the SHAP values you ll notice we reference Trees in shap. com brandenkmurray nothing works change 20 to 2000 change 25 to 3000 to get best performance good for submit. RandomForestClassifier 62 1. Problem Feature 31 1. csv the training set. com dansbecker permutation importance 1. Partial Dependence Plots 54 1. Affect of each feature on the model s predictions. The Goal behind of ML Explainability for Santander is 1. Data Collection Visualization Data Preprocessing Data Cleaning 4 1 Data Collection Reducing memory size by 50 Because we make a lot of calculations in this kernel we d better reduce the size of the data. 6 5 Funny Combine you can follow me on GitHub https github. com learn machine learning explainability in kaggle. What features have the biggest impact on predictions 1. Visualization 42 1. As you can see from the above we will refer to three important and practical concepts in this section and try to explain each of them in detail. com gpreda santander eda and prediction https www. How to calculate and show importances 52 1. Exploratory Data Analysis EDA 4 1. As guidance to read the tree 1. 5 5 Partial Dependence PlotIn this section we see the impact of the main variables discovered in the previous sections by using the pdpbox https pdpbox. Machine Learning Explainability for Santander 5 1. Load packages 2 1. As you move down the top of the graph the importance of the feature decreases. com gpreda santander eda and prediction 1. png 4 3 4 skewness and kurtosis 5 Machine Learning Explainability for SantanderIn this section I want to try extract insights from models with the help of this excellent Course https www. in this section you will see following model 1. Santander ML Explainability CLEAR DATA. The task is to predict the value of target column in the test set. com brandenkmurray nothing works https www. com dansbecker partial plots https www. Note Yes Var_81 are more effective on our model. 3 3 VariablesWe are provided with an anonymized dataset containing numeric feature variables the binary target column and a string ID_code column. com dansbecker permutation importance https www. Notebook Content1. com files vvHEZw33BGqEUW8aBYm4epYJWOfSeUBPVQAsgz7aWaNe0pmDBsjgggBxsyq 8VU1FdBshuTDdL2 bp2ALs0E 0kpCV5kVdwu imbdata. Note how to extract insights from models 2 A Data Science Workflow for Santander Of course the same solution can not be provided for all problems so the best way is to create a general framework and adapt it to new problem. 150 MB after ReducingReducing for train data setReducing for test data set 4 1 1Data set fields 4 2 2 numerical values Describe 4 2 Visualization 4 2 1 hist 4 2 2 Mean Frequency 4 2 3 countplot 4 2 4 histIf you check histogram for all feature you will find that most of them are so similar 4 2 6 distplot The target in data set is imbalance 4 2 7 violinplot 4 3 Data PreprocessingBefore we start this section let me intrduce you some other compitation that they were similar to this 1. References 7 1 IntroductionAt Santander https www. com dromosys sctp working lgb 1. But the SHAP package has explainers for every type of model. 7 References creditsThanks fo following kernels that help me to create this kernel. 3 1 Problem Feature1. You can see my workflow in the below image You should feel free to adjust this checklist to your needs Go to top top 2 Load packages 2 1 Import 2 2 Setup 2 3 Version 3 Problem DefinitionIn this challenge we should help this bank identify which customers will make a specific transaction in the future irrespective of the amount of money transacted. Leaves with children show their splitting criterion on the top1. The pair of values at the bottom show the count of True values and False values for the target respectively of data points in that node of the tree. Model Development 6 1. Data Collection 41 1. Extract insights from models. Find the most inmortant feature in models. The y axis is interpreted as change in the prediction from what it would be predicted at the baseline or leftmost value. lightgbm 61 1. 4 Exploratory Data Analysis EDA In this section we ll analysis how to use graphical and numerical techniques to begin uncovering the structure of your data. com en us azure machine learning studio algorithm choice https docs. com arjanso reducing dataframe memory size by 65 kernel https www. A blue shaded area indicates level of confidence 5 7 SHAP Values SHAP SHapley Additive exPlanations is a unified approach to explain the output of any machine learning model. Problem Definition 3 1. com brandenkmurray nothing works for get better result chage fold_n to 5 import Dataset to play with it Based on this great kernel https www. com miklgr500 catboost with gridsearch cv https www. Could use multiple rows if desired package used to calculate Shap values Create object that can calculate shap values Calculate Shap values params is based on following kernel https www. com c home credit default risk1. 6 Model DevelopmentSo far we have used two models and at this point we add another model and we ll be expanding it soon. Funny Combine 65 1. com mjbahmani I hope you find this kernel helpful and some UPVOTES would be very much appreciated. In this kernel we are going to create a Machine Learning Explainability for Santander based this perfect course https www. partial plots https www. The features that are shown in green indicate that they have a positive impact on our prediction1. The test set contains some rows which are not included in scoring. com dromosys sctp working lgb https www. Exclude strings Print current column type make variables for Int max and min Integer does not support NA therefore NA needs to be filled test if column can be converted to an integer Make Integer unsigned Integer datatypes Make float datatypes 32 bit Print new column type Print final result written by MJ Bahmani written by MJ Bahmani for binary target Create the data that we will plot plot it Create the data that we will plot plot it Create the data that we will plot plot it Create the data that we will plot plot it use 1 row of data here. ", "id": "mjbahmani/santander-ml-explainability", "size": "12611", "language": "python", "html_url": "https://www.kaggle.com/code/mjbahmani/santander-ml-explainability", "git_url": "https://www.kaggle.com/code/mjbahmani/santander-ml-explainability", "script": "lightgbm train_test_split NuSVR pyplot IPython.display pyplot as plt check_balance CatBoostClassifier xgboost sklearn.svm numpy seaborn catboost check_missing_data tree norm reduce_mem_usage Pool sklearn.tree roc_auc_score matplotlib.patches sklearn StratifiedKFold matplotlib.pyplot DecisionTreeClassifier pdp info_plots svm sklearn.model_selection pandas PermutationImportance roc_curve RandomForestClassifier get_dataset scipy.stats matplotlib display eli5.sklearn pdpbox sklearn.metrics sklearn.ensemble ", "entities": "(('you', 'model'), 'see') (('d', 'data'), 'size') (('customers', 'money'), 'see') (('we', 'data'), 'EDA') (('it', 'approximation'), 'work') (('best performance', 'submit'), 'brandenkmurray') (('works', 'kernel https great www'), 'brandenkmurray') (('me', 'kernel'), '7') (('you', 'feature decreases'), 'move') (('they', '1'), 'set') (('features', 'predictions'), 'have') (('we', 'course https perfect www'), 'go') (('Image different source', 'api'), 'mean') (('we', 'it'), 'use') (('Imbalanced dataset', 'two classes'), 'be') (('them', 'monetary goals'), 'look') (('SHAP package', 'model'), 'have') (('5 Partial Dependence 5 section we', 'pdpbox https pdpbox'), 'PlotIn') (('we', 'available problem'), 'have') (('that', 'values'), 'arjanso') (('6 1 6 2 3 6 4 you', 'other models'), 'catboostclassifier') (('6 Funny 5 you', 'GitHub https github'), 'Combine') (('section I', 'Course https excellent www'), 'Explainability') (('nothing', 'https www'), 'work') (('it', 'baseline'), 'interpret') (('we', 'detail'), 'refer') (('certainly importance', 'one'), 'be') (('Goal', 'Santander'), 'be') (('SHAP', 'NIPS details'), 'see') (('how feature', 'predictions'), 'show') (('you', 'which'), 'plot') (('we', 'question'), 'Importance') (('so best way', 'new problem'), 'note') (('pair', 'tree'), 'show') (('What', 'above 1'), 'io') (('feature', 'sample model'), 'prepare') (('SHAP Values SHAP SHapley Additive 5 7 exPlanations', 'machine learning model'), 'indicate') (('Var_81', 'more model'), 'note') (('5 2', 'eli5 https eli5'), 'be') (('they', 'prediction1'), 'indicate') (('which', 'scoring'), 'contain') (('Leaves', 'top1'), 'show') (('2 task', 'test set'), 'aimin') (('Calculate Shap values params', 'kernel https www'), 'use') (('evaluation 3 4 Submissions', 'ROC curve'), 'evaluate') (('3 3 VariablesWe', 'target binary column'), 'provide') (('it', 'data'), 'make') (('task', 'test set'), 'be') (('we', 'shap'), 'answer') (('DeepExplainer', 'Deep Learning models'), 'work') (('how we', 'it'), 'train') (('What', 'above 53 1'), 'infer') "}
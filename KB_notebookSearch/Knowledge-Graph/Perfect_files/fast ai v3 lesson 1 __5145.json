{"name": "fast ai v3 lesson 1 ", "full_name": " h1 Lesson 1 What s your pet h2 Looking at the data h2 Training resnet34 h2 Results h2 Unfreezing fine tuning and learning rates h2 Training resnet50 h2 Other data formats ", "stargazers_count": 0, "forks_count": 0, "description": "21 using a complex model that was specific to pet detection with separate Image Head and Body models for the pet photos. pdf which features 12 cat breeds and 25 dogs breeds. This suggests that it just finds it difficult to distinguish some specific categories between each other this is normal behaviour. Lesson 1 What s your petIn this lesson we will build our first image classifier from scratch and see if we can achieve world class results. Other data formats bs 16 uncomment this line if you run out of memory even after clicking Kernel Restart. We will first see which were the categories that the model most confused with one another. It will be explained later in the course and you can learn the details in the resnet paper https arxiv. If this happens click Kernel Restart uncomment the 2nd line below to use a smaller batch size you ll learn all about what this means during the course and try again. In this particular dataset labels are stored in the filenames themselves. from_name_re gets the labels from the filenames using a regular expression https docs. It s astonishing that it s possible to recognize pet breeds so accurately Let s see if full fine tuning helps If it doesn t you can always go back to your previous model. Let s see how accurate we can be using deep learning We are going to use the untar_data function to which we must pass a URL as an argument and which will download and extract the data. To help it along let s us use larger images too since that way the network can see more detail. Furthermore when we plot the confusion matrix we can see that the distribution is heavily skewed the model makes the same mistakes over and over again but it rarely confuses other categories. We will need to extract them to be able to classify the images into the correct categories. The first thing we do when we approach a problem is to take a look at the data. Don t know what these things mean Not to worry we will dive deeper in the coming lessons. Our model will need to learn to differentiate between these 37 distinct categories. Fortunately the fastai library has a handy function made exactly for this ImageDataBunch. ResultsLet s see what results we have got. This is an indicator that our classifier is working correctly. For the moment you need to know that we are building a model which will take images as input and will output the predicted probability for each of the categories in this case it will have 37 outputs. The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models. We _always_ need to understand very well what the problem is and what the data looks like before we can figure out how to solve it. Training resnet34Now we will start training our model. 0 https hackernoon. ai course For more information you can visit https www. The main difference between the handling of image classification datasets is the way labels are stored. io convolutional networks backbone and a fully connected head with a single hidden layer as a classifier. com pytorch 1 0 468332ba5163. Looking at the dataWe are going to use the Oxford IIIT Pet Dataset http www. We are going to work with the fastai V1 library http www. Let s dive in Every notebook starts with the following three lines they ensure that any edits to libraries you make are reloaded here automatically and also that any charts or images displayed are shown in this notebook. We reduce the batch size a bit since otherwise this larger network will require more GPU memory. In this case the mistakes look reasonable none of the mistakes seems obviously naive. If you re using a computer with an unusually small GPU you may get an out of memory error when running this notebook. We will try to see if what the model predicted was reasonable or not. Basically resnet50 usually performs better because it is a deeper network with more parameters. We will use a convolutional neural network http cs231n. Taking a look at the data means understanding how the data directories are structured what the labels are and what some sample images look like. That s a pretty accurate model Training resnet50Now we will train in the same way as before but with one caveat instead of using resnet34 as our backbone we will use resnet50 resnet34 is a 34 layer residual network while resnet50 has 50 layers. uk vgg publications 2012 parkhi12a parkhi12a. uk vgg data pets by O. If you like this Kernel enough to fork it please remember to upvote as well This is the first notebook from version 3 of the fast. We import all the necessary packages. According to their paper the best accuracy they could get in 2012 was 59. We will train for 4 epochs 4 cycles through all our data. ai 2018 10 02 fastai ai which sits on top of Pytorch 1. Let s see if we can achieve a higher performance here. Unfreezing fine tuning and learning ratesSince our model is working as we expect it to we will unfreeze our model and train some more. ", "id": "hortonhearsafoo/fast-ai-v3-lesson-1", "size": "5145", "language": "python", "html_url": "https://www.kaggle.com/code/hortonhearsafoo/fast-ai-v3-lesson-1", "git_url": "https://www.kaggle.com/code/hortonhearsafoo/fast-ai-v3-lesson-1", "script": "fastai fastai.vision ", "entities": "(('this', 'other'), 'suggest') (('which', 'data'), 'let') (('usually better it', 'deeper more parameters'), 'perform') (('resnet34Now we', 'model'), 'start') (('which', 'cat 12 breeds'), 'pdf') (('displayed', 'notebook'), 'let') (('We', 'www'), 'go') (('they', '2012'), 'be') (('you', 'always back previous model'), 'astonish') (('it', '37 outputs'), 'need') (('we', 'results'), 'see') (('this', 'course'), 'click') (('we', 'higher performance'), 'let') (('you', 'resnet paper https arxiv'), 'explain') (('you', 'when notebook'), 'get') (('you', 'Kernel even Restart'), 'bs') (('we', 'how it'), '_') (('as well This', '3 fast'), 'remember') (('network', 'more detail'), 'let') (('Looking', 'www'), 'go') (('we', 'world class results'), 'Lesson') (('we', 'deeper coming lessons'), 'know') (('We', 'neural convolutional network'), 'use') (('when we', 'data'), 'be') (('you', 'https www'), 'ai') (('labels', 'image classification datasets'), 'be') (('fastai Fortunately library', 'exactly ImageDataBunch'), 'have') (('predicted', 'what'), 'try') (('over it', 'rarely other categories'), 'see') (('sample images', 'what'), 'mean') (('We', 'data'), 'train') (('mistakes', 'reasonable mistakes'), 'look') (('fastai 2018 10 02 which', 'Pytorch'), 'ai') (('model', '37 distinct categories'), 'need') (('we', 'more'), 'work') (('dataset particular labels', 'filenames'), 'store') (('from_name_re', 'expression https regular docs'), 'get') (('We', 'correct categories'), 'need') (('that', 'models'), 'provide') (('bit otherwise larger network', 'GPU more memory'), 'reduce') (('that', 'Body pet photos'), '21') (('resnet50 layer 34 residual resnet50', '50 layers'), 's') (('model', 'most one'), 'see') "}
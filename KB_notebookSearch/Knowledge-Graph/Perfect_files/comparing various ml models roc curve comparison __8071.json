{"name": "comparing various ml models roc curve comparison ", "full_name": " h3 Importing all the libraries h3 Reading the file h3 Let us check if there is any null values h3 Checking the encoded values h3 Plotting boxplot to see the distribution of the data h1 Standardising the data h1 Principal Component Analysis h3 Let us take only first two principal components and visualise it using K means clustering h3 Thus using K means we are able segregate 2 classes well using the first two components with maximum variance h1 Performing PCA by taking 17 components with maximum Variance h3 Splitting the data into training and testing dataset h1 Default Logistic Regression h1 Logistic Regression Tuned model h3 Taking a look at the correlation h1 Gaussian Naive Bayes h1 Support Vector Machine h1 Support Vector Machine without polynomial kernel h1 Support Vector machine with polynomial Kernel h3 Trying default model h3 Thus default Random forest model is giving us best accuracy h3 Let us tuned the parameters of Random Forest just for the purpose of knowledge h3 n jobs h3 Default Decision Tree model h3 Thus default decision tree model is giving us best accuracy score h3 Let us tune the hyperparameters of the Decision tree model h2 Neural Network h3 Applying default Neural Network model h3 Tuning the hyperparameters of the neural network ", "stargazers_count": 0, "forks_count": 0, "description": "Performing PCA by taking 17 components with maximum Variance Splitting the data into training and testing dataset Default Logistic Regression Logistic Regression Tuned model L1 and L2 are regularization parameters. Default Decision Tree model Thus default decision tree model is giving us best accuracy score Let us tune the hyperparameters of the Decision tree model 1 Criterion Decision trees use multiple algorithms to decide to split a node in two or more sub nodes. 2 activation Activation function for the hidden layer. Now let us check which features constitutes maximum information. The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors. Support Vector machine with polynomial Kernel Trying default model Thus default Random forest model is giving us best accuracy. L1 is the first moment norm x1 x2 w for regularization case that is simply the absolute d\u0131stance between two points where L2 is second moment norm corresponding to Eucledian Distance that is x1 x2 2 w 2 for regularization case. In simple words L2 Ridge shrinks all the coefficient by the same proportions but eliminates none while L1 Lasso can shrink some coefficients to zero performing variable selection. 1 hidden_layer_sizes Number of hidden layers in the network. This will give you positive class prediction probabilities This will threshold the probabilities to give class predictions. Higher number of trees give you better performance but makes your code slower. Increasing max_features generally improves the performance of the model as at each node now we have a higher number of options to be considered. Hence I am not running this. degree 2 3 4 5 6 C 1 10 100 500 1000 kernel poly tuned_parameters min_samples_leaf range 5 10 5 n_estimators range 50 200 50 max_depth range 5 15 5 max_features range 5 20 5 This will give you positive class prediction probabilities This will threshold the probabilities to give class predictions. Support Vector Machine without polynomial kernelThe grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the tuned_parameter. max_features and min_samples_leaf is same as Random Forest classifier Neural Network Applying default Neural Network model Tuning the hyperparameters of the neural networkIt is turning out to be computationally expensive for me with tuned model. We can see that the dataset has values in strings. 1 Auto This will simply take all the features which make sense in every tree. C min_sample_leaf Leaf is the end node of a decision tree. Both L1 and L2 regularization prevents overfitting by shrinking imposing a penalty on the coefficients. The details of Gini and entropy needs detail explanation. The 1st 17 components retains more than 90 of the data. Hence you need to strike the right balance and choose the optimal max_features. Gaussian Naive Bayes Support Vector MachineThe gamma parameter defines how far the influence of a single training example reaches with low values meaning far and high values meaning close. 2 max_depth Maximum depth of tree vertical depth Used to control over fitting as higher depth will allow model to learn relations very specific to a particular sample. Here we simply do not put any restrictions on the individual tree. 0001 4 max_iter Maximum number of iterations. Thus we perform label encoding on the data. The models used are as follows 1 Principal Component Analysis 2 Logistic Regression 3 Gaussian Naive Bayes 4 Support Vector Machine 5 Random Forest Classifier 6 Decision trees 7 Simple neural network Importing all the libraries Reading the file Let us check if there is any null values Thus we have two claasification. Also any suggestion to improvise it is welcome. default 200 This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. com kaggle docker python For example here s several helpful packages to load in Input data files are available in the. all rows all the features and no labels all rows label only Scale the data to be between 1 and 1 This will give you positive class prediction probabilities This will threshold the probabilities to give class predictions. The C parameter trades off misclassification of training examples against simplicity of the decision surface. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. The solver iterates until convergence determined by tol or this number of iterations. n_jobs This parameter tells the engine how many processors is it allowed to use. A value of 1 means there is no restriction whereas a value of 1 means it can only use one processor. The GridSearchCV instance implements the usual estimator API when fitting it on a dataset all the possible combinations of parameter values are evaluated and the best combination is retained. Hence it is important to try different values to get good estimate. So I am opting for RandomizedSearchCV. If only a subset of features are correlated with the label lasso outperforms ridge as in lasso model some coefficient can be shrunken to zero. Either the mushroom is poisonous or edible Thus we have 22 features 1st one is label and 8124 instances. Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub nodes. A low C makes the decision surface smooth while a high C aims at classifying all training examples correctly by giving the model freedom to select more samples as support vectors. They re used to avoid overfiting. For instance if the total number of variables are 100 we can only take 10 of them in individual tree. A logistic the logistic sigmoid function returns f x 1 1 exp x. Principal Component Analysis We can see that the last 4 components has less amount of variance of the data. But it is proving computationally expensive here. I am going to apply 6 Supervised machine learning models on the given dataset. Let us tuned the parameters of Random Forest just for the purpose of knowledge There are 3 features which can be tuned to improve the performance of Random Forest 1 max_features 2 n_estimators 3 min_sample_leaf A max_features These are the maximum number of features Random Forest is allowed to try in individual tree. B n_estimators This is the number of trees you want to build before taking the maximum voting or averages of predictions. You should choose as high value as your processor can handle because this makes your predictions stronger and more stable. B tanh the hyperbolic tan function returns f x tanh x. RandomizedSearchCV implements a randomized search over parameters where each setting is sampled from a distribution over possible parameter values. Large number may overfit the data. The strategy is to apply default model first with no tuning of the hyperparameter and then tuned them with different hyperparameter values and then I ll plot ROC curve to select the best machine learning model. 2 sqrt This option will take square root of the total number of features in individual run. 3 log2 It is another option which takes log to the base 2 of the features input. A smaller leaf makes the model more prone to capturing noise in train data. If all the features are correlated with the label ridge outperforms lasso as the coefficients are never zero in ridge. This has two main benefits over an exhaustive search 1 A budget can be chosen independent of the number of parameters and possible values. 2 Adding parameters that do not influence the performance does not decrease efficiency. Taking a look at the correlation The grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the tuned_parameter. But for sure you decrease the speed of algorithm by increasing the max_features. C relu the rectified linear unit function returns f x max 0 x 3 alpha L2 penalty regularization term parameter. We need to convert all the unique values to integers. Checking the encoded values Plotting boxplot to see the distribution of the data Separating features and label Standardising the data Note We can avoid PCA here since the dataset is very small. Let us take only first two principal components and visualise it using K means clustering Thus using K means we are able segregate 2 classes well using the first two components with maximum variance. ", "id": "nirajvermafcb/comparing-various-ml-models-roc-curve-comparison", "size": "8071", "language": "python", "html_url": "https://www.kaggle.com/code/nirajvermafcb/comparing-various-ml-models-roc-curve-comparison", "git_url": "https://www.kaggle.com/code/nirajvermafcb/comparing-various-ml-models-roc-curve-comparison", "script": "train_test_split pyplot pyplot as plt sklearn.svm numpy sklearn.cluster cross_val_score seaborn MLPClassifier subprocess SVC GaussianNB sklearn.naive_bayes sklearn.tree sklearn.neural_network sklearn.linear_model PCA sklearn auc matplotlib.pyplot DecisionTreeClassifier sklearn.grid_search metrics sklearn.model_selection pandas KMeans roc_curve RandomForestClassifier LogisticRegression matplotlib RandomizedSearchCV check_output LabelEncoder sklearn.decomposition GridSearchCV sklearn.metrics sklearn.ensemble StandardScaler sklearn.preprocessing ", "entities": "(('one', 'features 22 1st'), 'be') (('relu', 'linear unit function f alpha L2 penalty regularization term rectified max 0 3 parameter'), 'return') (('sure you', 'max_features'), 'decrease') (('dataset', 'strings'), 'see') (('details', 'detail explanation'), 'need') (('now we', 'options'), 'have') (('best combination', 'parameter values'), 'implement') (('Also suggestion', 'it'), 'be') (('code', 'better performance'), 'give') (('are', 'individual tree'), 'let') (('it', 'how many processors'), 'tell') (('grid search', 'tuned_parameter'), 'take') (('which', '2 features'), 'log2') (('predictions', 'high value'), 'choose') (('us', 'sub two nodes'), 'model') (('which', 'tree'), '1') (('high C', 'support vectors'), 'make') (('This', 'class predictions'), 'row') (('we', 'individual tree'), 'take') (('which', 'maximum information'), 'let') (('here dataset', 'PCA'), 'check') (('where setting', 'parameter possible values'), 'search') (('far values', 'low values'), 'define') (('Hence it', 'good estimate'), 'be') (('which', 'sub most homogeneous nodes'), 'split') (('model', 'train data'), 'make') (('Thus default Random forest model', 'best accuracy'), 'machine') (('We', 'integers'), 'need') (('Here we', 'individual tree'), 'put') (('null Thus we', 'two claasification'), 'be') (('Hence you', 'optimal max_features'), 'need') (('that', 'efficiency'), 'decrease') (('coefficient', 'zero'), 'shrink') (('that', 'x1 regularization 2 2 case'), 'be') (('I', 'given dataset'), 'go') (('Used', 'very specific particular sample'), '2') (('C min_sample_leaf Leaf', 'end decision tree'), 'be') (('you', 'predictions'), 'n_estimators') (('Default Logistic Regression Logistic model Tuned L1', 'training'), 'perform') (('you', 'output'), 'list') (('solver', 'iterations'), 'iterate') (('tan hyperbolic function', 'f tanh x.'), 'return') (('It', 'python docker image https kaggle github'), 'default') (('C parameter', 'decision surface'), 'trade') (('This', 'class predictions'), 'give') (('2 option', 'individual run'), 'sqrt') (('1 budget', 'parameters'), 'have') (('This', 'class predictions'), 'degree') (('gamma parameters', 'support vectors'), 'see') (('networkIt', 'tuned model'), 'be') (('sigmoid logistic function', 'f 1 exp 1 x.'), 'return') (('last 4 components', 'data'), 'Analysis') (('it', 'only one processor'), 'value') (('Support Vector Machine', 'tuned_parameter'), 'generate') (('then I', 'machine learning best model'), 'be') (('coefficients', 'ridge'), 'correlate') (('Thus we', 'data'), 'perform') (('L1 Lasso', 'zero performing variable selection'), 'coefficient') (('1st 17 components', 'data'), 'retain') (('we', 'maximum variance'), 'let') "}
{"name": "cord 19 round 2 task 8 risk factors ", "full_name": " h1 Extracting information on covid 19 risk factors and constructing benchmark data for building machine learning models h2 Summary Tables of Studies Addressing 24 Different Risk Factors h1 Introduction h4 This notebook was organized in the following structure h1 Developing a Cleaned Dataset with Annotated Entity Types h2 Processing the CORD 19 Dataset h2 Entity Annotation h2 Aggregation and Indexing of CORD 19 Articles h1 Creating the Summary Tables h2 Loading the Data h2 Retrieving COVID 19 Related Articles h2 Keywords for Retrieving Articles Related to the Summary Table h3 Defining extended keyword lists for risk factors severity terms and mortality terms h2 Extracting relevant information h3 Extracting sentences with ratio pattern from Text column and add a new column called Sentence h3 Running the pipeline for all the other risk factors h2 Generating Summary Tables h1 Building machine learning models to answer specific questions h2 Sentence parsing h4 Loading the json files h2 Getting the Shortest Paths for Risk Factors h3 Finding the shortest pathes in the typed dependency graph between risk factor terms and disease severity fatality terms h3 Let s take risk factor age as an example finding the shortest path for age to severity fatality terms h3 Getting the shortest paths for all the risk factors ", "stargazers_count": 0, "forks_count": 0, "description": "com gdsttian data nodes relations code for index by time https www. After parsing the sentence on local machine we stored the files as json files. io scispacy to annotate additional entities. Codes of the tools can be accessed by the following links code for utility tools https www. For articles with pmids and or pmcids the pmids and pmcids will be used for getting entities annotations from PubTator. com allen institute for ai CORD 19 research challenge we developed a dataset which is clean and annotated with different entities such as genes disease chemicals etc. Query of relevant articles plays an important role in creating the summary tables. These articles were queried using a list of keywords. age hypertension etc. Developing a Cleaned Dataset with Annotated Entity Types Processing the CORD 19 Dataset https www. If we manually annotate the sentences based on the questions we have proposed above then we can build machine learning models to extract the specific information required by the summary table. The manually verified data can be used to build machine learning models to develop better information extraction systems. Extracting sentences with ratio pattern from Text column and add a new column called SentenceFollowing regex will find pattern like ratio keywords any word any word or ratio keywords In the dataframe defined above we store the sentences with the ratio pattern in the column Sentence. com allen institute for ai CORD 19 research challenge discussion 150921 of the CORD 19 challenge https www. There are more than 35 thousand articles identified as relevant to COVID 19 in the CORD 19 dataset https www. com allen institute for ai CORD 19 research challenge last updated on June 09. When annotations by different tools overlap with each other we selected the annotations with the largest span. These manually curated data can also be used to build machine learning models. Defining extended keyword list for risk factors Defining extended keyword lists for severity terms and mortality terms Getting papers related with age searching over titles and abstracts published in 2020 Get the subset of Covid 19 related papers The following pattern is looking for pattern ratio keywords numbers Search over full text to get papers with pattern ratios such as OR AOR HR AHR RR RH and save these to a dictionary if any word in combined synonyms list is in abstract then we store the paper print rate if any word in combined synonyms list is in body text then we store the paper print rate Transfering dictionary to a dataframe If there are more than one sentences matching the pattern then store it in another column Sentence2 Combining column Setence and Sentence2 Here we use df_dic to store the dataframe. gov research pubtator provides annotations of biomedical concepts in PubMed abstracts and PMC full text articles. Each article was stored in a JSON file after the above pre processing. Extracting information on covid 19 risk factors and constructing benchmark data for building machine learning models Summary Tables of Studies Addressing 24 Different Risk FactorsWe developed a pipeline and a set of approaches to create the summary tables as specified in task 8 using the CORD 19 Dataset https www. py python data_aggregation. Getting the shortest paths for all the risk factorsshort_path. html BeFree http ibi. gov pmc about covid 19 and manual reading of some relevant articles. The manually verified data can be used as benchmark data for evaluating future studies on this type of problems 3. All codes for data aggregation and indexing were given as follows code for data aggregation https www. Does the sentence describe the risk factor relationship beween the risk factor term and the disease term or severity fatality 2. py python data_indexing_time. and disease keywords COVID 19 severity mortality etc. com allen institute for ai CORD 19 research challenge updated on June 9. The two models and the entities annotated by each model are listed as follows en_ner_craft_md genes taxonomies sequence ontologies chemicals gene ontologies and cellline en_ner_jnlpba_md DNA cell type cellline RNA and proteinAll annotations were combined into a final set of annotations. To be more specific the goal is to create summary tables report about Hypertension Diabetes Male gender Heart Disease COPD Smoking Status Age Cerebrovascular disease Cardio and cerebrovascular disease Cancer Respiratory system diseases Chronic kidney disease Chronic respiratory diseases Drinking Overweight or obese Chronic liver disease Asthma Chronic digestive disorder Dementia Endocrine diseases Heart Failure Immune system disorder Race Black vs White Ethnicity Hispanic vs non Hispacni This notebook was organized in the following structure 1. The CORD 19 competition https www. py python entities_post_tiabs_to_pubtator. To tackle the challenges we have organized a collaborative team including scientists from Insilicom Inc. com allen institute for ai CORD 19 research challenge asked participants to create summary tables with specific structures derived by expert curators. com a deep learning powered search engine for biomedical literature. py python data_nodes_relations. to_csv csv riskfactor_name. We will first try some pre trained deep learning models. com gdsttian data indexing word Creating the Summary TablesAfter the clean annotated dataset was created we can start the query and information extraction process. Insilicom specializes in providing innovative technologies to help scientists effectively use Big Data to accelerate their research and development efforts. Entity AnnotationEntity annotation is very helpful for extracting relevant information. py python data_indexing_word. All codes for annotations are available through the following links code for acquiring existing PubTator annotations https www. As most of the articles associated with COVID 19 were published in 2020 we limited the publication time to year 2020. PubTator https www. gov research pubtator annotations were then parsed and organized in a consistent format for each article. which also contain numerical results in the ratio pattern. Is a tagged number in the sentence the numerical result for such relationship If the answers to the above three questions are true then we can fill some important columns of the summary table. We manually verified the summary tables generated by our pipeline for the following purposes 1. py python entities_additional_annotation. gov research pubtator. For those without pre calculated annotations we used the PubTator https www. org nmonath befree src master. To tackle such problem we formulated it as building machine learning models to perform classification tasks. It recently developed the Biomedical Knowledge Discovery Engine BioKDE https biokde. scispacy https allenai. com gdsttian data aggregation code for entities summary and relation building https www. com allen institute for ai CORD 19 research challenge including scholarly articles related to COVID 19 was created for global research community to generate helpful insight for the ongoing combat against this infectious disease using state of the art text mining NLP and other AI technologies. Once the labelled training data are available we will build the model and update our notebook. py data pathes folder for system data path of final json files dictionary mapping cord_uid to numeric id for each paper dictionary of list of papers for each publish year dictionary of list of papers for each word in title dictionary of list of papers for each word in abstract word counts by paper entity checking lists including disease list blacklist etc. Transfer dictionary to a dataframe Adding column Sentence to store the sentences with pattern ratio keywords Modifying the dataframe Save dataframes as csv files dfn. gov research pubtator web interface to retrieve the annotations. Addtional work can be done to decide if the paper is truly relevant to the target table based on the column Sentence. io for tokenization of titles and abstracts. py pip install git https bitbucket. csv Save dataframes in a dictionary Get dataframe by risk factor name Study type extend keywords Regex for extracting sample size Filling Study Type Filling Sample Size Filling Ratios Saving risk factor dataframes into csv files Storing the files in a list and a dictionary Get the file from the dictionary Defining Graph data structure Note assumes edges are bi directional Defining dijsktra to get the shortest path from initial node to target node shortest paths is a dict of nodes whose value is a tuple of previous node weight next node is the destination with the lowest weight Work back through destinations in shortest path Reverse path Switching the order of a tuple Getting the intersection of two lists Getting the shortest path from initial node to target node with the dependecies print intersection sent_list combined_syn short_path dictionary take file name as a key and list of path as values gen_dic dictionary take touple from_node to_node file index as a key and path as a value file index is to distinguish those same from_node to_node print intersection sent_list combined_syn Saving gen_dic into a csv file. Loading the json files Getting the Shortest Paths for Risk Factors Finding the shortest pathes in the typed dependency graph between risk factor terms and disease severity fatality terms Let s take risk factor age as an example finding the shortest path for age to severity fatality terms. py python entities_process_pubtator_annotation. gov research pubtator index. Sentence parsingTo build the machine learning models since the training sample size will be relatively small we will perform sentence parsing to generate more informative input for the machine learning model. The shortest pathes are used to further curate the relevant sentences. keys Importing Python Packages and Tools Reading summary tables Displaying summary tables python preprocess_get_ids. Keywords for Retrieving Articles Related to the Summary Table Defining extended keyword lists for risk factors severity terms and mortality terms Extracting relevant informationWe will first take age as an example and later generalize to other risk factorsWith age related papers we select those papers with patterns indicating numerical outcome of the studies for example containing OR AOR HR AHR RR and RH. com gdsttian utils code for search tools https www. Using the PubTator https www. They will also be used in the future for building predictive models for the corresponding information extraction tasks Finally we have manually verified the summary tables before submitting to obtain a manually curated dataset which can be used in future studies as benchmark data. In order to use BeFree http ibi. com allen institute for ai CORD 19 research challenge tasks taskId 888. At the moment we are still working on generating high quality labelled data. git python entities_get_pubtator_annotation. gov research pubtator include Genes Diseases Chemicals Species Mutation CelllineBeside PubTator https www. We used spaCy https spacy. io scispacy includes different models for biomedical concept annotation among which two were used in our pipeline. Does the sentence contain numerical result for such relationship 3. Running the pipeline for all the other risk factorsTo this point we have dataframes with information needed to fill the summary table for different risk factors. Sentence parsing was performed using Stanford Parser. com gdsttian preprocess get ids code for article process https www. Other information can also be extracted and used in the model building process. These tools can be used for data loading article query and display. com gdsttian data indexing time code for index by words https www. com gdsttian entities post tiabs to pubtator code for retrieving completed title and abstract annotations from PubTator https www. When different tools annotate entities at the same span we gave priority to PubTator https www. gov research pubtator API we acquired annotations for the articles in the CORD 19 Dataset https www. The manually verified information can be more valuable for scientists studying COVID 19 2. The codes for extracting ids and article pre processing can be found as listed code for getting idscode for article process. com gdsttian entities additional annotation esearch pubtator include Aggregation and Indexing of CORD 19 ArticlesWith all the CORD 19 articles processed and the annotations combined they were aggregated into a single JSON file. com gdsttian befree ner covid19. com allen institute for ai CORD 19 research challenge was organized by Kaggle as a call for actions to develop tools and information for answering scientific questions with high priority. es befree annotates entities of genes and diseases a python package needs to be installed from the BeFree repo https bitbucket. Articles returned from the query were ranked by the counts of the keywords occuring in the articles. One type of information we extract from sentence result is the shortest pathes between risk factor terms and disease terms. For each article the entities identified were summarized and relations between entities were extracted if they co occur in the same sentence. code for getting ids https www. For example whether a sentence should be an entry in the table can be determined by answering the following questions 1. py python preprocess_cord_data. Note that these setences are all from the column Text. We import the python packages and the tools we developed for the process. com gdsttian preprocess cord data. We call this as ratio pattern. com gdsttian mining search tool Loading the Data Retrieving COVID 19 Related ArticlesInformation for the summary tables need to be extracted from the articles relevant to COVID 19. com allen institute for ai CORD 19 research challenge we verified the ids of doi pmid and pmcid of each article and organized all the articles in a consistent format. com gdsttian entities retrieve tiabs from pubtator code for parsing PubTator annotations https www. In order to retrieve target articles we created indices of articles by publication time and keywords in titles and abstracts. using PubTator https www. entities dictionary entity relation dictionary mapping sent id to numeric id mapping word to a list of numeric sent id dictionary of all sentences with unique id packages load dataset for search and display Defining extended keyword quries for risk factors Collecting the query name as a list for future usage. Click code to see the code. Such sentences are stored in the Sentence column in the generated dataframes. Creating the Summary Tables Retrieving COVID 19 Related Articles Keywords for Retrieving Articles Related to the Summary Table Extracting relevant infromation Generating the Summary Tables3. Our information extraction pipeline consists of the following components. Defining a function called get_odds to select papers with ratio pattern. com and the department of statistics of Florida State University. py python entities_retrieve_tiabs_from_pubtator. es befree in our pipeline we modified a function of the package which can be found here https www. First based on the CORD 19 dataset https www. The entities annotated by PubTator https www. Building machine learning models to answer specific questions Sentence Parsing Getting the shortest paths for risk factors Developing a Cleaned Dataset with Annotated Entity Types Processing the CORD 19 DatasetTo process the CORD 19 Dataset http https www. We defined the list of extended keywords based on those used by the PMC COVID 19 Initiative https www. All PubTator https www. com gdsttian entities process pubtator annotation code for adding BeFree and scispacy annotations https www. Here we are displaying our manually curated summary tables using the results of our pipeline IntroductionThe COVID 19 pandemic has caused nearly 8 million confirmed infected patients and more than 430 thousand deathes worldwide. Generating Summary Tables Building machine learning models to answer specific questionsFilling some columns of the summary table can be considered as answering certain questions. To answer these questions the current question answering systems do not work well because the answers are highly specific to the questions. com allen institute for ai CORD 19 research challenge when they are available. es befree and scispacy https allenai. gov research pubtator annotations we also used BeFree http ibi. In response to the pandemic the CORD 19 dataset https www. Round 2 https www. Task 8 is to create summary tables that address risk factor studies related to COVID 19 http www. In the above dataframe the column Text stores the paragraph with a matching pattern The column Ratio stores all the numerical results of the corresponding ratio pattern. Our current pipeline can extract sentences with both risk factor keywords i. com allen institute for ai CORD 19 research challenge Entity Annotation Aggregation and Indexing of CORD 19 Articles2. com gdsttian entities get pubtator annotation code for posting titles abd abstracts to PubTator for annotations https www. One of the articles was displayed as follows. io scispacy annotated entities Second we used extended keywords to query articles relevant to a paticular topic Third we used synonyms to further increase the coverage of the retrieved relevant articles Fourth we used regular expressions to extract specific information for filling certain columns of the tables Fifth we parsed the relevant sentences to obtain typed dependency graphs which were used to compute the shortest pathes between relevant keywords such as chemical names and COVID 19 related terms. ", "id": "bitmman/cord-19-round-2-task-8-risk-factors", "size": "15470", "language": "python", "html_url": "https://www.kaggle.com/code/bitmman/cord-19-round-2-task-8-risk-factors", "git_url": "https://www.kaggle.com/code/bitmman/cord-19-round-2-task-8-risk-factors", "script": "add_edge IPython.display intersection interactive get_odds utils Graph() tqdm shortest_path interact switch dijsktra mining_search_tool defaultdict pandas ipywidgets display widgets __init__ collections ", "entities": "(('we', 'json files'), 'store') (('we', 'Insilicom Inc.'), 'tackle') (('two', 'pipeline'), 'include') (('Entity AnnotationEntity annotation', 'very relevant information'), 'be') (('they', 'JSON single file'), 'include') (('Extracting', 'Dataset https 8 CORD 19 www'), 'develop') (('gov research pubtator', 'Genes Diseases Chemicals Species Mutation CelllineBeside PubTator https www'), 'include') (('they', 'same sentence'), 'summarize') (('article', 'pre processing'), 'store') (('It', 'Biomedical Knowledge Discovery Engine BioKDE https recently biokde'), 'develop') (('sentence', 'such relationship'), 'contain') (('disease keywords', 'severity mortality 19 etc'), 'COVID') (('com gdsttian preprocess', 'article process https www'), 'get') (('manually verified data', 'problems'), 'use') (('notebook', 'following structure'), 'be') (('com gdsttian entities', 'annotations https BeFree www'), 'process') (('manually verified information', 'COVID'), 'be') (('shortest pathes', 'further relevant sentences'), 'use') (('gov research pubtator we', 'Dataset https CORD 19 www'), 'API') (('then we', 'summary table'), 'build') (('pre processing', 'article process'), 'find') (('we', 'titles'), 'create') (('when they', 'com allen research ai CORD 19 challenge'), 'institute') (('we', 'notebook'), 'be') (('which', 'genes disease chemicals such etc'), 'institute') (('com allen institute', 'last June'), 'update') (('we', 'largest span'), 'select') (('we', 'PubTator https www'), 'give') (('we', 'process'), 'import') (('returned', 'articles'), 'rank') (('we', 'information query process'), 'create') (('current pipeline', 'risk factor keywords i.'), 'extract') (('gov research pubtator we', 'BeFree http also ibi'), 'annotation') (('tools', 'data loading article query'), 'use') (('setences', 'all column'), 'note') (('we', 'publication time year'), 'limit') (('Here we', 'dataframe'), 'store') (('displaying', '8 nearly million confirmed infected patients'), 'cause') (('One', 'articles'), 'display') (('manually curated data', 'machine learning also models'), 'use') (('which', '19 related terms'), 'scispacy') (('com gdsttian entities', 'PubTator annotations https www'), 'retrieve') (('codes', 'PubTator annotations https existing www'), 'be') (('We', 'following purposes'), 'verify') (('information extraction pipeline', 'following components'), 'consist') (('well answers', 'highly questions'), 'work') (('then we', 'summary table'), 'be') (('articles', 'keywords'), 'query') (('which', 'benchmark data'), 'use') (('Other information', 'model building also process'), 'extract') (('columns', 'certain questions'), 'consider') (('we', 'AOR HR AHR OR RR'), 'take') (('actions', 'high priority'), 'organize') (('we', 'PubTator https www'), 'use') (('Codes', 'utility tools https www'), 'access') (('com gdsttian entities', 'PubTator https abstract www'), 'post') (('codes', 'data aggregation https www'), 'give') (('point we', 'risk different factors'), 'have') (('we', 'still high quality labelled data'), 'work') (('scientists', 'research efforts'), 'specialize') (('manually verified data', 'information extraction better systems'), 'use') (('gov research pubtator', 'PubMed abstracts'), 'provide') (('dictionary', 'print intersection sent_list combined_syn csv to_node file'), 'dataframe') (('we', 'risk factor shortest terms'), 'be') (('entry', 'following questions'), 'be') (('Query', 'summary tables'), 'play') (('we', 'consistent format'), 'institute') (('sequence ontologies', 'annotations'), 'list') (('research 19 global community', 'art text'), 'create') (('keys', 'summary tables python preprocess_get_ids'), 'read') (('We', 'learning deep models'), 'try') (('disease severity fatality s', 'fatality terms'), 'load') (('paper', 'column'), 'do') (('gov research pubtator annotations', 'article'), 'parse') (('sentence', 'risk factor term'), 'describe') (('pmids', 'PubTator'), 'use') (('com allen institute', 'expert curators'), 'ask') (('Such sentences', 'generated dataframes'), 'store') (('We', 'Initiative https PMC COVID 19 www'), 'define') (('we', 'column'), 'find') (('py data pathes', 'disease list blacklist etc'), 'folder') (('Sentence parsing', 'Stanford Parser'), 'perform') (('com gdsttian entities', 'annotations https www'), 'get') (('relatively we', 'machine learning model'), 'build') (('we', 'classification tasks'), 'formulate') (('that', 'http 19 www'), 'be') (('which', 'package'), 'modify') (('which', 'ratio pattern'), 'contain') (('i d', 'future usage'), 'send') (('19 Related ArticlesInformation', 'relevant COVID'), 'tool') "}
{"name": "getting started with standard gans tutorial ", "full_name": " h1 How to Paint with Generative Adversarial Networks h2 Introduction and Setup h1 Load in the data h1 Build the DCGAN h2 Network Upsample and Downsample h2 Build the generator h2 Build the discriminator h2 Define the Least Squares Loss h2 Throw it on the TPU h3 Things to note h1 What about Second GANs h3 Check that notebook out here where we use the improvements from this notebook h1 Create submission files ", "stargazers_count": 0, "forks_count": 0, "description": "ch event 595059 contributions 2497383 attachments 1431666 2199445 gan_presentation_IML. reduce_mean predictions_real labels_real 2 2. You can see I put down a bit of augmentation using random_jitter and flip to increase our data set because we simply don t have enough data forThen load the data and display the first images to see if it all worked out. So this is where we compile and train the model. Notice that I changed the loss function from the Binary Crossentropy used in the CycleGAN to a Least Squares approach taken from the RaLSGAN for dogs https www. Finally we can compare apples to oranges. png Figure describing Generative Adversarial Networks from my PhD thesis https dramsch. The learning process is collaborative. reduce_mean predictions_real labels_real 2 tf. Because we are building a generative model we don t need the labels or the image id so we ll only return the image from the TFRecord. Build the generatorThis generator samples from noise reshapes it and upsamples the entire thing. Build the discriminatorThe discriminator takes in the input image and classifies it as real or fake generated. The problem This is now two GANs to train that perforn the forward and backward transformation to create the new style from nothing. Build the DCGAN Network Upsample and DownsampleThe downsample as the name suggests reduces the 2D dimensions the width and height of the image by the stride. As the instance normalization is not standard in the TensorFlow API we ll use the layer from TensorFlow Add ons. Because TPUs are pretty awesome. The stride is the length of the step the filter takes. Maybe you ll even find some in the comments. real_label Add random noise to the labels important trick Train the generator Train the discriminator Calculate loss LSGan d_loss tf. The generator gets better at fooling the discriminator and the discriminator gets better at figuring out which data is real and which isn t. All the images for the competition are already sized to 256 x 256. fill batch_size 1 self. Please head over and upvote https www. You can probably guess that they can be tricky to train due to so many moving parts. What about Second GANs Alternatively because us machine learning scientists had a bit too much GPUs running idle people came up with the idea of cycle consistent GANs. The DCGAN would not converge on BCE whatsoever and the LSGAN works surprisingly well for the amount of data we have. First load in the filenames of the TFRecords. They re a really cool concept and even used in scientific simulation at CERN https indico. com speedwagon ralsgan dogs. com jesperdramsch how to paint with more gans ls cyclegan aug You can create Monets with Generative Adversarial Networks GAN in a few different ways. The private investigator discriminator randomly gets assigned real and fake data to investigate. They re pretty useful generally and have been applied in many domains and style transfer applications. Some important stuff you may want to check out if you re interested are keywords like Wasserstein GANs Gradient Penalization Attention and in this context Style Transfer namely face2face. GAN from Dramsch PhD thesis. io CycleGAN images objects. The artist generator draws its inspiration from a noise sample and creates a rendering of the data you are trying to generate with said GAN. GANs are technically two networks that work against each other illustrated below. org wiki Nash_equilibrium is reached which means neither can learn new tricks and get better. com jesperdramsch intro to deep fakes videos and metadata eda if you re interested to learn how GANs are used to alter images videos and sounds. Import the following packages and change the accelerator to TPU. io CycleGAN for when you don t have Monet available to paint your favorite subject. reduce_mean predictions_gen labels_real 2 2 Train the generator Train the discriminator Calculate loss LSGan g_loss tf. Did I mention they re quite versatile This also builds on the Baseline Tutorial. io examples generative dcgan_overriding_train_step. Additionally we need to scale the images to a 1 1 scale. Since the stride is 2 the filter is applied to every other pixel hence reducing the weight and height by 2. We can generate them from scratch using one GAN where the GAN basically imagines a Monet from scratch. This has become a very popular area of research warranting a GAN Zoo https github. Instead of outputing a single node the discriminator outputs a smaller 2D image with higher pixel values indicating a real classification and lower values indicating a fake classification. Things to noteWe re using a few tricks here including soft labeling differing learning rates augmentation a better loss function etc. reduce_mean predictions_gen labels_real 2 tf. reduce_mean predictions_real tf. Which of course it does because it s taken directly from the tutorial. Conv2DTranspose does basically the opposite of a Conv2D layer. jpg Check that notebook https www. We ll load both for the CycleGAN. For the first GAN we only need the Monets as training data. com amyjang monet cyclegan tutorial Introduction and SetupFor this tutorial we will be using the TFRecord dataset. We ll be using an instance normalization instead of batch normalization. png Load in the dataWe want to keep our photo dataset and our Monet dataset separate. com jesperdramsch how to paint with more gans ls cyclegan aug out here where we use the improvements from this notebook Create submission files resizing to 286 x 286 x 3 randomly cropping to 256 x 256 x 3 random mirroring extract 1 batch from the dataset bs 256 256 3 Upsampling bs 128 128 64 bs 64 64 128 bs 32 32 256 bs 34 34 256 bs 31 31 512 bs 33 33 512 bs 30 30 1 generates Monet esque paintings differentiates real Monet paintings and generated Monet paintings Sample random points in the latent space labels_gen tf. Upsample does the opposite of downsample and increases the dimensions of the of the image. reduce_mean predictions_gen tf. CycleGANs were introduced for unpaired Image to Image Translation https junyanz. In mathematical terms they are learning until a Nash equilibrium https en. How to Paint with Generative Adversarial Networks This is part 1 see part 2 here https www. As these images are RGB images set the channel to 3. Define the Least Squares Loss Throw it on the TPU And build a GAN with the help of the keras documentation https keras. com hindupuravinash the gan zoo of all named GANs. fake_label labels_real tf. In this tutorial we ll go in depth into Creating images from noise Deep Convolutional Generative Adversarial Networks DCGANs Better Loss Functions Data Augmentations Training Tensorflow GANs on TPUs This copies in part from my Intro to Deepfakes https www. ", "id": "jesperdramsch/getting-started-with-standard-gans-tutorial", "size": "6238", "language": "python", "html_url": "https://www.kaggle.com/code/jesperdramsch/getting-started-with-standard-gans-tutorial", "git_url": "https://www.kaggle.com/code/jesperdramsch/getting-started-with-standard-gans-tutorial", "script": "albumentations flip tensorflow_addons load_dataset random_jitter keras kaggle_datasets discriminator_loss functools numpy view_image generator_loss decode_image layers Generator upsample KaggleDatasets tensorflow random_crop tensorflow_datasets matplotlib.pyplot train_step downsample preprocess_image_train partial MonetGan(keras.Model) Discriminator tensorflow.keras compile read_tfrecord __init__ normalize ", "entities": "(('we', 'TensorFlow Add ons'), 'use') (('private investigator', 'randomly real data'), 'assign') (('GAN we', 'training data'), 'need') (('where we', 'model'), 'be') (('where GAN', 'scratch'), 'generate') (('filter', 'step'), 'be') (('Maybe you', 'comments'), 'find') (('This', 'GAN Zoo https github'), 'become') (('Conv2DTranspose', 'Conv2D layer'), 'do') (('png Load', 'photo dataset'), 'want') (('This', 'Generative Adversarial How Networks'), 'paint') (('probably they', 'so many moving parts'), 'guess') (('CycleGANs', 'Image Translation https junyanz'), 'introduce') (('we', 'https www'), 'go') (('technically two that', 'other'), 'be') (('it', 'first images'), 'see') (('images', 'already 256 256'), 'sized') (('png Figure', 'PhD thesis https dramsch'), 'describe') (('They', 'style pretty generally many domains applications'), 're') (('we', 'TFRecord dataset'), 'com') (('Upsample', 'image'), 'do') (('they', 'Nash equilibrium https'), 'learn') (('2 filter', '2'), 'apply') (('images', '3'), 'be') (('you', 'context'), 'be') (('I', 'dogs https www'), 'notice') (('real_label', 'discriminator'), 'Add') (('Things', 'labeling learning rates loss here soft differing better function'), 'augmentation') (('Finally we', 'oranges'), 'compare') (('quite This', 'Baseline also Tutorial'), 'mention') (('so we', 'TFRecord'), 'build') (('it', 'directly tutorial'), 'do') (('We', 'instance normalization'), 'use') (('you', 'GAN'), 'draw') (('neither', 'new tricks'), 'reach') (('labels_gen', 'latent space'), 'jesperdramsch') (('cyclegan You', 'a few different ways'), 'jesperdramsch') (('They', 'CERN https indico'), 're') (('we', 'data'), 'converge') (('data', 'better discriminator'), 'get') (('Additionally we', '1 1 scale'), 'need') (('how GANs', 'images videos'), 'intro') (('now two that', 'nothing'), 'problem') (('name', 'stride'), 'build') (('bit too much GPUs idle people', 'cycle consistent GANs'), 'about') (('discriminator', 'lower fake classification'), 'of') (('don Monet', 'favorite subject'), 'io') "}
{"name": "ai bootcamp w1 challenge 2 layer nn group 6 ", "full_name": " h1 Week 1 Challenge h2 The task h2 The data h3 Loading the data into Python h2 Logistic regression h2 2 Layer network h2 3 Layer network h2 Excel tips h3 Matrix multiplication h3 You cannot change part of an array h3 Transpose h3 Exponents h3 Softmax h3 Random initialization h2 Grading h2 Submission ", "stargazers_count": 0, "forks_count": 0, "description": "So you need to make the reference to those fixed. The normalized data and one hot encodings have been copied over to the logistic regression and 2 Layer Wine net sheet. The activation function of the hidden layer is tanh the activation function for the output layer is softmax again. Get labels Get inputs Print shapes just to check Package imports Matplotlib is a matlab like plotting library Numpy handles matrix operations SciKitLearn is a useful machine learning utilities library The sklearn dataset module helps generating datasets Display plots inline Just some helper functions we moved over from the last chapter sigmoid function Log Loss function Log loss derivative Load parameters from model Linear step First activation function Second linear step Second activation function Load parameters from model Load forward propagation results Backpropagation Calculate loss derivative with respect to output Calculate loss derivative with respect to second layer weights Calculate loss derivative with respect to second layer bias Calculate loss derivative with respect to first layer Calculate loss derivative with respect to first layer weights Calculate loss derivative with respect to first layer bias Store gradients Helper function to plot a decision boundary. com en us article MMULT function 40593ed7 a3cd 4b6b b9a3 e4ad3c7245eb. You may choose the size of the two hidden layers yourself. Make sure to use Paste values only when you copy over the weights Try to experiment with the learning rate while you train and get the loss as low as possible. You will learn about normalization next week but the basic goal is to ensure that all features of the data have the same mean and standard deviation. The Excel file contains everything you need to solve the challenge in Excel. You can load the data like this Here the parameters are initialized for 2 layer neural network. Logistic regressionYour first task it to implement logistic regression in Excel. If you don t fully understand this function don t worry it just generates the contour plot below. The network has an input size of 13 and an output of 3. The taskYou got a call from Italy. Loading the data into PythonYou can fork this notebook or simply create a new Kernel connected to this Kernels datasource in Kaggle. ExponentsYou can calculate e x using the EXP function. To make training easier the data has also been normalized already. GradingThis weeks challenge is not a competition for the most accurate prediction. com en us article TRANSPOSE function ed039415 ed8a 4a81 93e9 4b6dfac76027 function. Set min and max values and give it some padding Generate a grid of points with distance h between them Predict the function value for the whole gid Plot the contour and training examples Do forward pass get y_hat Turn values to either 1 or 0 Get total number of examples Do a prediction with the model Ensure prediction and truth vector y have the same shape Calculate the number of wrong examples Calculate accuracy First layer weights First layer bias Second layer weights Second layer bias Package and return model Load parameters Update parameters Store and return parameters Gradient descent. Instead you are to build a classifier which recognizes the wine maker from 13 attributes of the wine. You will implement a multi class classifier in Excel and Python. To update parameters copy over the New W1 and New b1 over into W1 and b1 on the left of the sheet. So scroll to the right to see the full sheet. It uses a softmax activation for the output layer. To multiply two matrices select the output area where you want the output to be enter the formula and hit CONTROL SHIFT ENTER. To make the sheet easier to handle Forward pass Backward pass and weight update are ordered horizontally not vertically. 3 Layer networkAfter you have implemented a 2 layer network open a new sheet and implement a 3 layer network. To calculate the exponent of multiple values element wise like you have to do for softmax you enter EXP and then the range of cells. The goal of the challenge is to deepen your understanding of how neural networks work. The dataYou can find all data in the datasource connected to this notebook on kaggle. 2 Layer networkIn the next sheet you will implement a 2 layer neural network. See this youtube tutorial https www. Just make sure that the output has a size of 3. The hidden unit has a size of 5. You deserve to kick your feed up and enjoy a glass of wine. In this case either hit CONTROL SHIFT ENTER to apply the formula for the entire area or exit with ESC. Alcohol Malic acid Ash Alcalinity of ash Magnesium Total phenols Flavanoids Nonflavanoid phenols Proanthocyanins Color intensity Hue OD280 OD315 of diluted wines Proline The wine makers had 178 bottles left in their cellars. Say you have a sample with 3 values you want to compute softmax for. So to create random numbers once and then freeze them use RAND for all cells first then copy it and paste the values using paste values only on the same cells. So we will use these bottles as our training data. The labeling machine has mixed up the labels of three wine cultivars. Note that softmax needs all cells of the example. 0 A B C 1 0. The original data contains the 13 measurements for all 178 bottles. com en us article RAND function 4cbfa695 8869 4788 8d90 021ea9f5be73 function. Your first offer to distinguish the three wine makers by taste and then spend a couple of months drinking wine and labeling bottles as been refused. You cannot change part of an array. This is what we return at the end. Because this is a multi class problem the output y has already been converted to one hot matrix. Forward propagation Backpropagation Gradient descent parameter update Assign new parameters to the model Print loss accuracy every 100 iterations Hyper parameters I picked this value because it showed good results in my experiments Initialize the parameters to random values. You can train this network the same way as the logistic regression network. Sometimes you might encounter a warning You cannot change part of an array. Note however that the rand function create a new random number every time excel refreshes. Note that you have to copy over two sets of weights and biases this time. But first let s solve this weeks challenge. We need to learn these. Excel tips Matrix multiplicationThe excel function for matrix multiplication is called MMULT https support. SubmissionFor the excel challenges submit your finished Excel notebook through slack. Week 1 ChallengeCongratulations You made it through the first weeks content The first week is the hardest because you have to learn about many new concepts. Now there are thousands of bottles of which nobody knows who made them. TransposeTo transpose a matrix in excel you can use the TRANSPOSE https support. In a famous wine region a disaster has happened. SoftmaxYou will have to enter the formula for softmax element wise. This makes it easier to deal with the data. That is you enter the formula for one cell and can then expand it for the other cells. com watch v 5bNooxRm960 if you have trouble. The first week is also the most math heavy. Not that if you use transpose you always need to use CONTROL SHIFT ENTER otherwise it will not do anything. For this you will have to hit CONTROL SHIFT ENTER again. 1 A_1 1 A_1 2 A_1 3 EXP A1 SUM EXP A1 C1 EXP B1 SUM EXP A1 C1 EXP C1 SUM EXP A1 C1 Random initializationYou can create random numbers in Excel using the RAND https support. Instead points are awarded to teams who submit the following implementations Excel Logistic Regression 2 points 2 Layer Neural Net 2 points 3 Layer Neural Net 4 pointsPython 2 Layer Neural Net 2 points 3 Layer Neural Net 4 pointsA total of 14 points can be won. For the python notebook create a public kernel and share the link via slack. So it is all downhill from here. ", "id": "erkkinool/ai-bootcamp-w1-challenge-2-layer-nn-group-6", "size": "6206", "language": "python", "html_url": "https://www.kaggle.com/code/erkkinool/ai-bootcamp-w1-challenge-2-layer-nn-group-6", "git_url": "https://www.kaggle.com/code/erkkinool/ai-bootcamp-w1-challenge-2-layer-nn-group-6", "script": "backward_prop tanh_derivative calc_accuracy train matplotlib.pyplot forward_prop predict sigmoid log_loss_derivative pandas plot_decision_boundary initialize_parameters log_loss update_parameters numpy ", "entities": "(('normalized data', 'one hot logistic regression'), 'copy') (('class multi output', 'already one hot matrix'), 'be') (('python notebook', 'slack'), 'create') (('excel challenges', 'slack'), 'submit') (('which', 'wine'), 'be') (('You', 'logistic regression same way network'), 'train') (('you', 'loss'), 'make') (('who', 'them'), 'be') (('dataYou', 'kaggle'), 'find') (('disaster', 'wine famous region'), 'happen') (('how neural networks', 'understanding'), 'be') (('labeling machine', 'wine three cultivars'), 'mix') (('you', 'Excel'), 'contain') (('You', 'wine'), 'deserve') (('rand however function', 'new random number'), 'note') (('So we', 'training data'), 'use') (('Update', 'Gradient descent'), 'Set') (('Here parameters', '2 layer'), 'load') (('CONTROL SHIFT', 'ENTER'), 'have') (('it', 'just contour plot'), 'generate') (('You', 'two hidden layers'), 'choose') (('wine makers', 'cellars'), 'Alcalinity') (('network', '3'), 'have') (('you', 'other cells'), 'be') (('Logistic Neural Neural Neural Excel Regression 2 2 Net 2 3 Neural Net 4 pointsPython 2 2 3 4 pointsA total', '14 points'), 'award') (('It', 'output layer'), 'use') (('SoftmaxYou', 'softmax element'), 'have') (('Loading', 'Kaggle'), 'fork') (('original data', '178 bottles'), 'contain') (('otherwise it', 'anything'), 'need') (('you', 'trouble'), 'watch') (('GradingThis weeks challenge', 'most accurate prediction'), 'be') (('Layer 2 next sheet you', 'layer neural 2 network'), 'networkin') (('you', 'many new concepts'), 'make') (('Excel tips Matrix multiplicationThe excel function', 'matrix multiplication'), 'call') (('bias Store', 'decision boundary'), 'be') (('So you', 'those'), 'need') (('layer 2 network', 'layer 3 network'), 'implement') (('you', 'TRANSPOSE https support'), 'transpose') (('you', 'softmax'), 'say') (('softmax', 'example'), 'note') (('first s', 'weeks challenge'), 'let') (('You', 'Excel'), 'implement') (('CONTROL', 'ESC'), 'SHIFT') (('you', 'weights'), 'note') (('it', 'data'), 'make') (('You', 'array'), 'encounter') (('output', 'CONTROL SHIFT ENTER'), 'select') (('it', 'values'), 'update') (('Backward pass update', 'Forward'), 'pass') (('features', 'same mean deviation'), 'learn') (('you', 'then cells'), 'enter') (('Just output', '3'), 'make') (('EXP A1 SUM EXP A1 C1 EXP B1 SUM EXP A1 C1 EXP C1 SUM EXP A1 Random 1 2 3 initializationYou', 'RAND https support'), '1') (('activation function', 'output layer'), 'be') (('ExponentsYou', 'EXP function'), 'calculate') "}
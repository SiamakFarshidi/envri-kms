{"name": "build gan assignment stylegan ", "full_name": " h1 Components of StyleGAN h3 Goals h3 Learning Objectives h2 Getting Started h2 Truncation Trick h2 Mapping z w h2 Random Noise Injection h2 Adaptive Instance Normalization AdaIN h1 text AdaIN boldsymbol mathrm x i boldsymbol mathrm y boldsymbol mathrm y s i frac boldsymbol mathrm x i mu boldsymbol mathrm x i sigma boldsymbol mathrm x i boldsymbol mathrm y b i h2 Progressive Growing in StyleGAN h2 Running StyleGAN ", "stargazers_count": 0, "forks_count": 0, "description": "Implement the components of StyleGAN. Optional hint for InjectNoise1. This is to save time training later. This helps StyleGAN to create high resolution images by gradually doubling the image s size until the desired size. Components of StyleGAN GoalsIn this notebook you re going to implement various components of StyleGAN including the truncation trick the mapping layer noise injection adaptive instance normalization AdaIN and progressive growing. Upsample to the starting_size bilinearly https pytorch. To do this you need to create a noise tensor that is the same size as the current feature map image. You would then pass this into the discriminator and use the feedback to update the weights of your generator. New starting weights are generated for every new layer or generator where this class is used. This is comprised of an upsampling layer a convolutional layer random noise injection an AdaIN layer and an activation. Create an AdaIN object 5. The weight should have the shape 1 channels 1 1. Optional hint for forward1. This introduces uncorrelated noise and is meant to increase the diversity in the image. org docs master generated torch. Getting StartedYou will begin by importing some packages from PyTorch and defining a visualization function which will be useful later. text AdaIN boldsymbol mathrm x _i boldsymbol mathrm y boldsymbol mathrm y _ s i frac boldsymbol mathrm x _i mu boldsymbol mathrm x _i sigma boldsymbol mathrm x _i boldsymbol mathrm y _ b i Optional hints for forward1. In fact you may recall playing with it in an earlier GAN notebook. The instance normalized image style scale and style shift have already been calculated for you. Calculate the transformed image UNIT TEST COMMENT Required for grading UNIT TEST COMMENT Required for grading UNIT TEST COMMENT Required for grading UNQ_C5 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL MicroStyleGANGeneratorBlock Replace the Nones in order to 1. The truncation value is at least 0 where 1 means there is little truncation high diversity and 0 means the distribution is all truncated except for the mean high quality fidelity. The 4 x 4 noise can be further passed through a generator block with upsampling to produce an 8 x 8 output. Remember that you only make the noise for one channel it is then multiplied by random values to create ones for the other channels. You will simulate progressive growing from an 8 x 8 image to a 16 x 16 image. Adaptive Instance Normalization AdaIN The next component you will implement is AdaIN. Create a LeakyReLU activation with slope 0. In the generated image the samples start from low alpha values and go to high alpha values. Running StyleGANFinally you can put all the components together to run an iteration of your micro StyleGAN You can also visualize what this randomly initiated generator can produce. Understand the components of StyleGAN that differ from the traditional GAN. Mapping z w The next component you need to implement is the mapping network. Then using an alpha alpha term you combine the higher resolution images obtained from 1 and 2. This method of gradually training the generator increases the stability and fidelity of the model. The truncation trick resamples the noise vector z from a truncated normal distribution which allows you to tune the generator s fidelity diversity. Instead of simply passing it to the generator block with upsampling StyleGAN gradually trains the generator to the new size by mixing in an image that was only upsampled. Create an object to inject noise 4. It takes the noise vector z and maps it to an intermediate noise vector w. You will start by creating a block for the StyleGAN generator. That is your final image or you could continue this process to make a 32 x 32 image or 64 x 64 128 x 128 etc. 2 Padding is used to maintain the image size UNIT TEST COMMENT Required for grading UNQ_C6 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL MicroStyleGANGenerator Typically this constant is initiated to all ones but you will initiate to a Gaussian to better visualize the network s effect You need to have a way of mapping from the output noise to an image so you learn a 1x1 convolution to transform the e. Truncation TrickThe first component you will implement is the truncation trick. The output is some noise that can then be transformed into a blurry 4 x 4 image. Random Noise InjectionNext you will implement the random noise injection that occurs before every AdaIN block. This makes it so z can be represented in a more disentangled space which makes the features easier to control later. Transform it into an image and then upsample it to be 16 x 16. However to reiterate in practice StyleGAN will slowly phase out the upsampled image by increasing the alpha parameter over many training steps doing this process repeatedly with larger and larger alpha values until it is 1 at this point the combined image is solely comprised of the image from the generator block. This trick is not exclusive to StyleGAN. For example imagine an image has 512 channels and its height and width are 4 x 4. Given an image x_i and the intermediate vector w AdaIN takes the instance normalization of the image and multiplies it by the style scale y_s and adds the style bias y_b. You would first create a random 4 x 4 noise matrix with one channel. Now you can implement progressive growing. Replace the Nones with the correct dimensions keep in mind that both linear maps transform a w vector into style weights corresponding to the number of image channels. This is where the progressive growing process begins. Within a layer every following time the noise injection is called you take another step with the optimizer and the weights that you use for each channel are optimized i. The code will automatically interpolate between different values of alpha so that you can intuitively see what it means to mix the low resolution and high resolution images using different values of alpha. Progressive Growing in StyleGANThe final StyleGAN component that you will create is progressive growing. This micro model you will implement will visualize what the model outputs at a particular stage of training for a specific value of alpha. Create a kernel_size convolution which takes in an image with in_chan and outputs one with out_chan https pytorch. org docs stable generated torch. However this will be done gradually. Remember the equation for AdaIN. You need 3 linear layers and should use ReLU activations. The mapping network in StyleGAN is composed of 8 layers but for your implementation you will use a neural network with 3 layers. StyleGAN starts with a constant 4 x 4 x 512 channel tensor which is put through an iteration of the generator without upsampling. Optional hints for MappingLayers1. Learning Objectives1. As such you will do two separate operations with the 8 x 8 noise 1. UNQ_C1 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL get_truncated_noise Test the truncation sample UNQ_C2 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL MappingLayers Please write a neural network which takes in tensors of shape n_samples z_dim and outputs n_samples w_dim with a hidden layer with hidden_dim neurons UNIT TEST COMMENT Required for grading Test the mapping function UNQ_C3 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL InjectNoise You use nn. You need to calculate the learnable style scale and bias by using linear mappings from w. You will now have two images that are both double the resolution of the 8 x 8 noise. 512 channels into 3 channels Note that this is simplified with clipping used in the real StyleGAN First generator run output Second generator run output Upsample first generator run output to be same size as second generator run output Interpolate between the upsampled image and the image from the generator using alpha UNIT TEST COMMENT Required for grading Check if the block works Check that the interpolation is correct The noise is exaggerated for visual effect. Pass it into the next generator block to create an output noise that you will then transform to an image. The key here is that the alpha term is gradually increased until eventually only the image from 1 the generator is used. Next you multiply the 4 x 4 matrix by each one of these values. Then your model would create 512 values one for each channel. You may find torch. Parameter so that these weights can be optimized Initiate the weights for the channels from a random normal distribution Set the appropriate shape for the noise Creates the random noise Applies to image after multiplying by the weight for each channel UNIT TEST COMMENT Required for grading UNIT TEST COMMENT Required for grading UNIT TEST Check that something changed Check that the change is per channel Check that the per channel change is roughly normal Make sure that the weights are being used at all UNQ_C4 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL AdaIN Normalize the input per dimension You want to map w to a set of style weights per channel. By mixing an upsampled 8 x 8 image which is 16 x 16 with increasingly more of the 16 x 16 generator output the generator is more stable as it progressively trains. Finally you add this noise tensor to the image. This is done by transforming it into a set of style parameters and introducing the style to the image through AdaIN. This code should be five lines. To increase control over the image you inject w the intermediate noise vector multiple times throughout StyleGAN. The noise tensor is not entirely random it is initialized as one random channel that is then multiplied by learned weights for each channel in the image. Your linear layers should be input hidden_dim hidden_dim output. This creates a random tensor of 512 channels and 4 x 4 pixels the same dimensions as the image. lerp https pytorch. Remember that this is done after the model is trained and when you are sampling beautiful outputs. ", "id": "amoghjrules/build-gan-assignment-stylegan", "size": "8459", "language": "python", "html_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-stylegan", "git_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-stylegan", "script": "torch.nn.functional get_self show_tensor_images MicroStyleGANGeneratorBlock(nn.Module) numpy upsample_to_match_size InjectNoise(nn.Module) torch.nn get_style_shift_transform get_mapping truncnorm make_grid get_style_scale_transform matplotlib.pyplot forward get_truncated_noise get_weight MappingLayers(nn.Module) AdaIN(nn.Module) scipy.stats __init__ MicroStyleGANGenerator(nn.Module) torchvision.utils ", "entities": "(('intermediate vector', 'style scale'), 'take') (('image style scale', 'style already you'), 'normalized') (('You', 'generator'), 'pass') (('when you', 'beautiful outputs'), 'remember') (('method', 'model'), 'increase') (('You', 'ReLU activations'), 'need') (('generator', '1'), 'be') (('You', '16 16 image'), 'simulate') (('where class', 'new layer'), 'generate') (('This', 'desired size'), 'help') (('you', 'GAN earlier notebook'), 'recall') (('that', 'then blurry 4 4 image'), 'be') (('features', 'more disentangled space'), 'make') (('introduces', 'image'), 'uncorrelate') (('which', 'out_chan https pytorch'), 'create') (('that', 'both 8 8 noise'), 'have') (('This', 'upsampling layer'), 'comprise') (('It', 'noise vector intermediate w.'), 'take') (('that', 'image'), 'be') (('you', 'channel'), 'take') (('model', 'alpha'), 'visualize') (('more it', 'generator 16 16 output'), 'be') (('Finally you', 'image'), 'add') (('it', 'alpha'), 'interpolate') (('4 4 noise', '8 8 output'), 'pass') (('which', 'upsampling'), 'start') (('you', '1'), 'combine') (('You', 'nn'), 'IDENTIFIER') (('You', 'StyleGAN generator'), 'start') (('weight', '1 1'), 'have') (('it', 'other channels'), 'remember') (('you', 'multiple times StyleGAN'), 'increase') (('final you', '32 32 image'), 'be') (('samples', 'alpha high values'), 'in') (('distribution', 'quality mean high fidelity'), 'be') (('You', 'w.'), 'need') (('combined image', 'generator block'), 'phase') (('that', 'image'), 'train') (('512 channels', 'example'), 'imagine') (('You', 'one channel'), 'create') (('noise', 'visual effect'), 'note') (('you', 'then image'), 'pass') (('This', 'AdaIN'), 'do') (('Now you', 'progressive growing'), 'implement') (('randomly initiated generator', 'also what'), 'put') (('You', 'channel'), 'parameter') (('you', '3 layers'), 'compose') (('linear maps', 'image channels'), 'replace') (('that', 'AdaIN block'), 'InjectionNext') (('that', 'traditional GAN'), 'understand') (('you', 'that'), 'grow') (('Next you', 'values'), 'multiply') (('mapping layer', 'instance normalization adaptive AdaIN'), 'component') (('such you', '8 8 noise'), 'do') (('you', 'fidelity diversity'), 'resample') (('so you', 'e.'), 'use') (('Then model', 'channel'), 'create') (('which', 'visualization function'), 'get') (('This', 'image'), 'create') (('that', 'feature map same current image'), 'need') (('i', 'Optional forward1'), 'mathrm') "}
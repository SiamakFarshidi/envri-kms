{"name": "breast cancer classification ", "full_name": " h1 Problem Statement h1 Objective h1 Importing the Packages h1 Loading the dataset h1 About the dataset h1 classify cells to whether the samples are benign mild state 2 or malignant evil state 4 h1 Dropping the unwanted columns h1 Checking for missing values h1 Checking for Categorical variables h1 Checking whether the dataset is a balanced or not h1 Summary h1 Data Visualisation h1 Taking out the predictors and predicted variables seperately h1 Splitting the dataset h1 Training My Models h1 Logistic Regression Model h1 Naive Bayes Model h1 SVM Model h1 Kernal SVM Kernal taken is polynomial kernal h1 KNN Model h1 Decision tree h1 Random forest h1 XGBoost h1 Model Evaluation Metrics h1 Prediction using trained model h1 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "Sample code number id number2. Here we have taken the loop iteration till 27 as per thumb rule optimum k value is always Square root of number of records. So we cannot apply mathematical operations on this column. the larger the number thegreater the likelihood of malignancy. no single measurement can be used to determine whether it is benign or malignant. It is a balanced dataset. We could simply remove it as synthetic data would not contribute to right decisions. 35 Precision 96 Recall 96 F1 Score 96. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. Checking whether the dataset is a balanced or not. Uniformity of Cell Size 1 104. The metrics for this model are as followsAccuracy 98. Single Epithelial Cell Size 1 107. Fitting Decision Tree Classification to the Training set for gini 0. Decision treeThe metrics for this model are as followsAccuracy 96. BareNuc variable is an object data type so need to convert it into integer data type. For example running this by clicking run or pressing Shift Enter will list all files under the input directory Any results you write to the current directory are saved as output. Random forestThe metrics for this model are as followsAccuracy 97. Normal Nucleoli 1 1010. Model Evaluation MetricsWe can see KNN performing well and then comes random forest and XGBoost which have more accuracy and F1 Score as well. This is the description of the features of the dataset. Objective To Build a breast cancer classifier on the dataset that can be accurately classify as benign and malignant. My random forest model is also predicting the same as benign. Importing the Packages Loading the dataset. Public Source https s3 api. So BareNuc is converted to integer data type. XGBoostThe metrics for this model are as followsAccuracy 97. Bland Chromatin 1 109. Fitting Random Forest Classification to the Training set Predicting the Test set results Accuracy of our model. The mean of class is closer to 2 indicating there are more benign cases. 81 Precision 97 Recall 98 F1 Score 98. For cell size perimeter was measured as the distancearound the nuclear border which is considered to be uniform. The minimum and maximum value of all input variables are 1 and 10 respectively. so square root of 699 rounds of to 26. Divide the data as train and test dataset Accuracy of our model. modelling Knn Classifier nothing but we are using euclidean distance lets see the best value of k for which the model is predicting with high accuracy. My xg boost model is also predicting the same as benign. Class 2 for benign 4 for malignant Clump thickness indicates that radius was computed by averaging the length of radial line segments from the center ofthe nuclear mass to each of the points of the nuclear border. the proportion of benign and malignant is almost 2 1. each of the attribute is assigned to number from 1 10 by the pathologists. Bare Buc is an object type which is not a numeric value. 948905109489051 Predicting the Test set results Accuracy of our model. Fitting the XGBoost to the training set Predicting the test results Confusion Matrix Accuracy of our model. KNN ModelLet us find the optimum value for K. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. The metrics for this model are as followsAccuracy 97. Dropping the unwanted columns. Marginal Adhesion 1 106. Data Visualisation clump thickness is evenly distributed to some extent. The count of each column is 699 which suggests there are no missing values. Statistically the death toll due to this disease has increased drastically in last few decades. Checking for Categorical variablesAll the variables are Categorical variables. Identify the unwanted rows Taking out the predictors and predicted variables seperately for the further. This prediction system may provide easy and a cost effective way for screening cancer and may playa significant role in earlier diagnosis process for different types of cancer and provide effective preventiveapproach. Problem StatementBreast Cancer is one of the leading cancer developed in many countries including India. read_csv Input data files are available in the. SVM ModelThe metrics for this model are as followsAccuracy 96. 89 Precision 94 Recall 96 F1 Score 95. Bare Nuclei 1 108. Clump Thickness 1 103. The predicted value of class is 2 which suggests it is a benign tumor. 08 Precision 96 Recall 98 F1 Score 97. ConclusionBreast Cancer has become the foremost cause of death worldwide for womens. Taking out the predictors and predicted variables seperately Splitting the dataset. All other variables are skewed to the right. Kernal taken is polynomial kernal. Many people avoid cancer screening due to the cost involved in taking numeroustests for diagnosis. 54 Precision 98 Recall 99 F1 Score 98. Checking for missing valuesNo Missing values found in the dataset. Naive Bayes ModelThe metrics for this model are as followsAccuracy 94. Uniformity of Cell Shape 1 105. So Here lets simply removethe non numeric data. we are using a dataset that has a 9 predictors in each record 699 records Let us drop the ID column as it doesnot influence the output class. For measuring the cell shape area is measured bycounting the number of pixels in the interior of the nuclear border and adding one half of the pixels on the perimeter. For a particular row and in that row a particular column BareNuc if values are non numeric. The most successful way to reducecancer deaths is to detect it earlier. So that is why it is taken. Marginal adhesion is measured bycombining the perimeter and area to give a measure of the compactness of the cellnuclei classify cells to whether the samples are benign mild state 2 or malignant evil state 4 id clump thickness uniformity of cell size uniformity of cell shape marginal adhesion single epithelial cell size bare nuclei bland chromatin normal nucleoli mitosis are the variables used to predict the output class. SummaryThe output variable class is discrete and takes two values 2 Benign and 4 Malignant. 35 Precision 95 Recall 97 F1 Score 96. Hence apart from medicinal solutions some Data Science solution needs to be integrated for resolving the death causing issue. The data frame is of shape 699 10 suggesting there are 699 training cases. There are 699 records and for each record we have multiple parameters that is measured. When pathologists examine FNA fine needle aspirate tissues samples in breast cancer diagnosis they consider the nine attributes. Prediction using trained modelThe trained models is used to predict a particular case clump thickness 1 uniformity of cell size 2 uniformity of cell shape 2 marginal adhesion 5 single epithelial cell size 3 bare nuclei 4 bland chromatin 6 normal nucleoli 4 mitosis 8. modelling SVM Confusion matrix and Accuracy of our model. With early diagnosis 97 women can survive for more than 5 years. Missing Or Null data points Let us check whether the dataset is a balanced or imbalanced one. Accuracy of our model. Training My Models Logistic Regression ModelThe metrics for this model are as followsAccuracy 97. If we recognise early we can take the necesaary action which results in less death toll. ", "id": "karteek93/breast-cancer-classification", "size": "6131", "language": "python", "html_url": "https://www.kaggle.com/code/karteek93/breast-cancer-classification", "git_url": "https://www.kaggle.com/code/karteek93/breast-cancer-classification", "script": "classification_report train_test_split confusion_matrix xgboost numpy XGBClassifier GaussianNB sklearn.neighbors sklearn.naive_bayes sklearn.tree sklearn.linear_model sklearn matplotlib.pyplot DecisionTreeClassifier svm sklearn.model_selection pandas RandomForestClassifier LogisticRegression KNeighborsClassifier sklearn.metrics sklearn.ensemble ", "entities": "(('Problem StatementBreast Cancer', 'India'), 'be') (('which', 'more accuracy'), 'see') (('variables', 'Categorical variablesAll'), 'check') (('Decision treeThe metrics', 'followsAccuracy'), 'be') (('ConclusionBreast Cancer', 'worldwide womens'), 'become') (('forest random model', 'benign'), 'predict') (('model', 'high accuracy'), 'model') (('radius', 'nuclear border'), 'indicate') (('SVM ModelThe metrics', 'followsAccuracy'), 'be') (('prediction system', 'effective preventiveapproach'), 'provide') (('that', 'multiple parameters'), 'be') (('Fitting Decision Tree Classification', 'gini'), 'set') (('that', 'dataset'), 'objective') (('minimum value', 'input variables'), 'be') (('clump', 'evenly extent'), 'distribute') (('valuesNo Missing values', 'dataset'), 'check') (('the larger number', 'malignancy'), 'thegreater') (('they', 'nine attributes'), 'consider') (('which', 'column'), 'be') (('output variable class', 'two values'), 'be') (('Training Models Logistic Regression ModelThe metrics', 'followsAccuracy'), '-PRON-') (('metrics', 'followsAccuracy'), 'be') (('read_csv Input data files', 'the'), 'be') (('most successful way', 'it'), 'be') (('data frame', 'shape'), 'be') (('forestThe Random metrics', 'followsAccuracy'), 'be') (('it', 'output class'), 'use') (('particular case', 'cell 5 single epithelial 3 bare 4 6 normal nucleoli'), 'use') (('Naive Bayes ModelThe metrics', 'followsAccuracy'), 'be') (('other variables', 'right'), 'be') (('mean', '2'), 'be') (('Data Science solution', 'issue'), 'need') (('It', 'python docker image https kaggle github'), 'come') (('This', 'dataset'), 'be') (('KNN ModelLet us', 'K.'), 'find') (('Many people', 'diagnosis'), 'avoid') (('values', 'column particular BareNuc'), 'for') (('you', 'output'), 'list') (('each', 'pathologists'), 'assign') (('proportion', 'benign'), 'be') (('it', 'class'), 'be') (('k optimum value', 'records'), 'take') (('97 women', 'more than 5 years'), 'survive') (('which', 'death less toll'), 'take') (('So BareNuc', 'integer data type'), 'convert') (('which', 'nuclear border'), 'measure') (('synthetic data', 'right decisions'), 'remove') (('xg boost model', 'benign'), 'predict') (('data object type', 'data integer type'), 'be') (('nuclei bare bland', 'output class'), 'measure') (('So we', 'column'), 'apply') (('death Statistically toll', 'drastically last few decades'), 'increase') "}
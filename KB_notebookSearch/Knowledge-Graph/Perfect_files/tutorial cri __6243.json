{"name": "tutorial cri ", "full_name": " h2 Introduction h1 1 Get your data h1 2 Explore the dataset h1 3 Define your objective and metrics h1 4 Set a baseline model h3 4 1 Create features h3 4 2 Run a simple algorithm h3 4 3 Optimize the hyper parameters of your algorithm h2 5 Improve features and model h3 5 1 Better features h3 5 2 Better Algorithms h2 6 Use Deep Learning ", "stargazers_count": 0, "forks_count": 0, "description": "Prepare the folds for a cross validation. and you didn t see that birth of date was in these values your algorithm is going to learn a completly dumb thing. Can you print the number of patients using the functions len and print 2. We use the very useful scikit learn package. This function run train the model For each fold Train the model on the training data And predict the results on the test data Return all the predictions probabilities between 0 and 1 Here we use kNN model And call the function run_model Let s print the results How does the accuracy evolves with the number of neighbors Here we use features extracted from a deep neural network we achieve much better results with the same algorithm that our simple histogram features we use pca to reduce the dimensionality of the inputs Nearest Neighbors The code to extract deep learning features a bit long to run model ResNet50 weights imagenet include_top False pooling max Logisitic Regression Exercice can you run this code with resnet_features_pca Are results better Random Forests Exercice can you find the best depth of the tree Are Resnet features better than histogram features We use keras library with tensorflow backend Special callback to see learning curves Preprocess the data center and normalize Create the model first layer convolution second layer pooling reduce the size of the image per 3 output 1 value between 0 and 1 probability to have cancer Use binary crossentropy as a loss function try to add loss to see the loss learning curve. Define your objective and metrics Now that you are familiar with your data you have to define your objective and the way you will measure how you achieved it. com use case 6 invasive ductal carcinoma idc segmentation 1. A common machine learning way to create a new model is 1. Python uses packages containing functions Packages must be imported to be used. It permits to quickly have a first score to compare with when using more complex models and it also often helps a lot to organize your code and data. A common technique is to partition the dataset into N equal parts called folds and to split N times the dataset such that each part will be once the test set. Note that accuracy is not always a good measure if you have an unbalanced dataset with only 1 of positive examples predicting always 0 negative will lead to a 99 accuracy The measure is often called metric or loss. On the learning curve you can observe the accuracy of the network on the training set in red and on the test set in blue. com presentation d 1V2KCgS7edbXpXsZZnARmX8zc79r78tgPMstH9JoT_fE Introduction In this tutorial we work on breast histology images. Get your data The first step is simply to get your data Data can have any modality csv file dicom image text file mp3 record. Optimize the hyper parameters of your algorithm 5. Plot histograms correlations use standard data analysis techniques sur as PCA Try to evaluate the difficulty of the task you want to perform And of course have a look to related works on this dataset Maybe someone did the work for you Here we can observe that colors are quite different between positive images and negative images. To measure the predictive performance using our metric we will use cross validation. You can change the value 0 to any value 10 87 etc. This step includes Checking data issues of any sort missing values outliers unreadable files etc. If m of these neighors e. Our goal is to classify Invasive Ductal Carcinoma IDC images vs non IDC images using a standard data science pipeline Explore your dataset Define your objective and a metric Set a baseline algorithm features model parameter optimization Improve it The dataset has been curated from Andrew Janowczyk website http www. Searching bias in the dataset. score4 train 1 2 3 4 test 5. sum don t look at next section How many images What is the size of the images Looking at some images images with label 0 no cancer negative image images with label 1 cancer positive image Each batch plot 25 negative images on the left and 25 positive images on the right. Colors could be an easy way to classify these images 3. In cross validation we split the dataset multiple times ex 80 20 or 90 10 and average the performances on the diffrent test sets. score3 train 1 2 3 5 test 4. Use Deep Learning Deep learning for images is end to end there is no need to exctract features from the image because the algorithm learns itself these features from raw data Neural networks are not easy to train especially from scratch and require a lot of data. The idea is to split the dataset into 2 groups the training set that we will use to calibrate the parameters of a model and the test set that we will use to evaluate the performance of the model using our metric. Extract features from your data. Can you print the number of patients with cancer using the functions print and np. We decide to keep 50 bins in the histogram but you can try other values up to 255 Here we visualize our features in 2D using PCA colored by the positive red negative blue class Exercice try to replace PCA by SpectralEmbedding TSNE Here we will use the k nearest neighbors algorithm given a new image find the k e. Don t expect it to have very good results Also use it as a black box as this tuto doesn t aim to explain how deep learning works Training a neural network can be long so we just use 1 foldA neural network is trained by showing him the dataset multiple times. The more epochs the more the networks learn to recognize the training imagss and generalize it s performance on the test set. It depends on what you want interested by the trade off precision recall use F1 score. Here is a simple example. Then using your favorite programming language mainly python or R and appopriated packages pandas numpy. Here we use stratified cross validation the proportion of positive and negative examples is the same in all folds Let s have a look to the split size and We look at RGB histograms represent colors. k 10 images in the training set with the most similar histograms. slides https docs. Our feature will be the concatenation of the 3 histograms red green and blue. Improve features and model 5. Run a simple algorithm 4. But when possible it shows amazing performance In the code below we run quite a randomly designed neural network to see how it works. A peak at 255 for all colors mean a lot of white Try 0 1 2. Each time the network saw the entire dataset is called epoch. We first import the numpy package We create a list X Print X Print the length of X We use the function sort to sort the list X and print the result If you click on the left you will execute this cell and see the result We first import all the packages we will need for the project I did the work for you images labels associated to images 0 no cancer 1 cancer Exercice 1. In our case the objective or task is binary classification of images and our measure performance will be the accuracy percentage of good classification. Optimize the hyper parameters of your learning algorithm 4. Explore the dataset Let s explore your dataset now It is fundamental to become familiar with your data especially if you re not an expert. Set a baseline model Now it s time to create our first model A good practice is to set a baseline i. Better features 5. Create features The PCA shows that our simple histogram feature already permits to linearly separate a bit positive and negative images Good point 4. score2 train 1 2 4 5 test 3. g m 6 have label 1 then output p 60. you can read your data. Histogram counts the number of pixels with a certain intensity between 0 and 255 for each color red green and blue. Use a learning algorithm you think appropriate k nearest neighbors linear or logistic regression random forests SVMs neural networks and XGboost 3. In our case we saw that colors of the images could be a good feature. Here expert knowledge is welcome 2. Better Algorithms 6. The machine learning scheme is quite different from the statistics scheme we evaluate a model based on its predictive performance and not on the probability to observe the data given the model. For instance imagine you have to predict the age of a patient based on is height weight and other values. Interested by the trade off true positive detection false positive detection Use ROC AUC. score5 predictive performance score1 score2 score3 score4 score5 5 4. But if we go too far the network memorized perfectly the training set very high accuracy on training which leads to poor generalization low accuracy on the test this phenomenom is called overfitting. For instance if you divide your dataset into 5 folds 1 2 3 4 5 then you will split 5 times the dataset train 2 3 4 5 test 1 evaluate performance on the test set to get score1 train 1 3 4 5 test 2. for negative images and 1 2 3 for positive images and compare the histograms. ", "id": "simjeg/tutorial-cri", "size": "6243", "language": "python", "html_url": "https://www.kaggle.com/code/simjeg/tutorial-cri", "git_url": "https://www.kaggle.com/code/simjeg/tutorial-cri", "script": "keras.datasets keras.layers keras.models keras matplotlib.pylab confusion_matrix StratifiedKFold as KFold numpy MaxPooling2D Dropout ResNet50 sklearn.manifold plot_accuracy Dense Callback on_epoch_end preprocess_input backend as K keras.callbacks sklearn.neighbors roc_auc_score sklearn.linear_model PCA StratifiedKFold SpectralEmbedding Sequential backend sklearn.model_selection roc_curve scipy.misc LogisticRegression RandomForestClassifier Conv2D EarlyStopping KNeighborsClassifier run_model mnist MetricsCheckpoint(Callback) keras.applications.resnet50 * __init__ TSNE sklearn.decomposition sklearn.metrics Flatten sklearn.ensemble ", "entities": "(('you', 'patient'), 'imagine') (('colors', 'quite positive images'), 'use') (('I', 'images'), 'import') (('algorithm', 'completly dumb thing'), 'see') (('you', 'blue'), 'observe') (('colors', 'images'), 'see') (('phenomenom', 'test'), 'memorize') (('it', 'test set'), 'learn') (('size', '25 positive right'), 'look') (('step', 'unreadable files'), 'include') (('how you', 'it'), 'have') (('you', 'len'), 'print') (('Good', 'already linearly bit positive images'), 'feature') (('You', '0 value'), 'change') (('model', 'loss learning curve'), 'run') (('Packages', 'functions'), 'use') (('Colors', '3'), 'be') (('We', 'colors'), 'use') (('you', 'precision recall use F1 trade score'), 'depend') (('Histogram', 'color red green'), 'count') (('we', 'test diffrent sets'), 'split') (('dataset', 'Andrew Janowczyk website'), 'be') (('test we', 'metric'), 'be') (('we', 'model'), 'be') (('features', 'data'), 'use') (('false positive detection', 'ROC AUC'), 'Use') (('Here we', 'k e.'), 'decide') (('data simply Data', 'modality csv file dicom image text file mp3 record'), 'get') (('you', 'functions print'), 'print') (('such part', 'dataset'), 'be') (('feature', 'red 3 histograms green'), 'be') (('logistic regression random forests', 'neural networks'), 'think') (('foldA neural just 1 network', 'dataset multiple times'), 'expect') (('measure', '99 accuracy'), 'lead') (('good practice', 'baseline i.'), 'set') (('learning common machine way', 'new model'), 'be') (('peak', 'white Try'), 'mean') (('we', 'cross validation'), 'use') (('we', 'breast histology images'), 'd') (('how it', 'randomly designed neural network'), 'show') (('it', 'code'), 'permit') (('We', 'package'), 'use') (('measure performance', 'accuracy good classification'), 'be') (('especially you', 'data'), 'explore') (('score1', 'test'), 'split') "}
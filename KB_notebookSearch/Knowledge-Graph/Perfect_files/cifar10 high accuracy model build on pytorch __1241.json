{"name": "cifar10 high accuracy model build on pytorch ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "Please find the code belowInitializing GPU UsageTransformations and Data AugmentationConverting the Input images to plot using pltDefining our ModelFitting our model with the inputs to generate output. We iter the batch of images to display converting our train_dataloader to iterable so that we can iter through it. I have build this on PyTorch but personally I like Tensorflow Keras more. But for this case I wanted to code my own model. This process will happen in normal cpu. e to work with 100 images at a time We need to convert the images to numpy arrays as tensors are not compatible with matplotlib. we do not need gradient for validation. Additionally I am sure that Transfer learning will yield much better accuracy if I use Vgg16 for suppose. Output nodes is 500 output nodes are 10 because our dataset have 10 different categories Apply relu to each output of conv layer. Calc loss after each batch i p by comparing it to actual labels. Maybe by running more epochs I can get better accuracy or some more hyper parameter tuning will help. loss per epoch accuracy per epoch appending for displaying applying the transformations on new image as our model has been trained on these transformations convert to numpy array for plt put inputs in device as our model is running there. setting the initial gradient to 0 backpropagating the loss updating the weights and bias values for every single step. input is color image hence 3 i p channels. Let me know the suggestions for hyper parameter tunning for the same model. resises the image so it can be perfect for our model. Displaying the progress. In this notebook I am using the Cifar10 dataset to classify various images. every batch of 100 images are put as an input. I p image size is 32 32 after 3 MaxPooling layers it reduces to 4 4 and 64 because our last conv layer has 64 outputs. This is a good practice run our model on cuda GPU for faster results same as categorical_crossentropy loss used in Keras models which runs on Tensorflow fine tuned the lr training our model put input according to every batch. taking the highest value of prediction. I have coded the traditional LeNet model with some hyper parameter tuning for this purpose. calculating te accuracy by taking the sum of all the correct predictions in a batch. As seen I got 71 accuracy for this model and te model performed well on images it had never seen before. t horizontal axis Rotates the image to a specified angel Performs actions like zooms change shear angles. Even though LeNet is a old it is still a very good model to start with. It correctly classified a random image from the internet. Set the color params comvert the image to tensor so that it can work with torch Normalize all the images Data augmentation is only done on training images Batch size of 100 i. FLips the image w. Input new image from web to check our model s accuracyUse the images from our validation dataset to check the precdictions As seen the predictions on new images are really good. 16 filters kernal size is tuned to 3 to avoid overfitting stride is 1 padding is 1 extract all edge features. We double the feature maps for every conv layer as in pratice it is really good. going from 1st batch of 100 images to the next batch We plot 20 images from our train_dataset converting to numpy array as plt needs it. Max pooling layer with kernal of 2 and stride of 2 flatten our images to 1D to input it to the fully connected layers Applying dropout b t layers which exchange highest parameters. input to device as our model is running in mentioned device. Different classes in CIPHAR 10 dataset. ", "id": "vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch", "size": "1241", "language": "python", "html_url": "https://www.kaggle.com/code/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch", "git_url": "https://www.kaggle.com/code/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch", "script": "torch.nn.functional transforms torchvision matplotlib.pyplot im_convert __init__ forward torch PIL nn Image datasets LeNet(nn.Module) numpy ", "entities": "(('batch', 'input'), 'put') (('10 different categories', 'conv layer'), 'be') (('t horizontal axis', 'shear angles'), 'rotate') (('I', 'own model'), 'want') (('it', 'te well images'), 'get') (('I', 'various images'), 'use') (('I', 'purpose'), 'code') (('tensors', 'matplotlib'), 'e') (('Data augmentation', '100 i.'), 'comvert') (('i', 'actual labels'), 'loss') (('personally I', 'Tensorflow Keras'), 'build') (('me', 'same model'), 'let') (('model', 'batch'), 'be') (('it', 'model'), 'resise') (('which', 'highest parameters'), 'layer') (('predictions', 'new images'), 's') (('code', 'output'), 'find') (('we', 'it'), 'iter') (('I', 'better accuracy'), 'get') (('stride 1 padding', 'edge 1 features'), 'tune') (('model', 'device'), 'loss') (('I', 'suppose'), 'be') (('it', 'pratice'), 'be') (('plt', 'it'), 'plot') (('input', 'mentioned device'), 'run') (('conv last layer', '64 outputs'), 'be') (('It', 'internet'), 'classify') "}
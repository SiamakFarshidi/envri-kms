{"name": "ml from scratch part 2 ", "full_name": " h2 Hello Kagglers h3 Checking The Data h3 Basic EDA h3 Brief Analysis of the data h3 Analysis Of Diabetic Cases h3 PairPlots h3 Observations h3 Let s Do Some Predictive Modeling h3 Stratification h3 SVM h3 Logistic Regression h3 Decision Tree h3 K Nearest Neighbours h3 In a Nutshell h2 Feature Extraction Selection h3 Correlation Matrix h3 Observations h3 Random Forest Classifier h3 Observations h2 Standardisation h3 Using Only Important Features And Standardisation h2 Cross Validation h2 Ensembling h3 Linear and Radial SVM h3 Linear SVM with Logistic Regression h3 Logistic Regression with Radial SVM h3 All 3 classifiers combined ", "stargazers_count": 0, "forks_count": 0, "description": "I will do these things in subsequent parts. Using Only Important Features And StandardisationThe above dataframe shows the new accuracy of the models after feature selection. 1 The K Fold Cross Validation works by first dividing the dataset into k subsets. EnsemblingEnsemble methods are techniques that create multiple models and then combine them to produce improved results. SVM Logistic Regression Decision Tree K Nearest Neighbours In a NutshellThe above algorithms are not giving vey high accuracy. Basic EDA Brief Analysis of the data Analysis Of Diabetic Cases PairPlots Lets us see the distribution of the features in the dataset Observations 1 The diagonal shows the distribution of the the dataset with the kernel density plots. If You find this notebook useful PLEASE UPVOTE Checking The DataThe data looks clean. Thus we stratify the data so that we have proportionate data for all the classes in both the training and testing data. 4 An algorithm may underfit over a dataset for some training data and sometimes also overfit the data for other training set. So during classification we may have accurate predictions for class1 but not for class2. A Voting Classifier can then be used to wrap your models and average the predictions of the sub models when asked to make predictions for new data. Then we can take an average of all the noted accuracies over the dataset. Please Upvote if Useful This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. 3 It reduces training time and reduces overfitting4 We can choose important features in 2 ways a Correlation matrix selecting only the uncorrelated features. Random Forest Classifier Observations 1 The important features are Glucose BMI Age DiabetesPedigreeFunction StandardisationThere can be a lot of deviation in the given dataset. Voting is one of the simplest ways of combining the predictions from multiple machine learning algorithms. We can see that the Accuarcy for linear Svm increases by 1 whereas it increases about 12 for Radial Svm. We can also use ensembling or averaging of different algorithms. We will be using weighted Voting Classifier. Let s Do Some Predictive Modeling Stratification When we split the dataset into train and test datasets the split is completely random. Thus we may have many instances of class 1 in training data and less instances of class 2 in the training data. We reserve 1 part for testing and train the algorithm over the 4 parts. Linear and Radial SVM Linear SVM with Logistic Regression Logistic Regression with Radial SVM All 3 classifiers combinedSo the maximum Accuracy which we could get by using ensemble models is 78. Hello Kagglers This notebook is sort of a guide to some important concepts in Machine Learning like 1 Feature Selection2 Standardisation3 Ensembling etc. For LR the accuracy decreases Cross ValidationMany a times the data is imbalanced i. stratify the outcome Gaussian Standardisation for K fold cross validation score evaluation k 10 split the data into 10 equal parts for Voting Classifier. Thus the instances of each class label or outcome in the train or test datasets is random. In our case we will use the Top 3 classifiers i. Ensemble methods usually produces more accurate solutions than a single model would. So the classifier with single accuracy will be assigned the highest weight and so on. An example in the dataset can be the BMI where it has 248 unique values. This high variance has to be standardised. Thus we should train and test our algorithm on each and every instance of the dataset. Thus with cross validation we can achieve a generalised model. e Linaer SVM Radial rbf SVM and Logistic Regression classifiers. com ash316 ml from scratch with iris notebook. The above boxplot shows that SVM and LR perform the best while Decision Tree performs the worst. 2 Feature Extraction means to select only the important features in order to improve the accuracy of the algorithm. 2 Let s say we divide the dataset into k 5 parts. It works by first creating two or more standalone models from your training dataset. com kaggle docker python For example here s several helpful packages to load in Input data files are available in the. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. The models used to create such ensemble models are called base models. So we cannot eliminate any features just by looking at the correlation matrix. We will do ensembling with the Voting Ensemble. This can be improved by using Feature Selection and using only relevant features. Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1. This is called K Fold Cross Validation. e there may be a high number of class1 instances but less number of other class instances. 3 We continue the process by changing the testing part in each iteration and training the algorithm over the other parts. So we can start with the analysis. Feature Extraction Selection 1 A lot many features can affect the accuracy of the algorithm. I have tried to explain the general idea behind these concepts so that it is helpful for begineers also. If your are completely new to Machine Learning I would suggest you to go through this basic tutorial to ML https www. 2 The scatter plots shows the relation between each and every attribute or features taken pairwise. We will assign to the classifiers according to their accuracies. The accuracies and errors are then averaged to get a average accuracy of the algorithm. Looking at the scatter plots we can say that no two attributes are able to clearly seperate the two outcome class instances. b RandomForestClassifier It gives the importance of the features Correlation Matrix Observations 1 All the features look to be uncorrelated. I would like you all for having a look at this notebook. ", "id": "ash316/ml-from-scratch-part-2", "size": "5717", "language": "python", "html_url": "https://www.kaggle.com/code/ash316/ml-from-scratch-part-2", "git_url": "https://www.kaggle.com/code/ash316/ml-from-scratch-part-2", "script": "train_test_split numpy seaborn subprocess StandardScaler #Standardisation sklearn.neighbors sklearn.tree sklearn sklearn.linear_model cross_val_score #score evaluation KFold matplotlib.pyplot DecisionTreeClassifier KFold #for K-fold cross validation metrics svm sklearn.model_selection pandas RandomForestClassifier LogisticRegression sklearn.cross_validation KNeighborsClassifier check_output sklearn.ensemble VotingClassifier #for Voting Classifier sklearn.preprocessing ", "entities": "(('It', 'training dataset'), 'work') (('it', 'begineers'), 'try') (('We', 'Voting Ensemble'), 'do') (('Correlation Matrix 1 features', 'features'), 'b') (('you', 'ML https www'), 'suggest') (('we', 'classifiers Top 3 i.'), 'use') (('k 10', 'Voting Classifier'), 'stratify') (('This', 'only relevant features'), 'improve') (('We', '4 parts'), 'reserve') (('Hello notebook', 'Feature Standardisation3 Ensembling 1 Selection2 etc'), 'Kagglers') (('we', 'generalised model'), 'achieve') (('Correlation matrix', 'only uncorrelated features'), '3') (('BMI Age DiabetesPedigreeFunction StandardisationThere', 'given dataset'), 'observation') (('single model', 'usually more accurate solutions'), 'produce') (('we', '5 parts'), 'let') (('We', 'Voting weighted Classifier'), 'use') (('Then we', 'dataset'), 'take') (('Thus instances', 'train'), 'be') (('So we', 'correlation just matrix'), 'eliminate') (('3 We', 'other parts'), 'continue') (('SVM Logistic Regression Decision Tree K Nearest NutshellThe algorithms', 'vey high accuracy'), 'Neighbours') (('Feature 2 Extraction', 'algorithm'), 'mean') (('I', 'notebook'), 'like') (('accuracies', 'algorithm'), 'average') (('that', 'improved results'), 'be') (('It', 'python docker image https kaggle github'), 'please') (('relation', 'pairwise'), '2') (('split', 'train'), 'let') (('Feature Extraction 1 lot many features', 'algorithm'), 'selection') (('algorithm', 'training other set'), '4') (('Thus we', 'dataset'), 'train') (('we', 'training data'), 'stratify') (('two attributes', 'outcome class clearly two instances'), 'say') (('Voting Classifier', 'new data'), 'use') (('times data', 'Cross ValidationMany'), 'decrease') (('you', 'output'), 'list') (('it', 'Radial Svm'), 'see') (('Decision Tree', 'worst'), 'show') (('we', 'ensemble models'), 'SVM') (('Cross Validation', 'k subsets'), '1') (('Standardization', 'standard 1'), 'be') (('we', 'class2'), 'have') (('Thus we', 'training 2 data'), 'have') (('where it', '248 unique values'), 'be') (('We', 'accuracies'), 'assign') (('1 diagonal', 'kernel density plots'), 'Lets') (('I', 'subsequent parts'), 'do') (('Voting', 'machine multiple learning algorithms'), 'be') (('We', 'also different algorithms'), 'use') (('Using', 'feature selection'), 'show') (('So classifier', 'highest weight'), 'assign') "}
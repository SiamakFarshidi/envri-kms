{"name": "detectron 2 2nd attempt ", "full_name": " h3 CHANGES h1 VinBigData detectron2 train h1 Table of Contents h1 Dataset preparation h1 Installation h1 Training method implementations h2 Data preparation h1 Customizing detectron2 trainer h2 Mapper for augmentation h2 Evaluator h2 Loss evaluation hook h2 LR scheduling h1 Loading Data h1 Data Visualization h1 Training h1 Visualize loss curve competition metric AP40 h1 Visualization of augmentation by Mapper h3 If this kernel helps you please upvote to keep me motivated Thanks h1 Next step h2 Discussions ", "stargazers_count": 0, "forks_count": 0, "description": "Here implemented VinbigdataEvaluator is constructed we can also use COCOEvaluator here. It is nice to start with however I want to customize the training behavior more to improve the model s performance. Data preparation detectron2 provides high level API for training custom dataset. AugInput image transforms self. 40 and replaced to show this value instead of AP with IoU 0. Its content is saved to metric. I insert LossEvalHook before evalutor to work well. Then I noticed that we can use many augmentations in albumentations so I implemented AlbumentationsMapper to support it. Data VisualizationIt s also very easy to visualize prepared training dataset with detectron2. width width of the image. roi_batch_size_per_image 128 faster and good enough for this toy dataset default 512 eval_period 20 aug_kwargs HorizontalFlip p 0. com c vinbigdata chest xray abnormalities detection discussion 207955. Mapper for augmentation Mapper class is used inside pytorch DataLoader. Python3 s json writer which always produces strings cannot serialize a bytestream unless you decode it. 95 1e 5 step dtype torch. We can analyze plot them to check how the training proceeded. You just need to wrap above training scripts by main method and use launch method provided by detectron2. pyplot as plt Ref https github. XYXY_ABS is used here meaning that absolute value of xmin ymin xmax ymax annotation is used in the bbox. Loss evaluation hookWe implemented Evaluator and now we can calculate competition metric however validation loss is not calculated inside Evaluator. NOTE this config means the number of classes but a few popular unofficial tutorials incorrect uses num_classes 1 here. inspired from Detectron https github. com facebookresearch detectron2 blob master INSTALL. It affects to the score a lot Preferable radiologist s id in the test dataset https www. This dataset_dicts contains the metadata for actual data fed into the neural network. com corochann preprocessing image original size lossless png on kaggle fails due to disk limit Please upvote the dataset as well Installationdetectron2 is not pre installed in this kaggle docker so let s install it. height height of the image. There are really many That s all I found that the competition data is not so many 15000 for all images 4000 images after filtering No finding images. Predicted box_proposals are in XYXY_ABS mode. dimension of precision TxRxKxAxM IoU dimension of recall TxKxAxM stats 2 _summarize 1 iouThr. read_csv imgdir test_meta. This can be done by adding Hook which calculates the loss to the trainer. Therefore we subtract 0. 1 step training prediction https www. annotation This is the ground truth annotation data for object detection which contains following bbox bounding box pixel location with shape n_boxes 4 bbox_mode BoxMode. Note that current implementation is not efficient in the sense that Evaluator s evaluation and LossEvalHook s loss calculation run separately even if both need a model forward calculation for same validation data. It is a ground up rewrite of the previous version Detectron and it originates from maskrcnn benchmark. Thankfully utf 8 works out which is also what the pycocotools _mask. html build_lr_scheduler supports only 2 types of LR scheduling WarmupMultiStepLR default WarmupCosineLR. transforms with MyMapper class it provides basic augmentations. out visualizer. This is the inverse of data loading logic in datasets coco. put_scalars validation_loss mean_loss is called to put this validation loss to the storage which will be saved to metrics. We remove the bbox field to let mask AP use mask area. com facebookresearch detectron2 Detectron2 is Facebook AI Research s next generation software system that implements state of the art object detection algorithms. png UPDATE 2021 1 11 I published prediction kernel please check https www. We can construct train_loader purely from cfg without instantiating trainer since it s class method. Load 1 image to get image size. build_hooks This method defines how to construct hooks. VinBigData 2 class classifier complete pipeline https www. Here I modified COCOEvaluator implementation to calculate AP with IoU 0. com c vinbigdata chest xray abnormalities detection discussion 219672 The 1 step pipeline which does not use any 2 class classifier approach is proposed. pop sem_seg_file_name None return dataset_dict h w Copyright c Facebook Inc. 5 ShiftScaleRotate scale_limit 0. com c vinbigdata chest xray abnormalities detection discussion 219221 Investigation of test dataset annotation distribution. md we need to know CUDA and pytorch version to install correct detectron2. com albumentations team albumentations pixel level transforms and Spatial level transforms https github. Here AlbumentationMapper is passed to construct DataLoader to insert customized augmentation process. py L255 noqa Record max overlap value for each gt box Return vector of overlap values all small medium large 96 128 128 256 256 512 512 inf sort predictions in descending order TODO maybe remove this and make it explicit in the documentation guard against no boxes find which proposal box maximally covers each gt box and get the iou amount of coverage for each gt box find which gt box is best covered i. put_scalar validation_loss mean_loss return losses How loss is calculated on train_loop self. LR_SCHEDULER_NAME as you can see from the docs. array obj category_id for obj in dataset_dict annotations dtype np. Famouns dataset s evaluator is already implemented in detectron2. TrainingIt s actually very easy to use multiple gpus for training. build_evaluator This class method defines how to construct Evaluator. Visualize loss curve competition metric AP40As I explained the calculated metrics are saved in metrics. plotly models setup For debug. Iter from 10k to 12k VinBigData detectron2 trainThis competition is object detaction task to find a class and location of thoracic abnormalities from chest x ray image radiographs. It provides Visualizer class we can use it to draw an image with bounding box as following. How many augmentations can be used in albumentations You can see official github page all Pixel level transforms https github. This is because model s evaluation is done in model. UPDATE 2021 2 18 Added links to relevant useful discussions in Next step topic. build_train_loader build_test_loader These class methods deine how to construct DataLoader for training data validation data respectively. put_scalars timetest 11 from detectron2. I also uploaded the original sized png images vinbigdata chest xray original png https www. To calculate validation loss we need to call model with the training mode. 5 RandomBrightnessContrast p 0. You can refer the Detectron2 Beginner s Tutorial https colab. Below code is to visualize the same data 4 times. Now the methods are ready. transforms albumentations augmentations properly handles bounding box. float32 compute recall for each iou threshold ar 2 np. You can change which one to use by setting cfg. In my experiment Calcification seems to be the most difficult class to predict. com facebookresearch Detectron blob a6a835f5b8208c45d0dce217ce9bbda915f44df7 detectron datasets json_dataset_evaluator. 5 to be consistent with the annotation format. I will demonstrate these augmentations later so you can skip reading the code and please just jump to next. Table of Contents Dataset preparation dataset Installation installation Training method implementations train_method Customizing detectron2 trainer custom_trainer Advanced topic skip it first time Mapper for augmentation mapper Evaluator evaluator Loss evaluation hook loss_hook Loading Data load_data Data Visualization data_vis Training training Visualize loss curve competition metric AP40 vis_loss Visualization of augmentation by Mapper vis_aug Next step next_step Dataset preparationPreprocessing x ray image format dicom into normal png image format is already done by xhlulu in the below discussion Multiple preprocessed datasets 256 512 1024px PNG and JPG modified and original ratio https www. com corochann vinbigdata 2 class classifier complete pipeline kernel explains how to train 2 class classifier model for the prediction and submisssion for this competition. It is loaded beforehand of the training on memory so it should contain all the metadata image filepath etc to construct training dataset but should not contain heavy data. See installation https detectron2. best most iou find the proposal box that covers the best covered gt box record the iou coverage of this gt box mark the proposal box and the gt box as used append recorded iou coverage level thresholds torch. Customizing detectron2 trainer This section is advanced I recommend to jump to Training scripts section for the first time of reading. DefaultTrainer is used in the example which provides the starting point to train your model with custom dataset. It does not take long time to train less than a day so this competition may be a good choice for beginners who want to learn object detection If this kernel helps you please upvote to keep me motivated Thanks Next step VinBigData detectron2 prediction https www. Here I will just use the dataset VinBigData Chest X ray Resized PNG 256x256 https www. is_train dataset_dict. Loading DataThis Flags class is to manage experiments. https user images. pop sem_seg_file_name None return dataset_dict h w it will be modified by code below aug_input T. print row print row class_name class_name row class_name It is No finding Use this No finding class with the bbox covering all image area. bbox_original int row x_min int row y_min int row x_max int row y_max test_meta pd. We can make own Trainer class MyTrainer here for this purpose and override methods to provide customized behavior. com facebookresearch detectron2 blob master configs COCO Detection faster_rcnn_R_50_FPN_3x. py L222 L252 noqa precision has dims iou recall cls area range max dets area range index 0 all area ranges max dets index 1 typically 100 per image tabulate it use RLE to encode the masks because they are too large and takes memory since this evaluator stores outputs of the entire dataset counts is an array encoded by mask_util as a byte stream. print anom_ind cv2_imshow out. Define Hook to calculate validation loss plotting training validation loss curve. trapz recalls thresholds When evaluating mask AP if the results contain bbox cocoapi will use the box area as the area of the instance instead of the mask area. Thus bounding box is adjusted when the image is scaled rotated etc At first I was using detectron2. Please refer official example train_net. the standard metrics Compute per category AP from https github. com xhlulu vinbigdata chest xray resized png 256x256 to skip the preprocessing and focus on modeling part. com c vinbigdata chest xray abnormalities detection discussion 220295 Suggests how to predict more smaller sized high aspect ratio bonding boxes. EvaluatorTo evaluate validation dataset to calculate competition metric we need Evaluator. For example many kinds of AP Average Precision is calculted in COCOEvaluator. augmentations aug_input image aug_input. Ref detectron2 docs Dataloader https detectron2. py L79 L88 For visualization. Since mapper is used inside DataLoader we can check its behavior by constucting DataLoader and visualize the data processed by the DataLoader. The defined Trainer class has class method build_train_loader. To define custom dataset we need to create list of dict dataset_dicts where each dict contains following file_name file name of the image. image category_id np. read_csv datadir sample_submission. Copy so the caller can do whatever with results unmap the category ids for COCO cocoapi does not handle empty results very well Saving generated box proposals to file. It is responsible for converting dataset_dicts into actual data fed into the neural network and we can insert augmentation process in this Mapper class. Trainer has attribute storage and calculated metrics are summarized. com facebookresearch detectron2 blob master MODEL_ZOO. This annotator does not find anything skip. com apofeniaco training on detectron2 with a validation set and plot loss on it to avoid overfitting 6449418fbf4e Now all the preparation has done MyTrainer overwraps build_evaluator method of DefaultTrainer provided by detectron2 to support validation dataset evaluation. HACKING overwrite iouThrs to calc ious 0. com corochann vinbigdata chest xray original png notebook https www. com drive 16jcaJoc6bCFAQ96jDe2HwtXj7BMD_ m5 scrollTo QHnVupBBn9eR Colab Notebook or version 7 of this kernel https www. What anchor size aspect ratio should be used https www. import matplotlib. 5 args parse Read data Read in the data CSV files alias sample_submission pd. Below LossEvalHook calculates validation loss in _do_loss_eval method and self. json jsonl format during training. detectron2 is one of the famous pytorch object detection library I will introduce how to use this library to train models provided by this library with this competition s data https github. com 1381301 66535560 d3422200 eace 11e9 9123 5535d469db19. com corochann vinbigdata detectron2 prediction too UPDATE 2021 1 24 I added more advanced usage to customize detectron2 especially How to define use mapper to add your customized augmentation. Note that both detectron2. DiscussionsThese discussions are useful to further utilize this training notebook to conduct deeper experiment. 15 rotate_limit 10 p 0. evaluation import COCOEvaluator PascalVOCDetectionEvaluator return PascalVOCDetectionEvaluator dataset_name not working return COCOEvaluator dataset_name bbox False output_dir output_folder flags General Data config all_train or valid20 original or wbf Training config images per batch this corresponds to total batch size WarmupMultiStepLR default or WarmupCosineLR Overwrite by param_dict flags_dict debug True outdir results debug imgdir_name vinbigdata chest xray resized png 256x256 split_mode valid20 iter 100 debug small value should be set. draw_dataset_dict per_image. category_id class label id for each bounding box with shape n_boxes get_vinbigdata_dicts is for train dataset preparation and get_vinbigdata_dicts_test is for test dataset preparation. You can check that augmentation is applied and every time the image looks different. Visualization of augmentation by MapperLet s check the behavior of Mapper method. com facebookresearch detectron2 blob 22b70a8078eb09da38d0fefa130d0f537562bebc tools visualize_data. get_image 1 pass aug_kwargs to cfg Let training initialize from model zoo pick a good LR Small value Frequent save need a lot of storage. We can finetune these pre trained architectures. Default build_lr_schduler method docs https detectron2. We can follow installation instruction https github. pop annotations None dataset_dict. io en latest _modules detectron2 solver build. Use validation data during training. int64 Remove unnecessary field. com albumentations team albumentations spatial level transforms with BBoxes checked can be used. maxDets 2 Infering it from predictions should be better Test set json files do not contain annotations evaluation must be performed using the COCO evaluation server. eval mode and it outputs bounding box prediction but does not output loss. 95 but we need AP with IoU 0. com corochann vinbigdata detectron2 prediction kernel explains how to use trained model for the prediction and submisssion for this competition. In practice loading all the taining image arrays are too heavy to be loaded on memory so these are loaded inside DataLoader on demand This is done by mapper class in detectron2 as I will expain later. 5 Visualize data. Training method implementationsBasically we don t need to implement neural network part detectron2 already implements famous architectures and provides its pre trained weights. record image_id index objs record annotations objs utils configs T. I will tune these parameters through the competition to improve model s performance. 0 is used in this kaggle docker image. In COCO annotations keypoints coordinates are pixel indices. io en latest tutorials data_loading. image_id id of the image index is used here. com corochann vinbigdata detectron2 train scriptVersionId 51628272 for the simple usage of detectron2 how to train custom dataset. These models are summarized in MODEL_ZOO. Ref Training on Detectron2 with a Validation set and plot loss on it to avoid overfitting https medium. main scripts starts from here. LR schedulingTo further customize learning rate scheduling you may override build_lr_scheduler class method to construct any pytorch LRScheduler. 4 Use the COCO default keypoint OKS sigmas unless overrides are specified COCOAPI requires every detection and every gt to have keypoints so we just take the first entry from both Copying inference_on_dataset from evaluator. Resize 800 800 it will be modified by code below if not self. html I implemented MyMapper which uses augmentations implemented in detectron2 and AlbumentationsMapper which uses albumentations library augmentations. com facebookresearch detectron2 blob master tools train_net. Define Evaluator and calculating competition metric AP40. COCOEvaluator only calculates AP with IoU from 0. yaml for this kernel. csv To get number of data. In this competition we need object detection model I will choose R50 FPN https github. This leads to a different definition of small medium large. Our Evaluator calculaes AP by class and it is easy to check which class is diffucult to train. However our predictions are floating point coordinates. ", "id": "explorerboi/detectron-2-2nd-attempt", "size": "14106", "language": "python", "html_url": "https://www.kaggle.com/code/explorerboi/detectron-2-2nd-attempt", "git_url": "https://www.kaggle.com/code/explorerboi/detectron-2-2nd-attempt", "script": "tools lightgbm albumentations dataclasses pathlib Boxes detectron2.data.samplers plotly.express DatasetEvaluator detectron2.config Optional evaluate preprocessing Path _do_loss_eval MyTrainer(DefaultTrainer) field plotly.io scipy _get_loss matplotlib.pyplot instances_to_coco_json detectron2.data COCOeval load_yaml _summarizeKps Visualizer PathManager CfgNode as CN DefaultTrainer get_vinbigdata_dicts_test pycocotools.cocoeval detectron2.data.datasets.coco pycocotools.mask collections _summarizeDets create_small_table get_vinbigdata_dicts detectron2.structures process _eval_predictions build_train_loader detectron2.evaluation catboost Flags MyMapper _summarize detectron2.evaluation.fast_eval_api setup_logger sklearn _derive_coco_results HookBase plotly.graph_objs build_evaluator pandas detectron2.evaluation.evaluator vin_summarize detectron2.engine display subplots IPython.core.display detectron2.utils.visualizer pycocotools.coco detectron2.utils.file_io build_detection_train_loader detectron2.engine.hooks save_yaml numpy get_cfg detectron2 dataclass plotly PascalVOCDetectionEvaluator detectron2.utils.logger Any detectron2.data.transforms detection_utils as utils build_test_loader COCOeval_opt typing log_every_n_seconds build_hooks plotly.offline VinbigdataEvaluator(DatasetEvaluator) LossEvalHook(HookBase) tqdm.notebook build_detection_test_loader DefaultPredictor plotly.figure_factory after_step pairwise_iou TrainingSampler HTML strtobool _tasks_from_predictions MetadataCatalog __call__ AlbumentationsMapper COCOEvaluator convert_to_coco_json DatasetCatalog launch xgboost update Union OrderedDict seaborn distutils.util _evaluate_predictions_on_coco tqdm detectron2.utils.comm COCO CfgNode _evaluate_box_proposals Dict detectron2.config.config KFold model_zoo tabulate sklearn.model_selection reset BoxMode _eval_box_proposals __init__ detection_utils ", "entities": "(('models', 'MODEL_ZOO'), 'summarize') (('gt box', 'gt box find'), 'overlap') (('com Detectron blob detectron', 'json_dataset_evaluator'), 'facebookresearch') (('which', 'custom dataset'), 'use') (('which', 'metrics'), 'call') (('html build_lr_scheduler', 'scheduling WarmupMultiStepLR default LR WarmupCosineLR'), 'support') (('LR learning schedulingTo further customize you', 'pytorch'), 'rate') (('we', 'also COCOEvaluator'), 'implement') (('dataset_dicts', 'neural network'), 'contain') (('t', 'pre trained weights'), 'method') (('we', 'DataLoader'), 'check') (('Calcification', 'experiment'), 'seem') (('class method', 'how Evaluator'), 'define') (('Facebook AI generation software next that', 'object detection algorithms'), 'be') (('which', 'trainer'), 'do') (('com c vinbigdata chest xray abnormalities detection discussion', 'aspect ratio bonding 220295 how more smaller sized high boxes'), 'suggest') (('com corochann class classifier complete pipeline vinbigdata 2 kernel', 'competition'), 'explain') (('This', 'datasets coco'), 'be') (('Pixel level', 'https github'), 'use') (('Here I', 'just dataset'), 'use') (('competition we', 'Evaluator'), 'need') (('Data preparation detectron2', 'custom dataset'), 'provide') (('it', 'loss'), 'output') (('detectron2 solver', '_ io latest modules'), 'build') (('put_scalar validation_loss mean_loss return How loss', 'train_loop self'), 'loss') (('I', 'data https github'), 'be') (('1381301 66535560 d3422200', '9123 5535d469db19'), 'com') (('800 800 it', 'code'), 'Resize') (('tutorials a few popular unofficial incorrect', 'num_classes'), 'mean') (('competition', 'chest ray image radiographs'), 'iter') (('albumentations augmentations', 'properly box'), 'transform') (('I', 'performance'), 'tune') (('Below code', 'same data'), 'be') (('competition data', 'finding images'), 'be') (('which', 'bbox_mode n_boxes 4 BoxMode'), 'annotation') (('evaluation', 'model'), 'be') (('I', 'reading'), 'customize') (('method', 'how hooks'), 'define') (('Now preparation', 'validation dataset evaluation'), 'train') (('that', 'gt iou coverage level thresholds used append recorded torch'), 'find') (('You', 'Tutorial https Detectron2 colab'), 'refer') (('1024px 256 512 PNG', 'below discussion'), 'dataset') (('evaluator stores outputs', 'byte stream'), 'dim') (('I', 'evalutor'), 'insert') (('We', 'override customized behavior'), 'make') (('many kinds', 'COCOEvaluator'), 'calculte') (('get_vinbigdata_dicts_test', 'dataset test preparation'), 'd') (('it', 'trainer'), 'construct') (('Read 5 args data', 'sample_submission pd'), 'parse') (('You', 'detectron2'), 'need') (('it', 'basic augmentations'), 'transform') (('which', 'class classifier 2 approach'), 'discussion') (('Frequent save', 'storage'), 'pass') (('print row print row class_name class_name row It', 'image area'), 'class_name') (('too 2021 1 I', 'customized augmentation'), 'UPDATE') (('where dict', 'image'), 'define') (('md we', 'pytorch correct detectron2'), 'need') (('Loading', 'experiments'), 'be') (('Trainer defined class', 'class method'), 'have') (('We', 'trained architectures'), 'finetune') (('This', 'small medium large'), 'lead') (('Famouns evaluator', 'already detectron2'), 'implement') (('I', 'detectron2'), 'adjust') (('so I', 'it'), 'notice') (('annotations evaluation', 'COCO evaluation server'), 'maxdet') (('I', 'detectron2'), 'be') (('later you', 'just next'), 'demonstrate') (('calculated metrics', 'attribute storage'), 'have') (('Here AlbumentationMapper', 'augmentation customized process'), 'pass') (('Predicted box_proposals', 'XYXY_ABS mode'), 'be') (('LossEvalHook', '_ do_loss_eval method'), 'calculate') (('TxKxAxM 2 _', '1 iouThr'), 'stat') (('DiscussionsThese discussions', 'deeper experiment'), 'be') (('we', 'box'), 'provide') (('class', 'class'), 'calculaes') (('level spatial transforms', 'BBoxes checked'), 'use') (('2021 11 I', 'https www'), 'UPDATE') (('which', 'albumentations library augmentations'), 'implement') (('Mapper class', 'pytorch DataLoader'), 'use') (('Define Evaluator', 'AP40'), 'metric') (('com xhlulu vinbigdata chest xray', 'part'), 'resize') (('so s', 'it'), 'corochann') (('however I', 'more performance'), 'want') (('you', 'it'), 'serialize') (('it', 'heavy data'), 'load') (('how training', 'them'), 'analyze') (('we', 'evaluator'), 'Use') (('you', 'Thanks'), 'take') (('d', 'image index'), 'image_id') (('Visualization', 'Mapper method'), 'check') (('ymin xmax ymax annotation', 'bbox'), 'use') (('We', 'installation instruction https github'), 'follow') (('Data VisualizationIt', 'detectron2'), 's') (('category ids', 'box very well generated proposals'), 'copy') (('validation however loss', 'Evaluator'), 'evaluation') (('Here I', 'IoU'), 'modify') (('I', 'png images vinbigdata chest png https also original sized xray original www'), 'upload') (('record index objs record annotations', 'utils configs'), 'image_id') (('it', 'maskrcnn benchmark'), 'be') (('COCOEvaluator', '0'), 'calculate') (('calculated metrics', 'metrics'), 'metric') (('we', 'training mode'), 'need') (('loss separately even both', 'validation same data'), 'note') (('dataset_dict it', 'aug_input T.'), 'sem_seg_file_name') (('class build_train_loader build_test_loader methods', 'data validation data'), 'deine') (('com albumentations team albumentations pixel level Spatial level', 'https github'), 'transform') (('you', 'docs'), 'LR_SCHEDULER_NAME') (('bbox cocoapi', 'instance'), 'recalls') (('mask AP', 'mask area'), 'remove') (('It', 'Preferable test dataset https lot i www'), 'affect') (('we', 'Mapper class'), 'be') (('com corochann vinbigdata detectron2 prediction kernel', 'competition'), 'explain') (('split_mode valid20 iter 100 debug small value', 'png'), 'return') (('I', 'R50 FPN https github'), 'need') (('However predictions', 'point coordinates'), 'float') (('TrainingIt', 'training'), 's') (('You', 'cfg'), 'change') "}
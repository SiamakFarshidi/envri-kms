{"name": "hubmap read data and build tfrecords ", "full_name": " h1 Disclaimer h1 Objective h1 Reading the Images h1 Reading and Showing a sample image and mask h1 Tiling the Large Images into 512x512 tiles h1 Transforming the Tiles into a TFRecord Dataset h1 Verifying the TFRecord correctness ", "stargazers_count": 0, "forks_count": 0, "description": "So now we know how to read each image and mask and that their types are uint8 and bool respectively. com marcosnovaes hubmap looking at tfrecords https www. I am a coach for this competition the focus of my contributions is on helping users to leverage GCP components GCS TPUs BigQueryetc. Verify all images were written Verifying the TFRecord correctnessLet s now read back a sample tile to verify correctness. Now let s move down the image by incrementing the height offset to 9 20 which should be the tile below 8 20 So the glom ends in that tile and there are fewer TRUE pixels. Reading the ImagesSome of the images are in TIFF format some are in BigTIFF. But in ML you only need to understand the TFExample https www. Reading and Showing a sample image and maskThe next cells show the code that can read the first image in the csv file. As we explore the tiles I also calculate the tile histogram. Also I try to develop notebooks quickly in order to help users early in competitions. The strategy adopted in this Notebook is to tile the images in 512X512 tiles and then transforming the tiles into TFRecords such that we can later use them as input to train models using GPU or TPU accelerators. There may be better ways to solving particular problems I welcome comments and suggestions. In the same fashion the code below scans the test directory and converts all the images there too. We will also build a pandas dataframe that has the metadata for each tile including the lowpass energy and mask density metrics that we derived above. Simply counting the number of TRUE pixels in the mask is a great metric that indicate the tile contains a glom. in order to solve large problems. This metric will be used when we want to filter the training dataset to make sure it includes a certain number of tiles with gloms. Using the TFRecord format for storing data should be easy but unfortunately it requires data serialization which complicates it a little bit. But notice that the masks are also provided as a. WARNING I ran out of memory trying to write both train and tests images in one session. This inline code will each image and mask in the train set swap axes when needed loading the image and mask into numpy arrays and then invoking the above function for each image mask pair. org api_docs python tf train Example format. It turns out that if we later select lowpass energy 100 we are garanteed to have actual tissue in the slide and we can discard anything with 100. It also builds a pandas dataframe with the metadata for all tiles. You can also easily costumize this Notebook if you want to produce tiles od different sizes I used 512x512 or if you want to include more metadata for each tile. If we look back at the polygon dump above it shows that the first glom starts at pixel 10503 4384. swapaxes function to change the shape using reshape will scramble the channels. Libs used in this NotebookLet s look at the input data. org tutorials load_data tfrecord but you don t need to read all this in this Notebook I provide an example specific for image data that you can quickly customize. 1G almost exceeding the Kaggle VM limit. This Notebook takes a long time to run because it processes all the competition files and the resulting compressed dataset is 18. I used the tiffile library and it seems to read the images with no problem. Voila Let s also verify that the tile metadata file is correct. IMPORTANT Notice that you need to use the numpy. com marcosnovaes hubmap tfrecord 512 I have also developed a Notebook that explains how to use the TFRecord Dataset https www. But they have very large dimensions we would not be able to train a ML model at these dimensions. This Notebook will tile the image using offsets for the height index and width index. I will be using the json files The following function converts the polygons into a numpy boolean mask with the same shape as the image. Use my contributions at your own risk I don t garantee that they will help on winning any competition but I am hoping to learn by collaborating with everyone. Let s now derive a metric for masks so that in the future we can easily find tiles with gloms. 8 20 which we previously noticed to contain a glom. If we move a little to the right and down we are then in the white zone. a Tile with coordinate 1 0 represents a tile with height offset 1 Tile Size in this case it starts at numpy coordinates 512 0 which means it is the tile below 0 0 a Tile with coordinate 0 1 represents a tile with wodth offset 1 Tile Size in this case it starts at numpy coordinates 0 512 which means it is the tile to the right of 0 0 As can be noticed in the sample image displayed there is a black border and then a lot of white surrounding the tissue. Here is the function that takes an image slices into tiles calculates tile metadata and commits to storage. Find and read the competition train. So let s try the values 0 0 and 5 5 and we should be a black and a white tile respectively. It is just not possible to read them all in memory in the Kaggle environment and it is also not possible to build a model using the whole image as input. The images in this competition have very high resolution averaging 30 000 x 30 000 pixels and this presents a difficult challenge in memory management. Verify all train images were written to file. To build the complete dataset I built one at the time. For each image you are provided a. Kaggle has a limit of 50 upper level directories so we will create one dir for each image. tiff image file and the Run Length Encoding Mask. verify that we can read all images select an image to investigate read json mask explore a few tiles Utilities serialize data into a TFRecord BytesList won t unpack a string from an EagerTensor. Going further down we find a cortex tile with no gloms. histogram function divides the color spectrum in 10 bins and shows how many pixels call within each bin. json file with polygon definitions. Here is the code that takes care of the difference in shapes. This template is explained in detail in this tutorial https www. This function writes a tile to storage notice the GZIP compression this makes possible for all the tiles to be stored locally without exceeding the HD allowance of the Kaggle machine. The id corresponds to the images provided. This loop will take a long time as each image is read just so we can tell its shape. So in the next section I takes the approach of tiling up the image and working with tiles. Tiling the Large Images into 512x512 tilesHere are some useful functions that use the numpy slicing capability to select specifc tiles of the image. NOTE The numpy arrays have dimensions height width channels. The test images will be needed for evaluating the loss during training. Objective The objective of this notebook is to provide an example of how to transform the HubMAP Hacking the Kidney competition dataset into a form that can readily used to train models leveraging accelerators. For serialization using TFExample we have to make any data fit into either one of 3 types bytes_feature float_feature int_64_featureIn this Notebook and image and mask are passed as bytes_features and the other metadata as int_64. And here is the white one 5 5 Now let s try to find a glomerulus. You CANNOT use reshape instead that will scramble the channels. Parse the input tf. We can notice that black and white fall into the higher end of the spectrum. I was able to process all files and then uploaded the results to a Kaggle daset that I have made public Link to the TFRecord Dataset Produced by this Notebook. In this Notebook I provide a little template code for dealing with TFExamples that can be quickly customized for any type of data. com marcosnovaes hubmap looking at tfrecords If you want to use the dataset without change you don t need to run the Notebook but do read through it because it provides a lot of insight on how the read the images masks and convert them to TFRecords. This notebooks provides some tips for reading the competitions images and masks and proposes a strategy to deal with the large sizes. This will take a long time. Black tiles have 0 pixels in the lower end while white actually dirty gray has only about 20 pixels in that region. Let s call this metric lowpass energy. I used this option instead in this Notebook. Disclaimer Hello Kagglers I am a Solution Architect with the Google Cloud Platform. If we observe the histogram we will notice that it will provide a useful way to filter black and white tiles later. org tutorials load_data tfrecord Let s read the tile with col offset 8 and row offset 20 i. create a pandas dataframe to store metadata for each tile create one directory for each row of images create directory populate the metadata for this tile read json mask write the dataframe convert all the test images read json mask write the dataframe read back a record to make sure it the decoding works Create a dictionary describing the features. My ideas and contributions represent my own opinion and are not representative of an official recommendation by Google. If we divide both indexes by 512 we expect to find a glom in tile 8 20 Bingo We found our first glom. IMPORTANT Note that in the case of a channel first TIFF number 3 first we need to swap the axis of the numpy array as noted below. com protocol buffers and that is a bit of a learning curve. The next cell reads all tiffs and prints their shapes. This is done using protocol buffers https developers. So a Tile with coordinate 0 0 represents the first tile on the top left corner. The masks are provided in the csv files in RLE format but we are also provided json files that describe the mask as polygons. It turns out that some TIFF images are channel first number 3 first and others channel last number 3 last. When reading them we must check if the 3 is first and swap the axis as needed. If we select 0 0 we expect to see a black tile. Transforming the Tiles into a TFRecord DatasetWe are now ready to read all the images one at a time or we will run out of memory and then writing each tile to a TFRecord file. Example proto using the dictionary above. I will be using this dataset on my subsequent notebooks. We then see that tiles with some actual tissue have a more even distribution. We introduce here the read TFRecord functions that follow the model described in this tutorial https www. ", "id": "marcosnovaes/hubmap-read-data-and-build-tfrecords", "size": "10146", "language": "python", "html_url": "https://www.kaggle.com/code/marcosnovaes/hubmap-read-data-and-build-tfrecords", "git_url": "https://www.kaggle.com/code/marcosnovaes/hubmap-read-data-and-build-tfrecords", "script": "verify_read imsave image_example get_tile_mask numpy seaborn _parse_image_function _int64_feature imread show_tile_and_mask tensorflow read_mask write_tfrecord_tiles get_tile matplotlib.pyplot pandas read_tf_dataset _float_feature _bytes_feature show_tile_dist create_tfrecord ", "entities": "(('3', 'axis'), 'check') (('we', 'GPU accelerators'), 'be') (('i d', 'images'), 'correspond') (('calculates', 'storage'), 'be') (('here white 5 Now s', 'glomerulus'), 'be') (('8 20 We', 'first glom'), 'expect') (('we', '100'), 'turn') (('first glom', 'pixel'), 'dump') (('we', 'image'), 'have') (('I', 'tile also histogram'), 'calculate') (('data', 'bytes_features'), 'have') (('that', 'shapes'), 'be') (('that', 'learning curve'), 'com') (('we', 'white then zone'), 'be') (('this', 'memory management'), 'have') (('some', 'BigTIFF'), 'format') (('Notebook', 'height index index'), 'tile') (('we', 'TFRecord file'), 'be') (('I', 'tiles'), 'take') (('Utilities', 'EagerTensor'), 'select') (('we', 'black tile'), 'expect') (('that', 'accelerators'), 'objective') (('that', 'data'), 'provide') (('instead that', 'channels'), 'use') (('0 0 we', 'values'), 'let') (('then tiles', 'more even distribution'), 'see') (('you', 'tile'), 'costumize') (('just we', 'shape'), 'take') (('tiles', 'Kaggle machine'), 'write') (('This', 'protocol buffers https developers'), 'do') (('So glom', 'tile'), 'let') (('masks', 'also a.'), 'notice') (('it', 'competition files'), 'take') (('IMPORTANT you', 'numpy'), 'notice') (('that', 'polygons'), 'provide') (('3 first we', 'numpy array'), 'note') (('it', 'tissue'), 'represent') (('inline code', 'image mask pair'), 'image') (('that', 'TFRecord Dataset https how www'), 'tfrecord') (('ideas', 'Google'), 'represent') (('template', 'https tutorial www'), 'explain') (('decoding works', 'features'), 'create') (('notebooks', 'large sizes'), 'provide') (('how the', 'TFRecords'), 'hubmap') (('I', 'time'), 'build') (('you', 'that'), 'tfrecord') (('white actually dirty gray', 'region'), 'have') (('it', 'problem'), 'use') (('tile', 'glom'), 'be') (('users', 'GCP components GCS TPUs BigQueryetc'), 'be') (('numpy arrays', 'dimensions height width channels'), 'NOTE') (('We', 'spectrum'), 'notice') (('I', 'comments'), 'be') (('that', 'https tutorial www'), 'introduce') (('It', 'tiles'), 'build') (('that', 'csv file'), 'show') (('you', 'TFExample https only www'), 'need') (('org api_docs', 'train Example tf format'), 'python') (('test images', 'training'), 'need') (('I', 'Notebook'), 'be') (('we', 'that'), 'build') (('how many pixels', 'bin'), 'divide') (('I', 'one session'), 'warning') (('row', '20 i.'), 'let') (('Also I', 'early competitions'), 'try') (('I', 'subsequent notebooks'), 'use') (('it', 'black tiles'), 'notice') (('we', 'dimensions'), 'have') (('further down we', 'gloms'), 'find') (('Libs', 'input data'), 'look') (('following function', 'image'), 'use') (('I', 'instead Notebook'), 'use') (('next cell', 'shapes'), 'read') (('which', 'it'), 'be') (('So Tile', 'top left corner'), 'represent') (('function', 'channels'), 'scramble') (('it', 'input'), 'be') (('types', 'how image'), 'know') (('includes', 'gloms'), 'use') (('we', 'gloms'), 'let') (('that', 'image'), 'tile') (('I', 'everyone'), 'hope') (('Verify', 'correctness'), 'write') (('we', 'previously glom'), '20') (('Disclaimer Hello I', 'Solution Google Cloud Platform'), 'Kagglers') "}
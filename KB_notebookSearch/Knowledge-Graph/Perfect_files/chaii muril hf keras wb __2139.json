{"name": "chaii muril hf keras wb ", "full_name": " h1 MURIL Multilingual Representations for Indic Languages h2 References h2 Stack h1 Table of Contents h2 Imports h2 Configuration h2 Dataset Split h2 Setting Tokenizer h2 Dataset Pipelines h2 Postprocessing Pipeline h2 Creating Dataset h2 Creating Model h2 Model Training h2 Make predictions on test set h2 Further Reading h3 If you learnt something from this kernel please don t forget to upvote ", "stargazers_count": 0, "forks_count": 0, "description": "Set to None the offset_mapping that are not part of the context so it s easy to determine if a token position is part of the context or not. Pandas for Data Preprocessing2. Start token index of the current span in the text. pdf Screenshot from 2021 09 05 15 27 50. Go through all possibilities for the n_best_size greater start and end. If no answers are given set the cls_index as answer. One example can give several spans this is the index of the example containing this span of text. Generally for MURIL a goood approach would be to finetune on squad 2 first and then finetune on the competition dataset. Hugging Face for pretrained model and tokenizer4. png Table of Contents1. But what is MURIL MURIL Khanuja et al simrankhanuja is a multilingual LM specifically built for Indic Languages. png attachment d3c64f59 55c8 4f4f 9eff d82c4e64779e. Otherwise move the token_start_index and token_end_index to the two ends of the answer. Update minimum null prediction. Imports section1 2. End token index of the current span in the text. Setting Tokenizer section4 5. Don t consider answers with a length that is either max_answer_length. Grab the sequence corresponding to that example to know what is the context and what is the question. MURIL as the pretrained model5. Dataset split section3 4. Note we could go after the last offset if the answer is the last word edge case. io examples nlp text_extraction_with_bert Stack1. We keep the example_id that gave us this feature and we will store the offset mappings. Model Training section9 10. Creating Model section8 9. Don t consider out of scope answers either because the indices are out of bounds or correspond to part of the input_ids that are not in the context. Logger Instance To make this work with TPU detect TPUs TPU detection detect GPUs Intialize wandb run We will label impossible answers with the index of the CLS token. Creating Dataset section7 8. Weights and biases for experiment tracking kaggle. com huggingface notebooks blob master examples question_answering. Start end character index of the answer in the text. Postprocessing Pipeline section6 7. data from Tensorflow for Data Pipelines3. png attachment a91d27e6 acff 4189 abf6 24314847de65. Dataset Pipeline section5 6. Keras Text extraction with Bert Link https keras. This wonderful notebook https github. ipynb by HuggingFace 2. I am going to use other postprocessing methods to improve the score. Detect if the answer is out of span in which case this feature is labeled with the CLS index. Read the full paper here https arxiv. Keras for Model training6. Configuration section2 3. Make Predictions on Test Set section10 Imports Configuration Dataset Split Setting Tokenizer Dataset Pipelines Postprocessing Pipeline Creating Dataset Creating Model Model Training Make predictions on test set Further Reading1. MURIL Multilingual Representations for Indic Languages In this notebook I try to train model using MURIL pretrained model combined with Hugging Face and Keras. Use Learning Rate Scheduler If you learnt something from this kernel please don t forget to upvote Creating a logger Specify the format Create a StreamHandler Instance Create a FileHandler Instance Create a logging. ", "id": "harveenchadha/chaii-muril-hf-keras-wb", "size": "2139", "language": "python", "html_url": "https://www.kaggle.com/code/harveenchadha/chaii-muril-hf-keras-wb", "git_url": "https://www.kaggle.com/code/harveenchadha/chaii-muril-hf-keras-wb", "script": "ChaiiDataset prepare_eval_features JaccardScore(keras.callbacks.Callback) train_test_split map_func_eval get_device keras wandb.keras numpy get_keras_model jaccard on_epoch_end transformers layers tqdm TFAutoModel prepare_tf_data_pipeline postprocess tensorflow tensorflow.keras.backend matplotlib.pyplot kaggle_secrets tqdm.auto plot_hist sklearn.model_selection pandas run_tokenizer AutoTokenizer init_logger get_jaccard_score tensorflow.keras seed_everything UserSecretsClient __init__ WandbCallback map_func get_callbacks prepare_train_features ", "entities": "(('goood approach', 'competition 2 first then dataset'), 'be') (('Postprocessing Pipeline', 'Further Reading1'), 'make') (('answers', 'answer'), 'set') (('We', 'CLS token'), 'Instance') (('we', 'offset mappings'), 'keep') (('that', 'length'), 'consider') (('that', 'context'), 'consider') (('feature', 'CLS index'), 'detect') (('token position', 'context'), 'set') (('don t', 'logging'), 'use') (('MURIL MURIL Khanuja et al simrankhanuja', 'Indic multilingual specifically Languages'), 'be') (('I', 'score'), 'go') (('several this', 'text'), 'give') (('question', 'example'), 'grab') (('I', 'Hugging Face'), 'Representations') (('io examples', 'text_extraction_with_bert Stack1'), 'nlp') (('answer', 'last offset'), 'note') "}
{"name": "luna pytorch vs cancer ", "full_name": " h2 Introduction h2 Load required libraries h2 Understand the Dataset h3 Annotations h3 Candidates h2 Missing data h2 Load the data h2 Train the Model h2 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "We can now train the model. We now remove from our list of candidates those that don t have a CT scan. It would be unrealistic to expect the model to learn how to predict positive samples with just a couple of data points. Load required libraries Understand the DatasetThe Luna16 Lung Nodule Analysis 2016 dataset contains chest CT scans and annotations indicating where there are nodules in each CT scan and their diameters. We now have a CT scan chunk ct_scan_chunk. We use a VALIDATION_STRIDE of 10 which means every 10th CT scan will be in the validation set. The X Y and Z coordinates of the center can be slightly different in the annotations and candidate files. Among these candidates those with the largest diameter will come before those with smaller diameters. Another thing to note is that there can be multiple annotations and candidates in a single CT scan. We will be using the cross entropy loss https ravimashru. All candidates with a diameter of zero recall this happens when the candidate coordinates are not close enough to any annotation coordinates or there is no corresponding annotation for the particular candidate will come after these. org SimpleITK Notebooks 01_Image_Basics. However for simplicity we ll assume that the dataset contains only one. We now convert the origin and voxel size from the patient coorindate system previously mentioned to coordinates that we can use to index into the NumPy array representing the CT scan. We ll load data from this dataset to save precious GPU time on Kaggle. org The model we will build will try to predict whether a particular region of a CT scan has a nodule or not. We use a range of 1000 or 1000 to remove extremely dense materials from the CT scan. Candidates that have a value of False for is_nodule will come last in the list with the same relative order of diameters as above. This probably happened because we don t have enough positive samples in the training and validation set. We read the CT scan and store it as a NumPy array. Also because our dataset is highly imbalanced we need a better strategy to train our model and also a better indication of model performance instead of accuracy. Next we create DataLoader s out of our datasets. First let us set up some utility functions for caching the dataset. We then sort the list of candidates in reverse order. They have great documentation https simpleitk. html available if you want to read more. The code used to set up caching is from the Deep Learning with PyTorch book and can be found in the book s GitHub repository https github. Train the ModelThis model is a PyTorch version of Sentdex https www. The numbers below the accuracy give us a clearer picture of what is going on. This notebook is my attempt to train the model that Sentdex https www. The entire CT scan is currently very large for us to work with. IntroductionThis notebook was created as a part of the Weights Biases PyTorch Book Reading Group https community. Since the list contains tuples the order of fields will determine the way the list is sorted. As we ll see later this will significantly speed up training after the first epoch. We use the glob module to find the. I guess we ll have to keep that champagne on the ice for a little longer. org articles hounsfield unit which goes from 1000 to 3000. The next step would be to convert this chunk of CT scan to a PyTorch tensor. That s not the entire story. There are two CSV files that we ll be working with annotations. This will allow us to easily access the centers and respective diameters of all nodules in a particular CT scan. com deep learning with pytorch dlwpt code blob master util disk. The center of the nodule is at index irc in the complete scan ct_scan. raw files associated with the candidate. The first epoch takes a long time but once the data is cached the other epochs are super fast ConclusionWe ve got an accuracy of over 99 on the validation set Time to pop the champagne But hang on. mhd file for a given seriesuid. com mashruravi luna16missingcandidates. We lost almost 50 of the data PANIC Well we d panic if this wasn t something we re just playing with. The cell below finds all such seriesuid s. have the same seriesuid. That path will be available at index 0 of the result. More information https luna16. Now let s put it all together in a few utility functions and a Dataset class. There are 443 seriesuid s in the annotations and candidates CSV files that don t have corresponding. There are 1 186 total annotations available. com sentdex first pass through data w 3d convnet in PyTorch. dev blog 2021 07 18 understanding cross entropy loss function to train our model so we need two columns for the output one hot encoded values of the boolean is_nodule value we re interested in. seriesuid is the unique identifer of the CT scan. The idea was to find a notebook on Kaggle with a TensorFlow model trained on the Luna16 dataset and try to convert it to PyTorch. In particular after sorting we ll have all candidates with the value of is_nodule as True at the beginning of the list. Therefore when looking for a candidate s diameter from the diameters dict we ll assume that if the center coordinates of the candidate are less than half the radius of the annotated nodule away from the center coordinates of the annotated nodule then they are the same nodule. Most of the code used to read the data comes from the amazing book we re reading in the group Deep Learning with PyTorch https www. However if fine for now as we won t be using the diameter information when building this simple model. We now create an instance of the model the loss function and an optimizer to train the model. We will extract a chunk by getting a list of three slices one for each direction and then using that to extract the actual values from the CT scan. png Missing dataThere are some seriesuid s in the dataset that don t have corresponding CT scans in the dataset. That sentence was a mouthful Maybe this diagram will be easier to understand image. Since it takes about 10 minutes to run I have made those seriesuid s available as a separate dataset https www. png attachment 93cf076d 063b 4b3f 90d4 1a1ab3f6fe04. com books deep learning with pytorch. That s equivalent to 41 RGB color images of resolution 512x512 for a single CT scan Since most of the CT scan doesn t contain any interesting to us we will extract 3 dimensional chunks of the CT scan that contain nodules as input for our model. So this model is not very useful right now. coordX coordY and coordZ are coorindates of the center of the mass. We will walk through and understand all the steps using a single candidate before putting the code together into utility functions and a PyTorch Dataset. Similarly we group the candidates that are part of the same CT scan and then use the diameters dictionary we created above to fetch each candidate s diameter. The huge difference between candidates and annotations tells us that we will have many candidates for which we won t have a diameter in the annotations file. There are over 750k candidates. ai c community events pytorch book 32 hosted by Sanyam Butani https www. The glob package can return multiple files that match the pattern specified. The model predicted all negatives correctly but didn t make any correct predictions for the positive data points. For now we ll try not to worry about this and move on with the data that we have left. com sentdex first pass through data w 3d convnet. com sentdex s TensorFlow model in this notebook https www. com sentdex built in his notebook First pass through Data w 3D ConvNet https www. AnnotationsThe annotations file contains the center and diameter of each mass in CT scans. We will first group all annotations that are part of the same CT scan i. The SimpleITK package has a very simple API that we ll use to get details about the CT scan. com gzuidhof full preprocessing tutorial has a great walkthrough and visualization of this data format. This notebook https www. We now have three slices we can use in each direction to extract the chunk we need. png attachment b9b5d21a 10c2 437e bc94 383e0182f2c5. Let s say we want to extract a chunk of size 10 along the index column and 18 rows and columns. class is 0 if the mass isn t a nodule and 1 if it is a nodule both malignant and benign. The actual values in the CT scan are in Hounsfield units HU https radiopaedia. png We will create a namedtuple to store the information that we combine from the candidates and annotations. csv and candidates_V2. Load the dataWe ll now walk through how we want to convert the data we have into a format that we can consume with PyTorch. CandidatesThe candidates file contains a class flag for each mass in the CT scans. The files could be in any one of the subset folders in the dataset. With the utility function and caching set up we can now create a PyTorch datset. We need to also convert the output we want from the model is_nodule into a PyTorch tensor. We also get the following information Center point of reference of the CT scan also known as the origin Size of each voxel short for volume pixel since each CT scan can have a different size of voxels Direction matrix that has a direction vector for of each axis in the CT scanWe convert the origin and voxel size to NumPy arrays so that they are easier to use in calculations. We can now load this file using the SimpleITK package. The glob module allows us to find the file by using patterns instead of manually looking inside each of the folders. ", "id": "shivanir23/luna-pytorch-vs-cancer", "size": "9974", "language": "python", "html_url": "https://www.kaggle.com/code/shivanir23/luna-pytorch-vs-cancer", "git_url": "https://www.kaggle.com/code/shivanir23/luna-pytorch-vs-cancer", "script": "find_missing_and_multiple diskcache diskcache.core store DataLoader core Disk Poly3DCollection numpy skimage mpl_toolkits.mplot3d.art3d FanoutCache io train_loop fetch torch.nn concurrent.futures ThreadPoolExecutor tqdm getCache LunaDataset(Dataset) MODE_BINARY eval_loop matplotlib.pyplot forward pandas BytesType tqdm.notebook torch.optim GzipDisk(Disk) LunaModel(nn.Module) morphology torch.utils.data __len__ namedtuple Dataset SimpleITK __init__ getCtScanChunk measure __getitem__ collections cassandra.cqltypes BytesIO ", "entities": "(('we', 'PyTorch'), 'load') (('list', 'way'), 'tuple') (('we', 'boolean value'), 'blog') (('We', 'utility together functions'), 'walk') (('We', 'loss https cross entropy ravimashru'), 'use') (('seriesuid', 'CT unique scan'), 'be') (('we', 'something'), 'lose') (('annotations file', 'CT scans'), 'contain') (('center', 'complete scan'), 'be') (('ConclusionWe super fast ve', 'champagne'), 'take') (('full preprocessing', 'data format'), 'have') (('files', 'dataset'), 'be') (('s', 'dataset https separate www'), 'make') (('us', 'folders'), 'allow') (('that', 'diameters'), 'come') (('com sentdex', 'Data w ConvNet https First 3D www'), 'pass') (('actual values', 'Hounsfield units HU https radiopaedia'), 'be') (('Train', 'PyTorch Sentdex https www'), 'be') (('we', 'above diameter'), 'group') (('corresponding annotation', 'these'), 'happen') (('CandidatesThe candidates', 'CT scans'), 'file') (('notebook', 'model'), 'be') (('those', 'smaller diameters'), 'come') (('highly we', 'instead accuracy'), 'also') (('notebook', 'Weights Biases'), 'create') (('CT 10th scan', 'validation set'), 'use') (('First us', 'dataset'), 'let') (('dataset', 'only one'), 'assume') (('They', 'documentation https great simpleitk'), 'have') (('next step', 'PyTorch tensor'), 'be') (('didn correctly t', 'data positive points'), 'predict') (('we', 'chunk'), 'have') (('2016 dataset', 'CT where scan'), 'require') (('particular region', 'nodule'), 'org') (('we', 'CT scan'), 'convert') (('We', 'model'), 'create') (('then they', 'annotated nodule'), 'dict') (('We', 'CT scan'), 'extract') (('we', 'PyTorch now datset'), 'create') (('We', 'reverse order'), 'sort') (('CSV two we', 'annotations'), 'be') (('they', 'calculations'), 'get') (('thing', 'CT multiple single scan'), 'be') (('later this', 'first epoch'), 'speed') (('DataLoader', 'datasets'), 'create') (('com sentdex', 'PyTorch'), 'pass') (('We', 'Kaggle'), 'load') (('we', 'candidates'), 'create') (('we', 'ice'), 'guess') (('path', '0 result'), 'be') (('what', 'clearer picture'), 'give') (('com sentdex', 'data w 3d first convnet'), 'pass') (('particular we', 'list'), 'have') (('However we', 'when simple model'), 'use') (('Maybe diagram', 'image'), 'be') (('we', 'CT scan'), 'have') (('model', 'data points'), 'be') (('don t', 'CT corresponding dataset'), 'be') (('we', 'that'), 'try') (('idea', 'PyTorch'), 'be') (('we', 'Deep PyTorch https www'), 'use') (('code', 'GitHub repository https github'), 'use') (('We', 'CT scan chunk now ct_scan_chunk'), 'have') (('X Y coordinates', 'slightly annotations'), 'be') (('we', 'annotations file'), 'tell') (('that', 'model'), 's') (('We', 'SimpleITK package'), 'load') (('Now s', 'utility together a few functions'), 'let') (('we', 'PyTorch tensor'), 'need') (('us', 'CT particular scan'), 'allow') (('We', 'CT scan'), 'use') (('pattern', 'multiple files'), 'return') (('that', 'same CT'), 'group') (('coordX coordY', 'mass'), 'be') (('We', 'NumPy array'), 'read') (('we', 'index 10 column'), 'let') (('don t', 'CT scan'), 'remove') (('don t', 'corresponding'), 'be') (('probably we', 'training set'), 'happen') (('org articles hounsfield which', '3000'), 'unit') "}
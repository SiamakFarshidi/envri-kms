{"name": "breast cancer detection original d83b2c ", "full_name": " h1 The training part starts from here on h2 Below is the model trained using data augmentation h1 XifengGuo h1 The Capsule Network starts from here on h2 Capsule Layer h2 The entire capsule network h2 More sophisticated model h2 Comparision between the models h3 However I am willing to add some more analysis and visualization in a sooner time h2 Sensitivity between the three models h2 Specificity between the three models h2 Precision h2 F measure h1 End Remarks ", "stargazers_count": 0, "forks_count": 0, "description": "plot train_acc1 color red plt. Below code reads the data from output. scale preds so that the class probas of each sample sum to 1 manual computation of crossentropy epochs 50 In cases if you try and are not getting the satisfactory accuracy compared to other models then it s advisable to train it for longer period of time by increasing the number of epochs. Next step is we need to extract the class names in which each files belong from its file names. Now lets look at the color ranges that our images have Code Conclusion From the above image we can conclude that brighter region is more than the darken region in our image. We will go for spliting testing set into validation set. if no true label mask by the max length of capsules. Capsule Layer This is the custom layer of capsule network. However I am willing to add some more analysis and visualization in a sooner time. Model x out_caps decoder masked noise layers. if 1 the norm of vector will be zoomed out. Also it trained in less no. param input_shape data shape 3d width height channels param n_class number of classes param routings number of routing iterations return Two Keras Models the first one used for training and the second one for evaluation. The training part starts from here on. x layers. Data Processing We will first shuffle are images to remove any patterns if present and then load them. It had performed well on the train data validation data and the test data as well as seen by the confusion matrix. argmax Y_test i 0 tn 1. Now we will split our data into training set and testing set. Now we have our three sets of train valid and test. The Code inspiration for undersampling is taken from a notebook https www. Therefore automation of detection of breast cancer using Histopathology images could reduce cost and time as well as improve the accuracy of the test. eval_model can also be used for training. plot val_acc1 color orange tp 0 for i in range 0 len Y_test Number of positive cases if np. In the next step we will OneHot encode our data to better work with neural networks. Doctors often do the biopsy or a scan if they detect signs of IDC. BENCHMARK MODEL A simple CNN model Now we will plot the confusion matrix Below is the model trained using data augmentation. We change pixels range from 0 255 to 0 1. x Conv2D 64 3 3 activation relu x x AveragePooling2D 2 2 x x Conv2D 128 3 3 activation relu x x Conv2D 128 3 3 activation relu x x Reshape 1 128 x capsule Capsule 64 8 3 True primarycaps This is more than one capsule layer This is more than one capsule layer This is more than one capsule layer output Lambda lambda z K. Therefore it is very important to detect the signs as early as possible. jpg Domain Background Breast Cancer is the most common type of cancer in woman worldwide accounting for 20 of all cases. Input shape n_class 16 noised_digitcaps layers. In 2012 it resulted in 1. Sensitivity between the three models. softmax_cross_entropy_with_logits expects logits Keras expects probabilities. Code Conclusion There are only png extentions which are present in alphabets therefore it means that we have only one image extention files with. While somewhat unstable nature was shown by augmented model. param y_true None n_classes param y_pred None num_capsule return a scalar loss value. Further I am willing to make this a more complex hence better model that may consists of more than just two capsule layers. End Training with data augmentation train or test init the model weights with provided one as long as weights are given will run testing For Image argumentaton the squashing function. x Reshape 1 128 x we use a margin loss batch_size 64 comment this line and uncomment the above line if you want the batch size of 64 the squashing function. This is an active research field lot of research papers and articles are present online one that I like is https www. 1 2 3 4 5 6 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 plt. And the transfer learning model s accuracy saturated at around 80. L y_true K. We can do two things either split test set further into valid set or split train se into valid set. We will now do undersampling to treat our data for class imbalances. argmax Y_test i 1 tp 1 for i in range 0 len Y_test number of negative cases if np. xticks y_pos objects hot encoding them create iterators for effective looping Plotting the confusion matrix for checking the accuracy of the model For Image argumentaton true label is provided with shape None n_classes i. plot val_acc1 color orange 1 2 3 4 5 6 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 plt. 5 in stead of 1 in hinton s paper. Image Argumentation We will now add image argumentation to our data so that it may be set for wider range of domainWe will also rescale our image pixels from range of 0 255. Model x y out_caps decoder masked_by_y eval_model models. Comparision between the models Graph of all four models validation accuracy and loss. add MaxPooling2D pool_size 2 2 epochs 50 In cases if you try and are not getting the satisfactory accuracy compared to other models then it s advisable to train it for longer period of time by increasing the number of epochs. The augmentor for CapsNet is called datagen_caps. function to view an image reads an image displays an image to plot histogram of pixel values present in an image VS intensities to open and write csv files Allows the use of display for DataFrames to shuffle the data to hot encode the output labels to hot encode the data For performing undersampling Constructor of the class to perform undersampling resamples the dataset resamples the dataset For Plotting the distribution of classes plt. I have by default added the data augmentation. 5 the norm will be zoomed in while original norm is less than 0. About 80 of all breast cancers are invasive ductal carcinomas. 68 million new cases and 522 000 deaths. Hence we applied the below call back in order to terminate as soon as it starts attaining nan loss. Input shape n_class masked_by_y Mask digitcaps y The true label is used to mask the output of capsule layer. softmax can not specify axis. Breast Cancer Detection https blogs. Conv2D filters 256 kernel_size 9 strides 1 padding valid activation relu name conv1 x primarycaps PrimaryCap conv1 dim_capsule 8 n_channels 32 kernel_size 9 strides 2 padding valid digitcaps CapsuleLayer num_capsule n_class dim_capsule 16 routings routings name digitcaps primarycaps out_caps Length name capsnet digitcaps y layers. We need to now preprocess our image file. One of the major problems is that women often neglect the symptoms which could cause more adverse effects on them thus lowering the survival chances. Data Extraction and Visualization Code Conclusion We can see that images are very small though they are cropped images its hard for human eye to understand them without using some high costly machines. 9 y_pred 0. The following are the functions and parameters that are further required for construction of Capsule Network. In India there are about one million cases every year and the five year survival of stage IV breast cancer is about 10. We will save it in output. softmax because K. Now we will plot the confusion matrix XifengGuo The Capsule Network starts from here on. When y_true i contains not just one 1 this loss should work too. gov pmc articles PMC5453426 as they used deep learning approach to study on histology images and achieved the sensitivity of 95 which is greater than many pathologists 90. We have a large dataset and we will work with neural networks therefore for better debugging we will use only a part of data considering limited RAM and non GPU processor this will not cost us much as we would also be using under sampling methods and image argumentation to deal with class imbalances and moderate data. We will now create our benchmark model. This shows the power of automation and how it could help in the detection of breast cancer. read_csv to check the name of the directory inside which we have our files we extract only png files adds support for opening manipulating and saving many different image file formats adds progress bar for the loops going through all the images will take up lot of memory so therefore we will check until we get three different dimentions. The cost of testing for breast cancer sets one back with 5000 which is a very big amount for poor families and also manual identification of presence and extent of breast cancer by a pathologist is critical. We would encode our output data which is present as Class1 and Class0 to 1 and 0. Specificity between the three models. Below two cells can plot the confusion matrix for the model2 capsule network. Add digitcaps noise masked_noised_y Mask noised_digitcaps y manipulate_model models. square z 2 capsule we use a margin loss epochs 50 In cases if you try and are not getting the satisfactory accuracy compared to other models then it s advisable to train it for longer period of time by increasing the number of epochs. com wp content uploads 2018 01 AI_Mammographie. For training masked Mask digitcaps Mask using the capsule with maximal length. Precision F measure End RemarksIt was observed that the CapsNet performed better than all of the models. Therefore we will load only that. of epochs and the remained stable for the rest of the epochs. add BatchNormalization import tensorflow as tf the squashing function. In developed countries the survival rate is although high but it is an area of concern in the developing countries where the 5 year survival rates are poor. Model x y noise decoder masked_noised_y return train_model eval_model manipulate_model def margin_loss y_true y_pred Margin loss for Eq. For prediction train_model models. define our own softmax function instead of K. argmax Y_test i 1 tp 1 Senstivity of models confusion_bench_s cnf_matrix_bench 1 1 tp 100 tp 0 tn 0 for i in range 0 len Y_test Number of postive cases if np. plot val_acc1 color orange plt. com paultimothymooney predict idc in breast cancer histology imagesWe also need a validation set inorder to check overfitting. Code Conclusion We have total of 277524 image filesNext Step is that we will check whether the dimentions of all the images are same or different Code Conclusion We can see that the dimentions of images are not equal therefore we would make it all equal to work bettter with our network. linear algebra data processing CSV file I O e. Through below 2 cells you can print the accuracy and loss of the model. used for computer vision tasks such as reading image from file changing color channels etc for plotting various graph images etc. IMPORT FILES Data Exploration In data exploration we will first check the name of the files. also no augmentation. Invasive ductal carcinoma IDC is the most common form of breast cancer. sum L 1 unpacking the data compile the model Begin Training with data augmentation shift up to 2 pixel for MNIST Training with data augmentation. add 256 5 5 input_shape 50 50 3 custom_model. 5 and be zoomed out while original norm is greater than 0. The entire capsule network More sophisticated modelWith 2 capsule layersIt was observed that the model after certain epochs starts attaining the nan loss. Input shape input_shape conv1 layers. Mainly used for prediction compute lengths of capsules true label provided no true label provided Transform matrix None 10 16 from utils import combine_images from capsulelayers import CapsuleLayer PrimaryCap Length Mask def CapsNet input_shape n_class routings A Capsule Network on MNIST. csv and displays it Class1 represents IDC and Class0 represents IDC Code Conclusion We can see that we have an unbalanced class and which is a common problem when we have medical data therefore this is one another problem that we have to deal with later. ", "id": "adityashrivastava/breast-cancer-detection-original-d83b2c", "size": "6610", "language": "python", "html_url": "https://www.kaggle.com/code/adityashrivastava/breast-cancer-detection-original-d83b2c", "git_url": "https://www.kaggle.com/code/adityashrivastava/breast-cancer-detection-original-d83b2c", "script": "keras.layers imblearn.under_sampling softmax cv2 #used for computer vision tasks such Lambda CapsuleLayer glob regularizers tqdm #adds progress bar for the loops layers plot_confusion_matrix Layer tensorflow.keras.utils tensorflow.keras.backend matplotlib.pyplot ImageDataGenerator  #For Image argumentaton PIL Model Capsule(layers.Layer) tensorflow.keras model_to_dot plot_log _to_tensor Activation keras.models keras RandomUnderSampler #For performing undersampling build to_categorical view_images initializers MaxPooling2D tensorflow.keras.models Length Dropout GlobalAveragePooling2D models Image #adds support for opening tensorflow customentropy train_generator pandas 0 images call combine_images test to_categorical #to hot encode the output labels optimizers PrimaryCap CapsNet manipulating CapsuleLayer(layers.Layer) Reshape IPython.display confusion_matrix compute_output_shape sklearn.utils plot_model keras.preprocessing.image numpy Image train ImageDataGenerator BatchNormalization keras.backend Capsule(Layer) capsulelayers shuffle manipulate_latent Conv2D activations Length(layers.Layer) display # Allows the use of display() for DataFrames to_categorical #to hot encode the data margin_loss get_config sklearn.metrics Flatten AveragePooling2D train_test_split callbacks tensorflow.keras.layers Mask(layers.Layer) SVG and saving many different image file formats Dense backend as K utils Mask tqdm Sequential squash backend sklearn.model_selection 1 images shuffle #to shuffle the data Input keras.utils hist_plot __init__ ", "entities": "(('We', 'validation set'), 'go') (('Now we', 'train'), 'have') (('We', 'class imbalances'), 'undersample') (('IV breast cancer', 'one year about million year five stage'), 'be') (('eval_model', 'also training'), 'use') (('original norm', '0'), '5') (('It', 'test confusion as well matrix'), 'perform') (('1 loss', 'just one'), 'contain') (('Below', 'data augmentation'), 'model') (('Keras', 'probabilities'), 'expect') (('However I', 'sooner time'), 'be') (('them', 'None'), 'provide') (('I', 'data augmentation'), 'add') (('capsule more than one This', 'AveragePooling2D'), 'Conv2D') (('dataset', 'classes plt'), 'read') (('ductal carcinoma Invasive IDC', 'breast most common cancer'), 'be') (('norm', 'vector'), 'zoom') (('param', 'second evaluation'), 'return') (('very they', 'high costly machines'), 'Extraction') (('out_caps Length name capsnet', 'y layers'), 'filter') (('capsule More sophisticated modelWith 2 layersIt', 'nan loss'), 'observe') (('more adverse effects', 'survival thus chances'), 'be') (('We', 'image now file'), 'need') (('that', 'Capsule Network'), 'be') (('somewhat unstable nature', 'augmented model'), 'show') (('it', 'bettter network'), 'Conclusion') (('Add', 'noise masked_noised_y'), 'digitcap') (('above you', '64 squashing function'), 'x') (('Capsule Network', 'confusion matrix'), 'plot') (('then it', 'epochs'), 'add') (('sum', 'data augmentation'), 'begin') (('then it', 'epochs'), 'capsule') (('we', 'image extention only one files'), 'Conclusion') (('which', '1'), 'encode') (('more complex hence better that', 'just two capsule layers'), 'be') (('y out_caps', 'eval_model masked_by_y models'), 'model') (('out_caps', 'noise masked layers'), 'Model') (('we', 'image class imbalances'), 'have') (('it', '0'), 'argumentation') (('how it', 'breast cancer'), 'show') (('you', 'model'), 'print') (('we', 'files'), 'Exploration') (('we', 'better neural networks'), 'OneHot') (('as long weights', 'squashing function'), 'run') (('We', 'train split valid set'), 'do') (('we', 'three different dimentions'), 'add') (('which', 'many pathologists'), 'article') (('transfer learning accuracy', 'around 80'), 'saturate') (('brighter region', 'image'), 'range') (('Now we', 'training'), 'split') (('then it', 'epochs'), 'pred') (('Code inspiration', 'notebook https www'), 'take') (('augmentor', 'CapsNet'), 'call') (('two cells', 'model2 capsule network'), 'plot') (('year survival where 5 rates', 'developing countries'), 'be') (('Therefore automation', 'test'), 'reduce') (('we', 'one that'), 'represent') (('y_pred None num_capsule', 'loss scalar value'), 'param') (('as soon it', 'nan loss'), 'apply') (('About 80', 'breast cancers'), 'be') (('Capsule This', 'custom capsule network'), 'Layer') (('I', 'research field research active papers'), 'be') (('files', 'file names'), 'be') (('first shuffle', 'then them'), 'Processing') (('which', 'pathologist'), 'set') (('Input n_class Mask true label', 'capsule layer'), 'shape') (('CapsNet', 'models'), 'measure') (('they', 'IDC'), 'do') (('jpg Domain Background Breast Cancer', 'cases'), 'be') (('Therefore it', 'very signs'), 'be') (('We', '255 0'), 'change') (('idc', 'overfitting'), 'predict') "}
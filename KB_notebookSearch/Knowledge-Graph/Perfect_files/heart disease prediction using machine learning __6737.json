{"name": "heart disease prediction using machine learning ", "full_name": " h3 So we have no missing values h3 This shows that most columns are moderately correlated with target but fbs is very weakly correlated h1 Exploratory Data Analysis EDA h1 Percentage of patient with or without heart problems in the given dataset h3 Here 0 is female and 1 is male patients h1 Heart Disease Frequency for ages h1 Heart Disease frequency for sex where 0 is female and 1 is male and red is have heart disease and blue is don t have heart disease h1 Heart disease according to Fasting Blood sugar h1 Analysing the chest pain 4 types of chest pain h1 Value 1 typical angina Value 2 atypical angina Value 3 non anginal pain Value 4 asymptomatic h1 Analysing The person s resting blood pressure mm Hg on admission to the hospital h1 Analysing the Resting electrocardiographic measurement 0 normal 1 having ST T wave abnormality 2 showing probable or definite left ventricular hypertrophy by Estes criteria h2 people with restecg 1 and 0 are much more likely to have a heart disease than with restecg 2 h1 Analysing Exercise induced angina 1 yes 0 no h3 People with exercise induced angina 1 are much less likely to have heart problems h1 Analysing the slope of the peak exercise ST segment Value 1 upsloping Value 2 flat Value 3 downsloping h1 Analysing number of major vessels 0 3 colored by flourosopy h3 count num major vessels h3 comparing with target h3 num major vessels 4 has astonishingly large number of heart patients h1 Analysing A blood disorder called thalassemia 3 normal 6 fixed defect 7 reversable defect h3 plotting the thalassemia distribution 0 1 2 3 h3 comparing with target h1 thalassemia and cholesterol scatterplot h1 thalassemia vs resting blood pressure scatterplot h2 Health rate vs age h1 Correlation plot h2 Correlation analysis h1 Splitting the dataset to Train and Test h2 importing Accuracy score h1 Modelling and predicting with Machine Learning h1 Logistic regression h1 Confusion Matrix h1 precision Score h1 Recall h1 F Score h1 Random Forest h1 Learning curve for Training score cross validation score h2 confusion matrix of Random Forest h1 precision score h1 recall h1 F score h1 Naive Bayes h2 confusion matrix of Naive Bayes h1 precision score h1 recall h1 f score h1 KNN K Nearest Neighbors h2 Confusion matrix h1 precision score h1 recall h1 f score h1 Decision Tree h2 Confusion Matrix h1 precision score h1 recall h1 f score h1 Final Score ", "stargazers_count": 0, "forks_count": 0, "description": "First of all let s equip ourselves with a handy tool that benefits from the cohesion of SciKit Learn library and formulate a general function for training our models. cp The chest pain experienced Value 1 typical angina Value 2 atypical angina Value 3 non anginal pain Value 4 asymptomatic 4. thal A blood disorder called thalassemia 3 normal 6 fixed defect 7 reversable defect 14. Note that thalassemia one of the variables in this dataset is heredity. It turns out that value of n_neighbours 8 is optimal. performance metrics Accuracy is the ratio between the number of correct predictions and total number of predications. recall frac TP TP FN F score is known as the harmonic mean of precision and recall. acc frac TP TN TP TN FP FN Precision is the ratio between the number of correct positives and the number of true positives plus the number of false positives. 13 The solver for weight optimization. trestbps The person s resting blood pressure mm Hg on admission to the hospital 5. fbs The person s fasting blood sugar 120 mg dl 1 true 0 false 7. height and weight Correlation analysis Splitting the dataset to Train and Test importing Accuracy score Modelling and predicting with Machine LearningThe main goal of the entire project is to predict heart disease occurrence with the highest accuracy. Major factors that can be modified are Smoking high cholesterol high blood pressure physical inactivity and being overweight and having diabetes. FP False positive has no heart disease FN False negative has heart disease confusion matrix of Random Forest precision score recall F score Naive Bayes confusion matrix of Naive Bayes precision score recall f score KNN K Nearest Neighbors Let s see if KNN can perform even better by trying different n_neighbours inputs. Logistic regressionBest ACCURACY possible using Logistic regression Confusion Matrixfmt d is format default precision Score Recall F Scorebalance of precision and recall score Random Forest Learning curve for Training score cross validation scoreNow let us prune the depth of trees and check the accuracy. TN True negative has no heart disease. Precision p frac TP TP FP Recall is the ratio between the number of correct positives and the number of true positives plus the number of false negatives. oldpeak ST depression induced by exercise relative to rest ST relates to positions on the ECG plot. ca The number of major vessels 0 3 13. exang Exercise induced angina 1 yes 0 no 10. Confusion Matrix precision score recall f score Final Score store numeric variables in cnames Set the width and height of the plot Correlation plot Generate correlation matrix Plot using seaborn library instantiate model train model check accuracy and print out the results Logistic Regression Logistic Regression supports only solvers in liblinear newton cg 93. Create CV training and test scores for various training set sizes Number of folds in cross validation Evaluation metric Use all computer cores 50 different sizes of the training set Create means and standard deviations of training set scores Create means and standard deviations of test set scores Draw lines Draw bands Create plot Random forest with 100 trees Gaussian Naive Bayes KNN Seek optimal n_neighbours parameter initialize an empty list list of algorithms names list of algorithms with parameters loop through algorithms and append the score into the list create a dataframe from accuracy results. According to another source the major factors that can t be changed are increasing age male gender and heredity. restecg Resting electrocardiographic measurement 0 normal 1 having ST T wave abnormality 2 showing probable or definite left ventricular hypertrophy by Estes criteria 8. chol The person s cholesterol measurement in mg dl6. target Heart disease 0 no 1 yes Heart disease risk factors to the following high cholesterol high blood pressure diabetes weight family history and smoking. We set max_depth 3 limiting the depth of the tree decreases overfitting. thalach The person s maximum heart rate achieved9. age The person s age in years2. sex The person s sex 1 male 0 female 3. I have chosen several algorithms typical for solving supervised learning problems throughout classification methods. acc frac 1 frac 1 2 frac 1 p frac 1 r frac 2pr p r Problem characteristics in context of our case study TP True positive has heart disease. This section includes all results obtained from the study and introduces the best performer according to accuracy metric. Other factors include stress alcohol and poor diet nutrition. Confusion matrix precision score recall f score Decision TreeThe accuracy on the training set is 100 while the test set accuracy is much worse. This leads to a lower accuracy on the training set but an improvement on the test set. slope the slope of the peak exercise ST segment Value 1 upsloping Value 2 flat Value 3 downsloping 12. So we have no missing values This shows that most columns are moderately correlated with target but fbs is very weakly correlated. Exploratory Data Analysis EDA From the total dataset of 303 patients 165 54 have a heart disease target 1 Percentage of patient with or without heart problems in the given dataset Here 0 is female and 1 is male patients Heart Disease Frequency for ages Heart Disease frequency for sex where 0 is female and 1 is male and red is have heart disease and blue is don t have heart disease Heart disease according to Fasting Blood sugar Analysing the chest pain 4 types of chest pain Value 1 typical angina Value 2 atypical angina Value 3 non anginal pain Value 4 asymptomatic Analysing The person s resting blood pressure mm Hg on admission to the hospital Analysing the Resting electrocardiographic measurement 0 normal 1 having ST T wave abnormality 2 showing probable or definite left ventricular hypertrophy by Estes criteria people with restecg 1 and 0 are much more likely to have a heart disease than with restecg 2 Analysing Exercise induced angina 1 yes 0 no People with exercise_induced_angina 1 are much less likely to have heart problems Analysing the slope of the peak exercise ST segment Value 1 upsloping Value 2 flat Value 3 downsloping Slope 2 causes heart pain much more than Slope 0 and 1 Analysing number of major vessels 0 3 colored by flourosopy count num_major vessels comparing with target num_major_vessels 4 has astonishingly large number of heart patients Analysing A blood disorder called thalassemia 3 normal 6 fixed defect 7 reversable defect plotting the thalassemia distribution 0 1 2 3 comparing with target thalassemia and cholesterol scatterplot thalassemia vs resting blood pressure scatterplot Health rate vs age Correlation plotCorrelation analysis is a method of statistical evaluation used to study the strength of a relationship between two numerically measured continuous variables e. lbfgs is an optimizer in the family of quasi Newton methods. In order to achieve this we will test several classification algorithms. Therefore we need to apply pre pruning to the tree. The reason for displaying accuracy on both train and test sets is to allow us to evaluate whether the model overfits or underfits the data so called bias variance tradeoff. This is an indicative that the tree is overfitting and not generalizing well to new data. ", "id": "chayandatta/heart-disease-prediction-using-machine-learning", "size": "6737", "language": "others", "html_url": "https://www.kaggle.com/code/chayandatta/heart-disease-prediction-using-machine-learning", "git_url": "https://www.kaggle.com/code/chayandatta/heart-disease-prediction-using-machine-learning", "script": "classification_report plotContinuous train_test_split plotAge confusion_matrix accuracy_score numpy seaborn plotCategorial recall_score train_model GaussianNB sklearn.neighbors sklearn.naive_bayes sklearn.tree sklearn.linear_model learning_curve matplotlib.pyplot DecisionTreeClassifier precision_score sklearn.model_selection plotGrid pandas RandomForestClassifier LogisticRegression KNeighborsClassifier sklearn.metrics sklearn.ensemble ", "entities": "(('target Heart Heart disease risk 0 factors', 'weight family history'), 'disease') (('KNN', 'n_neighbours even better different inputs'), 'have') (('lbfgs', 'quasi Newton methods'), 'be') (('I', 'classification methods'), 'choose') (('ST T wave 0 normal abnormality', 'Estes'), 'Resting') (('that', 'diabetes'), 'smoke') (('exang Exercise', 'angina'), 'induce') (('performance metrics Accuracy', 'total predications'), 'be') (('importing', 'highest accuracy'), 'analysis') (('us', 'accuracy'), 'be') (('Logistic Regression Logistic Regression', 'newton liblinear cg'), 'Set') (('person', 'hospital'), 'trestbps') (('test', 'training set'), 'recall') (('This', 'test set'), 'lead') (('Naive KNN optimal n_neighbours Gaussian parameter', 'accuracy results'), 'create') (('num_major_vessels 4', 'variables two numerically measured continuous e.'), 'have') (('person', '120 mg 1 true 0 false 7'), 'fbs') (('3 limiting', 'overfitting'), 'set') (('Therefore we', 'tree'), 'need') (('tree', 'well new data'), 'be') (('value', '8'), 'turn') (('section', 'accuracy metric'), 'include') (('fbs', 'moderately target'), 'have') (('us', 'bias variance so called tradeoff'), 'be') (('TP True positive', 'heart disease'), 'frac') (('thalassemia', 'dataset'), 'note') (('that', 'models'), 'let') (('t', 'age male gender'), 'increase') (('oldpeak ST depression', 'ECG plot'), 'relate') (('recall frac TP TP FN F score', 'precision'), 'know') (('Other factors', 'stress alcohol'), 'include') (('Precision p frac TP TP FP Recall', 'false negatives'), 'be') (('we', 'classification several algorithms'), 'test') (('acc frac TP TN TP TN FP FN Precision', 'false positives'), 'be') "}
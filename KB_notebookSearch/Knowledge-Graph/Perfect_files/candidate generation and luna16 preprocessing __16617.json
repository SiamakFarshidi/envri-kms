{"name": "candidate generation and luna16 preprocessing ", "full_name": " h2 Segmentation of Lungs h2 Classification of Lung Nodules ", "stargazers_count": 0, "forks_count": 0, "description": "The images are of size z 512 512 where z is the number of slices in the CT Scan and varies depending on the resolution of the scanner. We will be reducing our search space by first segmenting the lungs and then removing the low intensity regions. After that growing neural gas GNG is applied to constrain even more the structures that are denser than the pulmonary parenchyma nodules blood vessels bronchi etc. In summary we first generate candidates using Image Processing or UNet and then cut voxels around all candidate points and classify them. I will also provide links of useful resources and information. The model may overfit on the training dataset. Nodule Candidate Region of Interest Generation After segmenting the lung structures from the CT Scanned images our task is to find the candidate regions with nodules since the search space is very large. Pre processing methods for nodule detection in lung CT 3 This paper has used dot enhancementfilter applied to the 3D matrix of voxel data. We will also sample equal number of negative examples from the image for training. Thus we should weight the loss function accordingly. Thus Dropout or Spatial Dropout are used to avoid overfitting. The model is written in keras in the unet_model function. The CT Scans are grayscale images i. Deep Learning for the Classification of Lung Nodules 3 They have trained a CNN and tested the results on different datasets. Segmentation of Lungs After reading the CT Scan the first step in preprocessing is the segmentation of lung structures because it is obvious that the regions of interests lies inside the lungs. The script is written in Python. We use the LUNA16 dataset for training our UNET model. pdfDue to computational limitations the size of each cannot very large too. The sample_images folder has around 20 folders each corresponding to one CT Scan. A threshold of 604 400 HU is used at all places because it was found in experiments that it works just fine. mhd files and SimpleITK is used to read the image. Super pixel segmentation can be further used and shape properties can be applied on segmented regions. Deep convolutional neural networks are trained by 62 492 regions of interest ROIs samples including 40 772 nodules and 21 720 nonnodules from the Lung Image Database Consortium LIDC database. Automatic segmentation of lung nodules with growing neural gas and support vector machine 1 The proposed method consists of the acquisition of computerized tomography images of the lung the reduction of the volume of interest through techniques for the extraction of the thorax extraction of the lung and reconstruction of the original shape of the parenchyma. Experimental results demonstrate the effectiveness of the proposed method in terms of sensitivity and overall accuracy and that it consistently outperforms the competing methods. There are some nodules which may be attached to the lung wall. pdfUNET for Candidate Point Generation Nowadays Deep Learning methods are achieving good results in Segmentation problems in medical imaging. The draw_circle function is used to mark the nodule regions in the binary mask. The code of xgboost classifier for use with trainX containing features and trainY containing labels is below. io preprocessing image This is a simple 3D CNN architecture for classification. The libraries that will be used in this tutorial for reading processing and visualisation of data are matplotlib numpy skimage and pydicom 2. The bright region inside the lungs are the blood vessels or air. They show that the method outperforms a base feature engineering method using the same techniques for other stages of lung nodule detection and show that CNNs obtain competitive results. There is one more xgboost or SVM classifier on our dataset to classify the samples. There are more methods that can be tried to get the regions of interest. matplotlib is used for plotting the slices. Finding the lung nodule regions is a very hard problem because there are nodules that are attached to the blood vessels or are present at the boundary of the lung region. After that we will be segmenting the lung structures and then find the region of interest possible cancer regions in the CT Scans using Image processing methods. So we used this threshold to filter the darker regions. The code for preprocessing the LUNA16 dataset is below In the processing there are few things that must be tried 1. In order to understand the features of lung nodules they further construct new datasets based on the combination of artificial geometric nodules and some transformations of the original images as well as a stochastic nodule shape model. The points are clustered using DBScan algorithm and probability of a cluster is the mean of probabilities of all points in that cluster. After reading the 3D CT Scans we will first segment the lungs and then generate the binary mask of nodule regions. Do not sample negative examples randomly from CT Scan. aspx Automated Segmentation of Lung Regions using Morphological Operators in CT scan. Please upvote or leave a comment if you liked the tutorial. The model is trained in keras. After preprocessing the dataset the next thing is to train the model for segmentation. Since the nodule regions are very less the dataset is skewed. Thus we can cut many voxels around a nodule center and increase the size of the dataset for training. csv shows the submission format for stage 1. In the dataset the CT Scans are saved in. The left blood vessels can further be filtered using shape properties because we know that nodules are spherical in shape. Thus we further remove the two largest connected component. I will be considering cubic voxels of size 36. To visualise the slices we will have to plot them. Inside the folder there are many dicom files. the value of each pixel is a single sample which means it carries only intensity information. Also whole image can t be classified directly using 3D CNNs due to limit on computation we need to find possible regions of cancer and then classify them. It was found in experiments that all the region of interests have intensity 604 400 HU. CNN architectures like UNet can also be used to generate candidate regions of interest. LIDC dataset is used for training and the classification results are very good. The activation of the fully connected network of the classifier is extracted and this features is created for each CT Scan in our dataset. I will post more methods as soon I implement them. Each 3D CT Scan consists of many slices whose number depends on the resolution of the scanner and each slice has a Instance Number associated with it which tells the index of the slice from the top. As baselines they also look at using SVM kNN and logistic regression to perform the same task. Automated Segmentation of Lung Regions using Morphological Operators in CT scan 2 The get_segmented_lungs method is a little modification of this paper. org onlineResearchPaperViewer. csv file of LUNA16 dataset. 1 https keras. 06651 4 http www. There are few things that anyone should try to improve the accuracy 1 Use of multi scale CNNs to capture more features for classification. Each CT Scan consists of multiple 2D slices which are provided in a DICOM format. The LUNA 16 dataset has the location of the nodules in each CT Scan thus will be useful for training the classifier. I will first explain a common method using simple Image Processing and Morphological operations to segment the lungs and then will give references and summaries to good links of papers. It is visible that the lungs are the darker regions in the CT Scans. I am sharing a list of useful resources with a summary of all of them 1. Lung Nodule Detection using a Neural Classifier 4 This paper discusses a dot enhancement filter for nodule candidate selection and a neural classifier for false positive finding reduction. io en stable getting_started. edu reports2016 324_Report. A specified network structure for nodule images is proposed to solve the recognition of three types of nodules that is solid semisolid and ground glass opacity GGO. Training is performed by balancing the mini batches on each stochastic gradient descent SGD iteration to address the lack of nodule samples compared to background samples. com journals cmmm 2016 6215085 3 https arxiv. There are also a lot of good papers on Lung Segmentation and Nodule Candidate generation using Image Processing methods. Next is the script for training a classifier with 3D Convolutional Neural Networks. Next I will be discussing about preprocessing of the LUNA16 dataset and using it to train the UNet model. The plot_ct_scan function takes a 3D CT Scanned Image array as input and plots equally spaced slices. Thus we will have to find the regions that are more probable of having cancer. The lung nodule candidates can be further used for classification by cutting 3D voxels around them and passing it through a 3D CNNs which can be trained on LUNA16 dataset. At the end we save the resized CT Scan with its segmented lungs and binary mask of nodules. Dataset augmentation is very important because are nodules are generally circular or spherical in shape and are of different radius. com r Python comments 3t23vv what_advantages_are_there_of_using_anaconda 2 http pydicom. Thus we need a classifier to classify the candidates as either Nodule or Non Nodule. world_2_voxel Convert world coordinates to voxel coordinates. The get_segmented_lungs function segments a 2D slice of the CT Scan. voxel_2_world Convert voxel coordinates to world coordinates. We take the mean of the probabilities of this classifier as the final output probability. This reduces the number of candidates by a large number and preserves all the important regions with high recall. html Reading a CT Scan The input folder has three things one is the sample_images folders which has the sample CT Scans. Now we will read all the dicom slices for a scan and then stack them with respect to their Instance Number to get the 3D Lung CT Scanned Image. Pulmonary Nodule Classification with Convolutional Neural Networks 1 They use a CNN to predictwhether the image contains a pulmonary lesion. pdf 2 https www. This 3D filter attempts to determine local geometrical characteristics for each voxel computing the eigenvalues of the Hessian matrix and evaluating a likelihood function that was purposely built to discriminate between local morphology of linear planar and spherical objects modeled as having 3D Gaussian sections Q. org pdf physics 0507153. We then classify all the candidate points to reduce the False Positives. Then I will talk about how to preprocess LUNA16 dataset for training architectures like UNet for segmentation and candidate classification. This will be done by the create_nodule_mask function. At first I will read the random dicom file of a CT Scan. I am posting the methods with a little summary of all of them 1. By applying this 3D filter to artificial images we have verified the efficiency in detecting the Gaussian like regions even in the cases were they are superimposed to non Gaussian ones. I have defined three functions load_itk Used to read a CT_Scan for the. The image processing methods used for candidate points generation above does not need any training data. Finally the structures are classified as either nodule or non nodule through shape and texture measurements together with support vector machine. 2 Extract the features of fully connected layers and use xgboost on it to improve classification accuracy. After filtering there are still lot of noise because of blood vessels. I will make the results available with dataset augmentation and about making a sample submission on the kernel as soon as it I complete it. In this kernel I will be talking about the methods that will help in better understanding of the problem statement and visualisation of the data. This is also referred to as False Positive Reduction step. csv contains the cancer ground truth for the stage 1 training set images and stage1_sample_submission. Lung Nodule Classification Based on Deep Convolutional Neural Networks 4 In this work they present a method for classifying lung nodules based on CNNs. The segmentation of lung structures is very challenging problem because homogeneity is not present in the lung region similar densities in the pulmonary structures different scanners and scanning protocols. One very famous architecture is UNET which can be used for Nodule Candidates Points Generation in our case. Such large images cant be fed directly into a Convolution Network architectures because of the limit on the computation power. The performance is evaluated as a fully automated computerized method for the detection of lung nodules in screening CT in the identification of lung cancers that may be missed during visual interpretation. br juliomb resources 2016 lnc ciarp. In the dataset we have 1187 nodule points which is a very less number for training a deep network. Now I will segment the whole CT Scan slice by slice and show some slices of the CT Scan. In the LUNA16 dataset each CT Scan is annotated with nodule points and the radius of the nodule which is used to generate the binary mask. After reading the image file we will update the intensity values of 2000 with 0 because they are the pixels that fall outside of the scanner bounds. Dataset Augmentation should be done while training because the nodules are symmetric regions and of varying sizes thus dataset augmentation is very likely to help in such cases. I recommend people to install anaconda on their desktop because of its advantages mentioned here 1. All the dicom files for a CT Scan are inside one folder having the CT Scan s name. Training of these networks is done using annotated datasets. Pulmonary Nodule Classification with Deep Convolutional Neural Networks on Computed Tomography Images 2 They design a deep convolutional neural networks method for nodule classification which has an advantage of autolearning representation and strong generalization ability. It takes a 2D slice as input and returns a 2D slice of the same size as output. In this tutorial we will first start with reading the dataset and visualising it. Select using the candiate points or the False Positives Generated because it will train the model to discriminate non nodule regions better. Dataset augmentation can implemented using keras given at this 1 link. We segment lung structures from each slice of the CT Scan image and try not to loose the possible region of interests attached to the lung wall. I will post the dataset augmentation functions and Spatial Dropout very soon. pdf 3 https arxiv. There are few things to be kept in mind while training We wont use the slices that has no nodule region in the mask for training. Classification of Lung Nodules The candidate regions generated still has a lot of noise. In the preprocessed pickle data files randomly select 20 files and put it in a seperate folder as test set. I will first talk about preprocessing of the LUNA16 dataset. The next stage is the separation of the structures resembling lung nodules from other structures such as vessels and bronchi. I have outputted the slice after all steps for better visualisation and understanding of the code and applied operations. The threshold of 604 was taken from this paper. com science article pii S0010482512001412 2 http www. The segmented lungs can be further used to find the lung nodule candidates and regions of interest which may help in better classification of the CT Scans. After getting the regions of interest 3D voxels can be cut around regions of interest and used for classification. The plot_3d function plots the 3D numpy array of CT Scans. cands are the list of nodule points with the radius given in the annotation. I am currently working on training a classifier on the LUNA16 dataset. ", "id": "arnavkj95/candidate-generation-and-luna16-preprocessing", "size": "16617", "language": "python", "html_url": "https://www.kaggle.com/code/arnavkj95/candidate-generation-and-luna16-preprocessing", "git_url": "https://www.kaggle.com/code/arnavkj95/candidate-generation-and-luna16-preprocessing", "script": "plot_3d keras.layers get_point Poly3DCollection dice_coef ball dice_coef_loss fmin mpl_toolkits.mplot3d.art3d feature scipy matplotlib.pyplot binary_dilation binary_erosion read_ct_scan draw_circles STATUS_OK binary_opening hp train_classifier Activation keras.models create_data keras MaxPooling3D skimage Dropout ndimage remove_small_objects roberts sklearn skimage.segmentation sklearn.externals dilation seq pandas closing plot_ct_scan segment_lung_from_ct_scan load_itk model_selection perimeter OptTrain sobel clear_border unet_model get_segmented_lungs numpy get_patch_from_list subprocess regionprops world_2_voxel voxel_2_world Trials np_utils skimage.morphology skimage.filters disk Convolution3D check_output skimage.measure measure Flatten erosion data xgboost binary_closing Dense hyperopt backend as K tpe change_to_int reconstruction ndimage as ndi Sequential backend create_nodule_mask joblib optimize classifier keras.utils label __init__ score ", "entities": "(('We', 'UNET model'), 'use') (('you', 'tutorial'), 'upvote') (('that', 'nodules'), 'propose') (('1 proposed method', 'parenchyma'), 'segmentation') (('False it', 'nodule non regions'), 'select') (('points', 'cluster'), 'cluster') (('We', 'False Positives'), 'classify') (('Thus we', 'further two largest connected component'), 'remove') (('Such large images', 'computation power'), 'feed') (('Finally structures', 'support vector together machine'), 'classify') (('I', 'LUNA16 first dataset'), 'talk') (('I', 'them'), 'post') (('get_segmented_lungs function', 'CT Scan'), 'segment') (('I', 'CT Scan'), 'read') (('nodules', 'shape'), 'filter') (('CT Scans', 'dataset'), 'save') (('anyone', 'classification'), 'be') (('Then I', 'segmentation'), 'talk') (('regions', 'classification'), 'after') (('it', 'experiments'), 'use') (('plot_3d function', 'CT Scans'), 'plot') (('we', 'them'), 'visualise') (('which', 'case'), 'be') (('we', 'it'), 'start') (('which', 'autolearning representation'), 'classification') (('we', 'them'), 'generate') (('which', 'lung wall'), 'be') (('3 paper', 'voxel data'), 'pre') (('cands', 'annotation'), 'be') (('Now I', 'CT Scan'), 'segment') (('very nodules', 'different radius'), 'be') (('augmentation', 'very such cases'), 'do') (('It', 'output'), 'take') (('next stage', 'such vessels'), 'be') (('com journals', 'https 2016 6215085 3 arxiv'), 'cmmm') (('I', 'size'), 'consider') (('I', 'papers'), 'explain') (('which', 'DICOM format'), 'consist') (('they', 'non Gaussian ones'), 'verify') (('Training', 'background samples'), 'perform') (('model', 'unet_model function'), 'write') (('further properties', 'segmented regions'), 'use') (('Now we', 'Lung CT Scanned 3D Image'), 'read') (('We', 'lung wall'), 'segment') (('threshold', 'paper'), 'take') (('then region', 'Image processing methods'), 'segment') (('com science article', 'pii 2 www'), 'http') (('This', 'Reduction also False Positive step'), 'refer') (('sample_images which', 'sample CT Scans'), 'html') (('csv', 'stage'), 'show') (('512 where z', 'scanner'), 'be') (('next thing', 'segmentation'), 'be') (('Next I', 'UNet model'), 'discuss') (('which', 'binary mask'), 'dataset') (('Dataset augmentation', '1 link'), 'implement') (('CNN architectures', 'interest'), 'use') (('I', 'them'), 'share') (('that', 'pulmonary parenchyma nodules blood vessels bronchi'), 'apply') (('we', 'then them'), 'classify') (('Training', 'annotated datasets'), 'do') (('Thus Dropout', 'Spatial overfitting'), 'use') (('few that', 'below processing'), 'be') (('size', 'each'), 'pdfdue') (('Deep Learning Nowadays methods', 'medical imaging'), 'achieve') (('We', 'output final probability'), 'take') (('Thus we', 'loss function'), 'weight') (('This', 'CNN simple 3D classification'), 'io') (('This', 'create_nodule_mask function'), 'do') (('which', 'top'), 'consist') (('Thus we', 'training'), 'cut') (('draw_circle function', 'binary mask'), 'use') (('it', 'intensity only information'), 'be') (('lungs', 'CT darker Scans'), 'be') (('image processing methods', 'training above data'), 'need') (('CNNs', 'competitive results'), 'show') (('they', 'logistic same task'), 'look') (('I', 'it'), 'make') (('regions', 'lungs'), 'be') (('candidate regions', 'noise'), 'classification') (('Thus we', 'Nodule'), 'need') (('I', 'advantages'), 'recommend') (('which', 'very less deep network'), 'have') (('that', 'more cancer'), 'have') (('very hard that', 'lung region'), 'be') (('region', '604 400 HU'), 'find') (('that', 'training'), 'be') (('bright region', 'lungs'), 'be') (('I', 'LUNA16 dataset'), 'work') (('I', 'the'), 'define') (('that', 'data'), 'be') (('we', 'nodule regions'), 'segment') (('that', 'visual interpretation'), 'evaluate') (('plot_ct_scan function', 'equally spaced slices'), 'take') (('sample_images folder', 'CT one Scan'), 'have') (('model', 'training dataset'), 'overfit') (('I', 'dataset augmentation functions'), 'post') (('4 paper', 'finding neural false positive reduction'), 'Detection') (('matplotlib', 'slices'), 'use') (('This', 'high recall'), 'reduce') (('more that', 'interest'), 'be') (('search space', 'nodules'), 'Region') (('that', 'spherical 3D Gaussian sections'), 'attempt') (('location', 'thus classifier'), 'have') (('they', 'CNNs'), 'Classification') (('dicom files', 'CT name'), 'be') (('features', 'dataset'), 'extract') (('overall it', 'consistently competing methods'), 'demonstrate') (('csv', 'training set stage 1 images'), 'contain') (('I', 'operations'), 'output') (('mhd files', 'image'), 'use') (('They', 'pulmonary lesion'), 'Classification') (('get_segmented_lungs 2 method', 'little paper'), 'scan') (('that', 'data'), 'talk') (('trainY containing labels', 'features'), 'be') (('they', 'original images'), 'construct') (('which', 'LUNA16 dataset'), 'use') (('So we', 'darker regions'), 'use') (('very challenging homogeneity', 'similar pulmonary structures'), 'be') (('We', 'intensity then low regions'), 'reduce') (('Deep convolutional neural networks', 'Lung Image Database Consortium LIDC 21 720 database'), 'train') (('which', 'CT Scans'), 'use') (('3 They', 'different datasets'), 'Learning') (('We', 'training'), 'sample') (('that', 'scanner outside bounds'), 'update') (('classification results', 'training'), 'use') (('as soon I', 'them'), 'implement') (('we', 'binary nodules'), 'save') (('I', 'useful resources'), 'provide') "}
{"name": "face expression recognition with deep learning ", "full_name": " h1 Introduction h1 Quick data visualization h1 Setup the data generators h1 Setup our Convolutional Neural Network CNN h1 Train the model h1 Analyze the results ", "stargazers_count": 0, "forks_count": 0, "description": "This filter slides over the image by one pixel at each step stride. Therefore those structures have a better understanding of patterns that we can observe in images. edu wiki images 6 6c Convolution_schematic. This will allow us to load directly the weights of our model without having to re train it if we want to use it. The function flow_from_directory specifies how the generator should import the images path image size colors etc. This means that every neuron of one layer is connected to every neurons of the next layer. We can use it to plot the evolution of the loss and accuracy on both the train and validation datasets The validation accuracy starts to stabilize at the end of the 50 epochs between 60 and 65 accuracy. An output layer that will give the final result for instance a class prediction. We also have to save the structure of our CNN layers etc. The orange sliding matrix is called a filter or kernel. However it predicts quite poorly feared faces because it confuses them with sad faces. Using them slightly increased the training duration of the model. com jrishabh96 Facial Expression RecognitionLet s focus on how our convolution layers work. Now it s time to try our model in a real situation We will use flask to serve our model in order to perform real time predictions with a webcam input. ai images wiki perceptron_node. It can also perform data augmentation while getting the images randomly rotating the image zooming etc. A Neural Network with a lot of hidden layers is called a Deep Neural Network. We chose softmax as our last activation function as it is commonly used for multi label classification. Quick data visualizationFirst let s see how our images look like Can you guess which images are related to which expressions This task is quite easy for a human but it may be a bit challenging for a predictive algorithm because the images have a low resolution the faces are not in the same position some images have text written on them some people hide part of their faces with their handsHowever all this diversity of images will contribute to make a more generalizable model. We can see that the training loss is becoming much smaller than the validation loss after the 20th epochs. Convolutional Neural Networks also have Convolutional layers that apply sliding functions to group of pixels that are next to each other. With more research and more resources this model could certainly be improved but the goal of this study was primarily to focus on obtaining a fairly good model compared to what has been done in this field. Indeed this type of Neural Network NN is good for extracting the features of images and is widely used for image analysis subjects like image classification. Here this is simply due to the presence of dropout which is only applied during the training phase and not during the validation phase. We converted this data into raw images and splitted them in multiple folders images nbsp nbsp nbsp nbsp train nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp angry nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp disgust nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp fear nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp happy nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp neutral nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp sad nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp surprise nbsp nbsp nbsp nbsp validation nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp angry nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp disgust nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp fear nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp happy nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp neutral nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp sad nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp surprise 80 of our images are contained inside the train folder and the last 20 are inside the validation folder. The training loss is slightly higher than the validation loss for the first epochs which can be surprising. We chose the categorical cross entropy as our loss function as it is quite relevant for classification tasks. The dataset contains approximately 36K images. We will explain this in more details after. Each image corresponds to a facial expression in one of seven categories 0 Angry 1 Disgust 2 Fear 3 Happy 4 Sad 5 Surprise 6 Neutral. This architecture was inspired by the following work on the subject https github. This means that our model starts to overfit our training dataset after too much iterations. The image expressions in our training dataset are pretty balanced except for the disgust category. Dropout reduces overfitting by randomly not updating the weights of some nodes. Our metric will be the accuracy which is also quite informative for classification tasks on balanced datasets. com c challenges in representation learning facial expression recognition challengeThe data consists of 48x48 pixel grayscale images of faces. The size of this layer depends on the type of output we want to produce e. Each of them contain the following operations A convolution operator extracts features from the input image using sliding matrices to preserve the spatial relations between the pixels. If it is the case the new best model weights are saved into a file. During each step we multiply the filter with the corresponding elements of the base matrix. Different functions can be applied max sum mean. Other functions like tanh or sigmoid could also be used but ReLU has been found to perform better in most situations. net profile Martin_Musiol publication 308414212 figure fig1 AS 409040078295040 1474534162122 A general model of a deep neural network It consists of an input layer some here two. Keras has a very useful class to automatically feed data from a directory ImageDataGenerator. png w 342 h 562 We apply the ReLU function to introduce non linearity in our CNN. Those methods were tested on this dataset but they did not significantly increase the validation accuracy although they reduced the overfitting effect. Setup our Convolutional Neural Network CNN We chose to use a Convolutional Neural Network in order to tackle this face recognition problem. There are different types of filters and each one will be able to retrieve different image features https ujwlkarn. The following image summarizes how it works http deeplearning. The original data consisted in arrays with a greyscale value for each pixel. com 2016 08 screen shot 2016 08 05 at 11 03 00 pm. Some hidden layers that will allow the NN to learn complex interactions within the data. This helps prevent the NN from relying on one node in the layer too much. That is why the validation loss does not decrease a lot after. jpeg We also use some common techniques for each layer Batch normalization improves the performance and stability of NNs by providing inputs with zero mean and unit variance. Indeed we are more used to see higher validation losses than training losses in machine learning. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. Setup the data generatorsDeep learning models are trained by being fed with batches of data. io assets cnn maxpool. All those outputs were saved into the history variable. Now let s define the architecture of our CNN We define our CNN with the following global architecture 4 convolutional layers 2 fully connected layersThe convolutional layers will extract relevant features from the images and the fully connected layers will focus on using these features to classify well our images. Quick reminder of what a NN is A Neural Network is a learning framework that consists in multiple layers of artificial neurons nodes. Like for the convolutional step we apply a sliding function on our data. png An input layer that will get the data. We chose the Adam optimizer as it is one of the most computationally effective. into a file Analyze the resultsWe got outputs at each step of the training phase. The size of the input layer depends on the size of the input data. how many classes do we want to predict Classic NNs are usually composed of several fully connected layers. Each node gets weighted input data passes it into an activation function and outputs the result of the function https skymind. This method is often used as a way to artificially get more data when the dataset has a small size. One solution consists in early stopping the training of the model. Pooling is used to reduce the dimensionality of each features while retaining the most important information. png A NN is composed of several layers of nodes https www. The max function usually performs better. We could also use some different dropout values and performing data augmentation. IntroductionThe data comes from the past Kaggle challenge Challenges in Representation Learning Facial Expression Recognition Challenge https www. gif The green matrix corresponds to the raw image values. display some images for every different expression size of the image 48 48 pixels input path for the images count number of train images for each expression number of images to feed into the NN for every batch number of possible label values Initialising the CNN 1 Convolution 2nd Convolution layer 3rd Convolution layer 4th Convolution layer Flattening Fully connected layer 1st layer Fully connected layer 2nd layer number of epochs to train the NN serialize model structure to JSON plot the evolution of Loss and Acuracy on the train and validation sets show the confusion matrix of our predictions compute predictions compute confusion matrix plot normalized confusion matrix. Now that our CNN is defined we can compile it with a few more parameters. Finally we can plot the confusion matrix in order to see how our model classified the images Our model is very good for predicting happy and surprised faces. Train the modelEverything is set up let s train our model now Our best model managed to obtain a validation accuracy of approximately 65 which is quite good given the fact that our target class has 7 possible values At each epoch Keras checks if our model performed better than during the previous epochs. ", "id": "jonathanoheix/face-expression-recognition-with-deep-learning", "size": "9878", "language": "python", "html_url": "https://www.kaggle.com/code/jonathanoheix/face-expression-recognition-with-deep-learning", "git_url": "https://www.kaggle.com/code/jonathanoheix/face-expression-recognition-with-deep-learning", "script": "keras.layers Activation keras.models confusion_matrix keras.preprocessing.image numpy MaxPooling2D seaborn img_to_array Dropout Adam ImageDataGenerator BatchNormalization load_img Dense GlobalAveragePooling2D keras.callbacks plot_confusion_matrix keras.optimizers matplotlib.pyplot ModelCheckpoint Sequential Conv2D Model Input sklearn.metrics Flatten ", "entities": "(('images', 'etc'), 'perform') (('expression recognition challengeThe facial data', 'faces'), 'challenge') (('original data', 'pixel'), 'consist') (('png input that', 'data'), 'layer') (('Indeed we', 'machine learning'), 'be') (('we', 'e.'), 'depend') (('we', 'usually several fully connected layers'), 'want') (('One solution', 'model'), 'consist') (('image expressions', 'disgust pretty category'), 'be') (('2016 08 screen', '2016 08 05 11 03 00 pm'), 'com') (('Keras', 'directory ImageDataGenerator'), 'have') (('we', 'data'), 'apply') (('outputs', 'history variable'), 'save') (('it', 'most computationally effective'), 'choose') (('filter', 'step stride'), 'slide') (('green matrix', 'image raw values'), 'gif') (('Batch normalization', 'unit zero mean variance'), 'use') (('This', 'layer'), 'help') (('layersThe 2 fully connected convolutional layers', 'well images'), 'let') (('Indeed type', 'image classification'), 'be') (('it', 'label commonly multi classification'), 'choose') (('we', 'base matrix'), 'multiply') (('we', 'it'), 'allow') (('size', 'input data'), 'depend') (('png NN', 'nodes https www'), 'compose') (('it', 'sad faces'), 'predict') (('data', 'Learning Facial Expression Recognition Challenge https www'), 'come') (('resultsWe', 'training phase'), 'get') (('automatically face', 'image'), 'register') (('We', 'CNN layers'), 'have') (('also ReLU', 'better most situations'), 'use') (('dataset', 'K approximately 36 images'), 'contain') (('that', 'other'), 'have') (('how it', 'http'), 'summarize') (('Pooling', 'most important information'), 'use') (('confusion matrix plot', 'confusion matrix'), 'display') (('neuron', 'next layer'), 'mean') (('training loss', '20th epochs'), 'see') (('We', 'data augmentation'), 'use') (('it', 'classification quite tasks'), 'choose') (('Neural Network', 'hidden layers'), 'call') (('Neural learning that', 'neurons artificial nodes'), 'be') (('validation accuracy', '60 accuracy'), 'use') (('Dropout', 'nodes'), 'reduce') (('flow_from_directory how generator', 'images path image size colors'), 'specify') (('input data', 'function https skymind'), 'weight') (('convolution operator', 'pixels'), 'contain') (('h 342 We', 'CNN'), 'png') (('architecture', 'https subject github'), 'inspire') (('one', 'https'), 'be') (('model new best weights', 'file'), 'save') (('we', 'images'), 'have') (('which', 'validation phase'), 'be') (('model', 'better previous epochs'), 'set') (('diversity', 'more generalizable model'), 'let') (('NN', 'data'), 'layer') (('which', 'balanced datasets'), 'be') (('We', 'webcam input'), 's') (('learning models', 'data'), 'generatorsdeep') (('Using', 'model'), 'increase') (('Convolutional Neural We', 'face recognition problem'), 'setup') (('when dataset', 'small size'), 'use') (('model', 'very happy faces'), 'plot') (('which', 'first epochs'), 'be') (('model', 'too much iterations'), 'mean') (('image', 'seven categories'), 'correspond') (('last 20', 'validation folder'), 'convert') (('we', 'a few more parameters'), 'compile') (('they', 'overfitting effect'), 'test') (('We', 'more details'), 'explain') (('what', 'field'), 'improve') (('It', 'input layer'), 'figure') (('output that', 'class prediction'), 'layer') "}
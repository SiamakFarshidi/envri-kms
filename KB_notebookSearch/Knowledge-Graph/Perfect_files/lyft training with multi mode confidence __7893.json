{"name": "lyft training with multi mode confidence ", "full_name": " h1 Lyft Training with multi mode confidence h1 Environment setup h2 Function h2 Model h2 Training with Ignite h2 Configs h1 Main script h2 Loading data h2 Prepare model optimizer h2 Write training code h1 Items to try h1 Next to go h1 Further reference h3 If this kernel helps you please upvote to keep me motivated Thanks ", "stargazers_count": 0, "forks_count": 0, "description": "pt trigger MinValueTrigger validation main nll trigger flags. snapshot_freq iteration lr scheduler scheduler torch. Official utility script philculliton kaggle l5kit https www. It works with pytorch tensor so it is differentiable and can be used for training Neural Network. This will resolve relative paths from the config using the L5KIT_DATA_FOLDER env variable we have just set. zarr for actual model training validation prediction. Prepare model optimizer Write training codepytorch ignite pytorch pfn extras are used here. Here exponential decay of learning rate is applied by calling scheduler. Consider much better scheme to predict multi trajectory The model just predicts multiple trajectory at the same time in this kernel but it is possible to collapse trivial solution where all trajectory converges to same. To go further these items may be nice to try Change the cnn model now simple resnet18 is used as baseline modeling Training the model using full dataset lyft full training set https www. FailOnNonNumber Stop training when nan is detected. com corochann lyft deep into the l5kit library Save your time submit without kernel inference https www. Even you quit training using Ctrl C without finishing all the epoch the intermediate trained model is saved and you can use it for inference. com corochann lyft prediction with multi mode confidence Try yourself how good score you can get using only single model without ensemble To understand the competition in more detail please refer my other kernels too. com pfnet pytorch pfn extras It provides several extensions useful for training. Show progress bar during training Show log on jupyter notebook Save predictor. lambda function with scheduler. Such many functionalities can be added easily using extensions You can obtrain training history results really easily by just accessing LogReport class which is useful for managing a lot of experiments during kaggle competitions. Lyft Comprehensive guide to start competition https www. Especially just training much longer time may improve the score. So you can follow how the learning rate changed through the training. htmlContinued from the previous kernel Lyft Comprehensive guide to start competition https www. snapshot_object predictor best_predictor. Here the model is saved in regular interval flags. Only use 100 dataset for fast check. Only use 1000 dataset for fast check. pfnet pytorch pfn extras https github. We re building a LocalDataManager object. Lyft Training with multi mode confidence http www. com mathurinache kaggle l5kit does not work with pytorch GPU. Let s start writing main script to train the model Loading dataHere we will only use the first dataset from the sample set. pytorch ignite https github. report see LyftMultiRegressor for reporting point method and save to log file. Update 2020 9 6 Published prediction kernel Lyft Prediction with multi mode confidence https www. AgentDataset train 22496709 valid 21624612 ActualDataset train 100 valid 100 Train setup Save log to file Run evaluation for valid dataset in each epoch. Note Why training abstraction library is used You may feel understanding training abstraction code below is a bit unintuitive compared to writing raw training loop. com jpbremer lyft config files as dataset See previous kernel Lyft Comprehensive guide to start competition https www. ReduceLROnPlateau optimizer mode min factor 0. py assert all data are valid convert to batch_size num_modes future_len num_coords add modes add modes and cords error batch_size num_modes future_len reduce coords and use availability when confidence is 0 log goes to inf but we re fine with it error batch_size num_modes reduce time use max aggregator on modes for numerical stability error batch_size num_modes error are negative at this point so max gives the minimum one reduce modes print error error pred bs x time x 2D coords bs x mode 1 x time x 2D coords create confidence bs x mode 1 Model utils TODO support other than resnet18 This is 512 for resnet18 and resnet34 And it is 2048 for the other resnets X Y coords for the future positions output shape Bx50x2 You can add more layers here. You can try these things to see how the score changes at first set debug False to train with actual training dataset change training hyperparameters training epoch change optimizer scheduler learning rate etc. 1 plotly models setup Dataset utils Function utils Original code from https github. How to avoid this Next to go Update 2020 9 6 Published prediction kernel Lyft Prediction with multi mode confidence https www. com corochann lyft prediction with multi mode confidence Try yourself how good score you can get using only single model without ensemble Environment setup Please add pestipeti lyft l5kit unofficial fix https www. It automatically collects reported value in each iteration and saves the mean of reported value for regular frequency for example every 1 epoch. snapshot_object Saves the object. step You can invoke any function in regular interval specified by trigger. com jpbremer lyft scene visualisations If this kernel helps you please upvote to keep me motivated Thanks https github. com pfnet pytorch pfn extras releases tag v0. com corochann lyft deep into the l5kit library In this kernel I will run pytorch CNN model training. Extensions Each role ProgressBar ProgressBarNotebook Shows training progress in formatted style. 2 pred bs x modes x time x 2D coords confidences bs x modes Training utils Utils NOQA Lyft configs eval_every_n_steps 1 Data configs Model configs Training configs set env variable for data Rasterizer Train dataset dataloader Only use 1000 dataset for fast check. The advantage of abstracting the code is that we can re use implemented handler class for other training other competition. com philculliton lyft full training set Write your own rasterizer to prepare input image as motivation explained in previous kernel. Evaluator Evaluate on validation dataset. pt every epoch Check Save best validation predictor. You don t need to write code for saving models logging training loss metric show progressbar etc. Engine defines the 1 iteration of training update. com corochann bengali seresnext training with pytorch So what is happening in above training abstraction Let s understand what each extension did. Here model outputs both multi mode trajectory prediction confidence of each trajectory. PrintReport PrintReportNotebook Prints the value which LogReport collected in formatted style. 7 patience 5 min_lr 1e 10 Show lr column in log HACKING to fix ProgressBarNotebook bug Let s see training results directory. pt every epoch manager. com corochann lyft pytorch implementation of evaluation metric Further reference Paper of this Lyft Level 5 prediction dataset One Thousand and One Hours Self driving Motion Prediction Dataset https arxiv. Training loss with competition evaluation metric Use Training abstraction library pytorch ignite and pytorch pfn extras. Please add lyft config files https www. The history log and model s weight are saved by extensions LogReport and E. step every iteration. Items to tryThis kernel shows demonstration run of the training debug True. zarr data is used for visualization please use train. 14480 jpbremer lyft scene visualisations https www. com lyft l5kit blob 20ab033c01610d711c3d36e1963ecec86e8b85b6 l5kit l5kit evaluation metrics. com corochann lyft comprehensive guide to start competition Lyft Deep into the l5kit library https www. snapshot_object respectively easily which is a benefit of using training abstration. com c lyft motion prediction autonomous vehicles overview evaluation page we can predict 3 modes of motion trajectory. com pytorch ignite It provides abstraction for writing training loop. jpg The image from L5Kit official document http www. Modelpytorch model definition. com pytorch ignite for training abstraction. com corochann lyft comprehensive guide to start competition for details. These are done by provided util classes in pytorch pfn extras library You may refer my other kernel in previous competition too Bengali SEResNeXt training with pytorch https www. Especially followings are new items to try Predict multi mode with confidence As written in evaluation metric https www. Official Document IGNITE YOUR NETWORKS https pytorch. com corochann save your time submit without kernel inference Lyft pytorch implementation of evaluation metric https www. observe_lr LogReport will check optimizer s learning rate using this extension. LogReport Logging metrics reported by ppe. Training with IgniteI use pytorch ignite https github. FunctionTo define loss function to calculate competition evaluation metric in batch. com pestipeti lyft l5kit unofficial fix as utility script. Useful for logging printing evaluating saving the model scheduling the learning rate during training. org ignite Configs Main scriptNow finished defining all the util codes. ", "id": "corochann/lyft-training-with-multi-mode-confidence", "size": "7893", "language": "python", "html_url": "https://www.kaggle.com/code/corochann/lyft-training-with-multi-mode-confidence", "git_url": "https://www.kaggle.com/code/corochann/lyft-training-with-multi-mode-confidence", "script": "update_fn tools lightgbm DataLoader pathlib plotly.express PERCEPTION_LABELS preprocessing Path DotDict(dict) plotly.io scipy l5kit.data transform_points matplotlib.pyplot load_yaml Dataset optim torch __getitem__ collections MinValueTrigger LyftMultiModel(nn.Module) torchvision.models LyftMultiRegressor(nn.Module) ChunkedDataset TARGET_POINTS_COLOR animation catboost eval_func pytorch_pfn_extras.training.triggers Subset sklearn pytorch_neg_multi_log_likelihood_single plotly.graph_objs pandas pytorch_pfn_extras.training.extensions matplotlib __len__ display l5kit.rasterization subplots Callable prettytable math pytorch_neg_multi_log_likelihood_batch IPython.core.display IPython.display save_yaml numpy plotly l5kit.visualization resnet18 pytorch_pfn_extras typing LocalDataManager plotly.offline tqdm.notebook PrettyTable plotly.figure_factory torch.utils.data HTML ignite.engine IgniteExtensionsManager TransformDataset(Dataset) torch.utils.data.dataset l5kit.dataset Counter load_config_data pytorch_pfn_extras.training build_rasterizer xgboost l5kit.geometry seaborn draw_trajectory nn tqdm create_trainer transform Dict KFold l5kit.configs ceil forward sklearn.model_selection AgentDataset Tensor rc EgoDataset __init__ Engine ", "entities": "(('ProgressBar ProgressBarNotebook Shows', 'formatted style'), 'extension') (('it', 'where trajectory same'), 'consider') (('Here exponential decay', 'scheduler'), 'apply') (('We', 'LocalDataManager object'), 'build') (('Train setup 100 valid 100 Save', 'epoch'), 'train') (('Update', 'mode confidence https multi www'), 'kernel') (('step You', 'trigger'), 'invoke') (('log', 'extensions LogReport'), 'save') (('com corochann', 'evaluation https metric www'), 'save') (('you', 'inference'), 'quit') (('Items', 'True'), 'show') (('Lyft Comprehensive', 'competition https www'), 'guide') (('com pfnet pytorch pfn It', 'useful training'), 'extras') (('You', 'training loss show progressbar metric etc'), 'need') (('now simple resnet18', 'training set https full www'), 'be') (('env variable', 'fast check'), 'pre') (('LogReport Logging metrics', 'ppe'), 'report') (('You', 'pytorch https www'), 'do') (('FunctionTo', 'competition evaluation batch'), 'define') (('motivation', 'previous kernel'), 'write') (('Here model', 'regular interval flags'), 'save') (('you', 'other kernels'), 'try') (('Lyft Training', 'www'), 'http') (('we', 'sample set'), 'let') (('com corochann lyft pytorch implementation', 'Motion Prediction Dataset https One arxiv'), 'dataset') (('org ignite Configs Main scriptNow', 'util codes'), 'finish') (('when nan', 'training'), 'stop') (('multi', 'trajectory'), 'mode') (('extension', 'what'), 'training') (('Especially followings', 'evaluation https metric www'), 'be') (('s', 'training results directory'), 'patience') (('observe_lr LogReport', 'extension'), 'check') (('Bx50x2 You', 'more layers'), 'be') (('respectively easily which', 'training abstration'), 'snapshot_object') (('we', 'L5KIT_DATA_FOLDER env variable'), 'resolve') (('Especially just training', 'score'), 'improve') (('we', 'handler implemented other training other competition'), 'be') (('which', 'kaggle competitions'), 'add') (('com pytorch It', 'training loop'), 'ignite') (('com pfnet pytorch pfn extras', 'tag v0'), 'release') (('LogReport', 'formatted style'), 'Prints') (('learning how rate', 'training'), 'follow') (('report', 'log file'), 'see') (('you', 'me'), 'visualisation') (('Engine', 'training update'), 'define') (('you', 'Environment ensemble setup'), 'try') (('understanding', 'training below bit raw loop'), 'note') (('zarr data', 'train'), 'use') (('com lyft motion vehicles overview evaluation autonomous we', 'motion'), 'c') (('I', 'pytorch CNN model training'), 'lyft') (('image', 'www'), 'jpg') (('it', 'Neural Network'), 'work') (('Show', 'jupyter notebook Save predictor'), 'log') (('dataset', 'Lyft competition https Comprehensive www'), 'com') (('It', '1 epoch'), 'collect') (('changes', 'epoch change optimizer scheduler learning rate etc'), 'try') (('com mathurinache kaggle l5kit', 'pytorch'), 'work') (('epoch Check', 'validation best predictor'), 'pt') "}
{"name": "research yeast uvb radiation induced damage ", "full_name": " h2 Application of Artificial Intelligence Methods in the detection of changes in the Nuclear Chromatin Structure caused by UVB radiation h1 1 Research description h2 1 1 Assignment h2 1 2 Methods and tools h2 1 3 Data collection and processing h1 2 Development of machine learning models h2 2 1 Setting up the development environment h2 2 2 Adjustment of reproduction of the obtained results h3 2 2 1 The matplotlib library set up to display graphics h2 2 3 Data preparation h3 2 3 1 Loading of the data h3 2 3 2 Data verification h4 2 3 2 1 Pairplot h4 2 3 2 2 Independent T test h3 2 3 3 Elimination of NA values and outliers h4 2 3 3 1 Elimination of NA values h4 2 3 3 2 Test and elimination of outliers h3 2 3 4 Data normalization h2 2 4 Creating a training data and test data sets h2 2 5 Defining compiling and training the classification models h3 2 5 1 Multilayer perceptron h4 2 5 1 1 Model creating h4 2 5 1 2 Prediction on test data and model evaluation h3 2 5 2 Binary logistic regression h4 2 5 2 1 Model training h4 2 5 2 2 Model evaluation h3 2 5 3 Decision trees h4 2 5 3 1 Installation of the required libraries h4 2 5 3 2 Customize training data and test data h4 2 5 3 3 Decision tree using CHAID algorithm h4 2 5 3 4 Classification trees and regression trees h3 2 5 4 Random forest h4 2 5 4 1 Model creating h4 2 5 4 2 Model training h4 2 5 4 3 Model evaluation h4 2 5 4 4 Determining the most important predictors h4 2 5 4 5 Adjustment of model hyperparameters h4 2 5 4 6 Visual display of the best RF model h1 3 Research results h1 4 Conclusion h1 5 References h1 6 Software libraries h2 6 1 GitHub h2 6 2 Zenodo ", "stargazers_count": 0, "forks_count": 0, "description": "Methods and toolsIn the case of cell classification problems the best results could come from the following models Logistic regression Decision trees Bayesian networks Random Forests Linear Support Vector Machine Naive Bayes classifier as well as deep learning algorithms such as Artificial Neural Networks Recurrent Neural Networks and Convolutional Neural Networks. Installation of the required libraries 2. com max 358 1 1JDsJTBtb HdV53Bo3AUaw. Multilayer perceptronArtificial neural networks based on the Multilayer perceptron algorithm give much better results compared to the other listed models with at the same time a relatively simple implementation. Data normalizationIt is important to note that the normalization of data has a massive influence on the accuracy of predictions of individual models such as artificial neural networks as opposed to others e. Model storing 2. Data in Brief 36 107067. 0 Original work published 2015 3. Its use has given good results in detecting radiation with High LET high linear energy transfer Papakonstantinou et al. index keras One hot encode outputs keras First Hidden Layer Output Layer Compile the model pip install keras 2. Application of Gray Level co Occurrence Matrix Algorithm for Detection of Discrete Structural Changes in Cell Nuclei After Exposure to Iron Oxide Nanoparticles and 6 Hydroxydopamine. 2021 detection of cell damage under the action of toxin oxidopamine and iron oxide nanoparticles based on five statistical measures obtained by the GLCM method Nikolovski et al. 2021 which contributed significantly to cancer research. argmax rf_clf_best_predict axis 1 Pull out one tree from the forest Export the image to a dot file Use dot file to create a graph Plot the graph Evaluation table Plot the results. 0 Decision Tree Random Forest 1. describe include all 0. scipy scipy SciPy 1. Moreover researchers in the field of data processing see tremendous potential for developing advanced software systems for simpler and faster diagnostics of changes. 3390 radiation101000511. Corban Swain Meyer K. In some of the relatively recent works in the field of medicine this method has given good results in detection of Covid 19 virus infection based on the classification of images obtained by computed tomography CT which based on ten attributes obtained by the GLCM method achieves a prediction accuracy of 94 Ameer Mohammed 2021 processing of fingerprint data to determine the similarity in texture between parents and children based on data collected from people from the island of Lombok in Indonesia Bakti et al. Otherwise these missing values would need to be filled in to match the others of the observed attribute or to be completely removed from the set. png The pioneers in the development of this decision algorithm in their book allege medicine as one of the potential areas of application focusing on solving the problems of diagnosis and prognosis of heart attacks as well as cancer Breiman et al. The value removal method will be applied below. Gfyoung Sinhrks Hawkins S. read_excel data_file sheet_name 1 names all_data_columns predictors list set list train_df. 50 over training data whilst the different test data provided accuracy in the range of 45 to 55. 2 Computer software. Defining compiling and training the classification modelsIn the following the implementation and obtained accuracy results of the following classification models will be displayed 1. Materials Today Proceedings S2214785321031448. com serengil chefboost Original work published 2019 6. Model creatingThe neural network model created is the Multilayer perceptron with four input neurons three hidden layer neurons and two output layer neurons. The Treatment column indicates which cell was treated 1 and which was not 0. Based on a statistical significance t test the attribute that best describes the state of a cell is CellNucleusAssesment. Creating a training data and test data setsFollowing the recommendations of good practice the initial data set was divided into the part used for training 80 while the rest was left for testing the model results 20. columns set target_column train_df. ConclusionThe accelerated development of artificial intelligence and machine learning applications primarily in medicine indicates a significant shift in research and medical diagnostics in the future. decision trees where it does not play a significant role. Array programming with NumPy. Nature 585 7825 357 362. The number of neurons in the input and output layer depends on the type of data or the desired output so that here it is constant. 0 pip show keras keras from keras import callbacks build the model accuracy validation_split 0. Data preparation 2. We can normalize the data in several ways and below is an example of using the min max method. 2 pandas data_file kaggle input yeast uvb radiation induced damage ScUVB rc. Test and elimination of outliersOutliers are attribute values that deviate significantly from others. Terji Petersen Tratner J. Multilayer perceptron neural network 2. As previously stated we will remove these values from this work. By defining the deviation threshold all higher values were eliminated. mean roc_auc Instantiate the model using the default parameters Fit the model with data Prediction Train DataFrame Regression Classification Test DataFrame Regression Classification del test_instance Treatment ls outputs rules ls outputs rules Import Random Forest Model Create a Gaussian Classifier Train the model using the training sets y_pred clf. walk kaggle input for filename in filenames print os. Some of the models presented in the research are Multilayer perceptron Binary logistic regression decision tree using the Chi square automatic interaction detection algorithm CHAID Classification and Regression Trees and the Random forest algorithm. Loading of the dataModel training data is stored as an Excel spreadsheet. This could be considered one of the reasons that influenced the accuracy of classification of Random forest models to be the best bearing in mind that in addition to fractal lacunarity the value of this attribute is not based on the personal opinion of researchers but is the result of statistical analysis. The decision tree based on the CHAID algorithm gave about 6 worse results than the previous two models. The data arranged in this way can be further normalized and used for model training. Covid 19 detection using CT scan based on gray level Co Occurrence matrix. com numpy numpy releases tag v1. nan 0 regex True for i in range 0 len outliers 0 print z outliers 0 i outliers 1 i sklearn index train_df predictors. Visual display of the best RF model 3. If some of the data are missing it is necessary to eliminate the missing values that can significantly affect the model results and put them below satisfactory level. The obtained results seem encouraging and lead us to think about the possibilities of using this research approach in a series of similar experiments. Most of these changes are not easy to detect using conventional methods while the machine learning models such as neural networks offering the possibility to identify even these the so called isolated damages Davidovic et al. Alexbrc Peterson P. Compared with this the Random forest algorithm with adjusted hyperparameters proved to be the best algorithm for model development over a given data type with 0. Prediction on test data and model evaluationThe previous graph provides a comparative view of the existence of real damage binary categorical variable blue and the probability that the classifier will decide whether the damage exists green or not red individually for the first ten samples from the test data set. Model evaluation 2. AssignmentThe paper aims to develop models capable of detecting UVB radiation induced changes in cells by using modern methods and techniques of image processing along with the application of machine learning. 1038 s41586 020 2649 28. pyz_threshold 3 In the data exist 12 outliers that need special attention. For the script to run on another platform it is necessary to edit these settings. com code snippets python confusion matrix itertools plt. Research resultsThe paper tests the classification possibilities for five algorithms that may give the best results for a given data type. Jae Joon Lee Sepp\u00e4nen J. Data extraction of the gray level Co occurrence matrix GLCM Feature on the fingerprints of parents and children in Lombok Island Indonesia. The first sheet contains all the samples 2000. The setup of the development environment is performed in line with the requirements of development using this tool. Research descriptionThe paper covers the development of machine learning classification models that could distinguish healthy cells from the cells damaged through UVB radiation. Data verificationAfter loading the data it is necessary to define the predictor and the target column and check the predictor dependence to determine the attributes with the best impact on the classification result. Statistical and structural approaches to texture. Proceedings of the IEEE 67 5 786 804. Radiation 1 1 45 64. 1 we can state that each attribute makes a significant contribution in obtaining better classification results. xlsx treated_cells pd. The data set contains results for a total of 2000 cells of which 1000 cells were treated with UVB rays for 60 seconds inducing damage Treatment 1 while the other 1000 cells were not treated Treatment 0. predict X_test Model Accuracy print Accuracy metrics. net openpyxl openpyxl tags 3. However the decision tree models recognized CellMembraneAssesment as the most significant parameter while for instance Random forest as the most indispensable parameter singled out GLCMContrast. yticks Accuracy Class weighted accuracy Precision Recall F1 Score AUC Report Print print Mean Auc np. They occur most often when entering data incorrectly in the collection phase. The ability to notice cell damage by UVB radiation is one of the potentially best possibilities for practicing this method in medicine especially in radiology. Independent T testBased on the test results the CellNucleusAssesment attribute has the best influence on determining the cell condition Treatment attribute. Classification trees and regression treesDecision trees based on the CART algorithm use the Gini index as a metric for decision making. Such values can significantly affect the accuracy of the machine learning model leading it to draw wrong conclusions so it is necessary to make corrections to the data set. Both can be used to solve classification problems and to solve regression problems. To find the outliers the mathematical function Z score will be used which has the role of finding the values of each attribute based on their relationship with standard deviation and mean value or rather to display all values above the mean value. Chemico Biological Interactions 345 109533. Customize training data and test data 2. This decision making model is well accepted in the field of medicine. The implementation and success results of the classification of each of these models are listed below. The application of machine learning methods for the detection of yeast cell damage under the action of UVB radiation based on the results obtained using the GLCM method is a less researched area. We use it to solve the classification problem when there are two possible options between which it is necessary to make the right choice. If the dependent variable is dichotomous binary although the independent ones can be of any sort this type is called Binary logistic regression. An Exploratory Technique for Investigating Large Quantities of Categorical Data. Development of machine learning modelsThe study aims to probe the distinctive possibilities of classification models based on artificial intelligence and machine learning methods in detecting cell damage. Ever since he had shown its efficiency the decision tree using CHAID algorithm has remained one of the best choices for application in medicine to this day. Several variations of this model implement different algorithms based on varied metrics and features they all have in common are ease of implementation clarity and transparency in decision making. 5 Original work published 2010 2. accuracy_score y_test y_pred_rf Creating a bar plot Add labels to your graph Number of trees in random forest Number of features at every split Max depth Create random grid Random search of parameters Fit the model Show results rf_clf_best_predict_single np. Since there is not one of them with less significance e. Scikit learn Machine Learning in Python. The CART algorithm provided the worst model which achieved a classification accuracy of 90. 1017 S143192761901459410. Some of the algorithms that can be specifically applied to develop variations of the above models and which we can expect to achieve the best results for the observed data type are Multi layer Perceptron Binomial or Binary Logistic Regression Decision Tree Using Chi_Square Automatic Interaction Detection CHAID Classification and Regression Trees CART QUEST Quick Unbiased Efficient Statistical Tree C5. 3 matplotlib Customize matplotlib 1. Data collection and processingSeveral different methods could be used to quantify the structural changes in chromatin associated with aging the most effective is the textural method based on the Gray level co occurrence matrix GLCM. Haralick the pioneer in the development of this method in his original work Haralick 1979 lists a total of 14 statistical measures for better determination of the image texture. Saccharomyces cerevisiae were used as input data for the development of the model in the research when the changes were analyzed using the GLCM method. If such values exist this type of normalization is not a suitable form to use so we should look for an alternative. They rely on guidelines from the literature in which this type of network one hidden layer network is used to solve similar problems. matplotlib matplotlib REL v3. Decision trees Decision trees belong to supervised models of machine learning. Model training 2. Applied Statistics 29 2 119. Given that it has previously proved to be a poor choice for classifying this type of data giving approximate results we can say that this type of algorithm is still not applicable to solve the considered problem. Using Machine Learning Techniques for Asserting Cellular Damage Induced by High LET Particle Radiation. Random forest Random forest is an algorithm that combines the capabilities of multiple decision trees. any axis 1 Show rows with Na value and empty string in all cells Remove Na values and empty strings Option 1 Replace Na values with zero train_df train_df. Adjustment of reproduction of the obtained resultsTo get the same results every time you run the software you need to set the initial values for random selection functions. 1 Computer software. Classification and regression trees 1. com keras team keras releases tag v2. 1 system numpy tensorflow Setting the seed for numpy generated random numbers Setting the seed for python random numbers Setting the graph level random seed. The GLCM method has found application in all areas where image processing is the basis for further assay or research. Before normalization it should be tested whether the data has notably less or higher values than the average for the observed attribute so called outliers. 1 Show Na values print data data. Multilayer perceptron Binary logistic regression and Random forest gave roughly similar results. My unpublished research has shown that a model based on the Binary linear regression algorithm gives 1 to 5 better results over test data than the described model. Application of Artificial Intelligence Methods in the detection of changes in the Nuclear Chromatin Structure caused by UVB radiation 1. pandas dev pandas Pandas 1. Decision tree using CHAID algorithmIn his paper with several study examples and analyzes the author of the algorithm has shown its effectiveness comparing its capabilities with AID and THAID algorithms created up to 17 years earlier Kass 1980. Determining the most important predictorsThe essential attribute of the model in the graphs is the contrast parameter obtained by the GLCM method. The idea of developing classification models for this purpose arose from previous research on the progress of the machine learning application in detecting oxidative stress and DNA damage Davidovic et al. Adjustment of model hyperparametersWhen using the cross validation method it is necessary to determine the optimal parameters for creating a random forest model n_estimators max_features max_depth while the model already made over the observed data set is used as a basis for testing these values. The following is an example of code whose function is to remove such values if it finds them in the data. Application of artificial intelligence for detection of chemico biological interactions associated with oxidative stress and DNA damage. 9 Original work published 2010 import os for dirname _ filenames in os. The dependent variable in this type of regression is Bernoulli s random variable so there are two categories that we denote 0 for failure and 1 for success. From the previous graph we can see that the data has been removed from outliers. decision tree using the Chi square automatic interaction detection CHAID algorithm 4. Working with outliers involves two possible strategies removing or modifying values. TensorFlow Developers. From the previous graphs we see outliers in the values of the GLCMContrast and FractalLacunarity attributes. The ways of its action on cells are a very researched area observed from a medical point of view. Setting up the development environmentThe Kaggle IDE was used for development. Elimination of NA valuesThe previous table does not show missing values in the data set so it is complete. 5 higher classification accuracy than Multilayer perceptron models. 25 sklearn Get the confusion matrix print y_test_cat print y_test_single print predictions_rounded_single https howtolearnmachinelearning. Binary logistic regression Logistic regression describes the relationship between predictors that can be of continuous binary or categorical type. Binary logistic regression 3. decision tree using Classification and Regression Trees CART algorithm 5. Others contribute less to the accuracy of the classifier. Python Starlark Other. Software libraries 6. Jbrockmendel Bossche J. Microscopy and Microanalysis 25 4 982 988. Generally 5 to 10 measures are sufficient to obtain adequate results if we do not consider other values for the attributes. Elimination of NA values and outliersPerforming this step is not required if all the data are entered correctly into the database we are working with as that is the case here. The results of the last experiment on saccharomycetes lat. In contrast we do not have them in the CellNucleusAssesment and CellMembraneAssesment attributes because they are values from a pre limited range from 1 to 5. The matplotlib library set up to display graphics 2. Other reasons for choosing this type of network lie in the results of previous research. We can freely say that this model of decision making is to a large extent used in this area today. Since the test and elimination of the outliers were done in the previous step the data were normalized using the min max method. Model creating 2. In practice it is not necessary to determine all these measures to achieve the desired results especially when collecting data for the training of the machine learning models. Keras Deep Learning for humans v2. Ionizing radiation has a significant effect on DNA damage in particular. From the previous results of cross validation we can conclude that the recommended parameters for the development of a random forest model over the defined data are the following n_estimators 500 max_features sqrt max_depth 460 2. 3 Computer software. Changing the number of neurons in the hidden layer by adding new layers increases the complexity of the network while improving the accuracy of classification is minimal. GLCM contrast and fractal lacunarity were determined and scores on the integrity of the cell nucleus and cell membrane were assigned based on the researcher s subjective opinion. Python C Cython C JavaScript Shell Other. Models of machine learning based on the Random forest algorithm gave a surprisingly good result compared to other methods so we can consider them particularly important for solving both the considered and related problems. join dirname filename list folder data 1. ", "id": "lazardavidovic/research-yeast-uvb-radiation-induced-damage", "size": "22979", "language": "python", "html_url": "https://www.kaggle.com/code/lazardavidovic/research-yeast-uvb-radiation-induced-damage", "git_url": "https://www.kaggle.com/code/lazardavidovic/research-yeast-uvb-radiation-induced-damage", "script": "classification_report train_test_split IPython.display keras callbacks tensorflow.keras.layers to_categorical confusion_matrix stats accuracy_score tensorflow.keras.models numpy cross_val_score seaborn Image recall_score plot_roc_curve Dense view_pydot Chefboost as chef sklearn.tree plot_confusion_matrix scipy sklearn.linear_model sklearn tensorflow random tensorflow.keras.utils matplotlib.pyplot MinMaxScaler Sequential precision_score metrics sklearn.model_selection pandas roc_curve RandomForestClassifier LogisticRegression export_graphviz get_metrics tensorflow.keras scipy.stats chefboost RandomizedSearchCV display Chefboost sklearn.metrics sklearn.ensemble StandardScaler sklearn.preprocessing ", "entities": "(('Decision tree', 'AID'), 'show') (('Most', 'even so called isolated damages'), 'be') (('we', 'GLCMContrast attributes'), 'see') (('Defining', 'classification following models'), 'display') (('application', 'GLCM method'), 'be') (('test different data', '45 to 55'), 'provide') (('Decision trees Decision trees', 'machine learning'), 'belong') (('Otherwise missing values', 'completely set'), 'need') (('type', 'still considered problem'), 'give') (('which', 'cancer significantly research'), '2021') (('type', 'sort'), 'call') (('it', 'data set'), 'affect') (('keras keras', 'model accuracy validation_split'), '0') (('Classification treesDecision trees trees', 'decision making'), 'use') (('decision tree However models', 'GLCMContrast'), 'recognize') (('decision tree', 'interaction detection Chi square automatic CHAID'), 'algorithm') (('data_file kaggle input yeast uvb 2 pandas radiation', 'damage'), 'induce') (('so it', 'data'), 'show') (('9 Original work', '_ filenames os'), 'publish') (('Model creatingThe neural network model', 'Multilayer input four neurons'), 'be') (('rest', 'model results'), 'create') (('decision tree', 'day'), 'remain') (('CellNucleusAssesment attribute', 'cell condition Treatment attribute'), 'testbase') (('it', 'data'), 'be') (('data', 'min max method'), 'do') (('desired here it', 'data'), 'depend') (('you', 'selection random functions'), 'get') (('predictors', 'set list'), 'list') (('best results', 'Logistic regression Decision Random Forests Linear Support Vector Machine Naive Bayes Artificial Neural Networks Recurrent Neural Bayesian as well deep learning such Networks'), 'method') (('Loading', 'Excel spreadsheet'), 'store') (('1 other 1000 cells', 'Treatment'), 'contain') (('that', 'UVB radiation'), 'cover') (('X_test Model Accuracy', 'print Accuracy metrics'), 'predict') (('Others', 'classifier'), 'contribute') (('they', '5'), 'have') (('Changing', 'classification'), 'be') (('Haralick', 'image texture'), 'list') (('we', 'attributes'), 'be') (('it', 'classification result'), 'verificationafter') (('numpy', 'graph level random seed'), 'tensorflow') (('freely model', 'area'), 'say') (('model', 'described model'), 'show') (('recommended parameters', 'n_estimators max_features following 500 max_depth'), 'conclude') (('ways', 'view'), 'be') (('fractal scores', 'cell subjective opinion'), 'determine') (('attribute', 'classification better results'), 'state') (('implementation results', 'models'), 'list') (('pip', 'keras'), 'output') (('1 i', 'index train_df predictors'), 'regex') (('Moreover researchers', 'changes'), 'see') (('it', 'machine learning models'), 'be') (('which', 'Indonesia Bakti et al'), 'give') (('25 sklearn', 'confusion matrix print y_test_cat y_test_single predictions_rounded_single https print print howtolearnmachinelearning'), 'get') (('UVB capable radiation', 'machine learning'), 'aim') (('Some', 'Multilayer Binary logistic regression decision interaction detection algorithm CHAID perceptron Chi square automatic Classification'), 'be') (('them', 'particularly considered problems'), 'give') (('decision where it', 'significant role'), 'tree') (('They', 'collection incorrectly phase'), 'occur') (('accelerated', 'future'), 'indicate') (('which', '90'), 'provide') (('Multilayer logistic perceptron Binary regression', 'Random roughly similar results'), 'give') (('Working', 'values'), 'involve') (('normalization', 'others e.'), 'be') (('that', 'decision multiple trees'), 'be') (('it', 'settings'), 'run') (('model', 'values'), 'be') (('image where processing', 'further assay'), 'find') (('argmax rf_clf_best_predict', 'graph Evaluation results'), 'axis') (('Both', 'regression problems'), 'use') (('damage', 'test data set'), 'prediction') (('Data collection', 'level co occurrence matrix textural Gray GLCM'), 'use') (('Ionizing radiation', 'DNA damage'), 'have') (('making decision model', 'medicine'), 'accept') (('common ease', 'decision making'), 'implement') (('data', 'outliers'), 'see') (('when changes', 'GLCM method'), 'use') (('use', 'energy High LET high linear transfer'), 'give') (('previously we', 'work'), 'remove') (('setup', 'tool'), 'perform') (('Other reasons', 'previous research'), 'lie') (('Multilayer perceptronArtificial neural networks', 'same time'), 'give') (('decision tree', 'previous two models'), 'give') (('that', 'satisfactory level'), 'be') (('that', 'continuous binary'), 'describe') (('ability', 'especially radiology'), 'be') (('it', 'right choice'), 'use') (('Show axis 1 rows', 'Replace Na empty strings Option 1 zero'), 'remove') (('decision tree', 'Trees Classification CART'), 'algorithm') (('we', 'Multi layer Perceptron Binary Logistic Regression Decision Chi_Square Automatic Interaction Detection'), 'be') (('layer one hidden network', 'similar problems'), 'rely') (('that', 'data given type'), 'test') (('environmentThe Kaggle IDE', 'development'), 'set') (('attribute', 'cell'), 'be') (('suitable so we', 'alternative'), 'be') (('we', 'success'), 'be') (('Development', 'cell damage'), 'aim') (('idea', 'oxidative stress'), 'arise') (('which', 'mean value'), 'find') (('attribute that', 'significantly others'), 'be') (('obtained results', 'similar experiments'), 'seem') (('We', 'min max method'), 'normalize') (('data', 'observed attribute'), 'test') (('first sheet', 'samples'), 'contain') (('value', 'statistical analysis'), 'consider') (('that', 'correctly database'), 'require') (('higher values', 'deviation'), 'eliminate') (('that', 'special attention'), 'pyz_threshold') (('Import Random Forest Model', 'y_pred clf'), 'mean') (('data', 'model further training'), 'normalize') "}
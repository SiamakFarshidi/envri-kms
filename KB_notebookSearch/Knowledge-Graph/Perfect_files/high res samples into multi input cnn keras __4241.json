{"name": "high res samples into multi input cnn keras ", "full_name": " h1 High res samples into multi input CNN h1 Image preparation h1 Train our future input branch h1 Build the core model h1 Make predictions using our newly trained model h3 If you found this notebook helpful please give it an upvote It is always greatly appreciated ", "stargazers_count": 0, "forks_count": 0, "description": "We have an input_branch function that will generate the 3 input branches with our pretrained weights before merging them together. Image preparationJust to double check. We can check that the function works by displaying the random samples that will be used as inputs. Be careful if you decide to add data augmentation into your custom generator as your performance on the validation set will be biased. Build the core modelBelow we have our custom generator which will use the function to generate original scale 256x256 images from random samples. V13 It appeared that the model training was sometimes unstable as seen in V12 s log. 32 V11 Take the mean from the predicted isup score over 5 runs instead of the max over 3 runs score 0. Generate paths to the input files and a list with corresponding groundtruthWe re quickly shuffling the data and split the dataframe in two in order to keep a validation set. Time to use our custom generator which loads 3 samples into the branches. 34 V12 Now train the input branches first before training a model with 3 input branches with the input branches mostly frozen. In future version we will try to optimise the sampling strategy. We use 100 images from the training set. csv and apply predictions before saving the submission file. V14 Reduce the number of epochs in order to run in less than 6 hours and submit the notebook. Now time to build the model. High res samples into multi input CNNThis notebook will go through the steps required to take some high resolution samples from an image and feed them into a multi input CNN. In this case add a parameter to your custom generator to activate the augmentation. 15 V9 Apply to the model 3 times over each image at prediction time score 0. The model will never see the entire image and only three 256x256 pixels samples. 0 V8 Randomly samples 3 images at full resolution and feed them into a multi input CNN score 0. It ensures there is actually some kind of content in the returned sample and give the associated groundtruth. The activation layer for our output is set to softmax with 6 units representing the gradient from 0 to 5. We create a custom generator that will randomly take samples from each full scale image. One last check to ensure that the predict_submission function works as intended. If you found this notebook helpful please give it an upvote. The passes parameter will decide how many times we attempt to predict on a given image. Due to the random sampling we will do 3 passes on each image to increase our chances of finding the cancerous zones and keep the mean of all grades. Version notes V7 Stacked images randonly sampled and feed them into a ResNet50 score 0. If it finds the folder it will load test. It could also be set to linear if we approached this as a regression problem. The architecture itself will need some additional tuning later. Make predictions using our newly trained modelTime to predict on new data We use the function to retrieve random samples from the original full size images and simply feed it to the model. The gleason score will be calculcated from the corresponding masks for each image. To finish we add a condition that will check that the test images are available when running the notebook in submission mode. In previous versions of this notebook I tried to stack the three samples together and feed as one input into a ResNet50 but the model never learnt. The 3 input branches have their weight mostly frozen as they have already been trained using the gleason score. We need to use it both for our training data and validation data. This approach assumes that there is more value to learn from high resolution local areas in an image than a resized version of the entire image. We know generate images with 3 images with 3 channels each. Train our future input branchWe build a fairly basic CNN that will be trained using random 256x256pixel samples and the gleason score. This version brings so minor changes to try to fix that. It is always greatly appreciated remove all image file that don t have a mask file check that the sample is not empty and use the standard deviation to make sure there is something happening in the sample check that the sample is not empty and use the standard deviation to make sure there is something happening in the sample. To do so we will use a custom generator which will prepare the images live as we build the batches during training. ", "id": "frlemarchand/high-res-samples-into-multi-input-cnn-keras", "size": "4241", "language": "python", "html_url": "https://www.kaggle.com/code/frlemarchand/high-res-samples-into-multi-input-cnn-keras", "git_url": "https://www.kaggle.com/code/frlemarchand/high-res-samples-into-multi-input-cnn-keras", "script": "move cohen_kappa_score InputLayer get_single_sample Activation Reshape keras tensorflow.keras.layers sklearn.utils get_random_samples tensorflow.keras.models numpy MaxPooling2D Dropout shutil ImageDataGenerator ResNet50 BatchNormalization randint Dense Callback GlobalAveragePooling2D layers custom_generator tqdm copyfile tensorflow.keras.applications branch tensorflow ReduceLROnPlateau random matplotlib.pyplot tensorflow.keras.preprocessing.image tensorflow.keras.callbacks ModelCheckpoint custom_single_image_generator Sequential shuffle pandas keras.losses input_branch EarlyStopping Conv2D Model predict_submission Input mean_squared_error tensorflow.keras VGG16 sklearn.metrics Flatten ", "entities": "(('model', 'entire image'), 'see') (('We', '3 channels'), 'know') (('we', 'training'), 'use') (('we', 'sampling strategy'), 'try') (('we', 'grades'), 'do') (('which', 'random samples'), 'have') (('model', 'ResNet50'), 'learn') (('V7 Stacked images', 'ResNet50 score'), 'note') (('how many times we', 'given image'), 'decide') (('it', 'test'), 'load') (('also we', 'regression problem'), 'set') (('which', 'branches'), 'time') (('approach', 'entire image'), 'assume') (('architecture', 'additional tuning'), 'need') (('model training', 'sometimes log'), 'V13') (('It', 'associated groundtruth'), 'ensure') (('groundtruthWe', 'validation set'), 'shuffle') (('15 V9', 'prediction time score'), 'Apply') (('mostly they', 'gleason already score'), 'have') (('that', 'them'), 'have') (('that', 'inputs'), 'check') (('that', 'random 256x256pixel samples'), 'train') (('Randomly', 'input CNN multi score'), 'sample') (('V14', 'notebook'), 'reduce') (('gleason score', 'image'), 'calculcate') (('that', 'scale full image'), 'create') (('version', 'that'), 'bring') (('sample', 'sample'), 'appreciate') (('activation layer', '5'), 'set') (('performance', 'validation set'), 'be') (('input 3 branches', 'input branches'), 'train') (('notebook', 'upvote'), 'give') (('32 V11', 'runs instead over 3 score'), 'take') (('We', 'model'), 'make') (('We', 'training both data'), 'need') (('notebook', 'input multi CNN'), 'sample') (('test images', 'submission mode'), 'add') "}
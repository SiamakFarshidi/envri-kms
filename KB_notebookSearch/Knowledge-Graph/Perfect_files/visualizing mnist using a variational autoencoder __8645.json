{"name": "visualizing mnist using a variational autoencoder ", "full_name": " h1 Visualizing MNIST with a Deep Variational Autoencoder h2 1 Introduction h3 A What is autoencoding h3 B Autoencoders h3 C The Variational Variety h2 2 Data preparation h3 A Load Data h3 B Combine Train Test h3 C Split into training validation sets h3 4 Reshape normalize h2 3 Model construction h3 A Encoder network h3 B Sampling function h3 C Decoder network h3 D Loss h2 4 Train the VAE h2 5 Results h3 A Clustering of digits in the latent space h3 B Sample digits ", "stargazers_count": 0, "forks_count": 0, "description": "You can find a repo of examples from the book including the one that inspired this kernel here on GitHub https github. Variational autoencoders VAEs don t learn to morph the data in and out of a compressed representation of itself like the vanilla autoencoders I described above. Autoencoders Generally autoencoders have three parts an encoder a decoder and a loss function that maps one to the other. Decoder network D. The code here borrows heavily from Fran ccedil ois Chollet s example VAE from his book Deep Learning with Python https www. Clustering of digits in the latent space B. Reshape normalize Our encoder and decoder are deep convnets constructed using the Keras Functional API. When we color code those translated data points according to their known digit class we can see how the digits cluster together. In practice you re much more likely to see them being used to preprocess data as in denoising think images but it doesn t have to be or for dimensionality reduction. These types of autoencoders have much in common with latent factor analysis if you know something about that. Sample digits Another fun thing we can do is to use the decoder network to take a peak at what samples from the latent space look like as we change the latent variables. Recall that the VAE is trained using a loss function with two components 1. As we ll see shortly that loss is actually two different losses combined one that describes the difference between the input images and the images reconstructed from samples from the latent distribution and another that is the difference between the latent distribution and the prior the inputs. Combine train test C. Remember that we ve combined the original train and test data so the new train and validation sets that we make below will each have some images with missing 11 labels. epsilon is a tensor of small random normal values. The Kullback Liebler divergence between the latent distribution and the prior this acts as a sort of regularization term. Sampling function Next we create a function to sample from the distribution we just learned the parameters of. It s considered more of a semi supervised learning method as opposed to a truly unsupervised one since it s not entirely targetless. Also since we don t need the labels for building the model remember semi supervised it makes sense to combine the train and test data into one combined dataframe. What is autoencoding B. Reconstruction loss This is the cross entropy describing the errors between the decoded samples from the latent distribution and the original inputs. It s an algorithm for data compression where the functions for compression and decompression are learned from the data. In this example both the encoder and decoder networks are deep convnets. Split into training validation sets Despite being trained in a semi supervised way the VAE algorithm entails minimizing a loss function. Instead it learns the targets from the data itself. Despite all this talk of data compression autoencoders aren t typically used for that purpose. Clustering of digits in the latent space We can make predictions on the validation set using the encoder network. Instead they learn the parameters of the probability distribution that the data came from. Decoder network The decoder is basically the encoder in reverse. As we ll see VAEs can also be used to cluster data in useful ways. The Lambda layer wrapper let s us do this. You ll notice that the encoder below has two output layers one for the latent distribution mean z_mu and the other for its variance z_log_sigma. Thanks for reading generic backend so code works with either tensorflow or theano create label column in test dataset rearrange so that columns are in the same order as in train combine original train and test sets Hold out 5000 random images as a validation test sample free up some space and delete test and combined X s labels Normalize and reshape for MNIST Number of latent dimension parameters Encoder architecture Input Conv2D 4 Flatten Dense need to know the shape of the network here for the decoder Two outputs latent mean and log variance sampling function sample vector from the latent distribution decoder takes the latent distribution sample as input Expand to 784 total pixels reshape use Conv2DTranspose to reverse the conv layers from the encoder decoder model statement apply the decoder to the sample from the latent distribution construct a custom layer to calculate the loss Reconstruction loss KL divergence adds the custom loss to the class apply the custom loss to the input images and the decoded latent distribution sample VAE model statement Isolate original training set records in validation set X s and Y s Reshape and normalize Translate into the latent space set colormap so that 11 s are gray Display a 2D manifold of the digits figure with 20x20 digits Construct grid of latent variable values decode for each square in the grid. The Variational Variety There s a bunch of different kinds of autoencoders but for this post I m going to concentrate on one type called a variational autoencoder. Visualizing MNIST with a Deep Variational Autoencoder1. Model construction A. com brilliantFire deep learning with python notebooks. A decoder that can turn the sample from 2 back into an image. We ll see how the data cluster in the lower dimensional space according to their digit class. com Deep Learning Python Francois Chollet dp 1617294438 ref sr_1_1 ie UTF8 qid 1520470984 sr 8 1 keywords francois chollet. Encoder network A VAE has three basic parts 1. We want to train the autoencoder with as many images as possible. A variational autoencoder https i. What we end up with is a smoothly varying space where each digit transforms into the others as we dial the latent variables up and down. In this kernel I go over some details about autoencoding and autoencoders especially VAEs before constructing and training a deep VAE on the MNIST data from the Digit Recognizer competition. Data preparation A. We define a custom layer class that calculates the loss. In fact the hidden layers of simple autoencoders are doing something like principal component analysis PCA another method traditionally used for dimensionality reduction. The Variational Variety 2. Including the original test set data lets us see where they fall with respect to the known digit clusters. Encoder network B. With Keras everything has to be in a layer to compile correctly. For the simplest autoencoders the sort that compress and then reconstruct the original inputs from the compressed representation we can think of the loss as describing the amount of information lost in the process of reconstruction. The bottom right panel shows one of the more difficult to classify digits even for humans. png VAEs have received a lot of attention because of their generative ability though they seem to be falling out of fashion in favor of general adversarial networks or GANs in that regard. Split into new training validation sets D. The encoder and decoder learn models that are in terms of underlying unobserved latent variables. Since they learn about the distribution the inputs came from we can sample from that distribution to generate novel data. A means of sampling from that distribution and 3. What is autoencoding Autoencoding is much like what it sounds in the sense that the input and output are essentially the same. Loss We need one more thing and that s something that will calculate the unique loss function the VAE requires. Plotting the test set data in this space shows where the images with unknown digit classes fall with respect to the known digit classes. Reshape normalize 3. One of the assumptions underlying a VAE like this is that our data arose from a random process and is normally distributed in the latent space. Sampling function C. Typically when people are talking about autoencoders they re talking about ones where the encoders and decoders are neural networks in our case deep convnets. It s essentially an inference model and a generative model daisy chained together. We can take a look at a few random images. This goes for our sampling function. We ll need to separate the inputs from the labels normalize them by dividing the max pixel value and reshape them into 28x28 pixel images. This has the effect of translating the images from the 784 dimensional input space into the 2 dimensional latent space. In training the autoencoder we re optimizing the parameters of the neural networks to minimize the loss or distance and we do that by stochastic gradient descent yet another topic for another post. An encoder that that learns the parameters mean and variance of the underlying latent distribution 2. Now we can instantiate the model and take a look at its summary. Train the VAE Finally we fit the model. I learned that variational autoencoders VAEs can be used to visualize high dimensional data in a meaningful lower dimensional space. We can calculate this loss on a validation set with each training epoch as an estimate of how the model describes data it was not trained on. Combine Train Test Let s add a placeholder label column to the test dataset. We ll give all the test images a label of 11 for now This data goes to 11. Introduction I spent a rainy weekend recently learning about autoencoders using TensorFlow and Keras in Python. ", "id": "rvislaywade/visualizing-mnist-using-a-variational-autoencoder", "size": "8645", "language": "python", "html_url": "https://www.kaggle.com/code/rvislaywade/visualizing-mnist-using-a-variational-autoencoder", "git_url": "https://www.kaggle.com/code/rvislaywade/visualizing-mnist-using-a-variational-autoencoder", "script": "Model CustomVariationalLayer(keras.layers.Layer) matplotlib.patches call vae_loss scipy.stats keras.models matplotlib.pyplot keras backend metrics layers sampling pandas norm backend as K   # 'generic' backend so code works with either tensorflow or theano numpy ", "entities": "(('that', 'underlying unobserved latent variables'), 'learn') (('we', 'reconstruction'), 'for') (('This', '2 dimensional latent space'), 'have') (('epsilon', 'small random normal values'), 'be') (('encoder', 'Keras Functional deep API'), 'normalize') (('data', 'that'), 'learn') (('Introduction I', 'Python'), 'spend') (('Now we', 'summary'), 'instantiate') (('aren t', 'typically purpose'), 'despite') (('that', 'GitHub https here github'), 'find') (('We', 'digit class'), 'see') (('we', 'latent variables'), 'digit') (('t', 'dimensionality reduction'), 're') (('it', 'one combined dataframe'), 'need') (('Decoder decoder', 'basically reverse'), 'network') (('We', 'encoder network'), 'make') (('we', '11 labels'), 'have') (('code', 'Deep Python https www'), 'borrow') (('autoencoders variational VAEs', 'meaningful lower dimensional space'), 'learn') (('where images', 'digit known classes'), 'show') (('it', 'truly unsupervised one'), 'consider') (('hidden layers', 'dimensionality traditionally reduction'), 'do') (('We', 'as many images'), 'want') (('how digits', 'digit known class'), 'see') (('output below two layers', 'variance'), 'notice') (('where they', 'digit known clusters'), 'let') (('we', 'post'), 're') (('I', 'Digit Recognizer competition'), 'go') (('prior this', 'regularization term'), 'divergence') (('bottom right panel', 'even humans'), 'show') (('they', 'regard'), 'receive') (('that', 'latent distribution'), 'be') (('where encoders', 'neural case'), 'typically') (('that', 'underlying latent distribution'), 'encoder') (('s', 'test dataset'), 'combine') (('11 s', 'grid'), 'work') (('I', 'one type'), 'Variety') (('we', 'just parameters'), 'function') (('input', 'sense'), 'be') (('I', 'vanilla autoencoders'), 'learn') (('that', 'back image'), 'decoder') (('we', 'latent variables'), 'be') (('now data', '11'), 'give') (('Instead it', 'data'), 'learn') (('that', 'loss'), 'define') (('data', 'normally latent space'), 'be') (('encoder networks', 'example'), 'be') (('you', 'that'), 'have') (('Encoder VAE', 'three basic parts'), 'network') (('We', 'pixel 28x28 images'), 'need') (('Reconstruction This', 'latent distribution'), 'loss') (('VAE', 'loss unique function'), 'need') (('where functions', 'data'), 's') (('us', 'this'), 'let') (('VAE', 'two components'), 'recall') (('we', 'novel data'), 'learn') (('VAEs', 'useful ways'), 'use') (('everything', 'layer'), 'have') (('loss that', 'other'), 'have') (('We', 'a few random images'), 'take') (('it', 'data'), 'calculate') "}
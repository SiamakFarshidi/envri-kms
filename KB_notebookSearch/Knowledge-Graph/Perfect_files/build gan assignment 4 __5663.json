{"name": "build gan assignment 4 ", "full_name": " h1 Build a Conditional GAN h3 Goals h3 Learning Objectives h2 Getting Started h4 Packages and Visualization h4 Generator and Noise h4 Discriminator h2 Class Input h2 Training h2 Exploration h4 Changing the Class Vector h4 Changing the Noise Vector ", "stargazers_count": 0, "forks_count": 0, "description": "You can choose what these two images will be using your conditional GAN. For the discriminator you need to add a channel for every class. Learn the technical difference between a conditional and unconditional GAN. To do this you will need to update the input dimensions for both models. Changing the Noise VectorNow what happens if you hold the class constant but instead you change the noise vector You can also interpolate the noise vector and generate an image at each step. detach so you do not backpropagate through it b Combine the real images with image_one_hot_labels 2 Get the discriminator s prediction on the fakes as disc_fake_pred 3 Get the discriminator s prediction on the reals as disc_real_pred Make sure that enough predictions were made Make sure that the inputs are different Keep track of the average discriminator loss Zero out the generator gradients This will error if you didn t concatenate your labels to your image correctly Keep track of the generator losses Before you explore you should put the generator in eval mode both in general and so that batch norm doesn t cause you issues and is using its eval statistics Choose the interpolation how many intermediate images you want 2 for the start and end image Calculate the interpolation vector between the two labels Combine the noise and the labels Choose the start digit Choose the end digit How many intermediate images you want 2 for the start and end image This time you re interpolating between the noise instead of the labels This time you re interpolating between the noise instead of the labels Combine the noise and the labels again Generate noise vectors to interpolate between Choose the number of noise examples in the grid. from a batch and number of classes please create one hot vectors for each label. Your re basically morphing one image into another. Set for our testing purposes please do not change Build the neural network UNQ_C1 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED FUNCTION get_one_hot_labels UNQ_C2 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED FUNCTION combine_vectors Note Make sure this function outputs a float no matter what inputs it receives UNQ_C3 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED FUNCTION get_input_dimensions UNQ_C4 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL UNIT TEST NOTE Initializations needed for grading Dataloader returns the batches and the labels Flatten the batch of real images from the dataset Zero out the discriminator gradients Get noise corresponding to the current batch_size Now you can get the images from the generator Steps 1 Combine the noise vectors and the one hot labels for the generator 2 Generate the conditioned fake images Make sure that enough images were generated Now you can get the predictions from the discriminator Steps 1 Create the input for the discriminator a Combine the fake images with image_one_hot_labels remember to detach the generator. The documentation for F. For example if you re generating a picture of the number 1 you would need to 1. In addition to good variable naming this also means that you can use the generator and discriminator code you have previously written with different parameters. Optional hints for combine_vectors1. To do this you will need to write a function that combines two vectors. So starting from a image you will produce intermediate images that look more and more like the ending image until you get to the final image. There is a class within the PyTorch functional library that can help you. For the generator you will need to calculate the size of the input vector recall that for conditional GANs the generator s input is the noise vector concatenated with the class vector. Note that this assignment requires no changes to the architectures of the generator or discriminator only changes to the data passed to both. Understand the distinction between the class and noise vector in a conditional GAN. Packages and Visualization Generator and Noise Discriminator Class InputIn conditional GANs the input vector for the generator will also need to include the class information. This code can be done in one line. You will also need to do this when adding the class channels to the discriminator. This will let you choose what digit you want to generate. Given the labels of multiple images e. Getting StartedFor this assignment you will be using the MNIST dataset again but there s nothing stopping you from applying this generator code to produce images of animals conditioned on the species or pictures of faces conditioned on facial characteristics. The vector is all 0 s and a 1 on the chosen class. one_hot https pytorch. Again you can look to the PyTorch library for help. The documentation for torch. The class is represented using a one hot encoded vector where its length is the number of classes and each index represents a class. org docs master generated torch. Tell that to the generator so that it knows it should be generating a 1 2. Tell that to the discriminator so that it knows it should be looking at a 1. Build a Conditional GAN GoalsIn this notebook you re going to make a conditional GAN in order to generate hand written images of digits conditioned on the digit to be generated the class vector. There are a few locations where you will need to implement code. The generator will no longer take z_dim as an argument but input_dim instead since you need to pass in both the noise and class vectors. TrainingNow you can start to put it all together First you will define some new parameters mnist_shape the number of pixels in each MNIST image which has dimensions 28 x 28 and one channel because it s black and white so 1 x 28 x 28 n_classes the number of classes in MNIST 10 since there are the digits from 0 to 9 And you also include the same parameters from previous assignments criterion the loss function n_epochs the number of times you iterate through the entire dataset when training z_dim the dimension of the noise vector display_step how often to display visualize the images batch_size the number of images per forward backward pass lr the learning rate device the device typeThen you can initialize your generator discriminator and optimizers. You will begin by importing the necessary libraries and building the generator and discriminator. Specifically you might want to look at what the dim argument of torch. You ll then do some exploration of the generated images to visualize what the noise and class vectors mean. If the discriminator is told it should be looking at a 1 but sees something that s clearly an 8 it can guess that it s probably fakeThere are no explicit unit tests here if this block of code runs and you don t change any of the other variables then you ve done it correctly ExplorationYou can do a bit of exploration now Changing the Class VectorYou can generate some numbers with your new model You can add interpolation as well to make it more interesting. Learning Objectives1. Next you need to be able to concatenate the one hot class vector to the noise vector before giving it to the generator. This code can also be written in one line. one_hot may be helpful. Now to train you would like both your generator and your discriminator to know what class of image should be generated. Remember that you need to ensure that the vectors are the same type floats. Optional hints for get_one_hot_labels1. ", "id": "amoghjrules/build-gan-assignment-4", "size": "5663", "language": "python", "html_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-4", "git_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-4", "script": "torch.nn.functional DataLoader combine_vectors show_tensor_images interpolate_class make_gen_block nn tqdm transforms torchvision make_grid matplotlib.pyplot Generator(nn.Module) tqdm.auto forward Discriminator(nn.Module) interpolate_noise MNIST torch.utils.data test_input_dims get_noise __init__ weights_init torch make_disc_block torchvision.datasets get_input_dimensions get_one_hot_labels torchvision.utils ", "entities": "(('Combine', 'generator'), 'change') (('you', 'previously different parameters'), 'mean') (('it', '1 2'), 'tell') (('assignment you', 'facial characteristics'), 'get') (('1 you', '1'), 'need') (('instead you', 'noise'), 'take') (('input', 'noise class vector'), 'need') (('that', 'two vectors'), 'need') (('code', 'also one line'), 'write') (('You', 'discriminator'), 'need') (('vector', 'all 0 chosen class'), 'be') (('you', 'final image'), 'produce') (('instead time you', 'grid'), 'detach') (('you', 'class vector'), 'build') (('Your', 'another'), 'morph') (('class', 'image'), 'train') (('typeThen you', 'generator discriminator'), 'start') (('you', 'models'), 'need') (('assignment', 'both'), 'note') (('Specifically you', 'torch'), 'want') (('You', 'generator'), 'begin') (('as well it', 'interpolation'), 'guess') (('you', 'digit'), 'let') (('two images', 'conditional GAN'), 'choose') (('Again you', 'help'), 'look') (('Next you', 'generator'), 'need') (('you', 'class'), 'need') (('index', 'class'), 'represent') (('a few where you', 'code'), 'be') (('it', '1'), 'tell') (('noise', 'what'), 'do') (('You', 'step'), 'change') (('Packages', 'class also information'), 'need') (('that', 'you'), 'be') "}
{"name": "experiment tracking with weights and biases ", "full_name": " h1 What is W B h2 Why is W B useful h1 Dashboard experiment tracking h2 Track metrics h2 Visualize results h2 Train anywhere h2 Stay organized h1 Artifacts dataset versioning h3 Manage your pipeline Track data lineage h1 TL DR h1 1 Set up W B h2 1a Install wandb h2 1b Import wandb and log in h1 I have saved my API token with wandb api as Label h1 If you use some other Label make sure to change the same below h1 2 Build Input Pipeline h1 3 Set up your model h1 3 Train and evaluate with W B h2 3 Use wandb init to initialize a new W B run h2 3b Update wandb config h3 Filtering and Grouping h2 3c Log evaluation score with wandb log h1 4 Create a W B Artifact h2 4a Save your hard work with wandb log artifact h1 Resources ", "stargazers_count": 0, "forks_count": 0, "description": "ipynb to learn more about Artifacts. login key wandb_api More on W B login here https docs. Store your hyperparameters as a dictionary because you can later directly log this config dict to W B. Since it s a multi label classification task the output activation is sigmoid. gif Pro tip Note that the bar chart apprears if there are more than one value for a key. W B Artifacts lets you log the data that goes in like a dataset and out like trained model weights of these processes. Build input pipeline Encode competition provided labels Helper fu Read train. Setting a run type makes it easier to later filter and group runs for example if you want to compare multiple train runs. csv file Get absolute path Parse labels Look at the dataframe 5. com github wandb examples blob master colabs wandb artifacts Pipeline_Versioning_with_W 26B_Artifacts. In this section I ll show you how to create a model Artifact. Set up your modelBuild your model definition next. Each run gets its own Run Page which has tabs that contain more information about the run. Add your model file to the Artifact with wandb. png Artifacts dataset versioning Use W B Artifacts to track and version your datasets models dependencies and results across machine learning pipelines. init to initialize a new W B run. I also created some dataset Artifacts for this competition and you can check them all out here https wandb. ai quickstart and flexible integrated with every major ML framework https docs. Access your API key https wandb. As a reminder here s what s currently in CONFIG pythonCONFIG dict num_labels 6 train_val_split 0. config a dictionary like object for saving inputs to your job like hyperparameters for a model or settings for a data preprocessing job. Check out this discussion post https www. Training and validation split 6. If you don t have a Weights Biases account you can go to https wandb. png TL DRWeights Biases helps you build better models faster. See more setup options in this Colab https colab. For example you can create group for different model architecture names. ai ref cli wandb login. com watch v EIgoKitLUqM t 92s 1. Check out our Keras integration docs https docs. In other words Artifacts are a way to save your datasets and models. Here are some relevant links that you might want to check out Check out the official documentation https docs. ai guides track log logging objects. Check out the examples GitHub repository https github. Helper functions for input pipeline Convert the compressed string to a 3D uint8 tensor Normalize image Resize the image to the desired size Load image Resize image Parse label 7. environ WANDB_SILENT true after import os. png Stay organizedW B logs data into powerful querably tables that you can search filter sort and group. We will be using W B Keras integration WandbCallback to automatically save all the metrics and the loss values tracked in model. There are two ways you can login using a Kaggle kernel 1. ai ref python finish Finish and close a run. Build data loaders Data loader sanity check 8. ai guides track config An object that stores hyperparameters and settings related to a run. gif Train anywhereThe W B dashboard is centralized whether you re training on a local machine lab cluster or spot instances in the cloud all of your results get logged to a single place. 2 img_width 224 img_height 224 batch_size 64 epochs 10 learning_rate 0. EfficientNet Mixup K Fold using TF and wandb https www. Here are some other Kaggle kernels instrumented with Weights Biases that you might find useful. It will ask for the API key which you can copy paste in. The Plant Pathology 2021 competition is about multi label classification. Save your hard work with wandb. ai ref app pages run page model tab from the run above img https i. To build the input pipeline I have used tf. ipynb scrollTo xFf3zjBSixC1. Lots of components lots of places to go wrong lots of time spent debugging You might miss important details and have to retrain your model or you might train on the wrong data information leakage. log_artifact to save the Artifact. com c plant pathology 2021 fgvc8 to demonstrate some of its features Dashboard experiment tracking and Artifacts dataset and model versioning. com wandb examples for curated and minimal examples. ai guides integrations keras to learn more. project The name of the project where you re sending the new run. com product feedback 114053 to learn more about Kaggle secrets. Here s a gif showing the Charts Tab https docs. Weights and Biases comes with a light weight integration for Keras. config a dictionary like object that stores hyperparameters input settings and other independent variables. config https docs. Collaborating with your teammates is easier with such a holistic view of your pipeline. get_secret wandb_api wandb. You can use this Colab https colab. ai ref app pages run page charts tab System Tab https docs. This is a super handy feature. Dashboard experiment tracking Use the Dashboard as a central place to organize and visualize results from your machine learning models. init https docs. Build Input PipelineAfter importing wandb and other dependencies you can set up an input pipeline as normal. com a 65997094 8663152 for more details. Pro tip Use run. com ayuraj hpa multi label classification with tf and w b BirdCLEF Quick EDA with W B https www. ai guides integrations. ai guides integrations keras. ai ref python data types. log WandbCallback can be used for model. ai ayush thakur plant pathology runs 5yq0kz7t. centralized dashboard https i. Filtering and GroupingYou can use filter and group feature on W B dashboard to either hide crashed run group together multiple runs under one experiment group according to job_type select runs that satisfy a condition etc. Consider this as a repository of experiments. from kaggle_secrets import UserSecretsClientuser_secrets UserSecretsClient I have saved my API token with wandb_api as Label. log_artifact Within a run there are three steps for creating and saving a model Artifact. job_type This argument specifies a run type for example train or evaluate. log Finish the run Save model Initialize a new W B run Note the job_type Update wandb. Pro tip Head over to the W B dashboard my clicking on the link generated above. fit but not for model. config This argument sets wandb. Track metrics Visualize results Train anywhere Stay organized Save everything in one place and never lose your progress again Track metricsTrack model performance in real time and identify problem areas immediately. Here I m creating a new project called plant pathology and sending the run there at the same time. There are multiple ways to set up wandb. Artifacts dataset model versioning Store and version datasets models and results Know exactly what data a model is being trained on. config This sets wandb. This can be a good starting point. config Save model as Model Artifact Finish W B run. ai guides track advanced grouping. com ayuraj birdclef quick eda with w b 1. Import wandb and log inYou will need a unique API key to log in to Weights Biases. You can learn more about Group feature here https docs. Why is W B useful Kaggle competitions require fast paced model development and evaluation. ai guides track log Log a dict of scalars metrics like accuracy and loss and any other type of wandb object https docs. com ayuraj efficientnet mixup k fold using tf and wandb HPA Segmentation Mask Visualization with W B https www. Visualize resultsW B supports a large variety of media types visualize graphs images videos audio 3D objects and more https docs. init config argument as above in 3a. If you use some other Label make sure to change the same below. entity An entity is a username or team name where you re sending runs. ai ayush thakur plant pathology artifacts. There are a lot of components exploring the training data training different models combining trained models in different combinations ensembling and so on. config Evaluate model Log scores using wandb. Run a cell with wandb. Create an empty Artifact with wandb. config Saving your training configuration is useful for analyzing your experiments and reproducing your work later. ai site and create a FREE account. Create a W B ArtifactW B s Dashboard lets you log the model training process things like output logs code versions configuration hyperparameters and metrics. job_type Specify the type of run which is useful when you re grouping runs together into larger experiments using group. Visualize results in real time in an interactive centralized dashboard Identify how changing data affects the resulting modelPlus W B is fast get started with 6 lines of code https docs. Set up W BW B is very easy to set up and integrate. You can also use Kaggle secrets to store your API key and use the code snippet below to login. gif Now I ll use WandbCallback the lightweight Keras integration that I mentioned earlier. Later on I ll have a run that groups by EfficientNet so that I can compare runs from the different architectures more easily. Train and evaluate with W BIn this section I ll use wandb. Check out the docs to learn more about this integration https docs. Install wandb wandb the W B library comes baked into your Kaggle kernels However since wandb is rapidly improving I recommend pip install ing the latest version with the upgrade and q flags. Log evaluation score with wandb. gif At the end of the gif there s a graph that shows the lineage the deep thunder 8 save run produced the efficientnetb0 v0 model. Keep track of which model was trained on which data Manage your pipeline Track data lineageYou get a bird eye view on your entire machine learning workflow. Take a note of these arguments. Import other dependencies 2. png ResourcesI hope you find this kernel useful and I encourage you to try out Weights Biases. Initialize W B run Add type and kaggle_competition to wandb. Here s a gif showing how W B logs and displays a run s training configuration img https i. Here s a gif that shows how an Artifact appears within a Run Page. 001 architecture CNN infra Kaggle model_name efficientnetb0 group This argument specifies a value to group individual runs by. group Specify a group to organize individual runs into a larger experiment. com github wandb examples blob master colabs wandb log Configs_in_W 26B. Set hyperparameters 4. init arguments project This argument specifies the name of the W B project where the run gets sent to. finish to close the initialized W B run after a job_type is finished. finish https docs. This callback automatically saves all the metrics and the loss values tracked in model. gif You can click through this Run Page here https wandb. ai ref app pages run page system tab and Model Tab https docs. Define model EfficientNetB0 trained on ImageNet as backbone Model sanity check Initialize model Compile model Update CONFIG dict with the name of the model. com ayuraj hpa segmentation mask visualization with w b HPA Multi Label Classification with TF and W B https www. If you want to log metrics from evaluation you should call wandb. config directly Train Close W B run Initialize a run Note the job_type Update wandb. This is where W B comes in Dashboard experiment tracking Log and visualize experiments in real time Keep data and results in one convenient place. wandb_api user_secrets. This makes it easy to compare thousands of different models and find the best performing model for different tasks. The main objective of the competition is to develop machine learning based models to accurately classify a given leaf image from the test dataset to a particular disease category and to identify an individual disease from multiple disease symptoms on a single leaf image. Once you ve saved something as an Artifact all modifications are automatically logged giving you a complete history of changes. In an ML training pipeline you could add wandb. ai fully connected is a home for curated tutorials free form dicussions paper summaries industry expert advices and more. Here s a quick 1 42 intro thumbnail https i. If the project is not specified the run is put in an Uncategorized project. I ll use this Knowledge based competition Plant Pathology 2021 FGVC8 https www. What is W B Weights Biases W B is a set of machine learning tools that helps you build better models faster. ai ref python run is a W B unit of computation typically an ML experiment. WandbCallback is a lightweight Keras callback that I ll use later on. Run object https docs. Typical job types are train evaluate etc. With W B you can also group by config values meaning that you can compare the settings of different runs and see how they affect the output. Fully Connected https wandb. ai to learn more about the best practices and advanced features. Or you might use the wrong model for generating submission. ai guides track launch Initialize a new run. Think of an Artifact as a versioned folder of data. Pro tip If you want to silence W B related logs use this code snippet os. Set the random seeds 3. Plus the dashboard is interactive hover for more options and information. init to the beginning of your training script as well as your evaluation script and each piece would be tracked as a run in W B. Check out this Stackoverflow answer https stackoverflow. config with the wandb. ", "id": "ayuraj/experiment-tracking-with-weights-and-biases", "size": "14283", "language": "python", "html_url": "https://www.kaggle.com/code/ayuraj/experiment-tracking-with-weights-and-biases", "git_url": "https://www.kaggle.com/code/ayuraj/experiment-tracking-with-weights-and-biases", "script": "tensorflow_addons train_test_split wandb.keras numpy decode_image make_path layers models tensorflow matplotlib.pyplot get_model sklearn.model_selection pandas tensorflow.keras seed_everything show_batch WandbCallback parse_labels load_image ", "entities": "(('when you', 'group'), 'specify') (('UserSecretsClientuser_secrets I', 'Label'), 'from') (('com ayuraj efficientnet', 'W B https www'), 'mixup') (('modifications', 'changes'), 'save') (('Set', 'W BW B'), 'be') (('main objective', 'leaf single image'), 'be') (('com c plant pathology', 'features'), 'fgvc8') (('all', 'single place'), 'centralize') (('Here I', 'there same time'), 'm') (('ai ref python run', 'W B computation'), 'be') (('I', 'that'), 'gif') (('gif Pro tip bar chart', 'more than one key'), 'note') (('I', 'different architectures'), 'have') (('ai ref python', 'run'), 'finish') (('I', 'Artifact'), 'show') (('We', 'loss model'), 'use') (('username where you', 'runs'), 'be') (('ai ref app pages', 'page system tab'), 'run') (('other you', 'input pipeline'), 'set') (('Track metrics Visualize Train', 'problem areas'), 'result') (('you', 'documentation https official docs'), 'be') (('where run', 'W B project'), 'project') (('Visualize resultsW B', 'audio 3D objects'), 'support') (('deep thunder', 'save v0 8 efficientnetb0 model'), 'gif') (('that', 'run'), 'get') (('Artifacts', 'datasets'), 'be') (('you', 'https out here wandb'), 'create') (('Initialize W B', 'wandb'), 'run') (('it', 'different tasks'), 'make') (('you', 'wandb'), 'add') (('Kaggle useful competitions', 'model fast paced development'), 'be') (('png Artifacts', 'machine learning pipelines'), 'dataset') (('I', 'Weights Biases'), 'hope') (('ai', 'more'), 'guide') (('I', 'competition Plant Knowledge based Pathology'), 'use') (('I', 'wandb'), 'train') (('Collaborating', 'pipeline'), 'be') (('model', 'models'), 'dataset') (('Plant Pathology 2021 competition', 'label multi classification'), 'be') (('you', 'https wandb'), 'have') (('ai ref app pages', 'page charts tab System Tab https docs'), 'run') (('track log', 'object https docs'), 'guide') (('You', 'https here docs'), 'learn') (('how Artifact', 'Run Page'), 's') (('you', 'W B.'), 'store') (('you', 'paste'), 'ask') (('you', 'wandb'), 'call') (('log_artifact', 'three model'), 'be') (('how they', 'output'), 'group') (('ArtifactW Dashboard you', 'output logs code versions configuration hyperparameters'), 'a') (('you', 'better models'), 'be') (('you', 'submission'), 'use') (('callback', 'loss model'), 'save') (('where you', 'new run'), 'project') (('two you', 'Kaggle kernel'), 'be') (('how changing data', 'code https docs'), 'Identify') (('you', 'train multiple runs'), 'make') (('Track lineageYou', 'machine learning entire workflow'), 'keep') (('you', 'model architecture different names'), 'create') (('that', 'processes'), 'let') (('Helper functions', 'Load image Resize Parse label'), 'Convert') (('gif You', 'Run https Page here wandb'), 'click') (('Build data', 'Data loader sanity check'), 'loader') (('run', 'Uncategorized project'), 'put') (('dashboard', 'interactive more options'), 'be') (('backbone Model sanity check Initialize model Compile model Update CONFIG', 'model'), 'train') (('Import wandb', 'Weights Biases'), 'need') (('you', 'Weights Biases'), 'be') (('Build input pipeline Encode competition', 'labels Helper fu Read train'), 'provide') (('here what', 'num_labels'), 's') (('track launch', 'new run'), 'guide') (('querably you', 'filter sort'), 'stay') (('code snippet', 'use'), 'tip') (('you', 'other Label'), 'make') (('you', 'data information wrong leakage'), 'miss') (('ai ayush thakur plant pathology', '5yq0kz7 t'), 'run') (('I', 'input pipeline'), 'build') (('stores', 'input settings'), 'config') (('group', 'larger experiment'), 'specify') (('config', 'work'), 'be') (('init', 'W B.'), 'track') (('job_type', 'W B initialized run'), 'finish') (('stores hyperparameters', 'run'), 'guides') (('path Parse absolute labels', 'dataframe'), 'get') (('environ WANDB_SILENT', 'import os'), 'true') (('Dashboard experiment tracking', 'machine learning models'), 'Use') (('ai', 'form dicussions paper summaries industry expert fully curated tutorials free advices'), 'be') (('that', 'condition'), 'use') (('ai ref app pages', 'img https i.'), 'run') (('architecture CNN Kaggle model_name efficientnetb0 infra argument', 'group individual runs'), 'group') (('Pro', 'link'), 'tip') (('com ayuraj', 'b w 1'), 'birdclef') (('you', 'better models'), 'help') (('Weights', 'Keras'), 'come') (('argument', 'train'), 'specify') (('com github wandb examples master colabs blob wandb', '26B_Artifacts'), 'artifacts') (('rapidly I', 'upgrade'), 'wandb') (('You', 'below login'), 'use') (('W where B', 'one convenient place'), 'be') "}
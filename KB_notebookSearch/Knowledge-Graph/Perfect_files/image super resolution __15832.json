{"name": "image super resolution ", "full_name": " h1 Contents h3 1 Introduction h3 2 Problem Statement h3 3 Data h3 4 Analysis h3 5 Implementation h3 6 FSRCNN Implementation h3 7 Results h3 8 Conclusion h1 Introduction h3 1 1 SPOT VEGETATION h3 1 2 PROBA V h3 1 3 Super Resolution h1 Problem Statement h2 Utility Code h1 Data h4 Origin of the data h4 Changes in landscape h4 Image registration h3 Exploratory Data Analysis h1 Analysis h4 FSRCNN h1 Implementation h1 FSRCNN Implementation h1 Results h1 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "HR_ u v which results in a clear Peak Signal to Noise Ratio of t t tcPSNR 10. values at the cropped versions of each image that fall in clear pixels of the cropped hr image we first compute the bias in brightness b Next we compute the corrected clear mean square error cMSE of SR w. score import score_image_fast hr_crops from. FSRCNNFast Super Resolution CNN is an advanced method to speed up the SRCNN super resolution method. Data Data Exploratory Data Analysis EDA 4. The method is like this Instead of using a median image as input I tried to use multiple low resolution images 9 because atleast 9 images in each scene are available by stacking them on top of each other as channels and then feeding it to the model. Results Results 8. ResultsWe have our model loss MSE in the model_loss variable and we have the bicubic interpolation MSE loss stored in bicubic_loss variable Bicubic interpolation is the baseline method for super resolution defined by the challenge posters. The payload consists of 3 identical cameras each with a very compact Three Mirror Anastigmat TMA telescope. http scikit image. Hence we can say that our model performs better and beats the baseline method which is the aim of this challenge. As such the scenes are not always permanent but can change marginally. It was launched to support applications such as land use worldwide vegetation classification crop monitoring famine prediction food security disaster monitoring and biosphere studies. Deep Learning for Image Super Resolution https www. Model Technique Date Released FSRCNN Fast Super Resolution Convolutional Neural Network 2016 SRGAN Super Resolution Generative Adversarial Network 2017 These two above methods are single image super resolution methods which we modify a little bit to work for completing our task. Often a low resolution image is taken as an input and the same image is upscaled to a higher resolution which is the output. and operated by European Space Agency and uses a PROBA platform. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. However this is not the case for PROBA V or other satellites which could benefit from a post acquisition enhancement. To address this time problem FSRCNN came into existance FSRCNN doesn t upscale the input image initally and input the low resolution image to the network as it is then multiple convolutions are done on the image Feature Exraction Shrinking Mapping Expanding and finally a Deconvolution is performed on the image Transpose Convolution actually to upscale the image by the given factor. There is so much of old low resolution data available that be used by performing super resolution and finding new insights from the data which will save cost. We will be constructing a model based on FSRCNN with some minor changes. They re required by baseline_upscale. It is a miniaturised satellite tasked with a full scale mission to map land cover and vegetation growth across the entire planet every two days. Below we display some examples of all low resolution high resolution images and their clearance masks. AnalysisFirst I needed some domain knowledge of how super resolution works. http The image below shows two different methods I thought I could follow to get our task done. Problem Statement Problem 3. Utility Code Data Origin of the dataWe collected satellite data from the PROBA V mission of the European Space Agency from 74 hand selected regions around the globe at different points in time. add_subplot image registration display the scene s id to the left of the image https scikit image. But the challenge website tells us that they have defined another scoring technique named cPSNR clear Peak Signal Noise Ratio which we have use for scoring our model. Implementation FSRCNN ImplementationNow we create an object of our model class SuperResolution and transfer the models parameters to the CUDA deviceNext we call the train function to start training the model with our passed parameters as shown below. append N cPSNR The individual score for image SR is tsr_score min crop_scores t t tscore_image i NOTE Don t change these options. Then we combine all the channels into a single channel image. Image registrationThe images are delivered as recorded by PROBA V and have not been modified to align with each other. walk kaggle input for filename in filenames print os. The images provided for this challenge are not artificially degraded but are real images recorded from the very same scene just at different resolutions and different times. FSRCNN SRGAN CSFM and the winning model of the Kelvin PROBA V Challenge DeepSUM. int proba v super resolution data Exploratory Data AnalysisThere are atmost 19 low resolution images and atleast 9 low resolution images available for every given scene in the dataset along with their clearance mask which tells us which pixels in the image are obscured due to some artifact or some glitch. The goal of this challenge is to construct such high resolution images by fusion of the more frequent 300m images. org docs dev api skimage. Conclusion Conclusion Introduction 1. I tried to create a model for multi image super resolution as I have explained in my analysis above 1 MultiISR but unfortunately due to time and system capability contraints I was to not able to make it succesfully work although I believe that that the method will work given some more in depth study and experimenting. In my implementation I have used the method on right i. Single Image Super Resolution1. FSRCNN Implementation FSRCNN 7. For an image to be included in the dataset at least 75 of its pixels have to be clear for 100m resolution images and 60 for 300m resolution images. The V stands for Vegetation. Since our models cPSNR score is less than 1 we can say for sure that this model performs good at creating super resolution images using multiple low resolution images and it also beats the baseline method. We plot a graph below of both the losses to compare their values. clouds cloud shadows ice water missing etc and which should be considered clear. Implementation Implementation 6. The train function returns the best loss value it acquired while training and saves the model to local diskNext we define some of the methods and calculate the MSE for bicubic upsampling method. While the mean geolocation accuracy of PROBA V is about 61m sub pixelshifts in the content occur and are in a sense necessary to perform super resolution. Also I think GAN s are good for this kind of tasks and if we go in that direction and do some kind to gradual increase in the resolution of the low resolution image to high resolution image we might be able to get even better results than state of the art techniques as GANs are very good at creating synthetic data and that is the requirement of super resolution as we need to fill in those pixel in super resolution images which were not actually present. Any improvements on this data set might be transferable to larger collections of remote sensing data without the need to deploy more expensive sensors or satellites as resolution enhancement can happen post acquisition. They have provided the baseline bicubic interpolation cPSNR score in a file named norm. io import highres_image scene_id additional options at https matplotlib. 3 Super ResolutionSuper resolution is the process of upscaling and or improving the details within an image. 0 range would happen if img had signed values. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. The below image is taken from kelvins proba v challenge website. int proba v super resolution home Problem StatementPROBA V payload sensors allow for an almost global coverage 90 per day providing 300m resolution images. The data is composed of radiometrically and geometrically corrected Top Of Atmosphere TOA reflectances for the RED and NIR spectral bands at 300m and 100m resolution in Plate Carr\u00e9e projection. So below we score our model with cPSNR score. csv using which we have to normalize our cPSNR score to get the final cPSNR score. Although I knew about what super resolution is and have thought about how low resoltuion images can be converted to high resolution images I needed some technical details on how super resolution can be performed and does it match with my previous hypothesis that I have maintained in my head and therefore first I watched some videos on super resolution to understand the technical details better and I also read some blogs on the topic. We see from the above plot that the MSE of our model is less than the bicubic interpolation MSE and as we know that MSE is the value of average of difference between each pixel value between two images the smaller the better therefore we can say that our model performs better than the bicubic interpolation method which is ouur baseline method in estimating the target image as its MSE is lower than bicubic interpolation MSE which means the difference between the pixels of super resolution image predicted by the model and the and original high resolution image is very less. The 300m resolution data is delivered as 128x128 grey scale pixel images the 100m resolution data as 384x384 grey scale pixel images. It was initiated by the Space and Aeronautics department of the BELgian Science Policy Office launched into space from ELA 1 Ensemble de Lancement Ariane 1 at Guiana Space Centre on board Vega flight VV02 on 7 May 2013. Therefore this task of super resolution can have great impact on a lot of industries and hence this needs to be studied and more researched upon. The swath Total FOV is 103. Each image comes with a quality map indicating which pixels in the image are concealed i. create a copy of hr with NaNs at obscured pixels flatten used to bypass numba s indexing limitations tcrop_scores We denote the cropped 378x378 images as follows for all u v 0 6 HR_ u v is the subimage of HR with its upper left corner at coordinates u v and its lower right corner at 378 u 378 v we first compute the bias in brightness b Next we compute the corrected clear mean square error cMSE of SR w. For example running this by clicking run or pressing Shift Enter will list all files under the input directory for dirname _ filenames in os. Below we show some of the predicted images alongside with the original images. These two below models are the one I studied in deep because they covered two different aspects and methods of doing super resolution. Used for normalizing scores. log10 cMSE normalized cPSNR t t tcrop_scores. We expect you to submit a 384x384 image for each of the 290 test scenes for which we will not provide a high resolution image. In total the dataset contains 1450 scenes which are split into 1160 scenes for training and 290 scenes for testing. Introduction Introduction Spot Vegetation Spot V Proba V Proba V Super Resolution Super Resolution 2. aggregate import central_tendency from. It is built by QinetiQ Space N. Conclusion The model we trained above gave us better results than the baseline bicubic interpolation method. The scoring will take pixel shifts of the high resolution image into account as registration cannot be computed by the participant for the test set. com watch v MJ2FOFqr7hw t 12s There are mainly two different types of methods of super resolution that can be performed they are 1. DeepSUM is large and difficult to implement in the given timeframe and hence I didn t dig deep into it. 001 number_of_epochs 200 batch_size 16 the train function return the final loss of the model Calculate the median of all low resolution images to combine it into a single image Find the maximum value in the mask and divide the whole array by that value for normalisation Multiply both output image and target image by the mask so as to ignore those pixels for calculating MSE Average the MSE loss for all the scenes Call the get_bicubic_loss to calculate the bicubic interpolation MSE loss intialise data of lists with loss values. 2 PROBA V PROBA V Project for On Board Autonomy Vegetation is an ESA European SpaceAgency mission developed within the framework of the Agency s General SupportTechnology Programme GSTP devoted to the observation of the Earth s vegetation. The model then perform multiple convolutions on the image stack and learn features from all the channels images which eventually removes all the artifacts and faults in the image. The image shown below depicts the task that we need to perform. Analysis Analysis 5. On average each scene comes with 19 different low resolution images and always with at least 9. Although we combined multiple images by taking their median and forming a single image and then creating a super resolution image it is not truly a multi image super resolution algorithm which the challenge demanded. read_csv progress bar reading multiple files at once opencv Input data files are available in the. The bit depth of the images is 14 but they are saved in a 16 bit. If our final cPSNR value is less than 1 then we can say for sure that our model is better than baseline bicubic interpolation method. com watch v ppsqbOL073U t 61s Enhance Super Resolution From Google Two Minute Papers 124 https www. rescale http scikit image. com beyondminds an introduction to super resolution using deep learning f60aff9a499d Deconvolution youtube. int proba v super resolution data https kelvins. The Proba V mission provides multispectral images to study the evolution of the vegetation cover on a daily and global basis. 1 SPOT VEGETATIONThe overall objectives of the VEGETATION systems is to provide accurate measurements of basic characteristics of vegetation canopies on an operational basis Either for scientific studies involving both regional and global scales experiments over long time periods for example development of models of the biosphere dynamics interacting with climate models Or for systems designed to monitor important vegetation resources like crops pastures and forests. Each TMA having a FOV of 34 contains 4 spectral bands 3 bands in the visible range Blue Red and NIR and one band in the SWIR spectral range. Finally we perform a deconvolution on the single channel image we obtained from the previous layer to scale the image by the erquired factor. The main PROBA V payload is the Vegetation sensor a multispectral pushbroom spectrometer with 4 spectral bands and with a very large swath of 2285 km to guarantee daily coverage above 35 latitude. For every scene we are also given a high Resolution image our target image HR. Super resolution has wide scope in so many different fields including satellite imagery microscopes and telescopes. In case of SRCNN the input images need to be upscaled by the required factor before feeding it to the neural network and then consecutive convolutions are done to enhance the image quality to match the target high resolution image. append cMSE The individual score for image SR is tsr_score N 10. Source https kelvins. Each data point consists of exactly one 100m resolution image and several 300m resolution images from the same scene. Thus the super resolution can already be included in the final product of these satellites during post processing on the ground. Changes in landscapeThe images have been recorded within a time window of 30 days. log10 min crop_scores We assume that the pixel intensities are represented as real numbers 0 1 for any given image. Thus PROBA Vs products represent a convenient way to explore super resolution in a relevant setting. take all the images that have the same maximum clearance Images were given by the caller rather than loaded here. provided by the competition s organizers t tscore_image i We assume that the pixel intensities are represented as real numbers 0 1 for any given image. org api _as_gen matplotlib. The details in the high resolution output are filled in where the details are essentially unknown. To compensate for pixel shifts the submitted images are cropped by a 3 pixel border resulting in a 378x378 format. HR image HR image mask. com watch v WovbLx8C0yA An Introduction to Super Resolution using Deep Learning https medium. NOTE I also tried a different method shown on the left side in the image below for super resolution that is purely multi image but unfortunately I was not able to get expected results due to time contraints and system constraints which made me stop doing other experiments. This upscaling method and then enhancing the quality takes high amount of time. Create DataFrame Call the get_cpsnr function to calculate the model cpsnr score We define a scene images iterator We set it to cycle so that its never exhausted and never returns an error to StopIteration Get the images from the generator for the next scene Get the next batch of 16 images Reshape the image batch to feed it as input to the neuural network Convert the image batches into tensors Transfer the data to CUDA device Perform the forward pass of the model PLOT SOME OF THE EXAMPLES FROM THE DATASET THE SUPER RESOLVED IMAGE AND HIGH RESOLUTION IMAGE SIDE BY SIDE. com watch v Xk7myx9_OmU Deconvolutional Microscopy https www. png and a clearance map for the high resolution image. join dirname filename Any results you write to the current directory are saved as output. I have combined all the low resolution in a single image by taking median of each pixel in the image which gave us a cloud artifacts free image. Source Kelvins PROBA V Challenge https kelvins. specific warnings we wish to ignore Baseline cPSNR values for the dataset s images. This process which is known as Multi image Super resolution has already been applied to satellite before some of these satellites such as SPOT VGT or ZY 3 TLC have payloads that are able to take multiple images of the same area during a single satellite pass which creates a most favorable condition for the use of super resolution algorithms as images are taken simultaneously. Because only_clear True we generate copies of all lr images so the function will have no unintended side effects on the caller s side. PROBA V also provides 100m high resolution images but at a lower frequency of roughly every 5 days dependent on the location. warp All scenes are divided in two folders namely RED and NIR save the train images directory which is all we will be using for our model as we don t have high resolution images for the images present in test dataset Extract all the scenes paths and make a list Get the high resolution image and its mask for the scene 0348 HR image HR image mask Extract the low resolution images and their masks and display only the low resolution images Eight images are plotted We define an iterator for getting images from the directory create an object of the generator get_scene_images create a cycle iterator so that it never gets exhausted Get the images from the generator for the next scene Perform all the imports required for our implementation Check if GPU is available in the system or not set device to GPU if available otherwise set device to cpu only save checkpoint print summary super_model 9 128 128 Print the summary of all layers and parameters in the model print We got a better loss value Create an object of the SuperResolution class we have defined the neural net model class Call the train function on super_model object with learning_rate 0. HR_ u v which results in a clear Peak Signal to Noise Ratio of normalized cPSNR t tcrop_scores. html img as float64 safeguard against unwanted conversions to values outside the 0. Let N HR be the baseline cPSNR of image HR as found in the file norm. png format which makes them look relatively dark if opened in typical image viewers. Thus the dataset itself is not corrected for these shifts and none of the images are registered to each other. Multi Image Super ResolutionAfter my analysis to understand the problem and techniques to solve it I went through some of the latest research papers in the domain. int proba v super resolution problem. In those cases multiple images from the same patch are still available but originate from successive revisits over longer periods of time. keep track of the values at obscured pixels replace values at obscured pixels with NaNs aggregate the images suppress the warnings that originate when only_clear True but some pixels are never clear in any of the images from. ", "id": "pranavpandey2511/image-super-resolution", "size": "15832", "language": "python", "html_url": "https://www.kaggle.com/code/pranavpandey2511/image-super-resolution", "git_url": "https://www.kaggle.com/code/pranavpandey2511/image-super-resolution", "script": "create_panel torch.nn.functional Counter hr_crops highres_image DataLoader __call__ get_model_cpsnr compare_aggregates prepare_submission cycle IPython.display score_against_hr torch.autograd baseline_upscale get_hr_image get_optimizer check_img_as_float get_next_batch Image numpy seaborn scorer(object) train scene_id central_tendency score_image_fast glob # reading multiple files at once glob compare_to_hr SuperResolution(nn.Module) get_next_test_batch .aggregate mse scenes_paths torch.nn all_scenes_paths tqdm .io get_lr_images torchvision.utils score_summary transforms get_bicubic_loss Variable torchvision tqdm # progress bar cdf_plot save_checkpoint matplotlib.pyplot make_grid score_images forward defaultdict pandas compare_images .score bicubic_upscaling torch.optim scipy.stats percentileofscore torch.utils.data Dataset __init__ lr_scheduler score_image collections itertools describe get_scene_images lowres_image_iterator ", "entities": "(('PROBA Vs Thus products', 'relevant setting'), 'represent') (('Problem StatementPROBA V payload home sensors', 'm resolution 300 images'), 'allow') (('we', 'baseline bicubic interpolation method'), 'conclusion') (('It', 'vegetation entire planet'), 'be') (('we', 'passed parameters'), 'FSRCNN') (('we', 'upsampling bicubic method'), 'return') (('they', 'super resolution'), 'v') (('FOV', 'Blue one SWIR spectral range'), 'have') (('it', 'baseline also method'), 'beat') (('sure model', 'bicubic interpolation baseline method'), 'be') (('Input data at once files', 'the'), 'opencv') (('PROBA V PROBA V 2 Project', 'vegetation'), 'be') (('SR', 'individual image'), 'append') (('data', 'Plate Carr\u00e9e projection'), 'compose') (('we', 'target image HR'), 'give') (('Next we', 'SR w.'), 'compute') (('challenge', 'resolution truly multi image super which'), 'combine') (('FSRCNN', 'Kelvin PROBA V Challenge winning DeepSUM'), 'SRGAN') (('overall objectives', 'crops pastures'), 'be') (('we', 'cPSNR final score'), 'csv') (('Below we', 'resolution resolution low high images'), 'display') (('It', 'famine prediction food security disaster monitoring'), 'launch') (('which', 'resolution super images'), 'think') (('Vegetation', '35 latitude'), 'be') (('Super Resolution CNN', 'resolution advanced SRCNN super method'), 'fsrcnnfast') (('we', 'resolution high image'), 'expect') (('which', '290 testing'), 'contain') (('at least 75', 'm resolution 300 images'), 'have') (('which', 'cloud artifacts free image'), 'combine') (('we', 'that'), 'depict') (('Transpose Convolution', 'given factor'), 'come') (('registration', 'test set'), 'take') (('submitted images', '378x378 format'), 'crop') (('images', 'just different resolutions'), 'degrade') (('which', 'clouds cloud shadows ice etc'), 'water') (('we', 'erquired factor'), 'perform') (('goal', 'm more frequent 300 images'), 'be') (('deep they', 'super resolution'), 'be') (('Super resolution', 'satellite imagery microscopes'), 'have') (('bicubic interpolation MSE loss', 'challenge posters'), 'have') (('average scene', 'always at least 9'), 'come') (('most favorable condition', 'images'), 'apply') (('pixels', 'images'), 'keep') (('task', 'two different methods'), 'show') (('you', 'output'), 'join') (('pixel intensities', '0 1 given image'), 'provide') (('better I', 'topic'), 'know') (('payload', 'Mirror Anastigmat TMA very compact Three telescope'), 'consist') (('upscaling method', 'time'), 'take') (('we', 'little bit task'), 'release') (('We', 'values'), 'plot') (('HR', 'file norm'), 'let') (('We', 'minor changes'), 'construct') (('method', 'depth more study'), 'try') (('specific we', 'images'), 'warning') (('img', 'values'), 'happen') (('below image', 'kelvins proba v challenge website'), 'take') (('other which', 'post acquisition enhancement'), 'be') (('none', 'other'), 'correct') (('we', 'model'), 'tell') (('clearance same maximum Images', 'caller'), 'take') (('pixel intensities', '0 1 given image'), 'crop_scores') (('pixels', 'artifact'), 'be') (('data point', 'm resolution several 300 same scene'), 'consist') (('Don t', 'options'), 'cpsnr') (('Below we', 'original images'), 'show') (('pixels', 'image'), 'come') (('we', 'learning_rate'), 'warp') (('They', 'file'), 'provide') (('which', 'challenge'), 'say') (('multiple images', 'time'), 'be') (('HR _ u which', 'cPSNR t normalized tcrop_scores'), 'v') (('m resolution 300 data', 'grey scale pixel images'), 'deliver') (('Image registrationThe images', 'other'), 'deliver') (('It', 'python docker image https kaggle github'), 'come') (('function', 'side'), 'have') (('So below we', 'cPSNR score'), 'score') (('PROBA V', 'roughly every 5 days location'), 'provide') (('where details', 'resolution high output'), 'fill') (('they', '16 bit'), 'be') (('which', 'cost'), 'be') (('i', 'image https scikit image'), 'display') (('I', 'right i.'), 'use') (('then consecutive convolutions', 'resolution target high image'), 'need') (('how super resolution', 'domain knowledge'), 'need') (('which', 'image'), 'perform') (('difference', 'model'), 'say') (('SUPER', 'RESOLUTION IMAGE HIGH SIDE'), 'call') (('m sub about 61 pixelshifts', 'necessary super resolution'), 'occur') (('resolution enhancement', 'post acquisition'), 'be') (('I', 'model'), 'be') (('Proba V mission', 'daily basis'), 'provide') (('Super ResolutionSuper 3 resolution', 'image'), 'be') (('HR _ u which', 't t'), 'v') (('Changes', '30 days'), 'record') (('me', 'other experiments'), 'NOTE') (('which', 'higher resolution'), 'take') (('It', '7 May'), 'initiate') (('hence I', 't deep it'), 'be') (('them', 'image relatively typical viewers'), 'format') (('hence this', 'industries'), 'have') (('Then we', 'channel single image'), 'combine') (('train number_of_epochs 200 16 function', 'loss values'), '001') (('I', 'domain'), 'ResolutionAfter') (('Thus super resolution', 'ground'), 'include') (('Next we', 'SR w.'), 'create') "}
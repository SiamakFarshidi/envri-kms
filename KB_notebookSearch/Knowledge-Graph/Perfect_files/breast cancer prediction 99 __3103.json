{"name": "breast cancer prediction 99 ", "full_name": " h1 Data Set Information h2 Attribute Information h1 1 import library h1 2 load and analys data h4 from the first look in our data description we can see that h2 A finding missing values h1 3 feautres selection h4 Diagnosis h2 A correlation map h4 this feautres had a corralation valus 0 07 with the target columns h1 4 data vizualisation h2 Plotting many distributions h2 A diagnosis h2 B concave points worst h2 B concavity mean h2 3 perimeter worst h1 5 machine learning application h2 A split data h2 B Feature Scaling h3 a Logistic Regression h3 b KNN h3 c Support Vector Machines h3 d DecisionTreeClassifier h3 e RANDOM FOREST CLASSIFCATION h3 f ANN neural network h3 g xgboost h3 h catboost ", "stargazers_count": 0, "forks_count": 0, "description": "Bennett Decision Tree Construction Via Linear Programming. com products 9781783980284 graphics 3a298fcc 54fb 42c2 a212 52823e709e30. 97 101 1992 a classification method which uses linear programming to construct a decision tree. Lets remove them 120 5 machine learning application A split data B Feature Scaling a Logistic Regression b KNN c Support Vector Machines d DecisionTreeClassifier e RANDOM FOREST CLASSIFCATION f ANN neural network g xgboost h catboost manipulation data visualiation data default theme drop the id columns transformation of type of the target value to numerical drop this columns Feature Selection Making Confusion Matrix and calculating accuracy score Fit the model Confusion Matrix accuracy score Finding the optimum number of neighbors Training the K Nearest Neighbor Classifier on the Training set Predicting the Test set results Making the confusion matrix and calculating accuracy score Training the Support Vector Classifier on the Training set Predicting the test set results Making the confusion matrix and calculating accuracy score Finding the optimum number of max_leaf_nodes Training the Decision Tree Classifier on the Training set Predicting the test set results Making the confusion matrix and calculating accuracy score Finding the optimum number of n_estimators Training the RandomForest Classifier on the Training set Predicting the test set results Making the confusion matrix and calculating the accuracy score Initialising the ANN Adding the input layer and the first hidden layer Adding the second hidden layer Adding the third hidden layer Adding the fourth hidden layer Adding the output layer Compiling the ANN Training the ANN on the training set Predicting the test set results Making the confusion matrix calculating accuracy_score confusion matrix accuracy Making the confusion matrix and calculating the accuracy score Making the confusion matrix and calculating the accuracy score. 07 with the target columns fractal_dimension_mean texture_se smoothness_se symmetry_se fractal_dimension_se 4. load and analys data like we see all our feautres are numirical values exept the target value diagnosis M malignant B benign we had 569 Rows and 33 columns small data from the first look in our data description we can see that 1. Data Set Information Features are computed from a digitized image of a fine needle aspirate FNA of a breast mass. They describe characteristics of the cell nuclei present in the image. educd math prog cpo dataset machine learn WDBC Attribute Information 1. Relevant features were selected using an exhaustive search in the space of 1 4 features and 1 3 separating planes. The actual linear program used to obtain the separating plane in the 3 dimensional space is that described in K. Unnamed 32 columns is an empty column A finding missing values like we c our data is clean exept the last columns that is empty so we gonna drop it 3. feautres selection Diagnosis 1. data vizualisation Plotting many distributions A diagnosis B concave points_worst B concavity_meanWe can see there are some outliers. B benign 0 A correlation map this feautres had a corralation valus 0. This database is also available through the UW CS ftp server ftp ftp. Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society pp. 0 concavity severity of concave portions of the contour concave points number of concave portions of the contour symmetry fractal dimension coastline approximation 1 https static. A few of the images can be found at Web Link Separating plane described above was obtained using Multisurface Method Tree MSM T K. 5 3 perimeter_worstWe can see there are 2 outliers. B benign is the most frequent value in our target columns2. 3 32 Ten real valued features are computed for each cell nucleus radius mean of distances from center to points on the perimeter texture standard deviation of gray scale values perimeter area smoothness local variation in radius lengths compactness perimeter 2 area 1. Diagnosis M malignant B benign 3. Mangasarian Robust Linear Programming Discrimination of Two Linearly Inseparable Sets Optimization Methods and Software 1 1992 23 34. M malignant 12. ", "id": "midouazerty/breast-cancer-prediction-99", "size": "3103", "language": "python", "html_url": "https://www.kaggle.com/code/midouazerty/breast-cancer-prediction-99", "git_url": "https://www.kaggle.com/code/midouazerty/breast-cancer-prediction-99", "script": "plotly.graph_objects train_test_split plotly.express confusion_matrix xgboost CatBoostClassifier accuracy_score numpy sklearn.svm XGBClassifier seaborn catboost ExtraTreesClassifier preprocessing SVC sklearn.neighbors sklearn.tree sklearn sklearn.linear_model tensorflow matplotlib.pyplot DecisionTreeClassifier metrics sklearn.model_selection pandas RandomForestClassifier LogisticRegression KNeighborsClassifier sklearn.metrics sklearn.ensemble StandardScaler sklearn.preprocessing ", "entities": "(('database', 'UW CS ftp server ftp also ftp'), 'be') (('diagnosis B', 'data many distributions'), 'vizualisation') (('educd math prog cpo dataset machine', 'WDBC Attribute Information'), 'learn') (('that', 'K.'), 'use') (('classification 97 101 method which', 'decision tree'), '1992') (('Web Link Separating plane', 'Multisurface Method Tree MSM T above K.'), 'find') (('They', 'present image'), 'describe') (('3 32 Ten real valued features', 'radius lengths'), 'compute') (('Data Set Information Features', 'breast mass'), 'compute') (('Relevant features', '1 4 features'), 'select') (('confusion matrix', 'accuracy score'), 'remove') (('so we', 'it'), 'be') (('B benign', 'most frequent target'), 'be') (('we', '1'), 'load') (('B correlation feautres', 'corralation'), 'benign') "}
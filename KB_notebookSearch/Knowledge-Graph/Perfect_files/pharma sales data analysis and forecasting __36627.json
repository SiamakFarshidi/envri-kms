{"name": "pharma sales data analysis and forecasting ", "full_name": " h1 Case study univariate time series analysis and forecasting of pharmaceutical products sales data at small scale h1 1 Introduction h1 2 Theoretical background h2 2 1 Time series forecasting h3 2 1 1 ARIMA method h3 2 1 2 Prophet method h3 2 1 3 Neural networks h1 3 Methodology h1 4 Solution discussion h2 4 1 Feature engineering and data preparation h2 4 2 Time series analysis h3 4 2 1 Seasonality analysis h3 4 2 2 Stationarity analysis h3 4 2 3 Regularity analysis h3 4 2 4 Autocorrelation analysis h3 4 2 5 Data distribution analysis h2 4 3 Time series forecasting h3 4 3 1 Baseline forecasting accuracy h4 4 3 1 1 Na\u00efve forecasting h4 4 3 1 2 Average method forecasting h4 4 3 1 3 Seasonal Na\u00efve forecasting h3 4 3 2 ARIMA Forecasting h4 4 3 2 1 Choosing parameters for ARIMA model h4 4 3 2 2 Rolling forecasting with ARIMA model h4 4 3 2 3 Long term forecasting with ARIMA model h4 4 3 2 4 Rolling forecasting with Auto ARIMA model h4 4 3 2 5 Long term forecasting with Auto ARIMA model h3 4 3 3 Prophet forecasting h4 4 3 3 1 Grid search optimization of Prophet hyper parameters h4 4 3 3 2 Rolling forecasts with Prophet h4 4 3 3 3 Long term forecasting with Prophet h3 4 3 4 Forecasting with LSTM h4 4 3 4 1 Long term forecasting with Vanilla LSTM configuration h4 4 3 4 2 Long term forecasting with Stacked LSTM model h4 4 3 4 3 Long term forecasting with Bidirectional LSTM h1 5 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "For Na\u00efve forecasts all forecasts are set to be values of the last observation or ft 1 ot. P 1 if the ACF is positive at lag S else P 0. There are also improved SES methods which consider trends and seasonality. It is integrated I namely it uses differencing see above to make time series stationary within the method. Two different approaches to forecasting problem scoping were adopted. The method computes Akaike s Information Criterion AIC for many ARIMA models and chooses the best configuration. Before each forecast is made the process of optimizing hyper parameters p d q of ARIMA model was carry out. Optimal sets of hyper parameters are then used also for rolling forecasts. Each forecast is set to be equal to the mean of the observed values from the same time in previous seasonal cycles. Approximate or Sample Entropy methods can be used to quantify the regularity and predictability of fluctuations in a time series. Na\u00efve forecasting 4. The model facilitates easy customization and reliable forecasts with default configurations. changepoint_range usually does not have that much of an effect on the performance. MSE was used as metrics for comparing the performance and also as a loss function for LSTM. Average method forecasting 4. Besides p d q parameters of ARIMA SARIMA also considers additional parameters P D Q m P Seasonal autoregressive order. Finally pyramid arima package will be installed in order to use Auto ARIMA method. Thus selected group of drugs 57 drugs is classified to 8 Anatomical Therapeutic Chemical ATC Classification System categories M01AB Anti inflammatory and antirheumatic products non steroids Acetic acid derivatives and related substances M01AE Anti inflammatory and antirheumatic products non steroids Propionic acid derivatives N02BA Other analgesics and antipyretics Salicylic acid and derivatives N02BE B Other analgesics and antipyretics Pyrazolones and Anilides N05B Psycholeptics drugs Anxiolytic drugs N05C Psycholeptics drugs Hypnotics and sedatives drugs R03 Drugs for obstructive airway diseases R06 Antihistamines for systemic useATC codes features are added to the dataset namely a model has been transformed as indicated on the image below and data was resampled to the hourly time series. Main feature of RNNs is that they allow information to persist or they can inform the decision on some classification or regression task in the moment t by using observations or decisions at moments t 1 t 2. Grid search was used as adopted approach for hyper parameters optimization for ARIMA and Prophet model. Feature engineering and data cleaning including strategies for detecting outliers and their treatment code is ommited in this notebook because of the confidentiality issues. A new global Tensorflow session is configured. In all cases even without optimization LSTM models have achieved competitive performance. Its analysis involves understanding various aspects of the time series important for creating meaningful and accurate forecasts. Three different models were tested ARIMA SARIMA for rolling and long term forecast Facebook s Prophet for rolling and long term forecast and Long Short Term Memory LSTM artificial neural network architectures for long term forecast. the uncertainty interval to produce a confidence interval around the forecast. seasonality the repeating short term cycle in the series and 4. We can use Augmented Dickey Fuller ADF test to check stationarity of the data. In practice Prophet should be let to do that alone. Function split_sequence for transforming time series data to data for supervised machine learning problem is provided including constants such as number of previous steps to take into account. Long term forecasting with ARIMA model 4. Long term forecasting with Vanilla LSTM configuration 4. For a linear trending value should be linear. Then research methodology actually a problem neutral time series forecasting pipeline is presented. All warnings will be supressed for the cleaner presentation of this notebook this is a bad practice note that all presented code was tested. Then with optimal set of parameters rolling forecast and long term forecasting was carried out. Below boxplots on a weekly scale are shown for the purpose of exploring the weakly seasonality. If high it will be more flexible but then overfitting is possible. In all other cases 5 past observations were used. For additive series time dependent variable value is equal to the addition of four components namely y t Level Trend Seasonality NoiseIn multiplicative series changes increase or decrease over time y t Level Trend Seasonality NoiseEach time series can be decomposed to its four components by using different methods such as Na\u00efve Loess or STL. This is typically determined by domain experts. Seasonal Na\u00efve method is useful for time series that show seasonality effects. While SARIMA facilitates direct modeling of the seasonal component of time series by considering its own lag order differencing degree MA order and an actual lag SARIMAX provides the extension for using exogenous variables and thus enable multivariate time series forecasting. Typically Pearson coefficient of correlation is used meaning that linear correlation is assessed. Time series forecastingThere are many different methods and approaches to time series forecasting. All MSE metrics will be stored in a dataframe which will be later use for presentation of the overall results and comparison. feature engineering and data preparation 2. Rule of thumb P Q 2 2. This paper is structured into 4 main parts. One series is considered trend stationary if after removing the underlying trend series becomes stationary. In order to get comparable results pseudo random generators of Python Numpy and Tensorflow were set to fixed values. Rule 2 If the lag 1 autocorrelation is zero or negative or the autocorrelations are all small and random then the series does not need a higher order of differencing. Train test split method was used 52 weeks of test data. Baseline accuracy was calculated by using Na\u00efve and Seasonal Na\u00efve for rolling forecasts and Average method for long term ones. ARIMA Forecasting ARIMA method was used to to carry out short term rolling forecast and long term forecasting based on test data. Robert Nau Statistical Forecasting Method is improved with SARIMA Seasonal ARIMA SARIMAX Python implementation was used. Xt 2 Xt 1 yt after determining input vector dimension which gives best accuracies and time series scaling normalization or standardization. Dates of the pension payoff. Feature engineering and data preparation Initial dataset consisted of 600000 transactional data collected in 6 years period 2014 2019 indicating date and time of sale pharmaceutical drug brand name and sold quantity. Data distribution analysisChart with daily sales for different categories of interest is shown below. Theoretical backgroundTime series is a sequence of observations recorded at regular time intervals hourly daily weekly monthly quarterly and yearly. Case study univariate time series analysis and forecasting of pharmaceutical products sales data at small scaleThe objective of the research behind the paper was to validate different methods and approaches related to sales time series data preparation analysis and forecasting with aim to facilitate recommending sales and marketing strategies based on trend seasonality effects and forecasting sales of eight different groups of pharmaceutical products with diverse characteristics such as stationarity seasonality amount of residuals and sales data variance. Finally seasonal Na\u00efve forecast was carried out for the series that has been found as seasonal N02BE R03 and R06. Each of the time series summarizes sales of a group of pharmaceutical products. To some extent the proportion of the residuals when comparing with trend and seasonality can be also illustrated by the rolling means and standard deviation plots above. Sales spikes may be explained by the discounts applied in a short term. As a result of the interviews with pharmacists decision was made that the subject of analyses and forecasting will be actual drug categories instead of the individual drugs. the number of Fourier components each seasonality is composed of. Key performance indicator for forecasting accuracies in both approaches was Mean Squared Error MSE. The data preparation process for LSTM included transforming to stationary time series sequencing time series to supervised problem data shape Xt n_steps. Still analysis and forecasts on a smaller scale such as single distributor pharmacy chain or even individual pharmacy smaller periods such as weeks etc. First short theoretical background for time series analysis and forecasting is provided to inform the reader on the credibility of decisions made in the implementation of this case study. Before fitting all data was standardized rescaled in interval 1 1 and transformed to data for supervised problem. Introducing this feature may facilitate what if forecasting analysis of sales performance during marketing campaigns involving price reductions. This plot is sometimes called a correlogram or an autocorrelation plot. IntroductionOn a larger scale the sales forecasting in pharmaceutical industry is typically done by using Na\u00efve model where the forecasted values equal values in the previous period with added factor of growth which is specifically defined for different regions markets categories of products etc. The lag at which the PACF cuts off is the indicated value of p. Daily weekly and annual seasonality analysis were proven useful for identifying the periods in which special sales and marketing campaigns could be implemented except for N05B and N05C categories of drugs which did not exhibit significant regularities. That means also that the curve is smoother. In the remainder of this notebook final datasets will be used. Therefore during testing prediction in a timestep t is based on the model which fits the training set consisting of observations in timesteps 0 t 1 or f t f o 0 t 1. Time series analysis Time Series Analysis included seasonality stationarity autocorrelation regularity and data distribution analysis. Grid search optimization of Prophet hyper parametersBefore actual forecasting the optimal set of hyper parameters is determined by using grid search method. m of 12 for monthly data suggests a yearly seasonal cycle. Prophet model is tuned by using the following hyper parameters growth. Sales spikes are visible at the dates of state pensions payoff. All methods in all cases with exception of Prophet N02BE outperform reference benchmarks Naive and Seasonal Naive forecasts. See Theoretical background section for explanation of those methods. Also info messages are supressed for the same reason. Possible values of regression parameters of ADF are c constant only default ct constant and trend ctt constant and linear and quadratic trend nc no constant no trendAugmented Dickey Fuller ADF test have shown that all data but N02BA P value 0. Decomposition is especially useful for trend and uncertainty variance of residuals typically corresponds to randomness analysis. All these analyses and forecasts are made on a small scale for a single distributor pharmacy chain or even individual pharmacy. In order to get reproducible results in forecasting with LSTM following values are fixed seed value PYTHONHASHSEED environment variable Python s numpy s and Tensorflow s built in pseudo random generators. For that reason grid search optimization method was applied where different combinations of the hyper parameters were used to calculate MSE and then the combination producing the least MSE was chosen as optimal. Function seasonal_decompose can be used for analysis of the portions of each component of time series. changepoint_prior_scale is there to indicate how flexible the changepoints are allowed to be. One time series can be assumed to be additive or multiplicative although in a real world series that fit one or another model rarely exist. Long term forecasting with Bidirectional LSTM 5. Some common rules for choosing d are Rule 1 If the series has positive autocorrelations out to a high number of lags then it probably needs a higher order of differencing. Grid search optimization is carried out for both approaches in forecasting rolling and long term. Basic time series forecasting assumes regressing the observation at the time t on the observations in the previous time steps ft e1ot 1 e2ot 2 enot n. Na\u00efve forecasts are considered optimal when data follow a random walk and they can be used only in walk forward or rolling forecasts not in long term forecasting. An easy way to visualize these trends is with rolling means at larger time scales. In latter case the cap maximum value data will reach and floor minimum value data will reach of your predictions need to be provided. It is highly likely that the forecasts could be significantly improved by expanding the problem scope to multivariate time series forecasting and by including explanatory variables such as Weather data. N02BE and N05B charts though showing the similar trends are suppresed because of the larger scale which makes the other illustrations less readable. Q Seasonal moving average order. Analysis below shows 30 day and 365 day rolling mean and 30 day rolling standard deviation of sales data. Another stores actual time series data and is labeled as y. Time series data often exhibit some slow gradual variability in addition to higher frequency variability such as seasonality and noise. Long term forecasting with Auto ARIMA model 4. Paper presents only research work related to univariate time series analysis while potential candidates for explanatory input variables were also identified and shortly elaborated. Hyper parameters were optimized by using three approaches manually with ACF PACF plot analysis Python s statsmodels function and grid search optimization. guide very important decisions related to resource and procurement planning what if analyses return on investment forecasting business planning and others. If the data series is stationary d 0. MethodologyThe methodology for implementing this case study follows the typical time series forecasting pipeline consisting of three major phases 1. Longterm forecasting will be carried out by using 7 methods Average ARIMA AutoARIMA Prophet Vanilla LSTM Stacked LSTM Bidirectional LSTM. Number of past observations tested in input sequences was either 10 or 5. The main research question we tackle is related to exploring the feasibility of use of modern time series forecasting methods in pharmaceutical products sales forecasting on a smaller scale. D 1 if the series has a stable seasonal pattern over time. Components required for forecasting with LSTM are then imported. Confidence intervals are drawn as a cone. To conclude time series analyses and forecasts have guided potentially useful conclusions and recommendations to the pharmacy. Finally the discussion brings the description of actual results and some suggestions to the sales department driven by the result of the data analysis. Long term forecasting with Stacked LSTM model 4. National holidays as non working days with seasonal patterns similar to Sundays are expected to disrupt daily sales. It can be visually determined by plotting rolling statistics rolling means and variances. D 0 if the series has an unstable seasonal pattern over time. According to the authors Prophet is successful for forecasting data with strong human scale seasonality day of week time of year reasonable number of missing data and or outliers historical trend changes non linear trends with saturation at least one year of observations known holidays. The best results were achieved with training the model in 400 epochs. Relu activation function was used optimizer was Adam and loss function was Mean Squared Error. For long term forecasting Prophet and LSTM models have shown significantly better performance then benchmarks in the time series with seasonality. These plots are often called Autocorrelation Function ACF plots or correlograms. q moving average order size of the moving average window. It can be visually determined by plotting rolling statistics rolling means and variances or by using Augmented Dickey Fuller ADF or Kwiatkowski Phillips Schmidt Shin KPSS test. 05 the null hypothesis is rejected and series is considered as stationary. 5 or more negative the series may be overdifferenced. Seasonality analysisThe seasonality patterns can be explored in detail by using boxplots. Time series forecasting Forecasting models were fitted with weekly time series data with dataset of 302 rows. Effectiveness of three forecasting methods namely ARIMA Facebook s Prophet and Long Short Term Memory LSTM neural networks was investigated. Forecasting with LSTMLong term forecasting validation has been done with three LSTM configurations Vanilla LSTM Stacked LSTM and Bi directional LSTM. Seasonal decomposition can be also used for forecasting by building the model by using any other approach on the time series data with subtracted residual component as calculated by any of the decomposition methods such as STL. KPSS is used to test for trend stationarity. Hyperparameters of one ARIMA model are p lag order number of observations in prior time steps included in the model. Rolling forecasts with Prophet 4. ARIMA methodARIMA Auto Regressive Integrated Moving Average models are most commonly used tools for forecasting univariate stationary time series. Plot shows the lag value along the x axis and the correlation on the y axis between 1 and 1. Second average method was used to forecast. Another quite successful classical forecasting method is Simple Exponential Smoothing SES where forecasts are calculated as ot 1 \u03b1ot \u03b1 1 \u03b1 ot 1 \u03b1 1 \u03b1 2ot 2. If the ACF of the differenced series displays a sharp cutoff and or the lag 1 autocorrelation is negative then non zero MA factor should be added to the model. This implementation has built in stepwise optimizer which chooses optimal set of parameters p d q for non seasonal and p d q P D Q for seasonal series namely N02BE R03 and R06. Sudden declines in all categories could be explained by extreme weather conditions such as heavy rain thunderstorms and blizzards. Stacked LSTM is architecture with two or more hidden layers of LSTM units stacked one on top of another. \u03b1 1 \u03b1 not n with 0 \u03b1 1. First Na\u00efve forecasting was done and results presented. Also outliers are detected in consultation with pharmacy staff and treated by first imputing the missing data and then by imputing representative data by using several methods. By default this is set to a 95 confidence interval suggesting that correlation values outside of this code are very likely a correlation. Rolling forecast model can be used for short term resource planning and planning the procurement of stock of pharmaceutical products. In this research three different LSTM architectures were used. First one implements so called rolling forecast namely forecasting the sales in the next week by using the model trained with all historical data. Finally it uses the dependency between an observation and a residual error from a moving average model applied to lagged observations MA. Typically a time series data embodies each of the four different components 1. Stationarity of time series is the property of exhibiting constant statistical properties over time for example mean variance autocorrelation. Rolling forecasting with Auto ARIMA model 4. Here the forecast is equal to a weighted average of the past observations where weights decrease exponentially as we go back in time. First annual weekly and daily data analysis were done with objective to make potentially useful conclusions and propositions for improving sales and marketing strategies. The higher the entropies are the more difficult is to forecast the time series. Q 1 if the ACF is negative at lag S else Q 0. It is important to note that AIC tend not to be a good guide to selecting the appropriate order of differencing d of a model but only for selecting the values of p and q. trend long term increasing or decreasing value in series 3. Each of the method is complemented with two optimization and validation approaches relevant for short term so called rolling forecast scenario and long term forecasting. Three forecasting methods were tested ARIMA Prophet and LSTM. Forecasting was carried out at the weekly scale. Long term forecasts validation is based on MSE of one year forecast compared to actual observations. Some weekly seasonality is visible. However AIC is not used to score accuracy of the forecasting methods in this research. Next the actual implementation is presented by highlighting the steps made in following the proposed methodology in the case of pharmaceutical products sales data analysis and forecasting. The simplest methods which are typically used for determining baseline forecasting performance are Average Na\u00efve and Seasonal Na\u00efve those models are often used as benchmark models. Grid search optimization for rolling forecast produced the following best combinations of the hyper parameters Grid search optimization for long term forecast produced the following best combinations of the hyper parameters From the optimization stand of point some series are considered as so called white noise random time series data. This is the parameter that has been adopted. Regularity analysisFor calculating regularity and predictability of time series Approximate Entropy test was used. Time series data are collected from the Point of Sale system of a single pharmacy in period of 6 years. In latter case the cap maximum value data will reach and floor minimum value data will reach of predictions need to be provided. In general the partial correlation between two variables is the amount of correlation between them which is not explained by their mutual correlations with a specified set of other variables. Mean Absolute Percentage Error MAPE was provided only as an illustration because data on different groups of pharmaceutical products were on significantly diverse scales. seasonality_prior_scale parameter. The potential strength of time series prediction models is determined by autocorrelation correlation between what is considered as output variable Ot and input variables prior observations. Autocorrelation analysisAutocorrelation analysis illustrates the potential for time series data prediction. Rolling forecasting with ARIMA model 4. Trends and seasonality can be explored in time series decomposition view based on 30d rolling means. 249 in the series were stationary with maximum confidence. If the dataset is split to train and test sets then Average of training set is used as a forecast. exploratory data analysis time series analysis and 3. In order to define the baseline forecasting accuracy to improve from three tests were performed. This model can be used for business planning and making decisions of strategic nature. Seasonality is clearly confirmed for the categories of R03 R06 and N02BE. Model uses the dependency relationship correlation between an observation and some number of lagged observations AR in the past. This is especially useful when determining uptake of residuals in data based on the decomposed data. Kwiatkowski Phillips Schmidt Shin KPSS test found the trend non stationarity in N02BE R03 and R06. Neural networks Long Short Term Memory LSTM are a form of Recurrent Neural Networks RNN deep learning architectures that are characterized by the use of LSTM units in hidden layers. The main problem in smaller scale time series analyses and forecasts are significant uncertainties and sales performance very close to random making the forecasts with accuracies above thresholds as defined by Na\u00efve methods difficult to achieve. Following transforms for stationarizing data for methods which do not work well with non stationary data for example ARIMA are available 1 de trending removing the underlying trend in the series 2 differencing seasonal or cyclic patterns are removed by subtracting periodical values 3 logging linearizing trend with exponential function. As difficulty increases the time series converge to what is called white noise series of random numbers with mean equals 0. Forecasts have proven better than Na\u00efve methods and in acceptable intervals for long term planning. Train test split validation with one last year of data 52 rows was used for testing. However unlike downsampling where the time bins do not overlap and the output is at a lower frequency than the input rolling windows overlap and roll along at the same frequency as the data so the transformed time series is at the same frequency as the original time series. If the P Value of ADF test is less than 0. Baseline forecasting accuracyIn this subsection three summaries of the reference benchmarks namely Na\u00efve methods are provided. The lag at which the ACF cuts off is the indicated value of q. N02BE R03 and R06 series were found to exhibit annual seasonality. m The number of time steps for a single seasonal period. Although this model fails when the market saturates in general and on a larger scale it has proven as successful. Future work on univariate time series forecasting includes increasing the number of data exploring different other accuracy metrics optimization of hyper parameters for LSTM models and testing other architectures such as CNN LSTM and ConvLSTM. A plot of the autocorrelation of a time series by lag is called the AutoCorrelation Function ACF. level mean of time series data 2. For short term forecasts or so called rolling forecast validation or walk forward model validation train test split validation is performed in iterative fashion where observations are added to the training dataset after every individual weekly sales prediction while the model is fitted in each iteration. Seasonal ARIMA SARIMA method was tested by using Auto ARIMA implementation. Some rules for defining the initial set of parameters often used in a literature are as follows m is equal to the ACF lag with the highest value typically at a high lag. ADF test assumes that the null hypothesis is the time series possesses unit root and is non stationary. For example if we are regressing a variable Y on other variables X1 X2 and X3 the partial correlation between Y and X3 is the amount of correlation between Y and X3 that is not explained by their common correlations with X1 and X2. This parameter will again allow your seasonalities to be more flexible. Another visualization that can be useful for discovering seasonality patterns is related to rolling window means. For series with larger variances and randomness N05B and N05C and simpler Vanilla LSTM model 10 past observations produced better forecasting accuracy. ConclusionFor rolling forecast ARIMA method Auto ARIMA for series with seasonal character outperforms Prophet and is considered as a best candidate for short term sales forecasting. Mean Absolute Percentage Error MAPE is also measured for each of the scenarios. In other words how much can the changepoints fit to the data. In Average method the forecasts of all future values are equal to mean of the historical data. Finally data is then rescaled to weekly time series and stored. Some additional conclusions R03 and N05C has more outliers that the others indicating that their sales is more difficult to predict. Stationarity analysisStationarity of time series is the property of exhibiting constant statistical properties over time for example mean variance autocorrelation. Similar to downsampling rolling windows split the data into time windows and the data in each window is aggregated with a function such as mean median sum etc. Image below shows trends for each of the drug categories represented by the 365 d rolling means for each of those categories. In stationary time series the mean of the series variance of the series and covariance of the i th term and the i m th term should not be a function of time. Pearson coefficient is used to measure autocorrelation. Chart with weekly sales for different categories of interest was shown below. Three LSTM architectures were tested Vanilla LSTM Stacked LSTM and Bidirectional LSTM. Prophet model is tuned by using the following hyper parameters only selected parameters are noted growth. Time series analysis had two fold objective. Rolling window operations are another important transformation for time series data. The changepoints parameter is used when the changepoint dates are supplied instead of having Prophet determine them. The volume of this uptake implies the predictability of the time series higher the residuals lower the predictability. For all series entropy values were higher than 1 indicating low predictability with highest values for M01AE M01AB and N02BA. Long term forecasting with Prophet 4. Autocorrelation plots graphically summarize the strength of a relationship of an observation in a time series with observations at prior time steps with respect to the confidence interval typically 95 of confidence. Based on the problem and objective formal definition the data acquired from the sales information system are cleaned feature engineering approach was defined and all data are transformed to hourly time series consisting of aggregate sales among different classes of pharmaceutical products in hourly time periods namely anti inflammatory and antirheumatic products M01AB M01AE analgesics and antipyretics N02BA N02BE psycholeptics drugs N05B N05C drugs for obstructive airway diseases R03 and antihistamines for systemic use R06. Then stationarity autocorrelation and predictability analysis of the time series in individual groups was analyzed to infer the initial set of parameters for implementing the forecasting methods. Another approach is related to long term forecasting for example forecasting the future period of one year by using the model trained with historical data. D Seasonal difference order. LSTM was applied only for long term forecasting. However key improvements in sales forecasting are expected from reducing the uncertainty of the models by expanding to multivariate time series forecasting problem as explained above. Prophet forecasting Prophet model is fited with data in two columns where first one contains time information and is labeled as ds. Average method was used as a baseline for long term forecasting while Na\u00efve and Seasonal Na\u00efve were used for rolling forecasts. Forecasting results are validated by using two approaches short term and long term forecasts. In specific we benchmark the accuracies achieved with those methods against the performances of basic Na\u00efve Seasonal Na\u00efve and Average methods. NOTE this is illustrative example actual optimization is carried out with larger intervals of hyper parameters values. Prophet methodProphet is Facebook s additive regression model that includes linear or logistic trend yearly seasonal component modeled using Fourier series and user provided list of important holidays. If the lag 1 autocorrelation is 0. No optimization of hyper parameters was carried out. Solution discussionSolution will be using the set of Python libraries namely numpy for computational tasks pandas for data structures matplotlib for plotting and others libraries used for forecasting with LSTM are imported later. Seasonal Na\u00efve forecasting 4. noise or residuals random variations in the series. Autocorrelation plots graphically summarize the strength of a relationship with an observation in a time series with observations at prior time steps. Vanilla LSTM is made of a single hidden layer of LSTM units and an output layer used to make a prediction. This intermediary series is used for the formal definition of anomalies and their identification. Sales of antirheumatic drugs in M01AB and M01AE categories could be affected by the changes of atmospheric pressure. Typically it is equal to the lag at which PACF cuts off the cone of the confidence interval d differencing degree number of times that the raw observations are differenced. Those are series for whom the best result was achieved with p 0 d 0 and q 0. Mean squared error is used instead. Choosing parameters for ARIMA modelFirst method arma_order_select_ic was used to determine initial p and q parameters. In case that time series is non stationary it needs to be transformed. Thus the following analysis is relevant only for data with normal Gaussian distribution. While Prophet model is used both for rolling forecasts and long term forecasting optimization of hyper parameters is carried out only for long term forecasts. Minor autocorrelation is observed at ACF Auto Correlation Function and PACF Partial Auto Correlation Function plots for all series with exception of N05C sales. Research work behind the paper considers 8 time series with different statistical features. Rolling forecasting will be carried out by using 5 methods Naive Seasonal Naive ARIMA AutoARIMA Prophet. In bidirectional LSTM architecture model learns the input sequences both forward and backward. Another useful tool for determining autocorrelation are Partial Autocorrelation Function PACF plots. Some common rules for choosing initial AR and MA values p q found in the literature are If the PACF of the differenced series displays a sharp cutoff and or the lag 1 autocorrelation is positive then non zero AR factor should be added to the model. PACF plots highlight autocorrelation between observation ot and prior observations oi without taking into account correlations in the time steps in the interval t i. ", "id": "milanzdravkovic/pharma-sales-data-analysis-and-forecasting", "size": "36627", "language": "python", "html_url": "https://www.kaggle.com/code/milanzdravkovic/pharma-sales-data-analysis-and-forecasting", "git_url": "https://www.kaggle.com/code/milanzdravkovic/pharma-sales-data-analysis-and-forecasting", "script": "keras.layers keras.models ParameterGrid IPython.display ApEn ARIMA plot_pacf numpy seaborn _phi evaluate_models sklearn.preprocessing array Dense statsmodels.tsa.arima_model adfuller split_sequence Bidirectional mean_absolute_percentage_error mean_absolute_error LSTM tensorflow evaluate_arima_model matplotlib.pyplot MinMaxScaler plot_acf Sequential statsmodels.api sklearn.model_selection pandas seasonal_decompose statsmodels.tsa.seasonal statsmodels.tsa.stattools statsmodels.graphics.tsaplots _maxdist mean_squared_error kpss display HTML concat sklearn.metrics auto_arima pyramid.arima ", "entities": "(('Plot', 'between 1'), 'show') (('m', 'yearly seasonal cycle'), 'suggest') (('Forecasting results', 'two approaches short term'), 'validate') (('potential candidates', 'input explanatory variables'), 'present') (('One series', 'trend stationary underlying series'), 'consider') (('arima Finally pyramid package', 'Auto ARIMA method'), 'instal') (('performance Key indicator', 'approaches'), 'be') (('52 rows', 'testing'), 'split') (('LSTM three different architectures', 'research'), 'use') (('SARIMA Seasonal ARIMA method', 'Auto ARIMA implementation'), 'test') (('outliers historical trend', 'known holidays'), 'be') (('analyses', 'investment forecasting business planning'), 'guide') (('Average Seasonal models', 'often benchmark models'), 'be') (('Autocorrelation analysisAutocorrelation analysis', 'time series data prediction'), 'illustrate') (('Forecasts', 'term long planning'), 'prove') (('However AIC', 'research'), 'use') (('easy way', 'time larger scales'), 'be') (('Absolute Percentage Error Mean MAPE', 'scenarios'), 'measure') (('psycholeptics drugs', 'use systemic R06'), 'clean') (('Finally discussion', 'data analysis'), 'bring') (('Autocorrelation plots', 'confidence'), 'summarize') (('forecast Rolling model', 'pharmaceutical products'), 'use') (('yearly seasonal component', 'important holidays'), 'be') (('Finally data', 'time then weekly series'), 'rescale') (('changepoints', 'data'), 'fit') (('what', 'price reductions'), 'facilitate') (('they', 'moments'), 'be') (('This', 'domain typically experts'), 'determine') (('Analysis', 'rolling sales 365 30 day rolling standard data'), 'show') (('series', 'noise time series so called white random data'), 'produce') (('However key improvements', 'problem'), 'expect') (('Sales', 'atmospheric pressure'), 'affect') (('ARIMA Forecasting ARIMA method', 'term test long data'), 'use') (('Image', 'categories'), 'show') (('Next actual implementation', 'products sales data pharmaceutical analysis'), 'present') (('Function seasonal_decompose', 'time series'), 'use') (('Seasonal decomposition', 'such STL'), 'use') (('Data distribution analysisChart', 'interest'), 'show') (('Sales spikes', 'short term'), 'explain') (('Na\u00efve', 'Seasonal rolling forecasts'), 'use') (('residuals', 'predictability'), 'imply') (('info Also messages', 'same reason'), 'supresse') (('work', 'CNN such LSTM'), 'include') (('5 past observations', 'other cases'), 'use') (('it', 'general larger scale'), 'fail') (('floor value minimum data', 'predictions'), 'reach') (('we', 'smaller scale'), 'related') (('Model', 'past'), 'use') (('s', 'pseudo random generators'), 'be') (('output', 'autocorrelation correlation'), 'determine') (('This', 'decomposed data'), 'be') (('useful tool', 'autocorrelation'), 'be') (('Long term', 'ARIMA model'), 'forecasting') (('Baseline accuracy', 'term Average long ones'), 'calculate') (('MA then zero factor', 'model'), 'add') (('Also outliers', 'several methods'), 'detect') (('which', 'other variables'), 'be') (('practice bad presented code', 'notebook'), 'supresse') (('model', 'default reliable configurations'), 'facilitate') (('term forecasts Long validation', 'actual observations'), 'base') (('time transformed series', 'time original series'), 'be') (('data', 'such mean median sum'), 'split') (('Confidence intervals', 'cone'), 'draw') (('m', 'typically high lag'), 'be') (('249', 'maximum confidence'), 'be') (('Grid search optimization', 'approaches'), 'carry') (('optimization', 'hyper parameters'), 'carry') (('methods', 'N02BE outperform reference Seasonal Naive forecasts'), 'benchmark') (('what', 'mean equals'), 'increase') (('that', 'hidden layers'), 'network') (('Prophet', 'seasonality'), 'show') (('First short theoretical background', 'case study'), 'provide') (('data First annual weekly analysis', 'sales strategies'), 'do') (('below data', 'time hourly series'), 'classify') (('Train test split method', 'test 52 weeks data'), 'use') (('2 seasonal patterns', 'exponential function'), 'follow') (('instead Prophet', 'them'), 'use') (('method', 'best configuration'), 'compute') (('Kwiatkowski Phillips Schmidt Shin KPSS test', 'N02BE R03'), 'find') (('m th term', 'time'), 'th') (('Rolling forecasting', '5 methods'), 'carry') (('results comparable pseudo random generators', 'fixed values'), 'set') (('highly forecasts', 'Weather such data'), 'be') (('Prophet model', 'noted growth'), 'tune') (('analyses', 'distributor pharmacy single chain'), 'make') (('Sudden declines', 'rain such heavy thunderstorms'), 'explain') (('1 series', 'time'), 'd') (('intermediary series', 'anomalies'), 'use') (('sales', 'more outliers'), 'have') (('which', 'seasonal series'), 'build') (('Thus following analysis', 'normal Gaussian distribution'), 'be') (('Time series analysis', 'two fold objective'), 'have') (('Time series', '302 rows'), 'fit') (('that', 'seasonality effects'), 'be') (('Feature engineering cleaning', 'confidentiality issues'), 'ommite') (('which', 'timesteps'), 'base') (('that', 'N02BE seasonal R03'), 'carry') (('then combination', 'least MSE'), 'apply') (('data preparation process', 'sequencing time series'), 'include') (('Time series data', 'such seasonality'), 'exhibit') (('Choosing', 'initial p parameters'), 'use') (('study', 'residuals'), 'be') (('Optimal sets', 'then also rolling forecasts'), 'use') (('Auto ARIMA ARIMA', 'term sales short forecasting'), 'method') (('specific we', 'Na\u00efve Seasonal basic Na\u00efve'), 'benchmark') (('actual optimization', 'values'), 'NOTE') (('Stacked LSTM', 'another'), 'be') (('SES also improved which', 'trends'), 'be') (('preparation Feature engineering Initial dataset', 'quantity'), 'consist') (('First one implements', 'historical data'), 'call') (('Sample Approximate methods', 'time series'), 'use') (('Longterm forecasting', '7 methods'), 'carry') (('stores', 'time series actual y.'), 'label') (('Chart', 'interest'), 'show') (('Auto Integrated Moving ARIMA Regressive Average models', 'time univariate stationary series'), 'use') (('backgroundTime Theoretical series', 'observations'), 'be') (('Forecasting', 'weekly scale'), 'carry') (('Autocorrelation plots', 'time prior steps'), 'summarize') (('seasonality', 'Fourier components'), 'compose') (('stationarity Then autocorrelation', 'forecasting methods'), 'analyze') (('Each', 'forecast so rolling scenario'), 'complement') (('window Rolling operations', 'time series important data'), 'be') (('that raw observations', 'times'), 'be') (('Seasonality analysisThe seasonality patterns', 'boxplots'), 'explore') (('Dickey Fuller ADF quadratic constant trendAugmented test', 'data'), 'be') (('forecast', 'previous seasonal cycles'), 'set') (('then it', 'differencing'), 'be') (('forecasts', 'historical data'), 'be') (('ACF', 'indicated q.'), 'be') (('Prophet model', 'term only long forecasts'), 'carry') (('Each', 'pharmaceutical products'), 'summarize') (('which', 'significant regularities'), 'prove') (('Two different approaches', 'problem scoping'), 'adopt') (('P Value', 'ADF test'), 'be') (('model', 'iteration'), 'perform') (('KPSS', 'trend stationarity'), 'use') (('forecasts', 'last observation'), 'set') (('non it', 'case'), 'in') (('they', 'term long forecasting'), 'consider') (('that', 'X1'), 'be') (('Seasonality', 'R03 R06'), 'confirm') (('boxplots', 'weakly seasonality'), 'show') (('Minor autocorrelation', 'N05C sales'), 'observe') (('other illustrations', 'larger scale'), 'supprese') (('that', 'one model'), 'assume') (('MethodologyThe methodology', 'three major phases'), 'follow') (('conclude', 'pharmacy'), 'guide') (('Function split_sequence', 'account'), 'provide') (('Number', 'input sequences'), 'be') (('Research work', 'different statistical features'), 'consider') (('Hyper parameters', 'ACF PACF plot manually analysis'), 'optimize') (('which', 'time normalization'), 'xt') (('data', 'significantly diverse scales'), 'provide') (('1 ACF', 'else 0'), 'p') (('1 ACF', 'lag S else Q'), 'q') (('forecasts', 'Na\u00efve methods'), 'be') (('changepoint_range', 'performance'), 'have') (('paper', '4 main parts'), 'structure') (('Robert Nau Statistical Forecasting Method', 'SARIMA SARIMAX Python Seasonal ARIMA implementation'), 'improve') (('Decomposition', 'randomness typically analysis'), 'be') (('process', 'ARIMA model'), 'make') (('Long Short Term namely Facebook neural networks', 'forecasting three methods'), 'ARIMA') (('term long forecasting', 'forecast'), 'carry') (('trend long term', 'series'), 'increase') (('linear correlation', 'correlation'), 'use') (('which', 'products'), 'do') (('series Typically time data', 'four different components'), 'embodie') (('proportion', 'also rolling means'), 'illustrate') (('Finally it', 'observations lagged MA'), 'use') (('Stationarity analysisStationarity', 'variance mean autocorrelation'), 'be') (('AR then non zero factor', 'model'), 'be') (('Stationarity', 'variance mean autocorrelation'), 'be') (('Sales spikes', 'state pensions payoff'), 'be') (('approach', 'historical data'), 'relate') (('Time series data', '6 years'), 'collect') (('We', 'data'), 'use') (('that', 'window rolling means'), 'relate') (('randomness Vanilla LSTM simpler 10 past observations', 'forecasting better accuracy'), 'produce') (('actual optimal set', 'grid search method'), 'forecast') (('0 series', 'time'), 'D') (('Prophet model', 'parameters growth'), 'tune') (('It', 'visually rolling statistics rolling means'), 'determine') (('where first one', 'ds'), 'fit') (('best results', '400 epochs'), 'achieve') (('Forecasting', 'LSTM three configurations'), 'do') (('final datasets', 'notebook'), 'use') (('subject', 'drug actual instead individual drugs'), 'make') (('plot', 'lag'), 'call') (('AIC', 'p'), 'be') (('analysis', 'important meaningful forecasts'), 'involve') (('also additional parameters', 'ARIMA SARIMA'), 'consider') (('LSTM', 'term only long forecasting'), 'apply') (('tasks namely computational pandas', 'LSTM'), 'use') (('Grid search', 'ARIMA model'), 'use') (('ADF test null hypothesis', 'time series unit root'), 'assume') (('Hyperparameters', 'model'), 'be') (('Time series', 'time series forecastingThere many different forecasting'), 'be') (('time above series', 'method'), 'integrate') (('The higher entropies', 'time more difficult series'), 'be') (('time series Basic forecasting', 'enot ft e1ot 1 e2ot 2 n.'), 'assume') (('which', 'overall results'), 'store') (('PACF', 'indicated p.'), 'be') (('forecasting Three methods', 'Prophet'), 'test') (('then Average', 'forecast'), 'use') (('exponentially we', 'back time'), 'be') (('LSTM Three architectures', 'LSTM LSTM'), 'test') (('Time series analysis Time Series Analysis', 'seasonality stationarity distribution autocorrelation regularity analysis'), 'include') (('It', 'Dickey Fuller Kwiatkowski Phillips Schmidt Shin KPSS Augmented ADF test'), 'determine') (('time series forecasting neutral pipeline', 'actually problem'), 'present') (('Level Trend Seasonality NoiseEach time t series', 'Na\u00efve such Loess'), 'be') (('Vanilla LSTM', 'output prediction'), 'make') (('Long term', 'Bidirectional LSTM'), 'forecasting') (('correlation values', 'outside code'), 'set') (('Components', 'LSTM'), 'require') (('National holidays', 'daily sales'), 'expect') (('MSE', 'LSTM'), 'use') (('R03 series', 'annual seasonality'), 'find') (('best result', '0 0 0'), 'be') (('Simple Exponential Smoothing where forecasts', '1 ot'), 'be') (('entropy values', 'M01AE M01AB'), 'be') (('lag actual SARIMAX', 'multivariate time series thus forecasting'), 'provide') (('model', 'strategic nature'), 'use') (('Prophet', 'that'), 'let') (('Three different models', 'Long Short Term Memory network term LSTM artificial neural long forecast'), 'test') (('Trends', '30d rolling means'), 'explore') (('then series', 'differencing'), 'rule') (('Pearson coefficient', 'autocorrelation'), 'use') "}
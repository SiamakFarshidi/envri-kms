{"name": "getting started image processing basics ", "full_name": " h2 Basic Solution ", "stargazers_count": 0, "forks_count": 0, "description": "Reading the image We will be using the same example. The image has been read in the BGR colorspace. e it primarily contains only black and white. For more information https en. We have a third dimension as every pixel is represented by it s B G and R components. We reduced a dimension when we transformed from the BGR colorspace to grayscale. Since digital images are displayed using a combination of red green and blue RGB colors each pixel has three separate luminance values. Otsu s method exhibits relatively good performance if the histogram can be assumed to have bimodal distribution and assumed to possess a deep and sharp valley between two peaks source https en. It s extrememly hard to tell if there s a difference. The nuclei that are closer to one another get clustered to form one nuclei. In that respect KMeans may work better on images that aren t particularly grayscale or on images where there is no sharp contrast in the intensity values between objects of interest and the background What are some useful edge detection algorithms to create boundaries between nuclei that are extremely close to one another How do we as humans identify objects in an image We indeed take it for granted but if we think of objects as anything that has a fixed shape and size and is prominent with respect to the background what is the technical or computer definition of these terms This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. Importing the other necessary libraries Importing OpenCV the computer vision library Glob the training data and load a single image path To read the image To get rid of the x ticks and y ticks on the image axis To see the structure of the image let s display one row of the image matrix To transfrom the colorspace from BGR to grayscale so as to make things simpler To plot the image cmap has been used as matplotlib uses some default colormap to plot grayscale images To get rid of the x ticks and y ticks on the image axis To understand this further let s display one entire row of the image matrix Okay let s look at the distribution of the intensity values of all the pixels This is to flatten the matrix and put the intensity values of all the pixels in one single row vector To zoom in on the distribution and see if there is more than one prominent peak To plot the original image and mask side by side Let s see if K Means does a good job on this data 2 as we re still trying to seperate the lighter coloured nuclei from the darker coloured background To check if there s any difference Since we need to create a seperate mask for every nucelus let s store the masks in an iterable like a list We need to iterate from 1 as ndimage. Putting everything together The submission scored 0. label encodes every object starting from number 1 To see one such mask Function for rle encoding. Transforming the colorspace removes all color information leaving only the luminance of each pixel. Now there could be more nuclei than that as some nuclei have been combined into one and our mask hasn t been able to identify all the nuclei especially the ones in the top right corner. Around the 500 400 mark the three nuclei have been all combined together to form one cluster. We can try out something different i. Any layer of complexity that we add onto this should better this score failing which it is absolutely useless. This is the format required by the competition. label function example of 1 1 1 0 0 1 1 running RLE would give us 0 3 5 2 which means 3 pixels from the zeroth pixel inclusive and 2 pixels from the 5th pixel we see a series of 1sCredit to Kaggle user rahlkin https www. label function which labels features pixels in an array based on their interconnectedness. In the file named stage1_train_labels. However the 2 seperate spots in the top right corner get labelled as 2 different objects. zip we have the image IDs in one column and the Run Length Encoded RLE vector for one such mask i. label on this would give us 1 1 1 0 0 2 2 signifying the fact that there are 2 distinct objects in the row vector. These spots should have their labels KMeans Otsu set to 0 if their sizes are too small. So we need to seperate them using some edge detection algorithm like convolution with a sobel filter or canny edge detector as suggested by Ramsu Now for this competition we need to have a seperate mask for every nucleus. e for one nucleus in the other column. Why did this happen This is because grayscale is a range of monochromatic shades from black to white. We would expect this to occur as the nuclei cover a smaller portion of the picture as compared to the background which is primarily black. In simpler terms An RGB color can be understood by thinking of it as all possible colors that can be made from three colored lights for red green and blue. Otsu s method named after Nobuyuki Otsu is used to automatically perform clustering based image thresholding or the reduction of a graylevel image to a binary image. The function returns the labeled array and the number of distinct objects it found in the array. If these images were to appear in a newspaper column titled Spot the difference between except the obvious colour difference it would have had people scratch their heads in frustration. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. e a different picture in future work. org wiki RGB_color_space Basic SolutionIt is important to understand the structure of the image here. Run Length Encoding Every mask for every nucleus requires an RLE vector. Some important questions to ask are Will we achieve a satisfactory performance by converting all pictures to grayscale What are the different types of pictures in the dataset What are the numerous ways to seperate the background from objects of interest Otsu s method requires computing a graylevel histogram for us to find the optimum seperation value. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. where function to encode all pixels with an intensity value the threshold value as 1 and all other pixels as 0. T sets Fortran order down then right Running RLE on the last label_mask in label_array gives us Now defining a function that does is applicable to all images Reading the image To extract the image ID Reading it in OpenCV Converting everything to grayscale from BGR To remove the background Using Otsu s method to seperate the foreground objects from the background Coding objects with intensity values higher than background as 1 Extracting connected objects labels gives us the label of the different objects in every image starting from 1 and nlabels gives us the total number of objects in every image Iterating through every object label Individual masks for every nucleus RLE for every mask Return the dataframe Defining a function that takes a list of image paths pathlib. A particular BGR RGB color space is defined by the three chromaticities of the red green and blue additive primaries and can produce any chromaticity that is the triangle defined by those primary colors. com stkbailey teaching notebook for total imaging newbies so as to make the concepts simpler to understand. The 1s represent 1 such object nucleus in the entire picture. The result of this function will be stored in a variable called maskWe see that the mask has done a decent job. What is RLE RLE or Run Length Encoding converts a matrix into a vector and returns the position starting point of the first pixel from where we observe an object identified by a 1 and gives us a count of how many pixels from that pixel we see the series of 1s. In this notebook I ve tried to break down Stephen Bailey s fantastic notebook https www. If the result is 1 it means there is no difference at allThere is no difference at all. For a deeper explanantion as to why this could have happened one may read D Liu s paper http ieeexplore. Our job here is to seperate the two that is seperate the nuclei from the background. Luminance can also be described as brightness or intensity which can be measured on a scale from black zero intensity to white full intensity Thus this displays one entire row of the image matrix with the corresponding luminance or intensities of every pixel Removing the background We can see that there are 2 prominent peaks. This is the default colorpsace in which images are read in OpenCV. The optimal seperation value is somewhere around 20 but rather than relying on such descriptive statistics we should take a more formal approach such as using Otsu s method. The darker coloured nuclei are causing a problem as the pixels that represent these nuclei have intensity values lesser than Otsu s threshold value. read_csv Input data files are available in the. Therefore a grayscale image contains only shades of gray and no color i. Therefore these three values must be combined into a single value when removing color from an image. All in all the two major problems in this image are Insignificant spots dots being labelled as nuclei. The algorithm assumes that the image contains two classes of pixels following bi modal histogram foreground pixels and background pixels it then calculates the optimum threshold separating the two classes so that their combined spread intra class variance is minimal or equivalently so that their inter class variance is maximal. org document 5254345 reload true where he has compared K Means with Otsu s method Object identification To get a count of the total number of nuclei we can use the ndimage. This problem has been caused by some nuclei that have pixels where the intensity values are lesser than Otsu s threshold value thus causing only some pixels to have their label encoded as 1. Path objects analyzes each and returns a submission ready DataFrame We ll use this for the test images Creating one dataframe for every image Appending all these dataframes Returing the submission ready dataframe Final submission. com rakhlin fast run length encoding python for developing this function that has been used by many Kagglers for the purpose of this competition. So for example if 1 1 1 0 0 1 1 was our row vector using ndimage. 201 which gives us our baseline accuracy. Let s see if there is any difference by comparing the labels of Otsu and K Means at a pixel level summing over the booleans and dividing them by the total number of pixels in the image. However a more careful look suggests that the mask hasn t found out all the nuclei especially the two in the top right corner. org wiki Otsu 27s_method Now we ll use the np. The count of pixels with intensity values around 0 is extrememly high 250000. ", "id": "akshayt19nayak/getting-started-image-processing-basics", "size": "8237", "language": "python", "html_url": "https://www.kaggle.com/code/akshayt19nayak/getting-started-image-processing-basics", "git_url": "https://www.kaggle.com/code/akshayt19nayak/getting-started-image-processing-basics", "script": "sklearn.cluster threshold_otsu seaborn scipy list_of_images subprocess ndimage matplotlib.pyplot basic check_output pandas KMeans rle skimage.filters numpy ", "entities": "(('Insignificant spots dots', 'nuclei'), 'be') (('that', 'threshold lesser value'), 'cause') (('Basic RGB_color_space SolutionIt', 'image'), 'be') (('that', 'red green'), 'understand') (('Transforming', 'pixel'), 'remove') (('we', 'ndimage'), 'reload') (('it', 'which'), 'well') (('that', 'background'), 'be') (('that', 'one nuclei'), 'cluster') (('grayscale Therefore image', 'gray'), 'contain') (('we', 'such method'), 'be') (('we', 'nucleus'), 'need') (('together submission', 'everything'), 'put') (('labels', 'interconnectedness'), 'function') (('images', 'OpenCV'), 'be') (('mask hasn t', 'especially top right corner'), 'suggest') (('people', 'frustration'), 'be') (('three nuclei', 'together one cluster'), 'combine') (('I', 'Stephen notebook https ve fantastic www'), 'try') (('which', 'background'), 'expect') (('that', 'primary colors'), 'define') (('It', 'python docker image https kaggle github'), 'work') (('This', 'competition'), 'be') (('However 2 seperate spots', '2 different objects'), 'label') (('We', 'ndimage'), 'import') (('sizes', '0'), 'have') (('label', 'row 2 distinct vector'), 'give') (('read_csv Input data files', 'the'), 'be') (('we', '1s'), 'convert') (('We', 'background'), 'describe') (('Run Length mask', 'RLE vector'), 'encoding') (('s', 'image'), 'let') (('We', 'same example'), 'read') (('it', 'primarily only black'), 'contain') (('histogram', 'peaks source https two en'), 'exhibit') (('1s', 'entire picture'), 'represent') (('image', 'BGR colorspace'), 'read') (('zip we', 'Run Length Encoded RLE mask one such i.'), 'have') (('when we', 'grayscale'), 'reduce') (('you', 'output'), 'list') (('us', 'seperation optimum value'), 'be') (('count', '0'), 'be') (('Therefore three values', 'image'), 'combine') (('grayscale', 'white'), 'happen') (('which', 'baseline accuracy'), '201') (('that', 'competition'), 'run') (('we', 'Kaggle user rahlkin https www'), 'give') (('pixel', 'luminance three separate values'), 'have') (('mask hasn one t', 'especially top right corner'), 'be') (('Nobuyuki Otsu', 'binary image'), 'method') (('it', 'array'), 'return') (('that', 'image paths pathlib'), 'set') (('mask', 'decent job'), 'store') (('label', '1'), 'cause') (('org wiki Now we', 'np'), 'Otsu') (('inter class variance', 'two classes'), 'assume') (('concepts', 'imaging total newbies'), 'com') (('pixel', 'B G components'), 'have') (('one', 'D paper ieeexplore'), 'read') (('ready DataFrame We', 'ready dataframe Final submission'), 'analyze') "}
{"name": "learn2reg tutorial ", "full_name": " h2 Introduction h2 The whole picture h2 Importing provided helper functions h2 Registration using pretrained CNNs h2 Training a CNN for registration h2 Explanatory Details h3 2 Correlation layer implementation Basic steps h4 CNN Convolution operation h4 Correlation layer h3 3 Min Convolution h3 4 Spatial Transform ", "stargazers_count": 0, "forks_count": 0, "description": "Now we are able to compute the sum of squared differences SSD values for every spatial position between the moving feature representation m and its corresponding search region feature representations in the fixed image f. This cell imports all requires packages and provides namespace aliases insert at 1 0 is the script path or in REPL Here we import the image data and perform some preprocessing on the grayvalue images. 10931 the figure above illustrates the registration approach that will be implemented below. The image below illustrates this for an image that is convolved with a 2x2 kernel consecutively the red green yellow and blue patch are multiplied by the kernel to gain convolution output. The main idea is to incorporate learnable CNNs as feature extractors into an optimization pipeline that is inspired by a well studied discrete registration approach. Firstly the subvoxel accuracy determination of the minimum SSD position inside the search region will be computed by a weighted averaging. view operation to transform the moving tensor 1 C H W to C 1 H x W. the red T inside the discretized neighbourhood yellow rectangle. Specifying the search region by r_sz r_sz with r_sz being the size of the region we use the unfold operation to obtain the unfolded tensor of dimension C r_sz x r_sz H x W. The method is demonstrated on slices of abomdinal CT scans from the TCIA pancreas dataset. Now we visualize a pair of images fixed moving showing their grayvalue images annotations and feature representations. 4 Spatial TransformPerforming 1 step of the discrete registration approach to check whether so far the implementation is working. After having processed our registration image pair by a __CNN whose weights will be adjusted __ we try to find corresponding image contents cf. Here a 1 1 3 3 Image Tensor batch_sz channels heigth width is convolved with a 2x2 kernel without padding etc. view operation to swap the batch and channel dimensions. feat_mov 1 24 80 78 24 feature channels spatial HW dims feat_mov_unfold 24 121 6240 mind chans 11 11 121 displ steps 6240 80 78 spatial positions F. Here the idea is to transfer the regularized cost tensor from above into a displacement field. compute the cost tensor using the correlation layer2. While during a convolution we use the unfold operation to extract image patches __regions__ to be multiplied with a kernel for the correlation layer we also need to extract regions for our __similarity search__ on a predefined discrete neighbourhood grid. to crnt_dev 2 perform the SSD cost calculation based on the correlation layer. py tensor dimensionalities in comments are for an arbitrary choice of displace_range 11 feat sizes of 1 24 80 78 they clearly depend on the actual choice and only serve as numerical examples here. For more theoretical insights we refer you again to https arxiv. In the example below the 3x3 search region is defined by discrete voxel displacement pairs in 1 0 1 x 1 0 1 on the current resolution and 1 1 ideally yields the position with the highest correlation. compute the displacements using the meanfield function3. To achieve this per spatial position we combine weighted contributions of every possible displacement based on its cost determined by the correlation layer. The refinement of the learnable feature CNN weights will be performed further down. to crnt_dev The network defined here has the same architecture as the pretrained network above and we will train it from scratch on the given image data. Here we perform an average filtering along the spatial dimensions to get the final cost tensor. Relying on the implicit broadcasting along the first dimension when computing m f 2 we sum along the 0th dimension to obtain the SSD values for every spatial position in a tensor of dimension r_sz x r_sz H x W. Pushing the channel into the batch dimension allows to leave the feature channels untouched while constructing the search region patches along the first dimension with the unfold operation functionality. Correlation layerThis unfolding operation comes in very handy to implement the correlation layer where we need to perform a similar operation. applying the displacement field on the moving image with the warp_and_evaluate function Training a CNN for registrationNext we will start implementing our own correlation layer and start training a network for discrete image registrationNext we want to evaluate our network that we trained from scratch on the held out test data Explanatory Details 2 Correlation layer implementation Basic steps CNN Convolution operationIn order to move a filter kernel across an image behind the scenes an __ unfold __ operation is used to transfer this operation i. PyTorch documentation for the unfold operation https pytorch. The whole pictureExtracted from the MICCAI submission https arxiv. Since this process tends to be unstable due to noise or ambiguities in the following we introduce our two fold regularisation strategy. For the subvoxel displacement parameter estimation per spatial position we pursue the following strategy Starting with the SSD tensor of size r_sz x r_sz H x W computed in the last step above we first perform the difussion regularisation using min convolutions with a lower envelope of parabolas rooted at the displacement offsets with heights equalling the SSD values. com mattiaspaul learn2reg to load the provided dataset aside images and segmentations it contains the functions warp_and_evaluate which is used to visualise your results and meanfield which is required to regularise the probabilistic displacements Registration using pretrained CNNsIn the next cell we load pretrained network that computes features based on the input images fixed and moving. to crnt_dev generate the unfolded version of the moving encoding that will result in the shifted versions per channel according to the corresponding discrete displacement pair forward path pass both images through the network so that the weights appear in the computation graph and will be updated compute the cost tensor using the correlation layer compute the MIN convolution probabilistic output with the given function loss computation compute the weighted sum of the shifted moving label versions compute the loss as sum of squared differences between the fixed label representation and the warped labels perform the backpropagation and weight updates every grad_accum iterations backpropagate the accumulated gradients Validate patient 17 pat17 1 compute the feature representations. Based on the kernel size the patches are arranged into the unfolded matrix according to their position during the sweeping process of the convolution. In order to compute the correlation values for every voxel in the moving image for all discrete displacement steps in its corresponding search region in the fixed image we perform the following steps for an efficient implementation We use the. 10931 and focus on the practical implementation details below. This lower envelope is not directly differentiable but we can obtain a very accurate approximation using first a min pooling with stride 1 that finds local minima in the SSD tensor followed by two average pooling operations with stride 1 that provide a quadratic smoothing. unfold 3 Min ConvolutionThe finding of the displacement pair yielding the smallest SSD value corresponds to the idea of finding the feature representations that correlate the most. For the sake of clarity we process only one pair at a time. TODO IMPLEMENT THE CORRELATION LAYER or find the solution in learn2reg_discrete. Without padding we have 4 valid patches to apply the 2x2 kernel therefore the unfolded matrix is of dimensionality 4x4. In essence we change tensors 1 C H W to C 1 H W. Secondly these values are subsequently also averaged along the spatial image dimensions to result in a smooth displacement field. In essence applying the softmax function along the negatively weighted displacement dimension provides the weighting scheme for each displacement and their summation results in a smooth and continuous displacement per position. In order to obtain a reasonable displacement field this next step is the mean field inference. In addition to every slice we provide organ segmentations that will be used for registration evaluation purposes Dice scores as well as for the weakly supervised training of the feature extraction load TCIA data show an example patient slice Uncomment to use pretrained MIND net to extract features Now we prepare our train test dataset. resulting in a 1 1 2 2 output. in FlowNet to compute a dissimilarity map for a range of discrete displacement. html highlight unfold torch. In order to compute a reasonable displacement field a two fold regularisation strategy is employed. In the next part for this image pair we demonstrate the basic registration workflow after having defined the discrete search region size 1. the extraction of image patch sequences into a matrix multiplication. Importing provided helper functionsuse Add Data Search by URL and type kaggle. transpose 1 0 displace_range displace_range padding disp_hw feat_fixed 24 1 6240 compute scalarproduct along feature dimension per broadcast sum along 0 and reshape to 1 121 80 78 reshape the 4D tensor back to spatial dimensions. IntroductionIn this tutorial on discrete registration we will explore the implementation of the correlation layer used e. ", "id": "mattiaspaul/learn2reg-tutorial", "size": "7562", "language": "python", "html_url": "https://www.kaggle.com/code/mattiaspaul/learn2reg-tutorial", "git_url": "https://www.kaggle.com/code/mattiaspaul/learn2reg-tutorial", "script": "torch.nn.functional torch.optim learn2reg_discrete matplotlib.pyplot torch.nn my_correlation_layer numpy ", "entities": "(('Here we', 'cost final tensor'), 'perform') (('crnt_dev', 'correlation layer'), 'perform') (('80 78 they', 'only numerical examples'), 'be') (('Importing', 'Add Data type URL kaggle'), 'provide') (('Here idea', 'displacement field'), 'be') (('consecutively red green yellow', 'convolution output'), 'illustrate') (('We', 'the'), 'perform') (('we', 'regularisation two fold strategy'), 'introduce') (('so far implementation', 'registration 4 Spatial TransformPerforming 1 discrete approach'), 'step') (('78 feature HW feat_mov 1 24 80 24 channels spatial 24 121 6240 mind', '11 displ 11 121 steps'), 'dim') (('accuracy Firstly subvoxel determination', 'weighted averaging'), 'compute') (('we', 'dimension'), 'specify') (('1 that', 'quadratic smoothing'), 'be') (('Pushing', 'operation unfold functionality'), 'allow') (('regularisation two fold strategy', 'displacement reasonable field'), 'in') (('_ _ unfold _ _ operation', 'operation'), 'start') (('whole', 'MICCAI submission https arxiv'), 'pictureextracte') (('we', 'https again arxiv'), 'refer') (('Now we', 'train test dataset'), 'show') (('_ _ we', 'image contents corresponding cf'), 'after') (('we', 'SSD values'), 'pursue') (('TODO', 'learn2reg_discrete'), 'implement') (('summation', 'position'), 'provide') (('that', 'registration well studied discrete approach'), 'be') (('Now we', 'search region feature image corresponding fixed f.'), 'be') (('Here we', 'grayvalue images'), 'require') (('we', 'neighbourhood predefined discrete grid'), 'use') (('Secondly values', 'displacement smooth field'), 'average') (('that', 'registration above approach'), 'illustrate') (('we', 'dimension'), 'sum') (('we', 'H 1 W.'), 'change') (('Now we', 'grayvalue images annotations'), 'visualize') (('where we', 'similar operation'), 'come') (('that', 'most'), 'correspond') (('computes', 'input images'), 'learn2reg') (('we', 'time'), 'process') (('therefore unfolded matrix', 'dimensionality 4x4'), 'have') (('grad_accum iterations', 'feature 17 pat17 1 representations'), 'generate') (('we', 'search region discrete size'), 'demonstrate') (('1 1', 'highest correlation'), 'define') (('we', 'correlation layer'), 'combine') (('we', 'e.'), 'introductionin') (('patches', 'convolution'), 'arrange') (('refinement', 'feature CNN learnable weights'), 'perform') (('method', 'TCIA pancreas dataset'), 'demonstrate') (('above we', 'image given data'), 'to') (('width', 'etc'), 'heigth') "}
{"name": "nba salaries prediction in 2017 2018 season ", "full_name": " h1 Contents h1 1 Introduction Questions h1 2 Methods Results h2 2 1 Data Cleaning h2 2 2 Exploratory Analysis h3 2 2 1 Descriptive Statistics h3 2 2 2 Statistical Inference h3 2 2 3 Probability Distributions h2 2 3 Modelling h3 2 3 1 Feature Engineering h4 1 Creating Features h4 2 Pearson s R Square Correlation h4 3 Multicollinearity Analysis h3 2 3 2 Regression h4 1 Measure of Goodness RMSE h4 2 Selection of Model Multivariate Cross Validation and Bias Variance Trade off h4 3 Regularization Ridge Lasso and ElasticNet h3 2 3 3 Classification h4 1 Measure of Goodness Accuracy Score and Confusion Matrix h4 2 Selection of Model KNN SVM Na\u00efve Bayes Decision Tree Logistic Regression h4 3 Comparison Model Tuning Learning Curve and Curse of Dimensionality h1 3 Recommendations Discussions h2 Recommendations h2 Discussions h2 Reference ", "stargazers_count": 0, "forks_count": 0, "description": "com ff8040 Number of folds in cross validation Evaluation metric Use all computer cores 50 different sizes of the training set Create means and standard deviations of training set scores Create means and standard deviations of validation set scores Draw lines Draw bands Create plot curse of dimensionality one or two features are simple but it cannot recognize and divide our categories. Learning Curve is the process to see the change of correctness within the quantity of data set. Also the Age BPM USG VORP MP and PER also share the similar high VIF so some of them should be discarded. H1 There is significant difference of salaries between players from USA and not. com sflender comparing lin regression ridge lasso ElasticNet https www. array x_train_values. Secondly the correlations between players and their stats are not so strong which means that there are the situations that players are overpaid or underpaid. What recommendations can be made Firstly through our exploratory analysis and modelling process the difference between salaries of overseas and USA players are not significant but the number of USA players are almost 3 times more than that of overseas players. Welcome to my Mini Project. net guomutian911 article details 43317019 Bayes Theorem P a b P b a P a P b Bernoulli distribution Define the dataset Create bars Create names on the x axis Show graphic probability mass function S total 1 When variables are continous it becomes Probability Denstiy Function. 3 Classification 1 Measure of Goodness Accuracy Score and Confusion Matrix 2 Selection of Model KNN SVM Na\u00efve Bayes Decision Tree Logistic Regression 3 Comparison Model Tuning Learning Curve and Curse of Dimensionality3. Here we choose Country as our feature. 3 Regularization Ridge Lasso and ElasticNetThere are 3 ways to solve overfiting. Firstly model tuning is quite silimar with Bias Variance Trade off. Then we assume that our model does not cause overfitting or underfitting. read the data Matplotlib package for visualisation. This should be noticed by the teams managers. Different regularization methods perform differently. What are the most suitable regression and classification models to predict players salaries And how do the models work The most suitable regression model is 2nd order polynomial regression which has the RMSE of about 4. 3 Recommendations Discussions Recommendations What are the most important 4 features that influence the salary Through our modelling process the most important 4 features are draft number age WS and BPM. edu stat501 node 347 RMSE for testing data Cross Validation Spliting dataset into three parts for training validation and testing respectively. When the size of training size is small the score of training set is very high but the score of vaidation set is very low which causes overfitting. com joparga3 2 tuning parameters for logistic regression https www. Therefore we use imputation method to fill in the missing values. Compared with MSE and MAE RMSE can provide the same dimensionality with target variables and the sqaure function can make the measurement more precise than MAE when comparing different models. 3 Comparison Model Tuning Learning Curve and Curse of DimensionalityThe process of Model Tuning is similar to Bias Variance Trade off which is to find the balance that provide not only the high score of the training set but also good ability to predict the testing set. Methods Results 2. 7033 which is smaller than t critical then we prefer to think that there is no significant difference of salaries between players from USA and overseas. com select rows columns by name or index in dataframe using loc iloc python pandas Regularization parameter kernel type rbf working fine here default value kernel coefficient change to 1 from default value of 0. 3 Multicollinearity AnalysisAs we have 8 features now which may contain multicollinearity that make the model inaccurate and cause overfitting. KNN SVMThe use of gamma is similar to k in KNN. Value Creation Comparative Netnographic Study of Two NBA Online Communities. The similar phenomenon happens in another comparison which can be touted as an important way to see the details of our models prediction. Similarly within my ability stacking skills is not approachable yet. If it is larger than 10 we think that the multicollinearity is very strong and the feature should not be included. com diegosch classifier evaluation using confusion matrix 0 edge players 1 normal players 2 all stars 3 superstars Transform to df for easier plotting Learning Curve Number of folds in cross validation Evaluation metric Use all computer cores 50 different sizes of the training set Create means and standard deviations of training set scores Create means and standard deviations of validation set scores Draw lines Draw bands Create plot https blog. Also the identity information is captured such as age draftnumber and so on. Firstly we should have a look whether the data is completed or not. com junyingzhang2018 ridge regression score 0 119 Adjust alpha based on previous result Adjust alpha based on previous result Use alpha 40. DiscussionsIn this mini project there are some technical limitations such as normalization methods model selections and stacking skills. com pablovargas naive bayes svm spam filtering for binary target variables Model Tuning 5 fold cross validation How to find K 5 fold cross validation Learning Curve How KNN algorithm performs in both small size data and big size data choose an acceptable color https www. Therefore if the collinearity of our features are low the model will perform better. Here we use KNN SVM to fit the Binary target variables and use others to fit the Nominal variables. Apart from that the histogram of salaries can make it clear to see the distribution of NBA salaries. We can try non binary target variables. Model selection is important. Although I cannot apply these models this time I believe I will understand them in the nearing future. Therefore I select Decision Tree by reading the slides and select Logistic Regression by watching Andrew Ng s videos. So if we want to do the feature selection we can choose Lasso. Ridge Lasso ElasticNet As it is shown on the Figure 5 when degree 1 both of training and validation set s RMSE are quite low. drop USA NOT axis 1 inplace True Then we build nomial categories 0 edge players 1 normal players 2 all stars 3 superstars number of variables for heatmap Using scatter plots to detect the correlation value https etav. If the number of dimensions is similar to the amount of data each or several samples may form one class which may make the traing model performs well in the training set but losing its ability to predict the testing set at the same time. 1 Feature Engineering 1 Creating FeaturesIn order to make classification prediction it is neccessary to create discrete target variables according to players salaries. In this case the t statistics 0. Also players age is one of the most important issues in NBA for a player can make more profits if he can play longer. Selecting Features Creating Features buiding binary categories in order to make classifications prediction normal 0 star 1 copy_data. Here we retain the null hypothesis that the 1nd order polynomial model does not cause high bias. 2 Regression 1 Measure of Goodness RMSE 2 Selection of Model Multivariate Cross Validation and Bias Variance Trade off 3 Regularization Ridge Lasso and ElasticNet 2. As it is a discrete value we can build a probability mass function about age. The higher the gamma value it tries to exactly fit the training data set. Defining the dataset s new name in this project. Focusing on coefficients and we can find that Ridge regularization drives parameters to smaller values. Then we apply the bias variance trade off graph to see whether the assumption is true or not. As the increase of data size the score of training set becomes lower and the validation set s score becomes higher which means that the distance between these two groups are narrowing. In fact this phenomenon is quite popular in the real NBA market. 2 Statistical InferenceIn order to select appropriate features for prediction an independent t test can be applied to calculate whether a feature is significant enough. Secondly in order to get familiar with the dataset this report will use descriptive statistics statistical inference and concepts of probability distributions to make a description of the potential variables that we need to choose for moddelling. when alpha level. Here we can apply it to answer the question such as what is the probability that players salaries are higher than 10 million dollars given that the player is from USA Probability Distribution can make it clear to realize the feature of our variables. html Gaussian is for continous features \u503c\u5f97\u6ce8\u610f\u7684\u662f \u5728\u79bb\u6563\u6837\u672c\u4e5f\u5c31\u662f\u57fa\u4e8e\u9891\u7387\u7684\u4f30\u8ba1\u4e2d \u5982\u679c\u67d0\u4e2a\u7279\u5f81fn\u672a\u5728\u8bad\u7ec3\u96c6\u7684\u7c7b\u522bci\u4e2d\u51fa\u73b0\u8fc7 \u90a3\u4e48P fn ci \u9879\u4e3a0\u4f1a\u5bfc\u81f4\u6574\u4e2a\u4f30\u8ba1\u4e3a0\u800c\u5ffd\u7565\u4e86\u5176\u4ed6\u7684\u7279\u5f81\u4fe1\u606f \u8fd9\u6837\u7684\u4f30\u8ba1\u663e\u7136\u662f\u4e0d\u51c6\u786e\u7684 \u6240\u4ee5\u901a\u5e38\u9700\u8981\u5bf9\u4e8e\u6837\u672c\u8fdb\u884c\u6837\u672c\u4fee\u6b63\u4fdd\u8bc1\u4e0d\u4f1a\u67090\u6982\u7387\u51fa\u73b0 \u6bd4\u5982\u91c7\u7528laplace\u6821\u51c6 \u5bf9\u6ca1\u7c7b\u522b\u4e0b\u6240\u6709\u5212\u5206\u7684\u8ba1\u6570\u52a01 \u8fd9\u6837\u5982\u679c\u8bad\u7ec3\u6837\u672c\u96c6\u6570\u91cf\u5145\u5206\u5927\u65f6 \u5e76\u4e0d\u4f1a\u5bf9\u7ed3\u679c\u4ea7\u751f\u5f71\u54cd listone\u4fee\u6b63\u5219\u662f\u52a0\u4e00\u4e2a0 1\u4e4b\u95f4\u7684\u6570 \u548c\u591a\u5143\u6734\u7d20\u8d1d\u53f6\u65af\u4e2d\u901a\u8fc7\u7279\u5f81\u51fa\u73b0\u9891\u7387\u6765\u8ba1\u7b97P fn ci \u4e0d\u540c \u4f2f\u52aa\u5229\u6a21\u578b\u53ea\u8003\u8651\u51fa\u73b0\u4e0d\u51fa\u73b0\u7684\u4e8c\u503c\u95ee\u9898 for i in np. 1 Data CleaningMissing values and outliers would make the modelling process difficult. However as the size of this dataset only reaches 300 it cannot make sure that if the size is absolutly large more than 10 thousands how well will the curves perform. 2 Statistical Inference 2. While in other models maybe it is because of the number of features are not enough the curse does not appear. For example SVM does better in predicting label 0 while KNN performs better in predicting label 1. 3 Probability Distributions 2. Introduction Questions2. tolist convert dataframe The best result is captured at k 5 hence it is used for the final model. Bias Variance Trade off training RMSE validation RMSE RMSE for testing data At first we calculate the RMSE before regularization. 1 Descriptive Statistics 2. to 1 2 3 4 0 x_train_values_list np. 0 using shrinking heuristics stopping criterion tolerance no need to enable probability estimates 200 MB cache size all classes are treated equally print the logs no limit let it run will use one vs rest explicitly NB assumes that the features themselves are not correlated to each other. The meaning of regularization can be considered as punishiment. com question 38121173 https www. Determining NBA Free Agent Salary from Player Performance. Conversely a very small value of C will cause the optimizer to look for a larger margin separating hyperplane even if that hyperplane misclassifies more points. The most suitable point is not the highest point in training set but a balanced point which performs not so bad in both training and validation sets. In all although the effect of regularization is significant it is much better to choose the correct parameters and features. make copy to avoid changing original data when imputing. As expected the OWS DWS and WS have a high variance inflation factor because they explain the same meaning. net app_12062011 article details 52136117 Model Tuning https www. com all things ai in depth parameter tuning for svc 758215394769 https medium. Introduction QuestionsIn 2017 18 season the salary cap and the luxury tax of NBA reached 99 million and 119 million dolars respectively Di 2018. Curse of Dimensionality is one of the main reasons of overfitting. com machine learning 101 chapter 1 supervised learning and naive bayes classification part 1 theory 8b9e361897d5 https blog. loading pandas and numpy for data cleaning and exploratory anaysis. Continuing the Country problem a Bernoulli Distribution can be applied to see the difference between these two groups. The first way is to increase the size of dataset the second way is to choose a suitable model complexity and the third way is to use regularization to reduce the value of coefficient. But when degree 4 the difference between training set s RMSE and validation set s RMSE is obvious. This difference can be an opportunity to recruit more overseas players from other countries for the promotion. In Neural Networks IJCNN The 2011 International Joint Conference on pp. We believe that the dataset is suitable because it focuses on not only on ball stats such as scores rebounds and assists but also off ball stats which can capture those who have a big impact on the game without ball on the hand. Decision Tree model performs the best in Nominal target classification with 0. using median value of each column to fill the N A values because it will not be influened by outliers. 4 to predict the test data Lasso https www. At the beggining of this report we planned to apply other advanced models such as random forests ADBoost and so on. 1 Data Cleaning 2. However it is the mathematical concepts that let me realize that it is meaningless to apply them if I cannot understand the basic algorithm behind them. CART is for binary target variables ID3 is for nomial attributes and C4. 3 Classification 1 Measure of Goodness Accuracy Score and Confusion MatrixAccuracy Score is straight forward for it tells us the probability of the right answers that your model can predict. 2 Exploratory Analysis 2. And maybe that is the reason why my model s RMSE reachs over million. The first three methods are to read the central tendency of data and the rest are to describe the dispersion of datasets. It is also a good way to overcome the adverse impact of overfitting for a big size dataset can make a complex model performs well than a small size dataset. Because the missing value will have an adverse impact on the building of regression model. In our models the curse of dimensionality is obvious in SVM Naive Bayes and Logistic Regression where the high dimensional features cause overfiting. From the positive skewed histogram we can read that more than 33 of NBA players salaries are less than 3 million dollars while only no more than 40 players salaries are more than 25 million dollars. 05 two tailed test If t statistics t critical we retain the null hypothesis. 5 can be applied for continous features whcih is the most suitable in our case. Where as high gamma means the points close to plausible line are considered in calculation. It is oriented from Kaggle the largest online machine learning and data science community Narayanan Shi Rubinstein 2011. net li8zi8fa article details 76176597 GaussianNB MultinomialNB BernoulliNB http www. Therefore we choose NBA_DraftNumber Age WS BPM as our features for modelling. Setup a knn classifier with k neighbors https medium. This report chooses a dataset named NBA 2017 18 season players salaries. org wiki Bessel 27s_correction Proof_of_correctness_ _Alternate_3 covariance https blog. Therefore the VIF value can be chosen to detect the multicollinearity. net hzw19920329 article details 77200475 https www. And if the gamma value is too high it will cause overfitting. com machine learning 101 chapter 2 svm support vector machine theory f0812effc72 Regularization parameter kernel type rbf working fine here default value kernel coefficient change to 1 from default value of 0. com jack89roberts top 7 using elasticnet with interactions Comparison http www. 2 Selection of Model KNN SVM Na\u00efve Bayes Decision Tree Logistic RegressionFive Models are selected to fit our dataset. https thispointer. However if we want to know the Accuracy Score of each target group it is more suitable to use Confusion Matrix which will show the comparison of predicted values and real values in each group. In this case we choose median number of the whole column to fill in the missing variables because a median value will not be influened by outliers. 2 Selection of Model Multivariate Cross Validation and Bias Variance Trade offAt first we use multivariate linear regression to build our initial model. This is NBA Salaries Prediction version 3. Conversely we reject the null. In other words with low gamma points far away from plausible seperation line are considered in calculation for the seperation line. So we introduce the l to make the coefficients smaller than before. But if the multicollinearity exits Lasso will turn its coefficients to 0 while Ridge will not erase any feature value. If you think this is helpful or it has any problem please upvote it and discuss your idea with me. This also means that the salary problem needs to be paid attention by managers. com sflender comparing lin regression ridge lasso https www. Thirdly we will use regression and classification methods to select build and evaluate our models. And the performance of different models is shown above where 2nd order polynomial regression performs the best. The most suitable binary classification model is SVM taking the accuracy score of 0. sample variance Why does Bessel s correction use N 1 https en. Firstly the dataset should be cleaned in order to make it easier to build model. Secondly all models share the similar trends in the Learning Curve. 1 Descriptive StatisticsIn order to understand our data descriptive statistics can be used to get a well understand of the dataset. html https onlinecourses. After applying our models it is essential to use the model tuning techniques to find the best parameters that fit our dataset. As it is shown on the Figure 5 when degree 1 both of training and validation set s RMSE are quite low. When the model is too complex the values of coefficients are very large. But if we want to keep all features on the list we prefer Ridge. com lesliexong p 6907642. This means that the managers and coaches of all 30 teams have to focus on finding those who are ability to put their teams to another level within their budgets. In order to accept or reject our hypothesis we use cross validation to separate our data into training set and validation set 8 2. Naive BayesIn Naive Bayes we assume that the features are independent from each other. 0 using shrinking heuristics stopping criterion tolerance no need to enable probability estimates 200 MB cache size all classes are treated equally print the logs no limit let it run will use one vs rest explicitly Confusion Matrix Learning Curve Number of folds in cross validation Evaluation metric Use all computer cores 50 different sizes of the training set Create means and standard deviations of training set scores Create means and standard deviations of validation set scores Draw lines Draw bands Create plot curse of dimensionality one or two features are simple but it cannot recognize and divide our categories. Also multiple regression is the one that I cannot solve in programming language because I cannot find any example in others work. more features means more evidence in different dimensions but it could cause overfitting. 3 Probability DistributionsBayes Theorem is the fundamental concept of probability. Thridly different models have different sensitivities to dimensionality. In this report the 3 key questions are What are the most important 4 features that influence the salary What are the most suitable regression and classification models to predict players salaries And how do the models work What recommendations can be made In order to answer the questions data cleaning exploratory analysis and data modelling methods will be applied. com joparga3 2 tuning parameters for logistic regression Transform to df for easier plotting Learning Curve Number of folds in cross validation Evaluation metric Use all computer cores 50 different sizes of the training set Create means and standard deviations of training set scores Create means and standard deviations of validation set scores Draw lines Draw bands Create plot Curse of Dimensionality. Extracting two columns Salary and NBA_Country. But I believe that I will get them done in the future. For large values of C the optimization will choose a smaller margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. 1 Feature Engineering 1 Creating Features 2 Pearson s R Square Correlation 3 Multicollinearity Analysis 2. io python vif_factor_python. 2 Regression 1 Measure of Goodness RMSERoot Mean Squrare Error is a measure of how far the predicted points away from the real points. In this part we focus on regularization and select degree 4 to test the effectiveness of these three methods. Ridge https blog. Recommendations Discussions 1. H0 There is no significant difference of salaries between players from USA and not. The Regularization parameter tells the SVM optimization how much you want to avoid misclassifying each training example. The gamma parameter defines how far the influence of a single training example reaches with low values meaning far and high values meaning close. However the values of some models parameters are very large while others are quite small such as Naive Bayes which should be paid attention to. Logistic RegressionThrough Model Tuning Learning Curve Curse of Dimensionality and Confusion Matrix we can get some knowledge about models characteristics. 2 Methods Results 2. 2 extract columns convert 1 2 3. The methods here include mean median mode standard deviation interquatile range. From Andrew Ng s Open Course Normalization can change the big value features into a small value one which may make the lost function more accurate. I hope everybody can learn from it. edu jcrouser SDS293 labs lab10 py. And when it comes to 4nd order polynomial regression it causes overfiting. com drgilermo stephen curry s decision tree Transform to df for easier plotting Learning Curve Number of folds in cross validation Evaluation metric Use all computer cores 50 different sizes of the training set Create means and standard deviations of training set scores Create means and standard deviations of validation set scores Draw lines Draw bands Create plot Curse of Dimensionality logistic regression LR https www. Link prediction by de anonymization How we won the kaggle social network challenge. Therefore a model which can predict players salaries according to their performance data is necessary in the league. But I have not applied it because I think this will affect the real data s meaning and also I think it is meaningless because our RMSE is a relative value not an absolute one. Decision TreeThere are three ways to build a decision tree. Here we create two columns named Binary and Nominal as below 2 Pearson s R Square CorrelationIn order to choose features that are correlated to our target variables the Pearson s R Square Correlation can be applied to choose top 8 features that are most correlated to the salaries. arange 1 20 https www. Lastly Confusion Matrix tells us the performance on different target groups. Ending Importing all pakages that necessary. ", "id": "aishjun/nba-salaries-prediction-in-2017-2018-season", "size": "17270", "language": "python", "html_url": "https://www.kaggle.com/code/aishjun/nba-salaries-prediction-in-2017-2018-season", "git_url": "https://www.kaggle.com/code/aishjun/nba-salaries-prediction-in-2017-2018-season", "script": "OneVsRestClassifier train_test_split Lasso LinearRegression rmse_cv ElasticNetCV confusion_matrix Ridge statsmodels.stats.outliers_influence sklearn.svm numpy cross_val_score accuracy_score seaborn make_pipeline SVC tree GaussianNB sklearn.neighbors rmse_model sklearn.naive_bayes sklearn.tree sklearn.linear_model sklearn learning_curve KFold fillWithMedian matplotlib.pyplot DecisionTreeClassifier sklearn.multiclass metrics sklearn.model_selection pandas LogisticRegression precision_recall_fscore_support DataFrame sklearn.pipeline ElasticNet mean_squared_error PolynomialFeatures KNeighborsClassifier variance_inflation_factor GridSearchCV sklearn.metrics sklearn.preprocessing ", "entities": "(('Use', 'Draw Create plot https blog'), 'star') (('sample Why Bessel', 'correction N'), 'variance') (('methods', 'deviation interquatile here mean median mode standard range'), 'include') (('Therefore we', 'missing values'), 'use') (('distance', 'two groups'), 'become') (('why model', 'million'), 'be') (('them', 'future'), 'believe') (('Decision TreeThere', 'decision three tree'), 'be') (('Descriptive StatisticsIn data descriptive 1 statistics', 'dataset'), 'order') (('set', '1 training'), 'show') (('it', '1'), 'detail') (('we', 'such random forests'), 'plan') (('we', 'three methods'), 'focus') (('very feature', '10'), 'think') (('that', 'most salaries'), 'create') (('Curse', 'overfitting'), 'be') (('model', 'overfitting'), 'assume') (('Logistic where high dimensional features', 'SVM Naive Bayes'), 'be') (('it', 'outliers'), 'use') (('season 2017 18 players', 'dataset'), 'choose') (('model', 'that'), 'be') (('we', 'regularization'), 'Trade') (('validation', '8 2'), 'in') (('performs', 'size color https big acceptable www'), 'filter') (('Confusion we', 'models characteristics'), 'Curse') (('USA number', 'overseas players'), 'make') (('model', 'features'), 'perform') (('that', 'most important 4 features'), 'Recommendations') (('I', 'them'), 'be') (('too values', 'coefficients'), 'be') (('This', 'teams managers'), 'notice') (('0 KNN', 'better label'), 'do') (('SVM', '0'), 'be') (('rest', 'datasets'), 'be') (('median value', 'outliers'), 'choose') (('Secondly models', 'Learning Curve'), 'share') (('complex model', 'size well small dataset'), 'be') (('too it', 'overfitting'), 'cause') (('2 Selection', 'dataset'), 'select') (('it', 'categories'), 'use') (('which', 'real group'), 'be') (('VIF Therefore value', 'multicollinearity'), 'choose') (('where 2nd order polynomial regression', 'best'), 'show') (('you', 'training example'), 'tell') (('it', 'much correct parameters'), 'be') (('Lastly Confusion Matrix', 'target different groups'), 'tell') (('Learning Curve', 'data'), 'be') (('copy', 'original data'), 'make') (('ID3', 'nomial attributes'), 'be') (('critical then we', 'USA'), '7033') (('far values', 'low values'), 'define') (('Thridly different models', 'dimensionality'), 'have') (('that', 'dataset'), 'be') (('data modelling methods', 'exploratory analysis'), 'be') (('points', 'calculation'), 'consider') (('Regularization parameter kernel type rbf working fine', '0'), 'f0812effc72') (('balanced which', 'so bad training sets'), 'be') (('GaussianNB MultinomialNB BernoulliNB', '76176597'), 'detail') (('he', 'more profits'), 'be') (('It', 'largest online machine learning'), 'orient') (('it', 'categories'), 'estimate') (('hyperplane', 'training points'), 'choose') (('1nd order polynomial model', 'high bias'), 'retain') (('hyperplane even misclassifies', 'hyperplane'), 'cause') (('curse', 'features'), 'appear') (('it', 'overfitting'), 'mean') (('Use', 'Draw bands Create Dimensionality'), 'Transform') (('Multivariate Cross Bias Variance first we', 'initial model'), 'Selection') (('which', 'models prediction'), 'happen') (('which', 'league'), 'be') (('Ridge', 'feature value'), 'turn') (('it', 'me'), 'have') (('set', '1 training'), 'ElasticNet') (('RMSE', 'real meaning'), 'apply') (('Therefore I', 'videos'), 'select') (('5 hence it', 'final model'), 'dataframe') (('salary also problem', 'managers'), 'mean') (('Use', 'Draw Create plot Dimensionality'), 'com') (('example', 'others'), 'be') (('meaning', 'punishiment'), 'consider') (('we', 'Lasso'), 'so') (('it', 'players salaries'), '1') (('who', 'hand'), 'believe') (('classifications prediction', 'normal 0 star 1 copy_data'), 'select') (('difference', 'promotion'), 'be') (('model Firstly tuning', 'Bias Variance quite Trade'), 'be') (('salary Introduction QuestionsIn 2017 18 cap', '99 119 million dolars'), 'reach') (('third way', 'coefficient'), 'be') (('lost function', 'small value'), 's') (('joparga3', 'regression https logistic www'), 'com') (('we', 'smaller values'), 'focus') (('identity Also information', 'age such draftnumber'), 'capture') (('\u5728\u79bb\u6563\u6837\u672c\u4e5f\u5c31\u662f\u57fa\u4e8e\u9891\u7387\u7684\u4f30\u8ba1\u4e2d \u90a3\u4e48P fn \u6240\u4ee5\u901a\u5e38\u9700\u8981\u5bf9\u4e8e\u6837\u672c\u8fdb\u884c\u6837\u672c\u4fee\u6b63\u4fdd\u8bc1\u4e0d\u4f1a\u67090\u6982\u7387\u51fa\u73b0 \u5bf9\u6ca1\u7c7b\u522b\u4e0b\u6240\u6709\u5212\u5206\u7684\u8ba1\u6570\u52a01 \u8fd9\u6837\u5982\u679c\u8bad\u7ec3\u6837\u672c\u96c6\u6570\u91cf\u5145\u5206\u5927\u65f6 \u548c\u591a\u5143\u6734\u7d20\u8d1d\u53f6\u65af\u4e2d\u901a\u8fc7\u7279\u5f81\u51fa\u73b0\u9891\u7387\u6765\u8ba1\u7b97P fn \u5982\u679c\u67d0\u4e2a\u7279\u5f81fn\u672a\u5728\u8bad\u7ec3\u96c6\u7684\u7c7b\u522bci\u4e2d\u51fa\u73b0\u8fc7 ci \u9879\u4e3a0\u4f1a\u5bfc\u81f4\u6574\u4e2a\u4f30\u8ba1\u4e3a0\u800c\u5ffd\u7565\u4e86\u5176\u4ed6\u7684\u7279\u5f81\u4fe1\u606f listone\u4fee\u6b63\u5219\u662f\u52a0\u4e00\u4e2a0 1\u4e4b\u95f4\u7684\u6570 ci', 'np'), 'be') (('edu stat501', 'validation'), 'node') (('phenomenon', 'NBA quite real market'), 'be') (('discrete we', 'age'), 'build') (('I', 'nearing future'), 'believe') (('features', 'other'), 'estimate') (('that', 'testing also good set'), 'be') (('3 players less than million only no more than 40 salaries', 'NBA players salaries'), 'read') (('missing value', 'regression model'), 'have') (('Comparison', 'www'), 'com') (('it', 'model'), 'clean') (('data', 'look'), 'have') (('Regularization Ridge 3 Lasso', '3 overfiting'), 'be') (('Decision Tree model', '0'), 'perform') (('some', 'them'), 'share') (('applied', 'most case'), 'be') (('features', 'other'), 'Bayes') (('players', 'players'), 'be') (('it', 'variables'), 'apply') (('it', 'NBA salaries'), 'make') (('KNN SVMThe use', 'KNN'), 'be') (('Mean Squrare Error', 'how far predicted away real points'), 'measure') (('it', 'polynomial regression'), 'cause') (('measurement', 'when different models'), 'provide') (('Thirdly we', 'models'), 'use') (('absolutly large more than 10 thousands how well curves', 'only 300'), 'make') (('2nd order polynomial which', 'about 4'), 'be') (('they', 'same meaning'), 'have') (('who', 'budgets'), 'mean') (('very which', 'overfitting'), 'be') (('feature', 't independent test'), 'apply') (('How we', 'network kaggle social challenge'), 'prediction') (('1 normal players', 'correlation value https etav'), 'drop') (('traing model', 'same time'), 'be') (('05 t statistics two tailed t we', 'null hypothesis'), 'test') (('model', 'overfitting'), 'AnalysisAs') (('Probability DistributionsBayes 3 Theorem', 'fundamental probability'), 'be') (('net app_12062011 article', 'Model Tuning https 52136117 www'), 'detail') (('we', 'moddelling'), 'in') (('Here we', 'Nominal variables'), 'use') (('Country Bernoulli Continuing Distribution', 'two groups'), 'problem') (('coefficients', 'l'), 'introduce') (('we', 'Ridge'), 'prefer') (('RMSE set', 'training set'), 'but') (('Therefore we', 'modelling'), 'choose') (('assumption', 'graph'), 'apply') (('which', 'attention'), 'be') "}
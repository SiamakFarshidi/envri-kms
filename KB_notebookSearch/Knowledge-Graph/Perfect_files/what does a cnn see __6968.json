{"name": "what does a cnn see ", "full_name": " h1 Contents h2 1 Import the required libraries h2 2 Do everything we can to make our results reproducible h2 3 Load dataset and process it h2 4 Data Augmentation h2 5 Data Generator h2 6 Modelling h2 7 Model Interpretability h2 8 Can we or should we use CAM for model interpretability h3 Advantages h3 Disadvantages h2 9 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "Data Generator data gen 6. You can even say that the first feature that is far by the most important to our model is the face of a monkey. For CAM we will take the same sample image and get the output of the last convolution layer. Load dataset and process itWe will read the monkey_labels. txt file to extract the information about the labels. com aakashnain is it better than 2017. Data Augmentation augmentation 5. Import the required libraries 2. The more data you provide to a deep learning model the more it performance improves until unless your algorithm has reached a limit. These are Visualizing the intermediate layers outputs Class Activation Mapping http cnnlocalization. Can we or should we use CAM for model interpretability If you look at the above results of CAM you will find that in most of the class activation maps face of a monkey seems to be highly activated. We will be doing the same thing here. com media SRx5tBBrTQOBi giphy. For more details check out this excellent article https distill. ConclusionMachine learning models aren t pure black box. Well this statement is neither completely true not it is completely false. This is why I always store information about the dataset in dataframes and then use a generator to load the data on the fly. We will be using imgaug https github. You have to figure out how you can make the predictions interpretable. Do everything we can to make our results reproducible reproducibility 3. The labels are n0 n1 n2. We also compute the gradients for this layer which we will use to generate a heatmap. Most of the time you won t be able to load the entire dataset in the memory. Today we are going to deep dive into Model Interpretability. But this isn t always the scenario. This suggests that for our model at least face is a very discriminative feature. Model InterpretabilityNow starts the most important part. Perfect Store the names of all these intermediate layers in a list. Machine learning models especially Deep Learning models are often considered as a black box and hard to interpret. Can we or should we use CAM for model interpretability infer_results 9. Model Interpretability interpretability 8. How do you infer that for that particular class if the neck was more discriminative feature or face is Though it gives you an idea of discriminative features it fails to capture the high level semantic relationship within the hidden layers. It is not an easy task at all but the on going research in this area will lead to better ways of interpretability in the nearby future. We will create a mapping of these labels where each class will be represented by an integer starting from 0 to number of classes. We will also create a mapping for the names corresponding to a class. Data AugmentationWhen you have limited data deep models don t do very well. How do we explain the output of our model For example given an image what does the network consider important when classifying the image Can we get info about it Can we make our model a little grey box LOL Answering the above question is a bit difficult. Also as the dataset is very small and very very similar to Imagenet we would make minimal changes in the network to keep the trainable parameters as few as possible 7. edu Here are all the steps we are going to do We will start by selecting all the layers up to last convolution block in VGG16 excluding the Input layer. I am listing all of which I am aware of Advantages CAM is a weak supervision technique and it works well out of the box It is easy and simple to implement It gives a fair idea of the dominant features for which a model is looking for It is one of the easiest methods to explain the outputs of a CNN to anyone including even a non technical person. This is where data augmentation really comes handy. Deep learning models are data hungry. Hello Kagglers It has been a while since I made a new kernel. See the get_CAM function for details. pub 2018 building blocks a lot more has to be done in this direction. Modelling modelling 7. We can store this information in a list which then can be converted into a pandas dataframe. You can load the data into numpy arrays which then can be directly used for training. This gives an indication of how important a feature is we have 512 features in our last conv layer create a heatmap remove negative values normalize select the sample and read the corresponding image and label pre process the image generate activation maps from the intermediate layers using the visualization model get the label predicted by our original model choose any random activation map from the activation maps normalize the sample activation map convert pixel values between 0 255 get the heatmap for class activation map CAM Get the intermediate activations and plot the heatmap first visualize all the activation maps for this sample. Import the required libraries imports. This will be used for displaying all the activation maps of each convolution block for any sample image from our validation data. Disadvantages Even though CAM gives a fair idea about dominant features but it lacks to provide specific details. Although there have been many advancements in explaining the activations outputs of a neural network for example check this https distill. Let me know if you have any suggestions. I hope you enjoyed the kernel. We will be using Common Name for the last partThis is a very small dataset. We will use the names during visualizations of these activation maps Pretty cool isn t it Let s check the CAM for few more samples now 8. It is a fact that debugging a deep learning model is way harder than other machine learning models but there are ways by which you can get insights about your model and to an extent you can see what is happening. For example if you look at the examples above there are some cases where we have the activation heatmap ranging from neck to face. com aleju imgaug a very powerful library for augmenting our images. read_csv Set the seed for hash based operations in python Set the numpy seed Set the random seed in tensorflow at graph level Make the augmentation sequence deterministic As usual define some paths first to make life simpler Read the file Convert the data into a pandas dataframe Sneak peek Create a dictionary to map the labels to integers map labels to common names Creating a dataframe for the training dataset Define the path to the images Get the list of all the images stored in that directory Store each image path and corresponding label shuffle the dataset Creating dataframe for validation data in a similar fashion shuffle the dataset How many samples do we have in our training and validation data sneak peek of the training and validation dataframes some constants not truly though dimensions to consider for the images batch size for training total number of classes in the dataset Augmentation sequence horizontal flips roatation random brightness Get total number of samples in the data Get a numpy array of all the indices of the input data Define two numpy arrays for containing batch data and labels shuffle indices for the training data get the next batch process the next batch training data generator validation data generator simple function that returns the base model get the base model get the output of the second last dense layer add new layers define a new model Freeze all the base model layers compile the model and check it always user earlystopping the restore_best_weights parameter load the weights of the best iteration once the training finishes checkpoint to save model number of training and validation steps for training and validation number of epochs train the model let s plot the loss and accuracy get the training and validation accuracy from the history object get the loss get the number of entries visualize What is the final loss and accuracy on our validation data select all the layers for which you want to visualize the outputs and store it in a list Define a new model that generates the above output check if we have all the layers we require for visualization store the layer names we are interested in we want the activations for the predicted label choose the last conv layer in your model get the gradients wrt to the last conv layer take mean gradient per feature map Define a function that generates the values for the output and gradients get the values iterate over each feature map in yout conv output and multiply the gradient values with the conv output values. We will define a sequence of augmentations and for each image one of these augmentations will be applied to the image during training 5. There are some advantages and disadvantages when using CAM. Do you have any idea what are you doin http media. Load dataset and process it dataloading 4. pub 2018 building blocks 9. The last kernel was on Kaggle Survey Challenge 2018 https www. ModellingWe will be doing transfer learning here and I am choosing vgg16 as the base network. Define a new model vis_model that takes the same input as our model s input but outputs activations of all the intermediate layers we have selected. Here we will explore two methods that are very simple to use and can give some good insights about model predictions. You can choose whichever network you want. Check visualize_intermediate_activations function for more details. Conclusion conclusion 1. Happy Kaggling linear algebra data processing CSV file I O e. Do everything we can to make our results reproducibleThumb rule Always set the seed 3. ", "id": "aakashnain/what-does-a-cnn-see", "size": "6968", "language": "python", "html_url": "https://www.kaggle.com/code/aakashnain/what-does-a-cnn-see", "git_url": "https://www.kaggle.com/code/aakashnain/what-does-a-cnn-see", "script": "mlxtend.plotting skimage.transform join data_generator keras.layers pathlib keras.models train_test_split get_CAM os keras to_categorical listdir confusion_matrix numpy MaxPooling2D seaborn isdir Dropout Adam SGD Path Dense Callback remove preprocess_input backend as K visualize_intermediate_activations imgaug.augmenters keras.callbacks imread imgaug os.path plot_confusion_matrix RMSprop keras.optimizers tensorflow getcwd skimage.io keras.applications.vgg16 matplotlib.pyplot ModelCheckpoint Sequential backend abspath resize pandas sklearn.model_selection EarlyStopping Conv2D load_model Model show_random_sample Input VGG16 makedirs isfile keras.utils expanduser sklearn.metrics Flatten exists get_base_model ", "entities": "(('Happy Kaggling', 'linear algebra data CSV file'), 'process') (('you', 'memory'), 'be') (('we', 'as few'), 'be') (('This', 'validation data'), 'use') (('255 heatmap', 'sample'), 'give') (('names', 'class'), 'create') (('Today we', 'Model Interpretability'), 'go') (('grey LOL little Answering', 'above question'), 'explain') (('why I', 'fly'), 'be') (('We', 'last partThis'), 'use') (('intermediate layers', 'Class Activation Mapping http cnnlocalization'), 'visualize') (('you', 'network'), 'choose') (('s', 'few more samples'), 'use') (('algorithm', 'limit'), 'improve') (('reproducibleThumb rule', 'Always seed'), 'do') (('we', 'convolution last layer'), 'take') (('results', 'reproducibility'), 'do') (('that', 'monkey'), 'say') (('Deep Learning especially models', 'often black box'), 'consider') (('which', 'pandas then dataframe'), 'store') (('learning ConclusionMachine models', 't pure black box'), 'aren') (('you', 'monkey'), '-PRON-') (('one', 'training'), 'define') (('we', 'intermediate layers'), 'define') (('where we', 'face'), 'be') (('you', 'http media'), 'have') (('pub', 'building 2018 lot more direction'), 'have') (('Model InterpretabilityNow', 'most important part'), 'start') (('Load it', '4'), 'dataset') (('here I', 'base network'), 'do') (('model', 'even non technical person'), 'list') (('we', 'model interpretability'), 'Can') (('at least face', 'model'), 'suggest') (('that', 'model predictions'), 'explore') (('it', 'hidden layers'), 'infer') (('which', 'then directly training'), 'load') (('it', 'specific details'), 'disadvantage') (('what', 'extent'), 'be') (('itWe', 'monkey_labels'), 'read') (('It', 'nearby future'), 'be') (('don t', 'limited data deep models'), 'have') (('We', 'Input layer'), 'edu') (('last kernel', 'Kaggle Survey https Challenge 2018 www'), 'be') (('where class', 'classes'), 'create') (('we', 'heatmap'), 'compute') (('I', 'new kernel'), 'Kagglers') (('values', 'output conv values'), 'Set') "}
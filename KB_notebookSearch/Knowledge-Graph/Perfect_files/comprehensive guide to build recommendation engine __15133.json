{"name": "comprehensive guide to build recommendation engine ", "full_name": " h1 Introduction h1 1 Association Rule Learning h2 1 1 Data Preprocessing h3 1 1 2 Business Problem h3 1 1 3 Dataset Story h3 1 1 4 Variables h3 1 1 5 LIBRARIES h3 1 1 6 Load and Check Data h3 1 1 7 Outlier Observations h2 1 2 Preparing ARL Data Structure Invoice Product Matrix h2 1 3 Association Rules h2 1 4 Making Product Suggestions to Users at the Shopping Cart Stage h4 Some Notes h1 2 Content Based Filtering h3 Euclidean Distance h3 Cosine Similarity h2 2 1 Generating TF IDF Matrix h3 2 1 1 Libraries h4 2 1 2 CountVectorizer h4 2 1 3 tf idf h2 2 2 Creating Cosine Similarity Matrix h2 2 3 Making Suggestions Based on Similarities h2 2 4 Functionalize All Code of Content Based Filtering h1 3 Collaborative Filtering h2 3 1 Item Based Collaborative Filtering h3 3 1 2 Data Preprocessing h3 3 1 2 Creating the User Movie Df h3 3 1 3 Making Item Based Movie Suggestions h2 3 2 User Based Collaborative Filtering h3 3 2 1 Data Preprocessing h3 3 2 2 Determining The Movies Watched By The User To Make A Suggestion h3 3 2 3 Accessing Data and Ids of Other Users Watching the Same Movies h3 3 2 4 Identifying Users with the Most Similar Behaviors to the User to Suggest h3 3 2 5 Calculating the Weighted Average Recommendation Score h2 3 3 Matrix Factorization h4 What are these factors in this data h4 Some Notes h3 3 3 1 Data Preprocessing h3 3 3 2 Modelling h3 3 3 3 Model Tuning h3 3 3 4 Final Model and Prediction h1 4 References ", "stargazers_count": 0, "forks_count": 0, "description": "1 Item Based Collaborative Filtering Suggestions are made on item similarity. 2 Data Preprocessing We have 20000797 rows 6 columns we don t want to use all of them. 3 Dataset Story The data set named Online Retail II is a UK based online sale. References https github. Common movies count 50 3. In this notebook we will explain how to build a recommender system with these three methods. 2 Business ProblemTo suggest products to customers who have reached the basket stage. There is one more problem this above table. com blogs what are recommendation systems machine learning https en. org wiki Association_rule_learning pip install mlxtend libraries pd. 3 Accessing Data and Ids of Other Users Watching the Same Movies 28 3. 5 Calculating the Weighted Average Recommendation Score 30 3. rename columns user_id_2 userId inplace True rating pd. 6 Load and Check Data 7 1. Creating the TF IDF Matrix2. sort_values weighted_rating ascending False movie pd. read_csv kaggle input movielens 20m dataset movie. Frac is in ration of percentage you desire. 2 Preparing ARL Data Structure Invoice Product Matrix 9 1. These are called latent factors features in machine learning. We will aggregate data from James and other users. reset_index movies_to_be_recommend recommendation_df recommendation_df weighted_rating 3. 2 User Based Collaborative Filtering 25 3. 4 Functionalize All Code of Content Based Filtering 3. Description Product name Quantity Number of products. For instace let s look at the example below. Factor matrices User latent factors movie latent factors are actually two separate matrices. Preparing ARL Data Structure Invoice Product Matrix 3. fillna tfidf_matrix tfidf. csv return movies_to_be_recommend. 3 Matrix Factorization To fill in the blanks the weights of the latent features that are assumed to exist for users and movles are found over the existing data and predictions are made for non existent observations with these weights. 3 Making Item Based Movie SuggestionsLet s put all the codes in a single script 3. Data Preprocessing We have already defined user movie matrix above as named user_movie_df. We will use this data instead of making all the data process again. The weights of the latent factors are found on the filled observations. Making Suggestions Based on Similarities4. Identifying Users with the Most Similar Behaviors to the User to Suggest We will perform 3 steps 1. I know what to suggest with product X but if the person has already bought this product it is necessary to make a correction accordingly. ALS Spark ALS for big data. Content Based Filtering 12 2. The unique number of each transaction namely the invoice. let s take some sample from this data. These weights scores are first found on the existing data and then the empty sections are filled according to these weights. 3 Model Tuning 34 3. It s an optimization it s actually a gradient descent work. drop_duplicates corr_df pd. At the database level the userid should be checked. There are two levels in data. reset_index drop True top_users top_users. It expresses how many of the products on the invoices have been sold. columns random_user_df. isin users_same_movies random_user_df movies_watched corr_df final_df. Empty observations are filled with the weights found. DataFrame corr_df columns corr corr_df. If the word is in it it will count 1 or more othewise 0. Accessing Data and Ids of Other Users Watching the Same MoviesAs we can see above there are lots of people watched at least one movie in common but we need to put a threshold here. 1 Data Preprocessing 26 3. com in vahitkeskin https www. 01 we don t want to get below 0. Which one should we consider Calculation of weighted_rating there are 8071 movies list of movies to recommend james def user_based_recommender import pickle import pandas as pd random_user int pd. apply would only itinirate in row or columns minumum support value 0. 2 CountVectorizer 15 2. 2 Creating the User Movie Df 3. The ouput indicates Invoice 536527 has these above items. These systems forecast the most probable product that customers would buy and it is interesting to them. Thus p and q values are filled as a result of a certain iteration. One is corr other one is rating. There is a fine line you should consider 2. Preparation of the Working Script Euclidean Distance d p q sqrt sum_ i 1 infty x_i \u00dcr\u00fcn i\u00e7eriklerinin benzerlikleri \u00fczerinden tavsiyeler geli\u015ftirilir. 1 Data Preprocessing 2 1. 3 Dataset Story 4 1. We will only work on Germany let s filter. 4 Functionalize All Code of Content Based Filtering 19 1. And we want to see whether there are products at the intersections of the matrix or not. It is designed to identify strong rules that have been identified in databases using various measures of interest. Initially random p and q values and the values in the rating matrix are tried to be estimated. It assumes that the transition from two matrices to the user item matrix occurs with latent factors. 1 Data Preprocessing 32 3. 2 Preparing ARL Data Structure Invoice Product Matrix In this section we will create a matrix of invoice and products as in the example below. Collaborative Filtering Item Based Collaborative Filtering User Based Collaborative Filtering Model Based Collaborative Filtering 3. The reason why James watches the movie the genre of the film the director or actors of the film the duration of the film the language in which the film was shot. sort_values by corr ascending False top_users. index random_user movies_watched random_user_df. You can make the dataset smaller with this below code. 3 Making Suggestions Based on Similarities 18 2. Let s turn all these codes into a single function named create_invoice_product_df. There is also information that most of its customers are wholesalers. max_rows None \u00e7\u0131kt\u0131n\u0131n tek bir sat\u0131rda olmas\u0131n\u0131 sa\u011flar. Some Notes Matrix Factorization vs SVD is not the same SVD Singular Value Decomposition is a size reduction method. Users and movies are considered to have scores for latent features. 7 Outlier Observations 8 1. Unique number for each product. InvoiceDate Invoice date and time. sample 1 random_state 45. merge rating userId movieId rating how inner top_users_ratings weighted_rating top_users_ratings corr top_users_ratings rating top_users_ratings top_users_ratings top_users_ratings userId random_user recommendation_df top_users_ratings. 3 tf idf There are normalized numeric representations. 3 Making Suggestions Based on SimilaritiesCosine similarities of The American President movie and other movies. In each iteration erroneous estimations are arranged and the values in the rating matrix are tried to be approached. 2 Modelling 33 3. Seconly If there is a product in the columns we will convert it to 1. 2 CountVectorizerIn the Count operation the number of times each word occurs in each document is counted. columns userId movie_count users_same_movies user_movie_count user_movie_count movie_count 20 userId final_df pd. Estimation is made for null observations based on the available p and q. Content Based Filtering Represent texts mathematically vectoring texts Count Vector word count TF IDFIn this content based section we will go through these steps below. sum user_movie_count user_movie_count. 4 Making Product Suggestions to Users at the Shopping Cart Stage 11 1. It doesn t look good let s make id True in create_invoice_product_df for better looking matrix Let s define a function for checking StockCode number Let s check first stockcode s name 10002 1. 3 Making Item Based Movie Suggestions 24 3. 1 Generating TF IDF MatrixRecommendation System Based on Movie Overviews 2. The data we created in accordance with the data structure of the surprise library predictions Let s guess blade runner 541 for userid 1 Let s guess Whispers 356 for userid 1. 0 with James another person has low corr but high rating. We will assume the latent variables. 5 Libraries 6 1. showing the index number of the films generates index capturing the index of the title Calculating similarity scores by title the top 10 movies except itself the movie we chose Example Example def calculate_cosine_sim dataframe tfidf TfidfVectorizer stop_words english dataframe overview dataframe overview. StockCode Product code. 4 Making Product Suggestions to Users at the Shopping Cart StageExample Product Id 22492If want to see two product suggection Some Notes For example if I had 10 000 products I wouldn t be interested in all of them. We will convert all words to the matrix. We guessed for the movie she didn t watc here it is our parameters for the model epoch and learning rate Let s guess blade runner 541 for userid 1 Another example Cries and Whispers 356 for user id1. Step 1 Preparing the Data Set Step 2 Determining the Movies Watched by the User to Suggest Step 3 Accessing Data and Ids of Other Users Watching the Same Movies Step 4 Identifying Users with the Most Similar Behaviors to the User to Suggest Step 5 Calculating the Weighted Average Recommendation Score 3. Firstly we will assign 0 to NaN values. Which one should we consider I need to make a weighting based on rating and correlation. Calculating the Weighted Average Recommendation Score We will create a single score by simultaneously considering the impact of the users most similar to James correlation and the rating. Our aim is to suggest products to users in the product purchasing process by applying association analysis to the online retail II dataset. tolist movies_watched_df user_movie_df movies_watched user_movie_count movies_watched_df. 65 user_id_2 corr. 0 moving user_movie_count in the columns 40 treshold in common movies how many people watch the same movies with James he watched 50 movies there is one person watching the same movies let s bring users id watching the same movies We set all user in the columns but it doesn t look good therefore we will make them tidy making above matrix tidy Users with 65 percent or more correlation with James lets merge our new table with ratings taking out James from the table We have a problem here. Cosine SimilarityEuclidean Distance It finds the distance between two vectors. Let s make it more clear. Latent factors Or latent features Latent factors or variables. References 36 1. Association Rule Learning Association rule learning is a rule based machine learning approach for finding significant connections between variables in large databases. csv top_users_ratings top_users. read_csv kaggle input movielens 20m dataset rating. UnitPrice Product price in GBP CustomerID Unique customer number Country The country where the customer lives. While you are liking the movie there are some factors that you are not aware of. Aborted operation if it starts with C. IntroductionRecommender systems are a big part of our lives recommending products and movies that we want to buy or watch. 2 Creating Cosine Similarity Matrix 2. 4 Variables InvoiceNo Invoice number. Creating the Cosine Similarity Matrix3. How many times will I update the weight With this question what will my learning speed be There is a learning rate that represents the speed of these updates. We will create the correlation df. antecedent support probability of the first product consequent support probability of the second product and others support probability of two products or more appearing together confidence when product x is bought the probability of purchasing product y lift when x is taken the probability of getting y increases by this much lift 1. For instance there are movies that show the same liking structure as The Lord of The Rings movie. 1 Item Based Collaborative Filtering 21 3. 2 Creating the User Movie Df 23 3. Association Rule Learning ARL 1 1. com mvahit https www. If the person has not bought that product after checking it is necessary to recommend that product. Making Product Suggestions to Users at the Shopping Cart Stage 1. values random_user_df user_movie_df user_movie_df. 1 Generating TF IDF Matrix 13 2. Decomposes the user item matrix into 2 less dimensional matrices. 3 tf idf 16 2. In this case it should be done at category level When the person adds a product to the cart what I will suggest should already be clear. We will find the most similar finders Top Users We have a problem here. We do not want to recommend weighted_score below 3. agg weighted_rating mean recommendation_df recommendation_df. Should I do this replacement 10 times like 100 times So this is a hyperparameter for me that needs to be optimized by the user. Matrix factorization assume There are some latent factors when users like a movie. ADD TABLES PICTURE r_ 11 p_ 11 q_ 11 p_ 12 q_ 21 All p and q are found iteratively over the existing values and then used. concat movies_watched_df movies_watched_df. 3 Association Rules 10 1. For example if 5 is called 3 in one iteration the next one is called 4 then 5 is called. Only difference ALS make some changes on p and q values. Collaborative Filtering 20 3. User Based Collaborative FilteringSuggestions are made based on user similarities. We have four sentences. STEP 1 TF t Frequency of occurrence of a t term in the relevant document Total number of terms in the document term frequency Step 2 IDF t 1 log_e Total number of documents 1 number of documents with t term 1 inverse document frequency Step 3 TF IDF TF t IDF t Step 4 L2 normalization to TF IDF values 2. There are many ratings given to a movie. 4 Variables 5 1. It will not bring under 10000 taking out rare movies from dataframe all ratings we have 462 movies now let s pivot it columns count and title count are equal Another Example random selection of movies script of all codes user_movie_df create_user_movie_df this function helps to find the movie names Let s define a random user the output random user id we selected the random_user s movie here Taking out all NaN if you want to see all the movies that watched by random user execute this Let s check if random user watch 2001 A Space Odyssey 1968 how many movies he watched James movies Number of people who watched at least one movie in common with James. The product catalog of this company includes souvenirs. 01 In real life scenarios this minimum support value is very low. 3 Model TuningThere is the problem of how long I will do the process of changing the values. 1 Data Preprocessing 1. Determining The Movies Watched By The User To Make A Suggestion 3. 4 Final Model and PredictionUser_id1 didn t give any rate for Cries and Whispers but we predicted that userid1 would give 4. EXAMPLE Description NINE DRAWER OFFICE TIDY SET 2 TEA TOWELS I LOVE LONDON SPACEBOY BABY GIFT SET Invoice 536370 0 1 0 536852 1 0 1 536974 0 0 0 537065 1 0 0 537463 0 0 1 applymap will itinirate all cells in the dataframe. 7 Outlier Observations 1. 1 Libraries 14 2. reset_index user_movie_count. These hidden factors are also present in movies. In this notebook We will discuss three types of recommender system 1 Association rule learning ARL 2 content based and 3 collaborative filtering approaches. Association Rules We will subtract the probabilities of all possible products being together. If we apply this method for all the data all NaN values are going to be filled by the predicted values 4. 3 Model Based Collaborative Filtering Matrix Factorization 31 3. names user_id_1 user_id_2 corr_df corr_df. What are these factors in this data Comedy horror adventure action thriller youth having a specific actor director. There are 8071 movies we can t recommend all these movies. Someone has high corr but rating is 1. Cosine SimilarityA metric focused on the similarity of two vectors. 1 Data Preprocessing 22 3. We want to see the description products in the columns. reset_index top_users corr_df corr_df user_id_1 random_user corr_df corr 0. 1 Data Preprocessing 3. We can do this with unstack function we could have used pivot funct instead of it. fit_transform dataframe overview cosine_sim cosine_similarity tfidf_matrix tfidf_matrix return cosine_sim cosine_sim calculate_cosine_sim df content_based_recommender The Dark Knight Rises cosine_sim df movie counts rating count of each movies we don t want all ratings therefore we add trashold. creating the user movie dataframe The surprise library requires between which numbers it will be. 4 Identifying Users with the Most Similar Behaviors to the User to Suggest 29 3. 2 Business Problem 3 1. There must be an intermediate control mechanism. If there is a product in the columns we expect 1 if not 0. promotion can be considered as products. It takes sample from orginal data. The functions of a recommender system are to suggest things to the user based on a variety of criteria. 137658 people watched at least on movie common movies count 191 user_movie_count indicates how many movies each user watched notnull gives us binary output 1 or 0 if we don t do that the ratings count like 3. 6 Load and Check Data 1. It is assumed that the rating matrix is formed by the product of two factor matrices dot product. merge movie movieId title user_based_recommender pip install surprise We reduce the dataset to these four movies in terms of both followability and performance. 4 Final Model and Prediction 35 1. Store s sales between 01 12 2009 09 12 2011. 2 Determining The Movies Watched By The User To Make A Suggestion 27 3. Recommender systems have been around for decades but have recently come into the spotlight. add FORMULA OF MATRIX FAC. Netflix Amazon and other businesses employ recommendation algorithms to assist their clients in locating appropriate items or movies. 2 Creating Cosine Similarity Matrix 17 2. We will use groupby for this problem. ", "id": "kemalgunay/comprehensive-guide-to-build-recommendation-engine", "size": "15133", "language": "python", "html_url": "https://www.kaggle.com/code/kemalgunay/comprehensive-guide-to-build-recommendation-engine", "git_url": "https://www.kaggle.com/code/kemalgunay/comprehensive-guide-to-build-recommendation-engine", "script": "check_id mlxtend.frequent_patterns train_test_split association_rules SVD check_df surprise CountVectorizer create_user_movie_df cross_validate TfidfVectorizer Reader sklearn.feature_extraction.text retail_data_prep content_based_recommender check_film create_invoice_product_df accuracy replace_with_thresholds item_based_recommender pandas user_based_recommender surprise.model_selection apriori arl_recommender Dataset cosine_similarity calculate_cosine_sim sklearn.metrics.pairwise GridSearchCV outlier_thresholds ", "entities": "(('person', 'low corr'), 'have') (('Initially random p values', 'rating matrix'), 'try') (('Item Based Collaborative Filtering 1 Suggestions', 'item similarity'), 'make') (('NaN values', 'predicted values'), 'apply') (('person', 'product'), 'be') (('Comedy horror adventure action thriller youth', 'actor specific director'), 'be') (('aim', 'retail II online dataset'), 'be') (('values', 'user_movie_df user_movie_df'), 'random_user_df') (('Cosine SimilarityA metric', 'two vectors'), 'focus') (('that', 'interest'), 'design') (('we', 'example'), 'prepare') (('we', '1'), 'convert') (('1 s', '356 userid'), 'let') (('ADD TABLES PICTURE q 11 _ 11 11 _ 12 21 p', 'iteratively existing values'), 'r') (('product catalog', 'souvenirs'), 'include') (('s', 'example'), 'let') (('Data We', 'user movie already matrix'), 'preprocesse') (('we', 'three methods'), 'explain') (('we', 'movie'), 'generate') (('we', 'instead it'), 'do') (('hidden factors', 'also movies'), 'be') (('Thus p values', 'certain iteration'), 'fill') (('Users', 'latent features'), 'consider') (('I', 'rating'), 'consider') (('we', 'that'), 'be') (('learning that', 'updates'), 'update') (('We', 'problem'), 'treshold') (('movies_watched_df tolist user_movie_df', 'user_movie_count movies_watched_df'), 'movies_watched') (('how long I', 'values'), 'be') (('film', 'which'), 'reason') (('transition', 'latent factors'), 'assume') (('functions', 'criteria'), 'be') (('that', 'weights'), 'find') (('org wiki Association_rule_learning pip install', 'libraries'), 'mlxtend') (('read_csv kaggle input', 'm 20 dataset movie'), 'movielen') (('SET 536370 1 1 536974 0 537065 1 0 0 537463 0 0 1 applymap', 'dataframe'), 'description') (('don ratings', '3'), 'watch') (('when x', 'much lift'), 'support') (('it', 'them'), 'forecast') (('userid1', '4'), 'give') (('s', 'first name'), 'doesn') (('8071 we', 't movies'), 'be') (('We', '3 steps'), 'perform') (('then empty sections', 'weights'), 'find') (('who', 'basket stage'), 'suggest') (('Invoice', 'items'), 'indicate') (('Matrix factorization', 'latent when movie'), 'assume') (('dataset', 'code'), 'make') (('then 5', 'one iteration'), 'call') (('we', 'matrix'), 'want') (('userid', 'database level'), 'check') (('We', 'James'), 'aggregate') (('it', '1 othewise'), 'count') (('We', 'columns'), 'want') (('also most', 'customers'), 'be') (('s', 'single function'), 'let') (('s', 'user 1 356 id1'), 'be') (('merge rating', 'movieId how inner top_users_ratings weighted_rating'), 'rate') (('that', 'Rings movie'), 'be') (('We', 'ARL 2 content'), 'discuss') (('therefore we', 'trashold'), 'return') (('support minimum value', 'life real scenarios'), '01') (('User Based Collaborative FilteringSuggestions', 'user similarities'), 'make') (('Unique customer number where customer', 'UnitPrice Product GBP'), 'price') (('Empty observations', 'weights'), 'fill') (('we', '1'), '0') (('Association Rules We', 'possible products'), 'subtract') (('it', 'user movie dataframe'), 'create') (('merge pip install movie movieId We', 'followability'), 'surprise') (('who', 'common James'), 'bring') (('Recommender systems', 'recently spotlight'), 'be') (('apply', 'support only row minumum value'), 'itinirate') (('how many', 'invoices'), 'express') (('SVD Singular Value same Decomposition', 'SVD'), 'be') (('that', 'user'), 'do') (('We', '3'), 'want') (('common we', 'threshold'), 'be') (('we', 'pd random_user int pd'), 'consider') (('values', 'rating matrix'), 'arrange') (('s', 'only Germany'), 'work') (('We', 'James most similar correlation'), 'create') (('rule learning', 'large databases'), 'be') (('suggest', 'what'), 'do') (('Top We', 'problem'), 'find') (('Cosine SimilarityEuclidean It', 'two vectors'), 'Distance') (('rating matrix', 'factor matrices dot two product'), 'assume') (('Identifying 4 Users', 'Average Recommendation 5 Weighted Score'), 'step') (('I', 'them'), '4') (('We', 'data'), 'use') (('you', 'percentage'), 'be') (('fine you', '2'), 'be') (('Netflix Amazon', 'appropriate items'), 'employ') (('Latent factors', 'Latent factors'), 'feature') (('we', 'them'), 'datum') (('Estimation', 'available p'), 'make') (('ALS', 'p values'), 'make') (('weights', 'filled observations'), 'find') (('you', 'movie'), 'be') (('latent factors', 'machine learning'), 'call') (('content based we', 'steps'), 'vectore') (('occurs', 'document'), 'count') (('index random_user', 'random_user_df'), 'movies_watched') (('it', 'correction'), 'know') (('read_csv kaggle input', 'm dataset 20 rating'), 'movielen') "}
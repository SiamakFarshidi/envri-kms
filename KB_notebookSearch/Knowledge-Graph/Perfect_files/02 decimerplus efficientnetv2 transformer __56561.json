{"name": "02 decimerplus efficientnetv2 transformer ", "full_name": " h1 Bristol Myers Squibb Molecular Translation h2 Image Captioning End to End Pipeline EfficientNetV2 h1 TABLE OF CONTENTS h3 0 xa0 xa0 xa0 xa0IMPORTS h3 1 xa0 xa0 xa0 xa0BACKGROUND INFORMATION h3 2 xa0 xa0 xa0 xa0SETUP h3 3 xa0 xa0 xa0 xa0HELPER FUNCTIONS h3 4 xa0 xa0 xa0 xa0PREPARE THE DATASET h3 5 xa0 xa0 xa0 xa0MODEL PREPARATION h3 6 xa0 xa0 xa0 xa0DATASET CREATION h3 7 xa0 xa0 xa0 xa0CUSTOM MODEL TRAINING h3 8 xa0 xa0 xa0 xa0INFER ON TEST DATA h1 0 xa0 xa0IMPORTS xa0 xa0 xa0 xa0 h1 1 xa0 xa0BACKGROUND INFORMATION xa0 xa0 xa0 xa0 h1 2 xa0 xa0SETUP xa0 xa0 xa0 xa0 n h3 2 1 ACCELERATOR DETECTION h1 The name you gave to the TPU to use h1 or you can also specify the grpc path directly h1 TPU WORKER grpc xxx xxx xxx xxx 8470 h1 The zone you chose when you created the TPU to use on GCP h1 The name of the GCP project where you created the TPU to use on GCP h3 2 2 COMPETITION DATA ACCESS h3 2 3 LEVERAGING MIXED PRECISION h3 2 4 LEVERAGING XLA OPTIMIZATIONS h3 2 5 BASIC DATA DEFINITIONS INITIALIZATIONS h3 2 6 INITIAL DATAFRAME INSTANTIATION h3 2 7 USER INPUT VARIABLES h1 n 3 xa0 xa0HELPER FUNCTION CLASSESS xa0 xa0 xa0 xa0 n h3 3 1 GENERAL HELPER FUNCTIONS h1 4 xa0 xa0PREPARE THE DATASET xa0 xa0 xa0 xa0 h3 4 1 READ TFRECORD FILES CREATE THE RAW DATASET S h3 4 2 WHAT TO DO IF YOU DON T KNOW THE FEATURE DESCRIPTIONS OF THE DATASET h1 See an example h3 4 3 PARSE THE RAW DATASET S h3 4 4 WORKING WITH TF DATA DATASET OBJECTS h1 5 xa0 xa0MODEL PREPERATION xa0 xa0 xa0 xa0 h3 5 1 UNDERSTANDING THE MODELS ENCODER h3 5 2 UNDERSTANDING THE MODELS TRANSFORMER h3 5 2 0 TRANSFORMER HYPERPARAMETERS h3 5 2 1 TRANSFORMER POSITIAL ENCODING h3 5 2 2 TRANSFORMER MASKING h3 5 2 3 TRANSFORMER SCALED DOT PRODUCT ATTENTION h3 5 2 4 TRANSFORMER MULTI HEAD ATTENTION h3 5 2 5 TRANSFORMER POINT WISE FEED FORWARD NEURAL NETWORK h3 5 2 6 TRANSFORMER ENCODER DECODER NETWORK ARCHITECTURE OVERVIEW h3 5 2 7 TRANSFORMER ENCODER h3 5 2 8 TRANSFORMER DECODER LAYER COMPONENT h3 5 2 9 TRANSFORMER ENCODER COMPONENT h3 5 2 10 TRANSFORMER DECODER COMPONENT h3 5 2 11 TRANSFORMER PUT IT ALL TOGETHER h3 5 3 CREATE A LEARNING RATE SCHEDULER h3 5 4 WRAP THE CONFIGURATION DETAILS IN A CLASS OBJECT FOR EASY ACCESS h3 5 5 HOW TPU IMPACTS MODELS METRICS AND OPTIMIZERS h3 5 6 LOSS CLASSES AND REDUCTION h3 5 7 DISTRIBUTE THE DATASETS ACROSS REPLICAS h3 5 8 DISTRIBUTED COMPUTATION OPTIMIZING LOOPS h1 6 xa0 xa0MODEL TRAINING xa0 xa0 xa0 xa0 h3 6 1 INDIVIDUAL TRAIN STEP h3 6 2 INDIVIDUAL VAL STEP h3 6 3 INITIALIZE LOGGER h3 6 4 CUSTOM TRAIN LOOP h3 6 4 1 \u7b5b\u9009\u51fatokenS\u957f\u5ea6\u4e0d\u8d85\u8fc747\u7684\u5206\u5b50 \u4e14\u5747\u5728\u8bcd\u5178\u4e2d h3 6 4 2 decimer\u4ee3\u7801\u751f\u6210\u56fe\u7247\u7edf\u8ba1\u7ed3\u679c h3 6 4 3 \u539f\u59cb\u56fe\u7247\u7edf\u8ba1\u7ed3\u679c\u53ca\u53ef\u89c6\u5316 h3 6 4 3 \u53ef\u89c6\u5316\u7ed3\u679c h3 6 4 2 \u9884\u6d4b\u8f93\u51fa h2 6 4 1 small is good h2 6 4 2 large is good h2 6 4 1 heat h2 6 5 JUST IN CASE SAVE h3 6 5 JUST IN CASE SAVE h3 6 6 VIEW PREDICTIONS DISTRIBUTION OF LEVENSHTEIN DISTANCE FOR VAL DATASET h3 6 7 smiles and inchi lsd h1 7 xa0 xa0INFER ON TEST DATA xa0 xa0 xa0 xa0 h3 7 1 INDIVIDUAL TEST STEP AND DISTRIBUTED h3 7 2 RAW INFERENCE LOOP h3 7 3 TEST PRED POST PROCESSING h3 7 4 SAVE SUBMISSION CSV ", "stargazers_count": 0, "forks_count": 0, "description": "head 100 df_g2 df_g11. nbsp REFERENCE Tutorial TFRecord and tf. You define the operations for example forward pass compute loss values and gradients etc. Dataset from filepaths for conversion later raw_test_ds tf. size 299 299 m Chem. numpy if z not in 0 1 2 n plt. inchi_lsd 0 print df_1 df_1 inchi_lsd 0 inchi_lsd. index_word x for x in ls 1 np. However the tuple now contains PerReplica objects wheras before that tuple contained tensors representing the image and the label id respectively. where l 2 0 0 LD Levenshtein. uint8 predictions_seq_batch tf. join TEST_DATA_DIR test_records Get the Full Paths to The Individual TFRecord Files TEST_TFREC_PATHS sorted tf. nbsp NOTE The parsed images are tf. numpy print Levenshtein. Define a parsing function by using tf. dump loss_pkl open loss_pkl. where l END_TOKEN 0 0 p_s selfies_decoder p_s l_s selfies_decoder l_s pre_smiles_ecfp simies_to_ecfps p_s lable_ecfp simies_to_ecfps l_s pre_smiles_ecfp_batch. In particular the following methods and attributes are of special interest to us Use num_parallel_reads in tf. Recently deep learning methods have achieved state of the art results on examples of this problem. n print f t t t TRUNCATED VALUE v. argmax prediction_batch axis 1 output_type tf. distance p_s l_s if i 1000 0 print f Levenshtein Distance LD print f t p_s print f t l_s n pred_s. 8 TRANSFORMER DECODER LAYER COMPONENT Each transformer decoder layer consists of sublayers 1. cut df LDS_ALL bins listBins right True labels listLabels retbins False precision 3 include_lowest True auc_all_min min df target auc_all_max max df target cut_n 100 cut_ran auc_all_max auc_all_min 100 auc_list confirence_auc_list right_list for i in range cut_n i i 1 confirence_auc auc_all_min i cut_ran if 100 i confirence_auc auc_all_min i cut_ran cut_ran 10000 confirence_auc_list. express as px import seaborn as sns from PIL import Image import matplotlib import plotly import PIL import cv2 df pd. com c flower classification with tpus discussion 135443 for a good benchmark by Martin G\u00f6rner https www. mean df_g1 df_g. In this notebook we use a fixed number of training steps so we can also use python tf. input daily result levenshtein_distance_cleaned_JPO_all. decode for x in tqdm all_pred_ids 1 REQUIRED_DATASET_PAD. 1 UNDERSTANDING THE MODELS ENCODER We will be leveraging an EfficientNetV2 https arxiv. 11 TRANSFORMER PUT IT ALL TOGETHER Our Transformer consists of the transformer encoder transformer decoder and a final linear layer. However on G oogle C ompute E ngine GCE you will need to do the following python The name you gave to the TPU to useTPU_WORKER my tpu name or you can also specify the grpc path directly TPU_WORKER grpc xxx. numpy print sum pre_smiles_ecfp print sum 1 if i 0. experimental_local_results https www. The mask is multiplied with 1e9 close to negative infinity. See TPU extreme optimizations https www. DataFrame df image_id_all image_id_all df batch_dis_all batch_dis_all df preds_all smiles_all df preds_selfies_all selfies_all df selfies_labels_all selfies_labels_all df. head 100 df_g1 df_g1. join destination_directory file_name blobs storage_client. append pre_smiles_ecfp pre_ecfp tf. Let s get started nbsp REFERENCE Tutorial Using Iterators Tutorial Iterating Inside a tf. gather per_replica_seqs axis 0 pred_ids strategy. reset_index drop True pred_df pred_df. output of EfficientNetV2 The output of the decoder is the input to the linear layer and its output is returned. values 0 selfies_label_1 df df image_id_all image_id selfies_labels_all. This can be found on the GCP project dashboard page. whl Apt get Library used to easily calculate LD Built In Imports Visualization Imports efficientnet v2 efficientnet v1 Machine Learning and Data Science Imports For reference later EV2_NAME efficientnetv2 b2 EfficientNet Module Imports See EfficientNetV2 Base Config Detect hardware return appropriate distribution strategy TPU detection. TPUClusterResolver tpu TPU_WORKER zone ZONE project PROJECT nbsp WARNING Although the Tensorflow documentation says it is the project name that should be provided for the argument project it is actually the Project ID that you should provide. Let s go over two important points1. This includes but is not limited to model creation optimizer metrics sometimes checkpoint restore any custom code that creates distributed variables Once a variable is created inside a strategy s scope it captures the strategy s information and you can use it outside the strategy s scope. index df_final. filterwarnings ignore val_dist_ds iter strategy. The look ahead mask is used to mask the future tokens in a sequence. to peform just like witout using TPU. input daily result val_lsd_confidence_auc_4. string dist_test_ds iter strategy. figure figsize 20 10 dpi 80 plt. In the following cell we will demonstrate using dummy values and pretending we are distributing them how to deal with the accumulation of the loss values across replicas. Example TFRecordDataset Documentation Decoding PNGs Documentation4. mean df_2 print inchi_lsd\u4e0d\u4e3a0 print len df_2 df_1 for x y z w in val_ds. int64 default_value 150 feature_dict h tf. MolFromSmiles smiles if None mol fp fptype. cloud import storage storage_client storage. On TPU GPU CPU we will use an EfficientNetV2 B2 model Basic View of EfficientNetB0 Architecture w 380x380x3 Input. toolkit mol Chem. int64 default_value 150 else Define a parser Decode the tf. numpy to check the information. append lbls_s all_right_ratio len np. subplot 1 2 1 plt. append l_s if 1 in p or 1 in l smiles_all. RAW TFRECORD INVESTIGATION TO DETERMINE FEATURE DESCRIPTIONS STARTED. Hence square root of dk is used for scaling and not any other number because the matmul of Q and K should have a mean of 0 and variance of 1 and you get a gentler softmax. The scaled_dot_product_attention defined above is applied to each head broadcasted for efficiency. mha2 attn2 attn2 out1 padding_mask Residual connection followed by layer normalization batch_size target_seq_len d_model batch_size target_seq_len d_model Residual connection followed by layer normalization batch_size target_seq_len d_model sample_decoder_layer_output _ _ sample_decoder_layer tf. pool x x 2 72 208 img_logit self. Policy typically referred to as a dtype policy. n except print byte print f t t t TRUNCATED VALUE v. plot right_list 1 plt. For example pythonfeature_description feature0 tf. graph_objects as go import matplotlib. In the next cell we instantiate the learning rate function the loss object and the model s inside the scope nbsp REFERENCE TPUStrategy Scope Tutorial Custom Training With TPUs5. array pre_smiles_ecfp euclidean spatial. array pre_smiles_ecfp_batch print _val_pattern_batch. distance s1 s2 df_1 inchi_lsd df_1. 1 GENERAL HELPER FUNCTIONS 4 nbsp nbsp PREPARE THE DATASET nbsp nbsp nbsp nbsp 10514 In this section we prepare the tf. In other words the decoder predicts the next word token by looking at the encoder output and self attending to its own output. index_word x for x in p selfies_all. numpy 0 0 len batch_distance. sort_values by image_id. org api_docs python tf distribute Strategy run will have a communication between the local VM in our case the Kaggle VM and the remote TPU worker s. softmax is normalized on the last axis seq_len_k so that the scores add up to 1. Args filenames list of strings List of paths to that point to the respective TFRecord files is_test bool optional Whether or not to include the image ID or label in the returned dataset ordered bool optional Whether to ensured ordered results or maximize parallelization tokenized_smile bool optional Whether our dataset includes the tokenized smile or we will be creating it from the caption numpy array Returns Decoded tf. We say an operation is numerically unstable in float16 or bfloat16 if running it in one of those dtypes causes the model to have worse evaluation accuracy or other metrics compared to running the operation in float32. loc 1 LDS_ALL 100 right_list. concat all_pred_arr preds axis 0 all_pred_ids tf. decode_png The smile strings and Image IDs will just be left as byte string tensors. org api_docs python tf function. Each multi head attention block gets three inputs Q query K key V value These are put through linear Dense layers and split up into multiple heads. current_step epoch 1 TRAIN_STEPS Save every other epoch starting with first epoch Save after last epoch too. This is incorrect. grid print pre_smiles_ecfp print 1 if i 0. 1 \u7b5b\u9009\u51fatokenS\u957f\u5ea6\u4e0d\u8d85\u8fc747\u7684\u5206\u5b50 \u4e14\u5747\u5728\u8bcd\u5178\u4e2d 6. not_equal lbls END_TOKEN lbls 0 preds_sparse dense_to_sparse preds lbls_sparse dense_to_sparse lbls batch_distance tf. org api_docs python tf distribute Strategy run are also distributed values just like the distributed batches it takes as inputs. csv Instantiate our tool for logging for epoch in range 1 2 to compute epoch duration create distributed versions of dataset to run on TPU with 8 computation units Update current step Update the current step Calculate training step end of epoch validation step for _ in range 2 LDS tonimoto_list all_right_num get_levenshtein_distance_smiles preds lbls LDS_ALL. groupby w h lsd. function calls Prefixes and Their Respective Ordering Format ORDERING c h None b None t None m None s None i None h None t None m None Paths to Respective Image Directories TEST_DIR os. title title plt. iterrows w. experimental_distribute_dataset ds dist_ds will now be distributed across all replicas. seq_len_q depth_v Set print options Demo inputs 4 3 4 2 This query aligns with the second key so the second value is returned. loc 0 LDS_ALL res. Multi Head AAttention with padding mask 2. An example of iterating over a distributed dataset is python for dist_batch in dist_ds dist_step dist_batch Every step in the loop which calls strategy. apply sin to even indices in the array 2i angle_rads_row get_angles tf. groupby auc group. extend LDS for i p l in enumerate zip preds. For adaptive optimisers like Adam warmup also allows the optimizers to compute bettere statistics of the gradients. to_csv levenshtein_distance_cleaned_USPTO_all. The mask indicates where pad value 0 is present it outputs a 1 at those locations it outputs a 0 otherwise. cast i 2 TARGET_DTYPE d_model return pos angle_rates 0 2 4. batch_size target_seq_len d_model x block1 block2 self. TFRecordDataset to read files in parallel. PerReplica https github. upload_from_filename source_file_name print File uploaded to. To understand how strategy. drop_duplicates subset image_id_all df_1 df_3 batch_dis_all d 1 num_bin range int min df_1 int max df_1 d print df_1. csv index False import os os. It ensures that the model does not treat padding as the input. 4 TRANSFORMER MULTI HEAD ATTENTION This is an implementation of multi headed attention based on Attention is all you Need https arxiv. csv print f n. Dataset object options tf. MolToImage m options opts plt. split df_final. get_fingerprint_type RDKit Morgan fpSize 2048 T fptype. json bucket_name example_zhang_kaggle_storage upload_blob bucket_name. either the entire function is compiled with XLA or an errors. input daily result val_lsd_confidence_auc_5. take 1 for i in range 272 df_1 image_id df_1 image_id_all. Today most models use the float32 dtype which takes 32 bits of memory. The dtype of a layer s variables. AUTOTUNE return dataset disable order increase speed If not ordered this will read in by automatically interleaving multiple tfrecord files. txt smiles_dic selfies_dic with open smiles_dir as file lines file. 3 TRANSFORMER SCALED DOT PRODUCT ATTENTION Scaled dot product attention is an attention mechanism where the dot products are scaled down by sqrt d_k. pkl wb epoch image_id_all_1 for i in range len image_id_all image_id_all_1. If query key value are the same then this is self attention. apply lambda x get_lsd x pre_inchi x label_inchi axis 1 df_1. Residual connections help in avoiding the vanishing gradient problem in deep networks. batch_size input_seq_len d_model batch_size input_seq_len d_model maximum_position_encoding 101 maximum_position_encoding 72 maximum_position_encoding 73 print img_embedding_batch print img_embedding_batch. apply lambda x x 2 1 df_1 label_inchi df_1 image_id. numpy for i p l in enumerate zip preds. NVIDIA GPUs can run operations in float16 faster than in float32 TPUs can run operations bfloat16 faster than in float32 Therefore these lower precision dtypes should be used whenever possible on those devices. imshow draw print f pre inchi inchi print f label inchi lable_inchi plt. reshape and put through a final Dense layerInstead of one single attention head Q K and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. trainable_variables Initialize batch_loss Get image embedding once Teacher forcing feeding the target as the next input predictions. In the following cell we will create a function to generate our encoder model. numpy pre_smiles_selfies df_1 df_1 image_id_all image_id preds_all. experimental_distribute_dataset val_ds LDS_ALL confidence_loss_cls_all auc_all ecfps_cosine_all pearsonr_all jaccard_all euclidean_all image_id_all smiles_all selfies_all selfies_labels_all labels_all batch_dis_all pre_smiles_ecfp_batch preds lbls _logit encoder_logit _val_pattern_batch image_id dist_val_step val_dist_ds _ batch_dis get_levenshtein_distance preds lbls image_id_all. where l END_TOKEN 0 0 l_s. numpy pre_smiles_selfies df df image_id_all image_id preds_all. to_csv val_lsd_confidence_auc. list_blobs bucket_name for blob in blobs print blob. Finally the result tensor with the last dimension as value_dim can take an linear projection and return. It is a subclass of tf. numpy pre_smiles_ecfp_a np. val_acc_seq val_lsd_seq stat_logger. n else print f t t t TRUNCATED VALUE str v. colab import drive drive. function def dist_step dist_batch strategy. The decoder attends on the encoder s output and its own input self attention to predict the next word token. experimental_distribute_dataset https www. The results of strategy. numpy pred_s. shape sample_encoder_output sample_encoder img_logit training False mask None batch_size input_seq_len d_model def call self x enc_output1 enc_output2 training look_ahead_mask None padding_mask None adding embedding and position encoding. join list map str 1 if i 0. org api_docs python tf distribute in general certain objects will have to be created inside the strategy s scope Here is the rule of thumb Anything that creates variables that will be used in a distributed way must be created inside strategy. values 0 preds_selfies df df image_id_all image_id preds_selfies_all. append pre_smiles_ecfp df pd. head 100 df_2 df_1 df_1. 1 3 3 3 batch_size seq_len d_model batch_size seq_len d_model batch_size seq_len d_model batch_size num_heads seq_len_q depth batch_size num_heads seq_len_k depth batch_size num_heads seq_len_v depth scaled_attention. The goal is to zero out these cells and large negative inputs to softmax are near zero in the output. transpose and tf. n def get_angles pos i d_model angle_rates tf. pandas import plotly. 0 tensorflow python distribute values. join x for x in l np. These values are softmaxed to obtain attention probabilities. seq_len_q seq_len_k scale matmul_qk Calculate scaled attention logits add the mask to the scaled tensor. uint8 all_pred_ids tf. 2 RAW INFERENCE LOOP INFORMATION7. 1 ACCELERATOR DETECTION In order to use TPU we use TPUClusterResolver for the initialization which is necessary to connect to the remote cluster and initialize cloud TPUs. So after adding the positional encoding words feature representations will be closer to each other based on the similarity of their meaning and their position in the sentence feature vector in the d dimensional space. See the notebook on positional encoding https www. lstrip sel i print PAD_TOKEN print selfies_decoder selfies_encoder Cc1ccc Sc2ccc Sc3ccc C cc3 c C N c2C N cc1 def tf_load_image path img_size 192 384 3 invert False def decode_image image_data resize_to 192 384 3 sparse tensors are required to compute the Levenshtein distance preds tf. show import pandas as pd pd. constant 10000 TARGET_DTYPE tf. We also have to discuss how to collect the returned values from strategy. nbsp TIPS If you have multiple datasets attached to the notebook you should pass the name of a specific dataset to the get_gcs_path function. AUTOTUNE to automatically determine parallelization argument valuesThe parallel processing and prefetching are particular important when working with TPU This is because a TPU can process batches very quickly The dataset pipeline should be able to provide data for TPU efficiently otherwise the TPU will be idle. This will vastly reduce the running time and limit the time TPUs will sit idle waiting for data from the local VM. split image_id str tokens 0 smiles str tokens 1 selfies str tokens 2 smiles_dic image_id smiles selfies_dic image_id selfies for x y z w in val_ds. 4 WRAP THE CONFIGURATION DETAILS IN A CLASS OBJECT FOR EASY ACCESS 5. run replica_fn args dist_batch for dist_batch in dist_ds dist_step dist_batch Here replica_fn is a function that is going to be run on each replica and it should work with tensors not with PerReplica objects. train_loss_seq train_loss_cls stat_logger. 3 CREATE A LEARNING RATE SCHEDULER Adapting the learning rate for your stochastic gradient descent optimization procedure can increase performance and reduce training time. where ls 10 p_s. Example messages and when iterated over it we get scalar string tensors. Even if a dataset yields tuples of tensors the above code still works but replica_fn expects a single tuple of tensors as argument. ceil N_TEST OVERALL_BATCH_SIZE This is for padding our test dataset so we only have whole batches REQUIRED_DATASET_PAD OVERALL_BATCH_SIZE N_TEST OVERALL_BATCH_SIZE Modelling Information ATTN_EMB_DIM 192 print f n. decode_png which is an alias for tf. download_to_filename full_file_path. Dataset https www. The simplest way is to specify a list of filenames paths of TFRecord files. append j Reset the validation metrics as one epoch should not effect the next Print validation scores verbose logging step stop training when NaN loss is detected update learning rate lr_scheduler. xticks num_bin plt. Dtype policies specify the dtypes layers will run in target data type bfloat16 when using TPU to improve throughput The policy specifies two important aspects of a layer 1. EDIT In this notebook we have the option to use gradient accumulation https arxiv. index_word x for x in l 1 np. input daily result similes_test_2_heatmap_id_size. figure dpi 120 sns. run test_step args _img_batch predictions strategy. 1 3 This query aligns with a repeated key third and fourth so all associated values get averaged. numpy total N_TEST pred_df pred_df. Yield the default distribution strategy in Tensorflow Works on CPU and single GPU. Dense 72 name logit_dense2 activation sigmoid logit 2 591 logit self. describe display ld_df px. t_decoder t_tar enc_output1 enc_output2 training look_ahead_mask dec_padding_mask batch_size tar_seq_len target_vocab_size fn_out _ sample_transformer img_embedding_batch img_logit SAMPLE_LBLS training False batch_size tar_seq_len target_vocab_size print n. DERde Will yield at the lowest feature level 6 12 208 or 72 208 def get_efficientnetv2_backbone model_name include_top False input_shape 192 384 3 pooling None weights None Catch unsupported arguments Will yield at the lowest feature level 6 12 208 or 72 208 def get_efficientnetv1_backbone model_name include_top False input_shape 192 384 3 pooling None weights None if pooling or weights or include_top raise NotImplementedError n. org api_docs python tf data Dataset API we can use strategy. 5 TRANSFORMER POINT WISE FEED FORWARD NEURAL NETWORK Point wise feed forward network consists of two fully connected layers with a ReLU activation in between. There is however a particularity about the loss function which we will discuss further down as well. What is most impressive about these methods is a single end to end model can be defined to predict a caption given a photo instead of requiring sophisticated data preparation or a pipeline of specifically designed models. decode utf 8 selfies_df pd. shape batch_size target_seq_len d_model adding embedding and position encoding. com storage docs bucket storage_client. append p_s pre_smiles_ecfp simies_to_ecfps p_s pre_smiles_ecfp_batch. concat predictions_seq_batch decoder_input_batch axis 1 return predictions_seq_batch tf. zeros 1 MAX_LEN dtype tf. this is very similar to EfficientNetV2 Our encoder will create feature maps for each image which will in turn be passed to the decoder side of the network. 6 VIEW PREDICTIONS DISTRIBUTION OF LEVENSHTEIN DISTANCE FOR VAL DATASET INFORMATION6. Each TensorFlow operation has a precompiled GPU TPU kernel implementation that the executor dispatches to. 55 else 0 for i in list en_log. InvalidArgumentError exception is thrown nbsp REFERENCE XLA Optimizing Compiler for Machine Learning2. concat x img_logit 1 Example enoder output print img_embedding_batch. 1 INDIVIDUAL TRAIN STEP INFORMATION6. MolFromSmiles smiles_dic image_id_1 lable_inchi Chem. It is used to pad and mask future tokens in the input received by the decoder. parsed_example tf. with_options options dataset dataset. Here we will call this approach a learning rate schedule. On Kaggle this is always the case. nbsp WARNING XLA can not currently compile functions where dimensions are not inferrable that is if it s not possible to infer the dimensions of all tensors without running the entire computation nbsp NOTE XLA compilation is only applied to code that is compiled into a graph in TF2 that s only a code inside tf. Point Wise Feed Forward Neural Networks Each of these sublayers has a residual connection around it followed by a layer normalization. We will determine the number of steps or updates later for 1 training epoch. 6 INITIAL DATAFRAME INSTANTIATION 2. input daily result smiles. You will get something like pythonfeatures feature key class value int64_list value 57 feature key id value bytes_list value 338ab7bac feature key image value bytes_list value. int64 plt. append index 1 df_g11 df_g1. concat all_pred_ids tf. chained_assignment None import matplotlib. pkl print ld_df. edit_distance preds_sparse lbls_sparse normalize False print len np. In other words the mask indicates which entries should not be used. mount content drive force_remount True bms_train gs from_aws_0001 train_tfrecords bms_test gs from_aws_0001 val_records bms_test gs from_aws_0001 val_records_heatmap bms_test gs from_aws_0001 val_records_JPO bms_test gs from_aws_0001 val_records_UOB bms_test gs from_aws_0001 val_records_USPTO bms_test gs from_aws_0001 val_records_cleaned_good_JPO bms_test gs from_aws_0001 val_records_cleaned_JPO bms_test gs from_aws_0001 val_records_cleaned_UOB bms_test gs from_aws_0001 val_records_cleaned_USPTO bms_test gs from_aws_0001 val_records_cleaned_good_USPTO bms_test gs from_aws_0001 val_records_good_USPTO effnetv2 KaggleDatasets. append LD ld_df pd. numpy 2 1 0 k k 1 image_id str w i. However variables and a few computations should still be in float32 for numeric reasons so that the model trains to the same quality. For example python ds. 2 nbsp nbsp SETUP nbsp nbsp nbsp nbsp 10514 2. Datasets we will use for training and validation4. com using learning rate schedules deep learning models python keras for a basic tutorial on learning rade schedules. values 0 preds_selfies df_1 df_1 image_id_all image_id preds_selfies_all. org api_docs python tf concat to aggregate them into a single tensor. shape batch_size num_heads seq_len_q depth attention_weights. . function def replica_fn batch model batch. Chem import AllChem from rdkit. loc 0 LDS_ALL len df 100 plt. This means that to predict the third token only the first and second tokens will be used. tfrec key lambda x int x. subplot 1 2 2 plt. constant 2 dtype TARGET_DTYPE tf. 5 JUST IN CASE SAVE INFORMATION6. Each timestep in query attends to the corresponding sequence in key and returns a fixed width vector. 2 COMPETITION DATA ACCESS TPUs read data must be read directly from G oogle C loud S torage GCS. 2 WHAT TO DO IF YOU DON T KNOW THE FEATURE DESCRIPTIONS OF THE DATASET If you are the author who created the TFRecord files you definitely know how to define the feature description to parse the raw dataset. take 2 example tf. Positional Encoding3. numpy i try p_s. colors import ListedColormap import matplotlib. Map the raw dataset by _parse_function. numpy for i k v in enumerate example. numpy m1 Chem. get_cmap Set3 \u4f7f\u7528matplotlib\u4e2d\u7684\u989c\u8272\u76d8 plt. DistributedValues https www. 3 PARSE THE RAW DATASET S The general recipe to parse the string tensors in the raw dataset looks something like this STEP 1. trainable_variables decoder. If we utilized EfficientNetV2B7 we would have 2560 feature maps instead of the 1280 feature maps that EfficientNetV2B0 produces. Unless using a high level API like model. join bms_csv train_labels_w_extra. SECONDARY TASK DESCRIPTIONIn this notebook we will go through step by step training models with TPUs in a custom way. Therefore we can see that for each replica we calculate the sum of per examples losses divided by the batch size of the whole distributed batch which will give the optimizer the correct gradients to apply. The output of this summation is the input to the encoder layers. py L361 which is a subclass of tf. function Kaggle Discussion TPU Extreme Optimizations Kaggle Notebook Custom Training Loop With 100 Flowers on TPU6 nbsp nbsp MODEL TRAINING nbsp nbsp nbsp nbsp 10514 In this section we will define the training and validation routines as well as the final custom training loop that will execute everything we have worked on up until this point. What Is a Replica A single Cloud TPU device consists of FOUR chips each of which has TWO TPU cores. newaxis d_model 2 SAMPLE IMAGES ENCODER_CONFIG This will be the dimension the network outputs flattened IMG_EMB_DIM 6 12 208 IMG_EMB_DIM 6 12 232 self. join x for x in p l_s. DataFrame image_id x 0. get_gcs_path that will allow us to access the location of our input datasets within GCS. nbsp REFERENCES Guide Use TPUs Doc TPUClusterResolver2. range n_stes dist_step next dist_ds_iter dist_ds_iter iter dist_ds dist_process_dataset dist_ds_iter With the above discussions we are ready to define the routines used for training validation and prediction. append p_s lbls_s. mha2 enc_output1 enc_output2 out1 padding_mask enc_output1 enc_output1 enc_output2 attn2 attn_weights_block2 self. If we need to add on manually the smile Zip the datasets and tile the 1 channel image to 3 channels drop the old smile value Shuffling Batching prefetch next batch while training autotune prefetch buffer size Template Configuration Individual Respective Configurations test_ds get_dataset TEST_DS_CONFIG for SPLIT CONFIG in zip TRAINING VALIDATION TESTING TRAIN_DS_CONFIG VAL_DS_CONFIG TEST_DS_CONFIG TEST_DS_CONFIG TEST_DS_CONFIG plt. train_loss_cls train_acc_seq stat_logger. append pre_smiles_ecfp confidence_loss_cls loss_cls pre_smiles_ecfp encoder_logit i confidence_loss_cls_all. experimental_deterministic False and use it to get a new dataset that ignores the order of elements. reset_index drop True df_g11. 6 TRANSFORMER ENCODER DECODER NETWORK ARCHITECTURE OVERVIEW The transformer model follows the same general pattern as a standard sequence to sequence with attention model nmt_with_attention. This is obviously not ideal. for dist_batch in dist_ds strategy. join int_2_tok z for z in y i. apply smiles_to_inchi df_1 image_id df_1 image_id_all. Knowing this we are limited to using a reduction value of SUM or NONE as the default value and some of the other options will not work with TPU. 2 TRANSFORMER MASKING Mask all the pad tokens in the batch of sequence. append confidence_loss_cls. positional_encoding positional_encoding_2d 6 12 208 self. org api_docs python tf distribute DistributedValues that is the base class for representing distributed values. expand_dims pred_ids axis 1 axis 0 def arr_2_smile arr smile_str for i in arr c int_2_tok. The positional encoding vector is added to the embedding vector. prefetch to allow later batches to be prepared while the current batch is being processed. array LDS 0 0 len LDS 100 preds tf. If not ordered this will ensure that we use data as soon as it streams in rather than in its original order. 7 DISTRIBUTE THE DATASETS ACROSS REPLICASWith an input pipeline written using the tf. euclidean en_log_a pre_smiles_ecfp_a euclidean_all. AVERAGE LOSS BY EXAMPLE n t accumulated_loss MAX_LEN print f n n. plot auc_list plt. EXAMPLE OF TRUNCATED RAW TFRECORD TFEXAMPLE FROM TRAINING DATASET TO SHOW HOW TO FIND FEATURE DESCRIPTIONS n See an examplefor raw in raw_train_ds. 3 TEST PRED POST PROCESSING INFORMATION7. However you can iterate the distributed dataset inside a tf. show print confirence_auc_list print auc_list print right_list import pandas as pd from sklearn. The normalization is done on the d_model last axis. MolDrawing import MolDrawing DrawingOptions Only needed if modifying defaults df pd. append ecfps_cosine 0 0 r pearsonr pre_smiles_ecfp encoder_logit i pearsonr_all. There are N decoder layers in the transformer As Q receives the output from decoder s first attention block and K receives the encoder output the attention weights represent the importance given to the decoder s input based on the encoder s output. Therefore it is impossible in general to obtain the averaged per example loss over the whole distributed batch from by simply dividing it by the number of replicas. express as px from matplotlib. 1 3 This query aligns equally with the first and second key so their values get averaged. shape batch_size target_seq_len d_model enc_output2 img_logit def call self enc_output1 enc_output2 t_tar def call self enc_output1 t_tar Modified by zjh bypass transformer encoder batch_size inp_seq_len d_model dec_output. n EPOCHS 36 TOTAL_STEPS TRAIN_STEPS EPOCHS WARM_STEPS 100 WARM_START_LR 1e 5 PEAK_START_LR 2e 3 FINAL_LR 1e 4 def lr_schedule_fn step total_steps warm_lr_start warm_steps peak_lr_start lr_final n_epochs Function to generate the learning rate for a given step based on parameters Args step int The current step for which to calculate the respective learning rate total_steps int The total number of steps for the entire training regime warm_lr_start float The starting learning rate prior to warmup warm_steps int The number of steps for which the learning rate will ramp up to the desired peak learning rate value more steps will result in less dramatic changes to existing weights. This is done because for large values of depth the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. csv df_a df df batch_dis_all 10 print len df_a df_2 df_a image_id_all. MolToInchi m logLevel None treatWarningAsError False draw Draw. N decoder layersThe target is put through an embedding which is summed with the positional encoding. pythondef _parse_function example Args example A string tensor representing a tf. index_word x for x in p l_s. cut df LDS_ALL bins listBins right True labels listLabels retbins False precision 3 include_lowest True loss_all_min min df target loss_all_max max df target cut_n 100 cut_ran loss_all_max loss_all_min 100 print loss_all_max print loss_all_min print cut_ran loss_list confirence_loss_list right_list for i in range cut_n i i 1 confirence_loss loss_all_min i cut_ran if 100 i confirence_loss loss_all_min i cut_ran cut_ran 1000 confirence_loss_list. count loss_list. Warmup is commonly used in learning rate schedule where we start training a model with a much smaller learning rate and increase it during the first few epochs steps until the initial learning rate is used. See this article https machinelearningmastery. Inside the scope everything is defined in the same way it would be outside the distribution strategy. TFRecordDataset filenames num_parallel_reads N_PARALLEL dataset dataset. figure figsize 18 36 plt. MolToInchi m1 logLevel None treatWarningAsError False if m None inchi Chem. FixedLenFeature tf. n print n. map method to have parallel processing. FixedLenFeature shape 1 dtype tf. function def dist_process_dataset dist_ds_iter for _ in tf. Masked Multi Head Attention with look ahead mask and padding mask 2. values 0 image_id_1 image_id 2 1 print print f image id k w i. This layer the MHA layer first projects query key and value. Without them I wouldn t have been able to make this Awesome Notebook For Best Practices in Distributed Computing The Amazing Mark Wijkhuizen s TPU Training Notebook For This CompetitionTABLE OF CONTENTS 0 nbsp nbsp nbsp nbsp IMPORTS 1 nbsp nbsp nbsp nbsp BACKGROUND INFORMATION 2 nbsp nbsp nbsp nbsp SETUP 3 nbsp nbsp nbsp nbsp HELPER FUNCTIONS 4 nbsp nbsp nbsp nbsp PREPARE THE DATASET 5 nbsp nbsp nbsp nbsp MODEL PREPARATION 6 nbsp nbsp nbsp nbsp DATASET CREATION 7 nbsp nbsp nbsp nbsp CUSTOM MODEL TRAINING 8 nbsp nbsp nbsp nbsp INFER ON TEST DATA0 nbsp nbsp IMPORTS nbsp nbsp nbsp nbsp 10514 1 nbsp nbsp BACKGROUND INFORMATION nbsp nbsp nbsp nbsp 10514 PRIMARY TASK DESCRIPTION Given an image our goal is to generate a caption. If a dataset yield a single tensor you can do things like python tf. head for index row in df. append index 0 h. express as px import seaborn as sns from PIL import Image import matplotlib import plotly import PIL import cv2 df_final pd. 0000000001 1000000 listLabels 0 1 df group pd. apply lambda x x 2 1 k 0 smiles_dir f. org api_docs python tf distribute Strategy run each replica receives a part of the batch andcalculates the loss values separately. It requires both methods from computer vision to understand the content of the image and a language model from the field of natural language processing to turn the understanding of the image into words in the right order. org tutorials text transformer positional_encoding to learn more about it. TFRecordDataset TEST_TFREC_PATHS num_parallel_reads None feature_dict w tf. head target ecfps_cosine_all listBins 0 0. numpy i pattern _val_pattern_batch. int32 y if shuffle_buffer_size 1 dataset dataset. The jit_compile API has must compile semantics i. 3 LEVERAGING MIXED PRECISION Mixed precision is the use of both 16 bit and 32 bit floating point types in a model during training to make it run faster and use less memory. newaxis d_model 2 angle_rads_col get_angles tf. numpy total N_TEST smile arr_2_smile pred_arr for pred_arr in tqdm all_pred_arr 1 REQUIRED_DATASET_PAD. items print f tFEATURE i 1 print f t t KEY k if k image try print int print f t t t TRUNCATED VALUE v. AVERAGE LOSS ACROSS BATCH n t np. 9 TRANSFORMER ENCODER COMPONENT The TransformerEncoder consists of 1. xxx 8470 The zone you chose when you created the TPU to use on GCP. where l END_TOKEN 0 0 p_s selfies_decoder p_s compatible True pre_smiles_ecfp simies_to_ecfps p_s l_s selfies_decoder l_s compatible True l_smiles_ecfp simies_to_ecfps l_s pre_smiles_ecfp_batch. Multi Head Attention with padding mask V value and K key receive the encoder output as inputs. 0 TRANSFORMER HYPERPARAMETERS 5. iterrows ind df_final df_final image_id str row image_id_all 2 1. The output of this summation is the input to the decoder layers. N encoder layersThe input is put through an embedding which is summed with the positional encoding. At each location in the sequence y the MultiHeadAttention runs all 8 attention heads across all other locations in the sequence returning a new vector of the same length at each location. notebook import tqdm tqdm. init_hidden_state image_batch_embedding training False decoder_input_batch tf. append confirence_loss listBins_1 0 confirence_loss loss_all_max listLabels_1 0 1 df loss pd. val_loss_seq val_loss_cls stat_logger. values 0 selfies_label_1 df_1 df_1 image_id_all image_id selfies_labels_all. Chem import Draw from rdkit. tensorN strategy. Options if not ordered options. environ GOOGLE_APPLICATION_CREDENTIALS. function def distributed_test_step _img_batch _img_ids per_replica_seqs strategy. Concatenation of heads. 7 TRANSFORMER ENCODER Each transformer encoder layer consists of sublayers 1. lev_dist log_y True def test_step _image_batch Forward pass calculate gradients Args image_batch TBD smile_batch TBD Returns tbd image_batch_embedding encoder _image_batch training False hidden_batch memory_batch decoder. For example consider that Q and K have a mean of 0 and variance of 1. The following steps will be covered Use tf. function def dist_run_on_dataset dist_ds for dist_batch in dist_ds dist_step dist_batch dist_process_dataset dist_ds This way all the operations conducted on the dataset are compiled into a graph which is sent to the remote TPU worker s for execution. RAW TFRECORD INVESTIGATION TO DETERMINE FEATURE DESCRIPTIONS COMPLETED. cut df target bins listBins_1 right True labels listLabels_1 retbins False precision 3 include_lowest True res df. No parameters necessary if TPU_NAME environment variable is set. better for pretrained models peark_lr_start float The starting learning rate after warmup peak value lr_final float The final learning rate to step down to by the end of training n_epochs int The total number of epochs for the training regime Returns The learning rate float to be used for a given step if step SAMPLE_LBLS i print f nOUR PREDICTIONS n tSHAPE pred_output. There are N encoder layers in the transformer. enable XLA optmizations 10 speedup when using tf. shape batch_size num_heads seq_len_q seq_len_k batch_size seq_len_q num_heads depth batch_size seq_len_q d_model batch_size seq_len_q d_model CUSTOM batch_size encoder_sequence d_model TF NATIVE INNER LAYER batch_size seq_len dff OUTPUT batch_size seq_len d_model returns batch_size input_seq_len d_model Potentially unncessary by passing dropout1 to tf. uint8 for c_idx in range 1 MAX_LEN prediction_batch hidden_batch memory_batch decoder decoder_input_batch hidden_batch memory_batch image_batch_embedding training False decoder_input_batch tf. lev_dist log_y True val_dist_ds iter strategy. gather _img_ids axis 0 return predictions pred_ids all_pred_arr tf. reset_index print df_g2. blob destination_blob_name blob. string feature2 tf. plot right_list plt. int64 feature1 tf. The input to the encoder is the output of our image encoder i. TFRecordDataset to read the TFRecord files. 02368 In gradient accumulation each replica receives several batches before the optimizer applies the graidents we divide the sum of per examples losses by the update size i. argmax pred_output axis 1 print f nTHE CALCULATED INDIVIDUAL STEP LOSS n t loss_seq SAMPLE_LBLS i pred_output. get_gcs_path automl efficientdet efficientnetv2 effnetv2 gs kds f58e6eb872f6e631a1a7b17a5028b74b70a853301aacf67c57cb95a3 Installs Pips text chemfp 3. Final linear layer. The Keras mixed precision API allows you to use a mix of either float16 or bfloat16 with float32 to get the performance benefits from float16 bfloat16 and the numeric stability benefits from float32. The formula for calculating the positional encoding is as follows Large PE_ pos 2i sin pos 10000 2i d_ model Large PE_ pos 2i 1 cos pos 10000 2i d_ model 5. append l image_ids. uniform BATCH_SIZE_DEBUG int MAX_LEN D_MODEL dtype TARGET_DTYPE sample_encoder_layer_output img_logit False None None sample_decoder_layer_output. Use num_parallel_calls in tf. concat https www. show df_1 from rdkit import Chem from rdkit. Scaled dot product attention. loc i image_id ls 0 w int ls 1 h int ls 2 lsd 0 print df_final. pyplot as plt df pd. count len df_1 print df_1 inchi_lsd. name def download_to_kaggle bucket_name destination_directory file_name Takes the data from your GCS Bucket and puts it into the working directory of your Kaggle notebook os. Intuitively this method will allow a model to adjust itself less before it becomes more familiar with the dataset. Sometimes this is called learning rate annealing or adaptive learning rates. name def upload_blob bucket_name source_file_name destination_blob_name Uploads a file to the bucket. In the cell below we will create the functions and configuration template which will later be used to create our respective datasets nbsp REFERENCE Guide tf. numpy try p_s. By keeping certain parts of the model in the 32 bit types for numeric stability the model will have a lower step time and train equally as well in terms of the evaluation metrics such as accuracy. When leveraging a TPU this is a non trivial task. plot loss_list 1 plt. mha3 enc_output1 enc_output1 enc_output2 padding_mask attn2 attn_weights_block2 self. This should give you enough information to define the feature description. Each replica is essentially a copy of the training graph that is run on each core and trains a mini batch containing 1 8th of the overall batch size Google Cloud Dataset path to training and validation images Local path to training and validation images print f. split n tokens tokens 0. numpy print f pred smiles str pre_smiles_selfies print f smilles label smiles_dic image_id_1 print print f pre selfies preds_selfies print f selfies labels 1 selfies_label_1 print f selfies label selfies_dic image_id_1 print f LSD df df image_id_all image_id batch_dis_all opts DrawingOptions opts. Otherwise you can use like pythonexample tf. During training when a batch is distributed to the replicas https www. if epoch 2 1 or epoch EPOCHS save weights loss_pkl train_loss_seq stat_logger. numpy print sum list en_log. shape batch_size tar_seq_len d_model dec_output attention_weights self. org api_docs python tf distribute Strategy run has to be called inside tf. Point Wise Feed Forward Networks Each of these sublayers has a residual connection around it followed by a layer normalization The output of each sublayer is LayerNorm x Sublayer x The normalization is done on the d_model last axis. numpy _val_image_id_batch. For optimal performance reading from multiple files at once and disregarding data order if ordered False. Similarly to predict the fourth token only the first second and the third tokens will be used and so on. We will use this method to collect the labels and model predictions We will need to iterate over the dataset to perform inference train on the whole distributed dataset. The results are improvements in speed and memory usage. metrics import roc_curve auc import plotly. set_index w h df_g2 df_g2. nbsp NOTE For different encoder architectures we will have a different number of feature maps. 2 UNDERSTANDING THE MODELS TRANSFORMER 5. pythondataset raw_dataset. 7 smiles and inchi lsd INFORMATION7 nbsp nbsp INFER ON TEST DATA nbsp nbsp nbsp nbsp 10514 In this section we will use our trained model to generate the predictions we will use to submit to the competition7. txt with open path as file lines file. ACCUMULATED LOSS n t accumulated_loss print f n n. append r 0 j jaccard pre_smiles_ecfp encoder_logit i jaccard_all. experimental_deterministic False N_PARALLEL tf. numpy en_l encoder_logit. However there are two lower precision dtypes float16 and bfloat16 each which take 16 bits of memory instead. 4 LEVERAGING XLA OPTIMIZATIONS XLA Accelerated Linear Algebra is a domain specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes. function https www. Bristol Myers Squibb Molecular TranslationImage Captioning End to End Pipeline EfficientNetV2CREATED BY DARIEN SCHETTLER nbsp CREDIT TO THE FOLLOWING NOTEBOOKS I USED IN CREATING THIS KERNEL If you liked this notebook please upvote these other notebooks. function as shown by python tf. experimental_distribute_dataset val_ds for j in range VAL_STEPS preds lbls _logit encoder_logit _val_pattern_batch _val_image_id_batch dist_val_step val_dist_ds tonimoto_list all_right_num get_levenshtein_distance_smiles preds lbls print all_right_num len lbls 100 pre_smiles_ecfp_batch for i p l in enumerate zip preds. shape confidence_loss_cls loss_cls _val_pattern_batch _logit print confidence_loss_cls. TFRecordDataset TEST_TFREC_PATHS num_parallel_reads None raw_test_ds tf. take 1 for i in range 450 if len df_2 df_2. After the split each head has a reduced dimensionality so the total computation cost is the same as a single head attention with full dimensionality. dist_ds strategy. head 100 w h for index row in df_g1. 5 HOW TPU IMPACTS MODELS METRICS AND OPTIMIZERSIn order to use TPU or tensorflow distribute strategy https www. apply lambda x x 2 1 if len df_1 df_1 image_id. csv submission_e_14. AUTOTUNE else N_PARALLEL None dataset tf. When using TPU on Kaggle you don t need to specify arguments for TPUClusterResolver 2. index_word x for x in p 1 np. repeat if external_smile_dataset is not None dataset tf. pyplot as plt from tqdm. As the softmax normalization is done on K its values decide the amount of importance given to Q The output represents the multiplication of the attention weights and the V value vector. makedirs destination_directory exist_ok True full_file_path os. DataFrame df_final image_id 0 df_final w 0 df_final h 0 df_final lsd 0 df pd. Deep learning methods have demonstrated state of the art results on caption generation problems. count auc_list. get i if c break smile_str c return smile_str pred_df pd. MolFromSmiles pre_smiles_selfies plt. numpy 2 1 0 image_id str w i. patches as patches import plotly. csv from google. heatmap data df_g2 cmap plt. append confirence_auc listBins_1 0 confirence_auc 1 listLabels_1 0 1 df auc pd. shape n tARGMAX tf. join bms_csv sample_submission_w_extra. the number of examples used for one parameter update rather than by the size of a single distributed batch. ones REPLICA_BATCH_SIZE 1 dtype tf. nbsp DEFINITION The term numeric stability refers to how a model s quality is affected by the use of a lower precision dtype instead of a higher precision dtype. com tensorflow tensorflow blob v2. DATASET OBJECTS With the above parsing methods defined we can define how to load the dataset with more options and further apply shuffling bacthing etc. org api_docs python tf distribute Strategy experimental_distribute_dataset to turn it into a distributed dataset which produces per replica values which are objects of type PerReplica https github. tensorN batch model tensor0. MultiHeadAttention num_heads key_dim d_model Feed Forward NN Layer Normalization Layers Dropout Layers enc_output. seq_len_q seq_len_k shape. The input sequennce image embedding sequence in our case is passed through N encoder layers that generates an output for each word token in the sequence. show import warnings warnings. 1 INDIVIDUAL TEST STEP AND DISTRIBUTED INFORMATION7. shape N_PE_POS 72 N_PE_POS 101 D_FF 1024 add extra dimensions to add the padding to the attention logits. DataFrame df confidence_loss_cls_all confidence_loss_cls_all df LDS_ALL LDS_ALL df auc_all auc_all df ecfps_cosine_all ecfps_cosine_all df pearsonr_all pearsonr_all df jaccard_all jaccard_all df euclidean_all euclidean_all df image_id_all image_id_all_1 df. Q query receives the output from the masked multi head attention sublayer. show print confirence_loss_list print loss_list 1 print right_list 1 import pandas as pd from sklearn. append 0 if 1 not in p and 1 not in l p_s selfies_decoder p_s compatible True smiles_all. shuffle shuffle_buffer_size dataset dataset. numpy print if j 0 break def simies_to_ecfps_hex smiles fptype chemfp. The output of the decoder is the input to the final linear layer. run replica_fn args dist_batch where replica_fn expects a single tensor as arugment. append lbls_s Create tf. The optimizer should apply the gradient obtained from the averaged per examples loss over the whole distributed batch It s worth noting that each replica may infact receive different number of examples. run replica_fn args dist_batch The above code snippet is a high level concept and replica_fn doesn t necessary receive a single argument. expand_dims x 0 1 tf. numpy en_log encoder_logit i en_log_a np. 5 else 0 for i in list en_log. zeros 1 1 dtype tf. The tensors are then interpolated by these probabilities then concatenated back to a single tensor. not_equal lbls PAD_TOKEN preds 0 lbls tf. 2 INDIVIDUAL VAL STEP INFORMATION6. This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. input daily result levenshtein_distance_good_USPTO. The distributed datasets when working with TPU contain objects of type tensorflow. string which are then decoded with tf. This ensures that the words you want to focus on are kept as is and the irrelevant words are flushed out. create_bucket dataset_name print Bucket created. DataFrame lbl_smile lbls_s pred_smile pred_s image_ids image_ids selfies_df. decode utf 8 LDS. 2 decimer\u4ee3\u7801\u751f\u6210\u56fe\u7247\u7edf\u8ba1\u7ed3\u679c 6. groupby loss group. where ls END_TOKEN 0 0 print p_s pred_s lbls_s LDS image_ids val_dist_ds iter strategy. val_loss_cls val_acc_seq stat_logger. 00298 model to act as the Encoder CNN in our network. csv selfies_df pd. The output of the encoder is the input to the decoder. In this case that image is of a single molecule and the description caption is the smile string for that molecule. Therefore for efficient utilization of Cloud TPU a program should make use of each of the EIGHT 4x2 cores. We will be using a model architecture very similar to that found within the Show Attend and Tell Research Paper https arxiv. This will be discussed more in the section on training further down. experimental_distribute_dataset val_ds for _ in tqdm range VAL_STEPS total VAL_STEPS preds lbls _val_image_id_batch dist_val_step val_dist_ds lsd get_levenshtein_distance preds lbls for i p l h in enumerate zip preds. hist df_1 num_bin plt. csv target jaccard_all listBins 0 0. py L361 when iterating over it. ZONE us east1 b The name of the GCP project where you created the TPU to use on GCP. org api_docs python tf distribute Strategy run. Dense 208 name logit_dense1 activation None self. For example python tf. MolToInchi m logLevel None treatWarningAsError False return inchi df_1 pre_inchi df_1 preds_all. Create a description of the features. Multi head attention consists of four parts Linear layers and split into heads. fit defining something within the strategy s scope WILL NOT automatically distribute the computation. 7 USER INPUT VARIABLES 3 nbsp nbsp HELPER FUNCTION CLASSESS nbsp nbsp nbsp nbsp 10514 3. string image_id features image_id Figure out the correct information to return if tokenized_smile else smile features smile w feature_dict w h feature_dict h def load_dataset filenames is_test False ordered False tokenized_smile True Read from TFRecords. sum accumulated_loss MAX_LEN BATCH_SIZE_DEBUG n n print 100 Just for printing prediction_batch _ decoder _image_pattern _smile_batch_input training True look_ahead_mask combined_mask prediction_batch _ decoder _image_embedding _image_pattern _smile_batch_input training True look_ahead_mask combined_mask Update Loss Accumulator Update Accuracy Metric backpropagation using variables gradients and loss split this into two seperate optimizers lrs etc in the future we use the batch loss accumulation to update gradients gradients tape. When a TensorFlow program is run all of the operations are executed individually by the TensorFlow executor. org api_docs python tf distribute Strategy experimental_local_results to obtain a tuple of tensors from all replicas and we can use tf. org api_docs python tf distribute Strategy run to perform a distributed computation on different TPU replicas each processes a part of the batch. legend Confidence RECALL plt. This newly created raw dataset contains tf. 1 TRANSFORMER POSITIAL ENCODING Since this model doesn t contain any recurrence or convolution positional encoding is added to give the model some information about the relative position of the words in the sentence. 4 CUSTOM TRAIN LOOP INFORMATION 6. append p lbls_s. append auc_ ecfps_cosine cosine_similarity pre_smiles_ecfp encoder_logit i ecfps_cosine_all. set_index w h df_g2 df_g1. 3 INITIALIZE LOGGER INFORMATION6. experimental_distribute_dataset val_ds for _ in tqdm range VAL_STEPS total VAL_STEPS preds lbls _logit _val_image_id_batch dist_val_step val_dist_ds for i p l h in enumerate zip preds. PATHS TO CSVS print f t TRAIN CSV TRAIN_CSV_PATH print f t SS CSV SS_CSV_PATH When debug is true we use a smaller batch size and smaller model Distribution Information N_TRAIN 909353 N_VAL 100780 N_VAL 100000 N_VAL 450 N_VAL 5740 N_VAL 5704 N_TRAIN 921600 N_VAL 102400 N_VAL 5713 N_VAL 2538 N_VAL 272 N_TRAIN 10240 N_VAL 1024 Batching Information Could probably be 128 if DEBUG REPLICA_BATCH_SIZE BATCH_SIZE_DEBUG Input Image Information IMG_SHAPE 192 384 3 Autocalculate Training Validation Testing Information TEST_STEPS int np. list_blobs bucket_name for blob in blobs blob. shape batch_size input_seq_len d_model def call self x enc_output1 enc_output2 training look_ahead_mask None padding_mask None Residual connection followed by layer normalization batch_size target_seq_len d_model Merging connection between encoder and decoder MHA batch_size target_seq_len d_model attn2 attn_weights_block2 self. MolFromSmiles smiles inchi 0 if m None inchi Chem. format source_file_name destination_blob_name def list_blobs bucket_name Lists all the blobs in the bucket. compute_fingerprint mol return fp pattern 00000000000000000000020040000002000000000000000000000000000000000000000000000004040000000000000400000000000000000000000100000000000000000000000000000000000000000004010000008000004000000000000000200000000000800002000002000000011000080000000000000000000040000080800002000000010000040000000000010000000000000000000000000000000000000012000000000000100000000000000000100000000000000000008011000000000000001008000000000000000000000000000000204200000080000000000000000000000002000000000000000000000000000000000000000000 p_li fpstolist pattern pattern_2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 smil O CC CC1 C C C ON C C C OC CC1 a simies_to_ecfps smil a_hex simies_to_ecfps_hex smil hex_text_1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 s_text 00400020000000000000010000000000000000000000010000820000000000000000000000800000040000000000000408000000000000000000000040000000000000000000000000000008000000000004040000000000000000000800000000000000808000000000000000000000000000408000000000000000001000080000000002000000002000000000000200000000000000000000000000004000000000000000000000000000100040000200000000100000000100000000000000000100000000000000000000000000000000200000000000000000000000001000000000000000000402000000002000000000000000200000000000000000 print hex_text_1 fpstolist s_text sel O C Branch1_1 Branch2_2 C N C C N Ring1 Branch1_1 C C C N Branch1_1 C C C C N Branch1_1 C C C Ring1 Branch2_1 ls 9 7 3 4 19 2 12 2 3 5 6 4 2 2 2 5 4 2 2 2 2 5 4 2 2 2 6 13 10 0 0 0 print ls print END_TOKEN print np. Dataset as input pipeline Perform a custom training loop Correctly define loss function Gradient accumulation with TPUsMORE DETAIL ON IMAGE CAPTIONINGDescription From a Tutorial I Used As Reference Caption generation is a challenging artificial intelligence problem where a textual description must be generated for a given photograph. readlines for i in range len lines ls lines i. not_equal lbls END_TOKEN tf. LEARNING RATE SCHEDULE CREATION STARTING. When working with TPU either strategy. positional_encoding positional_encoding_2d 6 12 232 self. At this time we only want to use the raw no pretraining headless features with no pooling. numpy n n print 100 Just for printing print f n n. We SHOULD NOT calculate the average of the per example losses on the partial batch the replica recieves. where p END_TOKEN 0 0 except p_s. These are effectively a list of tensors of length num_attention_heads where the corresponding shapes are batch_size 1 key_dim batch_size 1 key_dim batch_size 1 value_dim Then the query and key tensors are dot producted and scaled see previous section. nbsp REFERENCE TF Mixed Precision Overview2. org api_docs python tf function or the replica function has to be annotated with tf. Parse example. zip dataset external_smile_dataset dataset dataset. Dataset Documentation5 nbsp nbsp MODEL PREPERATION nbsp nbsp nbsp nbsp 10514 In this section we prepare the models for training. When iterating over the dataset we will still get a tuple containing two values. TEST DATA DIRECTORY PATH IS n t TEST_DATA_DIR Set Mixed Precision Global Policy To use mixed precision in Keras you need to create a tf. head df_g df_final. title f IMAGE smile. In our case the original dataset yields tuples of tensors A distributed batch is also a tuple of PerReplica objects and the replica_fn is actually receiving the unpacked version of a tuple of tensors as arguments. loc ind lsd row LDS_ALL print df_final. The intuition behind this is as follows The gradients calculated on each replica will be synced across the replicas Therefore they are summed before the optimizer applies the gradients to update the model s parameters If we use the averaged per examples loss to compute the graident on each replica the final graident applied by the optimizer will correspond to the sum of these averaged per examples losses for respective replicas. numpy batch_dis_all. If pulling smile from TFRecords than order does not matter since we will be shuffling the data anyway for training dataset. The attention function used by the transformer takes three inputs Q query K key V value The equation used to calculate the attention weights is Large Attention Q K V softmax_k frac QK T sqrt d_k V The dot product attention is scaled by a factor of square root of the depth. map lambda x decode x is_test tokenized_smile num_parallel_calls N_PARALLEL return dataset def get_dataset filenames batch_size is_test False shuffle_buffer_size 1 repeat_dataset True preserve_file_order False drop_remainder True tokenized_smile True external_smile_dataset None Get a tf. index_word x for x in l selfies_labels_all. ParseFromString serialized_example. DataFrame lbl_smile lbls_s pred_smile pred_s lev_dist LDS ld_df. get_bucket bucket_name blob bucket. parse_single_example example feature_description return parsed_example STEP 3. FixedLenFeature shape dtype tf. MultiHeadAttention if using tf MHA Residual connection followed by layer normalization returns batch_size input_seq_len d_model Point wise Feed Forward Step returns batch_size input_seq_len d_model Residual connection followed by layer normalization returns batch_size input_seq_len d_model sample_encoder_layer_output sample_encoder_layer img_logit training False mask None batch_size input_seq_len d_model WE COULD USE A CUSTOM DEFINED MHA MODEL BUT WE WILL USE TFA INSTEAD self. 5 BASIC DATA DEFINITIONS INITIALIZATIONS 2. map _parse_function In the following cell we apply the above recipe to our BMS tfrecord dataset. data Build TensorFlow Input Pipelines Guide Better Performance With the tf. Modern accelerators can run operations faster in the 16 bit dtypes as they have specialized hardware to run 16 bit computations and 16 bit dtypes can be read from memory faster. train_acc_seq val_loss_seq stat_logger. The output of each sublayer is LayerNorm x Sublayer x. constant 1 TARGET_DTYPE tf. MolToInchi m logLevel None treatWarningAsError False return inchi def label_smiles_to_inchi id smiles smiles_dic id m Chem. dec_layers i x enc_output1 enc_output2 training look_ahead_mask padding_mask x. Embeddings represent a token in a d dimensional space where tokens encoded vectors with similar meaning feature representation will be closer to each other. See the demonstration above in the scaled dot product attention section. In our case the name of the dataset is the name of the directory the dataset is mounted within. append euclidean fpr tpr thredholds roc_curve pre_smiles_ecfp encoder_logit i auc_ auc fpr tpr auc_all. rsplit _ 2 1 Paths to relevant CSV files containing training and submission information TRAIN_CSV_PATH os. 6 LOSS CLASSES AND REDUCTIONIn order to accurately calculate loss when leveraging a TPU we have to accumulate the losses that will be calculated across the individual replicas. run will execute across the replicas we can look at an example python tf. The dtype the layer s computations are done in 2. csv SS_CSV_PATH os. batch batch_size drop_remainder drop_remainder dataset dataset. PROJECT my tpu project tpu tf. The attention output for each head is then concatenated using tf. input googletoken gleaming glass 315115 1431ba008903. shape batch_size seq_len vocab_size prediction_batch attention_weights decoder _image_logit decoder_pred_batch training False look_ahead_mask combined_mask prediction_batch attention_weights decoder _image_embedding _image_logit decoder_pred_batch training False look_ahead_mask combined_mask Update Loss Accumulator Update Accuracy Metric no teacher forcing predicted char is next transformer input Update Loss Metric def __init__ self verbose_frequency 100 print_style tight f ACC str self. This usually prevents breaking pretrained weights. 10 TRANSFORMER DECODER COMPONENT 1. apply label_smiles_to_inchi df_1 print len df_1 def get_lsd s1 s2 return Levenshtein. function def replica_fn batch tensor0. Because these kernels are unique to the model they can exploit model specific information for optimization. We will utilize a basic step function following a warmup phase. gradient batch_loss_seq encoder. val_acc 1 100 5 False df_1 print \u6e05\u6d17\u957f\u5ea6\u8d85\u8fc747 print len df_1 def smiles_to_inchi smiles m Chem. append p_s if len np. But the embeddings do not encode the relative position of words in a sentence or in our case the localization of features as encoded by our efficientnetv2 encoder model. join x for x in p np. parse and return a dataset w the appropriate configuration Load the dataset Fake Images Fake IDs If we are training than we will want to repeat the dataset. title size 20 plt. Dataset w the appropriate configuration Args TBD Returns TBD dataset load_dataset filenames is_test preserve_file_order tokenized_smile if repeat_dataset dataset dataset. For each return value we can use strategy. An appropriate mask must be used in the attention step. experimental_distribute_dataset test_ds for i in tqdm range TEST_STEPS total TEST_STEPS img_batch id_batch next dist_test_ds preds pred_ids distributed_test_step img_batch id_batch all_pred_arr tf. 8 DISTRIBUTED COMPUTATION OPTIMIZING LOOPSFor each distributed batch which contains PerReplica objects as discussed previously produced by a distributed dataset we use strategy. csv import pandas as pd from sklearn. Client project gleaming glass 315115 def create_bucket dataset_name Creates a new bucket. com storage docs blobs storage_client. Their matrix multiplication will have a mean of 0 and variance of dk. MultiHeadAttention num_heads key_dim d_model self. parse_single_example and the defined feature description. numpy 100 print batch_distance. Let s create a MultiHeadAttention layer to try out. extend image_id_all i df pd. Kaggle provides a utility library KaggleDatasets which has a utility function. XLA provides us with an alternative mode of running models it compiles the TensorFlow graph into a sequence of computation kernels generated specifically for the given model. val_lsd_seq pickle. 1 READ TFRECORD FILES CREATE THE RAW DATASET S Here we will leverage tf. bn1 img_logit training training x tf. batch_size 1 1 seq_len seq_len seq_len Used in the 1st attention block in the decoder. numpy print f pred smiles str pre_smiles_selfies print f smilles label smiles_dic image_id_1 print print f pre selfies preds_selfies print f selfies labels 1 selfies_label_1 print f selfies label selfies_dic image_id_1 print f inchi_LSD df_1 df_1 image_id_all image_id inchi_lsd opts DrawingOptions opts. join list map str pre_smiles_ecfp pred_s lbls_s LDS image_ids val_dist_ds iter strategy. 1 cp37 cp37m manylinux2014_x86_64. nbsp REFERENCE TF Tutorial Transformer Model for Language Understanding TF Tutorial Image Captioning TF Tutorial Neural Machine Translation w Attention5. something that is a tf. readlines for line in lines tokens line. where p 2 0 0 except p_s. where l END_TOKEN 0 0 else l_s. OF TRAIN VAL EXAMPLES N_EX 1 C 2 C 3 Branch1_1 4 Ring1 5 N 6 O 7 Branch1_2 8 9 10 Expl Ring1 11 Branch2_1 12 N 13 S 14 Branch1_3 15 O 16 Ring2 17 F 18 Branch2_2 19 Cl 20 Branch2_3 21 C 22 Br 23 P 24 S 25 I 26 P 27 B 28 N 29 Expl Ring2 30 0 1 2 C 3 C 4 Branch1_1 5 Ring1 6 N 7 O 8 Branch1_2 9 10 11 Expl Ring1 12 Branch2_1 13 N 14 S 15 Branch1_3 16 O 17 Ring2 18 F 19 Branch2_2 20 Cl 21 Branch2_3 22 C 23 Br 24 P 25 S 26 I 27 P 28 B 29 N 30 Expl Ring2 0 for i in range len sel print str. ", "id": "hymanli/02-decimerplus-efficientnetv2-transformer", "size": "56561", "language": "python", "html_url": "https://www.kaggle.com/code/hymanli/02-decimerplus-efficientnetv2-transformer", "git_url": "https://www.kaggle.com/code/hymanli/02-decimerplus-efficientnetv2-transformer", "script": "Draw efficientnetv2 TransformerDecoder(tf.keras.layers.Layer) get_levenshtein_distance_smiles plotly.express get_counter get_angles RDLogger step glob create_padding_mask matplotlib.patches scipy list_blobs tensorflow.keras.backend matplotlib.pyplot sim_tonimoto effnetv2_model print_out PIL encoder dense_to_sparse dist_val_step MolToInchi dist_train_step scipy.stats positional_encoding_1d encoder as selfies_encoder positional_encoding_2d create_mask TransformerDecoderLayer(tf.keras.layers.Layer) binary_loss_fixed arr_2_smile collections Transformer(tf.keras.Model) simies_to_ecfps_hex MultiHeadAttention(tf.keras.layers.Layer) rdkit.Chem.rdinchi plotly.graph_objects test_step rdkit.Chem.MolStandardize.rdMolStandardize pearsonr fpstolist kaggle_datasets MolDrawing val_step get_lr get_levenshtein_distance_inchi ListedColormap binary_focal_loss_fixed effnetv2_configs KaggleDatasets scipy.spatial.distance tensorflow np_positional_encoding_2d KerasFocalLoss google.colab train_step loss_fn loss_cls pandas call upload_blob rdkit.Chem.Draw.MolDrawing decode cosine_similarity spatial get_levenshtein_distance create_bucket tensorflow_addons point_wise_feed_forward_network load_dataset Config() prepare_for_training print_current_train numpy Image Chem scaled_dot_product_attention split_heads efficientnet.tfkeras ChargeParent rdkit.Chem initialize_encoder_config do_interleave create_look_ahead_mask selfies drive Encoder(tf.keras.Model) roc_curve tqdm; tqdm.pandas(); tqdm.notebook google.cloud seed_it_all get_dataset print_last_val sklearn.metrics.pairwise sklearn.metrics decoder Counter LRS() __call__ attributes) initialize_lr_config rdkit loss_seq seaborn download_to_kaggle decode_image AllChem jaccard get_efficientnetv2_backbone plot_lr_schedule lr_schedule_fn decoder as selfies_decoder flatten_l_o_l distributed_test_step initialize_decoder_config simies_to_ecfps auc smiles_to_inchi get_efficientnetv1_backbone matplotlib.colors datetime DrawingOptions #Only needed if modifying defaults brain_automl tf_load_image get_lsd label_smiles_to_inchi storage __init__ TransformerEncoderLayer(tf.keras.layers.Layer) CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule) StatLogger() TransformerEncoder(tf.keras.layers.Layer) ", "entities": "(('scores', '1'), 'normalized') (('you', 'Project actually that'), 'WARNING') (('learning initial rate', 'first few epochs steps'), 'use') (('we', 'example'), 'execute') (('only first tokens', 'third token'), 'mean') (('nbsp', 'TF Mixed Precision Overview2'), 'REFERENCE') (('value_dim', 'linear projection'), 'tensor') (('model', 'same quality'), 'be') (('you', 'TPUClusterResolver'), 'need') (('more steps', 'existing weights'), 'n') (('where you', 'GCP'), 'b') (('computation total cost', 'full dimensionality'), 'be') (('training target_vocab_size _ img_logit enc_output2 tar_seq_len SAMPLE_LBLS', 'print n.'), 't_tar') (('i', 'smiles_dic'), 'logLevel') (('attention dot where products', 'sqrt d_k'), 'be') (('learning Deep methods', 'caption generation problems'), 'demonstrate') (('confirence_loss cut_n 1 i', 'range'), 'df') (('output', 'final linear layer'), 'be') (('nbsp REFERENCES Guide', 'TPUs Doc TPUClusterResolver2'), 'Use') (('0 0 p_s selfies_decoder', 'simies_to_ecfps'), 'compatible') (('Dataset', 'later raw_test_ds'), 'tf') (('jit_compile API', 'semantics i.'), 'compile') (('We', 'Research Paper https arxiv'), 'use') (('so we', 'only whole batches'), 'OVERALL_BATCH_SIZE') (('when you', 'GCP'), 'xxx') (('distributed datasets', 'type tensorflow'), 'contain') (('output', 'decoder'), 'be') (('tensors', 'then back single tensor'), 'interpolate') (('we', 'training anyway dataset'), 'matter') (('output', 'linear layer'), 'output') (('input', 'image encoder i.'), 'be') (('which', 'network'), 'be') (('where it', 'very hard softmax'), 'do') (('org api_docs', 'single tensor'), 'python') (('dot product attention', 'depth'), 'take') (('embeddings', 'efficientnetv2 encoder model'), 'encode') (('we', 'validation'), 'n_stes') (('return predictions pred_ids axis 0 all_pred_arr', '_'), 'gather') (('2 1 EPOCHS', 'weights'), 'epoch') (('Point Wise Feed Forward Neural Each', 'layer normalization'), 'network') (('Adapting', 'training time'), 'CREATE') (('express', 'PIL plotly import cv2 pd'), 'import') (('that', 'elements'), 'False') (('transformer decoder layer', 'sublayers'), 'component') (('Policy', 'dtype typically policy'), 'refer') (('distribute Strategy tf run', 'Kaggle VM'), 'python') (('False', 'Draw'), 'logLevel') (('we', 'shuffling further bacthing etc'), 'OBJECTS') (('look', 'sequence'), 'use') (('we', 'dataset'), 'parse') (('we', 'update size'), '02368') (('learning Recently deep methods', 'problem'), 'achieve') (('end single model', 'specifically designed models'), 'be') (('which', 'type PerReplica https github'), 'python') (('K key', 'inputs'), 'receive') (('w feature_dict w h feature_dict h def load_dataset False', 'True TFRecords'), 'string') (('where tokens', 'other'), 'represent') (('we', 'replicas'), 'demonstrate') (('entire function', 'XLA'), 'compile') (('smile strings IDs', 'byte string just tensors'), 'leave') (('python', 'replica tf'), 'have') (('so associated values', 'repeated key third'), '3') (('model', 'different representational spaces'), 'split') (('expand_dims pred_ids', 'arr 1 axis 0 def i'), 'axis') (('python', 'tf'), 'have') (('replica_fn', 'arguments'), 'in') (('still replica_fn', 'argument'), 'work') (('attention', 'Linear heads'), 'head') (('simplest way', 'TFRecord files'), 'be') (('precision Therefore lower dtypes', 'whenever devices'), 'run') (('output', 'sublayer'), 'be') (('probably DEBUG', 'batch smaller size'), 'print') (('that', 'base distributed values'), 'python') (('data Dataset we', 'strategy'), 'python') (('1 1 1 Then query', 'key dot previous section'), 'be') (('encoding words feature So positional representations', 'd dimensional space'), 'be') (('it', 'distribution strategy'), 'define') (('Masked Multi Head Attention', 'ahead mask'), 'mask') (('Q query', 'head attention masked multi sublayer'), 'receive') (('EfficientNetV2B0', 'feature instead 1280 that'), 'have') (('i', 'PREDICTIONS n tSHAPE nOUR pred_output'), 'float') (('we', 'two values'), 'get') (('print inchi inchi print f', 'inchi lable_inchi plt'), 'draw') (('N_PE_POS 72 101 D_FF', 'attention logits'), 'shape') (('it', 'inputs'), 'python') (('dense_to_sparse lbls batch_distance', 'dense_to_sparse not_equal END_TOKEN 0 lbls_sparse'), 'lbl') (('computations', '2'), 'do') (('description caption', 'smile molecule'), 'be') (('attention output', 'then tf'), 'concatenate') (('nbsp', 'TPUs5'), 'instantiate') (('matmul_qk attention Calculate scaled logits', 'scaled tensor'), 'add') (('that', 'only tf'), 'compile') (('print f 1 selfies_label_1 selfies', 'LSD df'), 'pre') (('predicted char', 'shape vocab_size prediction_batch attention_weights _ image_logit decoder_pred_batch False look_ahead_mask'), 'batch_size') (('we', 'strategy'), 'computation') (('name download_to_kaggle bucket_name destination_directory file_name', 'Kaggle notebook os'), 'def') (('pythonfeature_description feature0', 'example'), 'tf') (('you', 'get_gcs_path function'), 'TIPS') (('which', 'memory'), 'use') (('i', '_ auc fpr tpr'), 'thredhold') (('TRAIN_CSV_PATH', 'os'), 'rsplit') (('all', 'TensorFlow individually executor'), 'execute') (('False def decode_image image_data 384 img_size 192 384 3 192 3 sparse tensors', 'Levenshtein distance preds'), 'sel') (('we', 'string scalar tensors'), 'get') (('_ get_levenshtein_distance', 'lbls image_id_all'), 'experimental_distribute_dataset') (('preds', '0 all_pred_ids'), 'axis') (('NaN when loss', 'update learning rate'), 'reset') (('executor', 'that'), 'have') (('uniform BATCH_SIZE_DEBUG', 'D_MODEL dtype'), 'int') (('code above snippet', 'level replica_fn high t necessary single argument'), 'run') (('we', 'tf'), 'python') (('LayerNorm normalization', 'd_model'), 'network') (('It', 'right order'), 'require') (('p_li fpstolist C C ON C C C pattern_2 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 OC', 'simies_to_ecfps smil'), 'return') (('bit 16 dtypes', 'memory'), 'run') (('we', 'tf'), 'prepare') (('you', 'raw dataset'), 'do') (('intelligence challenging artificial where textual description', 'given photograph'), 'define') (('We', 'partial batch'), 'calculate') (('us', 'GCS'), 'get_gcs_path') (('RAW TFRECORD INVESTIGATION', 'FEATURE DESCRIPTIONS'), 'start') (('edit_distance preds_sparse lbls_sparse', 'print len False np'), 'normalize') (('less it', 'more dataset'), 'allow') (('init_hidden_state image_batch_embedding', 'False decoder_input_batch'), 'training') (('model', 'input'), 'ensure') (('This', 'usually pretrained weights'), 'prevent') (('they', 'optimization'), 'be') (('values', 'attention probabilities'), 'softmaxe') (('shuffle', 'dataset dataset'), 'shuffle_buffer_size') (('where replica_fn', 'arugment'), 'run') (('Otherwise you', 'pythonexample'), 'use') (('However you', 'tf'), 'iterate') (('include_lowest 3 True', 'res df'), 'bin') (('preds', 'zip enumerate preds'), 'experimental_distribute_dataset') (('s', 'tf'), 'let') (('You', 'etc'), 'pass') (('MolToInchi m1', 'None treatWarningAsError None inchi Chem'), 'loglevel') (('you', 'scope'), 'include') (('100 i', 'i'), 'df') (('infact', 'examples'), 'apply') (('These', 'multiple heads'), 'get') (('training Local path', 'print f.'), 'be') (('This', 'training'), 'discuss') (('so values', 'equally first key'), '3') (('correct gradients', 'whole distributed batch'), 'see') (('you', 'tf'), 'be') (('you', 'gentler softmax'), 'use') (('test_step _ image_batch True def Forward', 'hidden_batch memory_batch False decoder'), 'lev_dist') (('we', 'encoder model'), 'create') (('test_records', 'Individual TFRecord Files TEST_TFREC_PATHS'), 'join') (('policy', 'layer'), 'specify') (('DATASET 3 RAW general recipe', 'STEP'), 'PARSE') (('optimal performance', 'False'), 'for') (('each', 'batch'), 'python') (('Teacher', 'input next predictions'), 'get') (('TPUs', 'local VM'), 'reduce') (('WE', 'INSTEAD self'), 'MultiHeadAttention') (('we', 'up point'), 'TPU') (('Shuffling Batching', 'zip TRAINING VALIDATION TESTING'), 'drop') (('output', 'decoder layers'), 'be') (('shape batch_size seq_len_q num_heads batch_size CUSTOM batch_size encoder_sequence TF NATIVE INNER LAYER dff OUTPUT d_model seq_len_k batch_size seq_len_q seq_len_q returns', 'tf'), 'num_heads') (('we', 'competition7'), 'smile') (('each', 'TPU TWO cores'), 'consist') (('express', 'PIL import cv2 df plotly pd'), 'import') (('matrix multiplication', 'dk'), 'have') (('TRANSFORMER POINT WISE 5 FEED FORWARD NEURAL NETWORK Point wise forward network', 'ReLU activation'), 'feed') (('something', 'feature d value bytes_list image value bytes_list 57 i 338ab7bac feature key value'), 'get') (('mount content', 'gs bms_test val_records bms_test bms_test gs bms_test train_tfrecords from_aws_0001'), 'drive') (('Therefore it', 'replicas'), 'be') (('MultiHeadAttention', 'location'), 'run') (('we', 'strategy'), 'use') (('you', 'grpc also path'), 'need') (('you', 'python'), 'tf') (('LDS all_right_num 2 get_levenshtein_distance_smiles', 'lbls LDS_ALL'), 'Instantiate') (('RDKit get_fingerprint_type Morgan', 'T 2048 fptype'), 'fpsize') (('that', 'strategy'), 'have') (('print f t KEY k 1 image', 'print int print f t t t TRUNCATED VALUE'), 'print') (('encoder layer', 'sublayers'), 'ENCODER') (('MolFromSmiles', 'None inchi 0 Chem'), 'smile') (('argmax prediction_batch', 'output_type 1 tf'), 'axis') (('PUT 11 Transformer', 'transformer encoder transformer decoder'), 'it') (('df_1 s1 s2', 'Levenshtein'), 'apply') (('nbsp', 'Language Understanding TF Tutorial Image'), 'REFERENCE') (('which', 'strategy'), 'be') (('450 len', 'range'), 'take') (('output', 'attention weights'), 'decide') (('output', 'encoder layers'), 'be') (('We', 'strategy'), 'have') (('configuration which', 'later respective datasets'), 'create') (('it', 'faster less memory'), 'be') (('results', 'speed usage'), 'be') (('that', 'individual replicas'), 'class') (('EfficientNetV2 Base Config Detect hardware', 'distribution strategy TPU appropriate detection'), 'get') (('formula', 'PE _ pos sin 2i d _ Large 2i pos 10000 model'), 'be') (('we', 'also python'), 'use') (('network outputs', 'IMG_EMB_DIM'), 'encoder_config') (('InvalidArgumentError exception', 'nbsp REFERENCE XLA Optimizing Machine Learning2'), 'throw') (('goal', 'caption'), 'be') (('mask', 'close negative infinity'), 'multiply') (('input', 'daily val_lsd_confidence_auc_5'), 'result') (('all_right_num 100 len i', 'zip enumerate preds'), 'experimental_distribute_dataset') (('we', 'training'), 'Dataset') (('you', 'other notebooks'), 'Myers') (('Here we', 'DATASET RAW S'), 'CREATE') (('jaccard_all', 'euclidean_all euclidean_all'), 'df') (('we', 'Architecture 380x380x3 Input'), 'use') (('n', 'f t t t TRUNCATED VALUE else str'), 'print') (('transformer model', 'attention model nmt_with_attention'), 'TRANSFORMER') (('default value', 'TPU'), 'limited') (('TEST_DIR', 'None Respective Image Directories'), 'call') (('i', 'image'), 'contain') (('it', 'PerReplica objects'), 'run') (('which', 'positional encoding'), 'decoder') (('TFRecordDataset N_PARALLEL', 'dataset'), 'filenames') (('MolToInchi m None treatWarningAsError', 'inchi'), 'logLevel') (('s', 'MultiHeadAttention layer'), 'let') (('rate', 'annealing'), 'call') (('you', 'https arxiv'), 'ATTENTION') (('replica', 'loss values'), 'python') (('TBD Returns TBD', 'dataset dataset'), 'Dataset') (('True False True True None', 'tf'), 'lambda') (('appropriate mask', 'attention step'), 'use') (('recurrence positional encoding', 'sentence'), 'encoding') (('TEST_STEPS total TEST_STEPS next dist_test_ds', 'distributed_test_step pred_ids img_batch tf'), 'experimental_distribute_dataset') (('model We', 'whole distributed dataset'), 'use') (('we', 'pooling'), 'want') (('which', 'utility function'), 'provide') (('only first second third tokens', 'Similarly fourth token'), 'predict') (('We', 'warmup phase'), 'utilize') (('input self own next word', 'output'), 'attend') (('print f 1 selfies_label_1 selfies', 'selfies_dic image_id_1 print inchi_LSD DrawingOptions opts opts'), 'pre') (('goal', 'output'), 'be') (('data', 'S torage directly G oogle C loud GCS'), 'read') (('which', 'positional encoding'), 'put') (('particular following methods', 'tf'), 'be') (('that', 'sequence'), 'pass') (('mask', 'immediately softmax'), 'do') (('first projects', 'key'), 'query') (('you', 'stability numeric float32'), 'allow') (('scaled_dot_product_attention', 'efficiency'), 'apply') (('also optimizers', 'gradients'), 'allow') (('when batch', 'https replicas www'), 'during') (('not_equal lbls PAD_TOKEN', '0 lbls'), 'pred') (('dataset', 'directory'), 'be') (('we', 'caption numpy array Returns'), 'list') (('this', 'tfrecord automatically multiple files'), 'return') (('This', 'GCP project dashboard page'), 'find') (('Residual connections', 'deep networks'), 'help') (('as soon it', 'rather original order'), 'ensure') (('attention weights', 'output'), 'be') (('Q', '1'), 'consider') (('which', 'execution'), 'dist_ds') (('model', 'such accuracy'), 'have') (('that', 'source code potentially changes'), 'be') (('Client project gleaming glass', 'create_bucket 315115 def new bucket'), 'create') (('it', 'specifically given model'), 'provide') (('experimental_distribute_dataset ds dist_ds', 'now replicas'), 'distribute') (('model', 'float32'), 'say') (('which', 'cloud TPUs'), 'DETECTION') (('this', 'When TPU'), 'be') (('it', '0'), 'indicate') (('readlines', 'lines'), 'ls') (('It', 'decoder'), 'use') (('We', 'EfficientNetV2 https arxiv'), 'understanding') (('decoder', 'own output'), 'predict') (('False 192 384 None', 'None'), 'yield') (('This', 'feature description'), 'give') (('fit', 'automatically computation'), 'distribute') (('we', 'which'), 'be') (('second value', 'second key'), 'input') (('precision However two lower which', 'memory'), 'be') (('gather', 'pred_ids 0 strategy'), 'axis') (('efficiently otherwise TPU', 'TPU'), 'determine') (('we', 'training'), 'dataset') (('input', 'daily val_lsd_confidence_auc_4'), 'result') (('we', 'gradients gradients tape'), 'sum') (('we', 'BMS tfrecord dataset'), 'map') (('we', 'feature maps'), 'NOTE') (('Here we', 'approach'), 'call') (('defaults', 'pd'), 'moldrawe') (('encoding positional vector', 'embedding vector'), 'add') (('pkl wb i', 'range len image_id_all'), 'epoch') (('We', 'training later 1 epoch'), 'determine') (('we', 'accumulation https gradient arxiv'), 'EDIT') (('format destination_blob_name list_blobs bucket_name', 'bucket'), 'source_file_name') (('TRANSFORMER ENCODER 9 TransformerEncoder', '1'), 'component') (('100 \u6e05\u6d17\u957f\u5ea6\u8d85\u8fc747 print len df_1 def 1 5 False df_1 print smiles_to_inchi', 'm Chem'), 'smile') (('None input_seq_len call self x training None padding_mask def enc_output2 None', 'embedding'), 'shape') (('final graident', 'respective replicas'), 'be') (('str str tokens 0 smiles tokens 1 selfies', 'str 2 selfies_dic'), 'split') (('VAL_STEPS VAL_STEPS preds', 'zip enumerate preds'), 'experimental_distribute_dataset') (('SECONDARY TASK notebook we', 'custom way'), 'DESCRIPTIONIn') (('normalization', 'd_model'), 'do') (('how quality', 'precision lower dtype'), 'DEFINITION') (('colors', 'ListedColormap import matplotlib'), 'import') (('entries', 'other words'), 'indicate') "}
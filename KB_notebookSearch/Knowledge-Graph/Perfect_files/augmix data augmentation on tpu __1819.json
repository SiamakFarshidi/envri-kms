{"name": "augmix data augmentation on tpu ", "full_name": " h1 ReadMe h1 Configuration h1 Dataset functions h1 Data visualization functions h1 Data augmentation h2 Helper functions h2 Transformations h2 AugMix h1 Visualization h2 Transformations h3 Original h3 Translate h3 Shear h3 Rotate h3 Solarize h3 Solarize Add h3 Posterize h3 Autocontrast h3 Contrast h3 Equalize h3 Brightness h3 Color h2 AugMix h3 More AugMix ", "stargazers_count": 0, "forks_count": 0, "description": "com mgornergoogle custom training loop with 100 flowers on tpu Optimized custom training loop I encountered significant memory issues what made it pretty useless for the competetition and thus I did not include this loss function. Interpolate Interpolation means we always stay within 0 and 255. is there any better way than manually typing all of these conditions I tried to randomly select transformation from array of functions but tensorflow didn t let me to you can play with these parameters level of transformations as described above in transformations integer from 1 to 10 number of different chains of transformations to be mixed number of transformations in one chain 1 means random from 1 to 3 get sample level of strength of transformations from 1 to 10. visualization of augmix https i. Configuration Dataset functions Data visualization functions Data augmentation Helper functions TransformationsThese are simple augmentations used by AugMix. Scale the image making the lowest value 0 and the highest value 255. ReadMeThis is my attempt to implement AugMix https arxiv. Extrapolate We need to clip and then cast. you can list the bucket with gsutil ls GCS_DS_PATH available image sizes predictions on this dataset should be submitted for the competition 00 09 10 19 20 29 30 39 40 49 50 59 60 69 70 79 80 89 90 99 100 102 convert image to floats in 0 1 range explicit size needed for TPU tf. Otherwise subtract 255 from the pixel. If step is zero return the original image. Shift lut prepending with 0. A possibly cheaper version can be done using cumsum unique_with_counts over the histogram values rather than iterating over the entire image. For the purposes of computing the step filter out the nonzeros. com cdeotte rotation augmentation gpu tpu 0 96. However AugMix performs better when used with special loss function Jensen Shannon Divergence Consistency Loss. In this notebook I implemented data augmentation part whichs seems to be working well. Works on CPU and single GPU. AugMix Visualization Transformations Original Translate Shear Rotate Solarize Solarize Add Posterize Autocontrast Contrast Equalize Brightness Color AugMix More AugMix Detect hardware return appropriate distribution strategy TPU detection. Otherwise build lut from the full histogram and step and then index from it. For optimal performance reading from multiple files at once and Diregarding data order. Order does not matter since we will be shuffling the data anyway disable order increase speed automatically interleaves reads from multiple files use data as soon as it streams in rather than in its original order returns a dataset of image label pairs if labeled True or image id pair if labeld False numpy and matplotlib defaults binary string in this case these are image ID strings data auto squaring this will drop data that does not fit into square or square ish rectangle size and spacing display magic formula tested to work from 1x1 to 10x10 images input image is one image of size dim dim 3 not a batch of b dim dim 3 fix for size 331 ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS FIND ORIGIN PIXEL VALUES Do addition in float. This is done in the C code for image. The second one indicates how much variation will particular transformation yield in other words how strong it will be. For each pixel in the image less than threshold we add addition amount to it and then clip the pixel value to be between 0 and 255. png Above image is from original paper. Compute the histogram of the image channel. Clip the counts to be in range. Scales each channel independently and then stacks the result. Every function takes image and level integer from 1 to 10 as arguments. Translate shear and rotate augmentations are based on this notebook https www. Compute the cumulative sum shifting by step 2 and then normalization by step. No parameters necessary if TPU_NAME environment variable is set. default distribution strategy in Tensorflow. While experimenting with custom implementation of this loss using optimized training loop from this notebook https www. pdfThis is also my first contact with tensorflow micro project so if you spot any errors and mistakes please report in the comments section. On Kaggle this is always the case. convert degrees to radians define rotation matrix For each pixel in the image select the pixel if the value is less than the threshold. string means bytestring shape means single element class is missing this competitions s challenge is to predict flower classes for the test dataset returns a dataset of image s Read from TFRecords. string means bytestring shape means single element returns a dataset of image label pairs tf. AugMix utilizes simple augmentation operations which are stochastically sampled and layered to produce a high diversity of augmented images. Assumes RGB for now. The value of addition is between 128 and 128. to compute mins and maxes. ", "id": "szacho/augmix-data-augmentation-on-tpu", "size": "1819", "language": "python", "html_url": "https://www.kaggle.com/code/szacho/augmix-data-augmentation-on-tpu", "git_url": "https://www.kaggle.com/code/szacho/augmix-data-augmentation-on-tpu", "script": "shear_x translate_y load_dataset solarize_add title_from_label_and_target pyplot pyplot as plt blend inner_loop_body kaggle_datasets shear_y scale_channel batch_to_numpy_images_and_labels build_lut numpy read_labeled_tfrecord translate_x decode_image brightness tensorflow_probability inner_loop_cond substract_means outer_loop_body contrast sample_level KaggleDatasets tensorflow affine_transform int_parameter augmix display_one_flower outer_loop_cond posterize apply_op color autocontrast matplotlib scale_values normalize rotate display_batch_of_images float_parameter read_unlabeled_tfrecord equalize solarize ", "entities": "(('we', 'always 0'), 'mean') (('function', 'arguments'), 'take') (('data augmentation part whichs', 'notebook'), 'implement') (('com cdeotte rotation augmentation gpu', '0 96'), 'tpu') (('challenge', 'TFRecords'), 'mean') (('Translate', 'notebook https www'), 'base') (('step', 'zero original image'), 'return') (('predictions', 'tf'), 'list') (('ReadMeThis', 'AugMix https arxiv'), 'be') (('value', 'addition'), 'be') (('possibly cheaper version', 'rather entire image'), 'do') (('we', '0'), 'add') (('However AugMix', 'loss function Jensen Shannon Divergence Consistency better when special Loss'), 'perform') (('Add Posterize Autocontrast Brightness Color AugMix Detect More hardware', 'distribution strategy TPU appropriate detection'), 'Translate') (('ORIGIN PIXEL VALUES', 'float'), 'matter') (('how it', 'other words'), 'indicate') (('optimal performance', 'multiple files'), 'for') (('thus I', 'loss function'), 'loop') (('single element', 'image label pairs'), 'mean') (('1 means', '10'), 'be') (('TransformationsThese', 'simple AugMix'), 'function') (('which', 'augmented images'), 'utilize') (('value', 'threshold'), 'define') (('you', 'comments section'), 'be') "}
{"name": "riiid comprehensive eda baseline ", "full_name": " h1 About the Riiid AIEd Challenge 2020 h1 Table of Contents h1 1 EDA h1 1 1 Exploring Train h1 The target answered correctly h1 1 2 Exploring Questions h1 1 3 Exploring Lectures h1 Example test h1 2 Baseline model ", "stargazers_count": 0, "forks_count": 0, "description": "As you can see there is exactly one question_id without at least one tag. First let s check if there are any question_id s without tags. For example a user might see three questions in a row before seeing the explanations for any of them. Since there are not that many lectures I want to check if it helps if a user watches lectures at all. Batches without lectures have about 8 more correct answers than batches with lectures. com its7171 cv strategyIn the previous version I made a function for all the merges fillna s and label encoding below. As mentioned in the data description 1 is actually no answer as the interaction was a lecture instead of a question. The last thing that I want to check is if having a lecture in a batch helps. Not a big deal but we need to keep in mind that we have to impute something here if we make features based on tags. 2 Exploring QuestionsMetadata for the questions posed to users. Baseline modelBelow I am adding user features. It remains possible that some questions weren t logged due to other issues that all datasets of mobile users are susceptible to such as if a user lost their connection mid question. text v i round v 2 color white fontweight bold fontsize 14 ha right va center please be aware that there is an issues with train. Do we have the full history of all user_id s Yes if we filter train on timestamp 0 we get a time 0 for all users. Initially I also included watches_lecture and prior_question_had_explanation but these two features are very questionable. Kaggle says that there are new users in the test set but let s check this anyway with example_test. csv really is just an example. Important In the Updates corrections and clarifications topic is said that the hidden test set contains new users but not new questions The train test data is complete in the sense that there are no missing interactions in the union of train and test data. EDAAltogether we are given 7 files. The TOEIC L R uses an optically scanned answer sheet. You can find the correct way to compose user features in all high scoring public notebooks which use loops to calculate values for each individual question. Those three would all share a task_container_id. For content features the story is different. The other files don t take very long to load and I am importing the CSVs directly. correct_answer the answer to the question. In this competition your challenge is to create algorithms for Knowledge Tracing the modeling of student knowledge over time. 3 Exploring Lectures 1. You will pair your machine learning skills using Riiid s EdNet data. As you can see below I am using only 5 features for this baseline. What are the so called Parts When following the link provided in the data description we find out that this relates to a test. I am again taking a sample of 200 and have taken out the content_ids with more than 25 000 questions asked. For both wrong and correct answers the mean is about 25 seconds. prior_question_elapsed_time. part top level category code for the lecture. timestamp int64 the time in milliseconds between this user interaction and the first event completion from that user. bundle_id code for which questions are served together. I also want to find out if there is a relationship between timestamp and answered_correctly. Let s find out how many answers were Right and Wrong per question_id so per content_id in train. Content_id is a code for the user interaction. If you want still check what the numbers look like with those features you can do that by simply hashing in and out the features line. part the relevant section of the TOEIC test. Please be sure to review the Time series API Details section closely. 3 Exploring LecturesMetadata for the lectures watched by users as they progress in their education. 001 the public score goes down 0. Seems that the questions are multiple choice answers 0 3. answered_correctly int8 if the user responded correctly. As you can see below table sorted on descending Percent_lecture the percent of lectures of the task_container_id s is never high. As you can see Part 5 has a lot more question_id s and is also the most difficult. Therefore I unfortunately went back to an ugly version of code repetition for those steps same code for validation and test_df. The meaning of the tags will not be provided but these codes are sufficient for clustering the questions together. timestamp int64 the time in milliseconds between this user interaction and the first event completion from that user. Below I am doing the same thing by content_id is question_id for content_type is question. As you can see there is a slight downward trend. The listening section consists of Part 1 4 Listening Section approx. There are 200 questions to answer in two hours in Listening approximately 45 minutes 100 questions and Reading 75 minutes 100 questions. 45 minutes 100 questions. Let s start by checking how much memory this dataframe is using. prior_question_had_explanation bool Whether or not the user saw an explanation and the correct response s after answering the previous question bundle ignoring any lectures in between. prior_question_elapsed_time float32 The average time in milliseconds it took a user to answer each question in the previous question bundle ignoring any lectures in between. task_container_id int16 Id code for the batch of questions or lectures. Let s fix this before continuing. com rohanrao tutorial on reading large datasets Thanks Rohan. content_id int16 ID code for the user interaction content_type_id int8 0 if the event was a question being posed to the user 1 if the event was the user watching a lecture. At first glance this does not seem very interesting regarding our target. Note that the time is the average time a user took to solve each question in the previous bundle. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedbackThe train dataset is ordered by ascending user_id and ascending timestamp. As the train dataset is huge I am gladly using the pickle that Rohan Rao prepared in this kernel https www. Dislaimer This a quick and dirty way. Tailoring education to a student s ability level is one of the many valuable things an AI tutor can do. In addition it is also interesting to see that the percent answered correctly for the missing values is closer to True than to False. This a low number compared to the tags with most answers. when looking at train we see that this question was just asked once. The tags seem valuable to me. 1 Exploring Train 1. com c riiid test answer prediction discussion 195032 add thousands separator this clears everything loaded in RAM including the libraries adding user features adding content features using one of the validation sets composed by tito save mean before splitting please be aware that there is an issues with train. The test data follows chronologically after the train data. 8 which means one lecture on about 36 questions. Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target. You ll be provided with the same sorts of information a complete education app would have that student s historic performance the performance of other students on the same question metadata about the question itself and more. The reading section consists of Part 5 7 Reading Section 75 minutes 100 questions. Is there a correlation between the percent_lecture and the percent_correct No I don t really see it. For instance the percent answered_correctly for a user s 10th question should be the average of his first 9 answers only. I actually do this at work all the time and in this case it reduces the time to load the dataset with the data types specified in the file description from close to 9 minutes to about 16 seconds. question_id foreign key for the train test content_id column when the content type is question 0. Now I can add up all Wrong and Right answers for all questions that are labeled with a particular tag and calculate the percent correct for each tag. Future information should not be used. I seemed as if a copy of train was kept in RAM at least temporarily and I ran into an out of memory error. So we should realize that example_test. task_container_id int16 Id code for the batch of questions or lectures. we can see that prior_question_had_explanation is object and taking a lot of memory while it is supposed to be boolean. Therefore I believe that the simpler model is preferred. However after adding a few features in this version I ran into memory issues. True means that the user was watching a lecture. Please note that there is double counting of questions for instance if a question has 5 tags its answers are aggregated in the totals of each of the 5 tags. About the Riiid AIEd Challenge 2020Riiid Labs an AI solutions provider delivering creative disruption to the education market empowers global education players to rethink traditional ways of learning leveraging AI. 3 Exploring Lectures 2. This is a time series code competition you will receive test set data and make predictions with Kaggle s time series API. 2 Exploring Questions 1. To find out I have made 5 bins of timestamp. Table of Contents 1. Without looking at the lecture interactions 1 we see about 1 3 of the questions was answered incorrectly. Your challenge in this competition is a version of that overall task you will predict whether students are able to answer their next questions correctly. user_id int32 ID code for the user. With those two features CV barely goes up less than 0. As we can see we have over 101 million rows the the train set. If anything the percent_correct actually seems to go down slightly. Basically these are the questions if content_type is question question_id foreign key for the train test content_id column when the content type is question. Can be compared with the train user_answer column to check if the user was right. Is null for a user s first question bundle or lecture. 001 and feature importance is very low for both features. Therefore we do not have the option to compare timestamps across users and the average based content features are as good as it gets for this dataset. The submission happens via the API. As you can see the differences are significant However we should also realize that the tag with the worst percent_correct only has about 250 000 answers. Baseline model 2. The meaning of the tags will not be provided but these codes are sufficient for clustering the lectures together. As you can see I have also changed the tags column into lists of tags. As we can see there is a new user in example_test indeed. Read 1 as null for lectures. As you can see the only noticable thing is that users who have registered relatively recently perform a little worse than users who are active longer. Below I am plotting the number of answers per user_id against the percentage of questions answered correctly sample of 200. As you can see it helps indeed Batches task_container_id may also contain lectures and I want to find out if there are any batches with high numbers of lectures. However as the feature works with regards to the CV see Baseline model I also wanted to find out if there is a trend. If we had real points in time we would have had the option to track changes in difficulty over time. mean see https www. As you can see it does not. 1 Exploring TrainThe columns in the train file are described as row_id int64 ID code for the row. Does it help if the prior_question_had_explanation Yes as you can see the percent answered correctly is about 17 higher when there was an explanation. As some users have answered huge amounts of questions I have taken out the outliers user_ids with 1000 questions answered. The target answered_correctlyAnswered_correctly is our target and we have to predict to probability for an answer to be correct. As you can see the trend is upward but there is also a lot of variation among users that have answered few questions. Let s also check out what the distribution of answered_correctly looks like if we groupby the 10 000 unique task_container_id s. As you can see there is s slightly downward trend. tags one or more detailed tag codes for the question. However timestamp 0 for user x is not the same as timestamp 0 for user y. Tito rightfully argues that just taking the last couple of questions from each user as the validation set leads to much on light users in this kernel Thanks Tito https www. Below I have taken a sample of 200 rows. The test iterations give interactions of users chronologically. Although it is probably better to treat not having an explanation as a disadvantage as there was an explanation before the vast majority of questions. prior_question_elapsed_time float32 The average time in milliseconds it took a user to answer each question in the previous question bundle ignoring any lectures in between. tag one tag codes for the lecture. We can also see the highest percentages of lectures are around 2. This year the company released EdNet the world s largest open database for AI education containing more than 100 million student interactions. The value is shared across a single question bundle and is null for a user s first question bundle or lecture. add thousands separator 1 year 31536000000 ms make function that can also be used for other fields for i v in zip pq. The goal is to accurately predict how students will perform on future interactions. Below I am displaying the count and percent correct by part. 000 rows for training. type_of brief description of the core purpose of the lectureLet s have a look at the type_of. user_answer int8 the user s answer to the question if any. As you can see most interactions are from users that were not active very long on the platform yet. Content_type_id False means that a question was asked. With a strong belief in equal opportunity in education Riiid launched an AI tutor based on deep learning algorithms in 2017 that attracted more than one million South Korean students. com c riiid test answer prediction discussion 195032 features user_questions user_mean content_questions content_mean watches_lecture prior_question_elapsed_time prior_question_had_explanation for now just taking 10. However that would make this baseline model a lot more complicated. lecture_id foreign key for the train test content_id column when the content type is lecture 1. Example testThis file is a very small file and only good to check what s in there. ", "id": "erikbruin/riiid-comprehensive-eda-baseline", "size": "14531", "language": "python", "html_url": "https://www.kaggle.com/code/erikbruin/riiid-comprehensive-eda-baseline", "git_url": "https://www.kaggle.com/code/erikbruin/riiid-comprehensive-eda-baseline", "script": "correct seaborn lightgbm FuncFormatter matplotlib.ticker matplotlib.pyplot sklearn.preprocessing LabelEncoder pandas sklearn.metrics matplotlib.style roc_auc_score numpy ", "entities": "(('Batches', 'lectures'), 'have') (('also percent', 'False'), 'be') (('I', 'batch'), 'be') (('listening section', 'Part'), 'consist') (('First s', 'question_id tags'), 'let') (('test data', 'train chronologically data'), 'follow') (('answer', 'probability'), 'be') (('that', 'few questions'), 'be') (('Submissions', 'predicted probability'), 'evaluate') (('I', 'lectures'), 'see') (('Baseline modelBelow I', 'user features'), 'add') (('user', 'them'), 'see') (('TOEIC L R', 'answer optically scanned sheet'), 'use') (('challenge', 'time'), 'be') (('1000 questions', 'user_ids'), 'answer') (('accurately how students', 'future interactions'), 'be') (('education global players', 'AI'), 'empower') (('i', 'zip pq'), 'add') (('we', 'time'), 'have') (('I', '25 more than 000 questions'), 'take') (('train test new data', 'train'), 'say') (('feature importance', 'very features'), 'be') (('we', 'new example_test'), 'be') (('that', 'very long platform'), 'be') (('Below I', 'content_type'), 'do') (('you', 'features simply line'), 'check') (('we', '101 over million rows'), 'see') (('you', 'task_container_id'), 'sort') (('also highest percentages', 'lectures'), 'see') (('here we', 'tags'), 'deal') (('content average based as it', 'dataset'), 'have') (('I', 'timestamp'), 'make') (('1 actually interaction', 'data description'), 'mention') (('test iterations', 'users'), 'give') (('that', 'one more than million South Korean students'), 'launch') (('questions', 'which'), 'code') (('answered_correctly we', '10 task_container_id 000 unique s.'), 'let') (('you', 'exactly one at least one tag'), 'be') (('You', 'EdNet data'), 'pair') (('who', 'relatively recently little worse users'), 'be') (('this', 'very target'), 'seem') (('user', 'train user_answer column'), 'compare') (('average user', 'previous bundle'), 'note') (('codes', 'questions'), 'provide') (('dataframe', 'how much memory'), 'let') (('I', 'tags'), 'change') (('that', 'tag'), 'add') (('two features', 'also watches_lecture'), 'include') (('I', 'memory issues'), 'run') (('user', 'lecture'), 'mean') (('which', 'about 36 questions'), '8') (('s', 'anyway example_test'), 'say') (('codes', 'lectures'), 'provide') (('Part', 'question_id 5 lot more s'), 'have') (('this', 'test'), 'find') (('everything', 'train'), 'add') (('I', 'really it'), 'be') (('don very long I', 'CSVs'), 'take') (('content_id content when type', 'question_id train foreign test'), 'key') (('reading section', 'Part 5 7 Reading Section 75 100 questions'), 'consist') (('time series code you', 'time series API'), 'be') (('saw', 'lectures'), 'bool') (('how many answers', 'train'), 'let') (('students', 'next questions'), 'be') (('where they', 'timestamp'), 'order') (('Below I', 'part'), 'display') (('value', 'question first bundle'), 'share') (('it', 'lectures'), 'float32') (('they', 'education'), 'LecturesMetadata') (('it', 'memory'), 'see') (('user', 'lectures'), 'be') (('validation', 'kernel'), 'argue') (('I', 'baseline'), 'use') (('complete app', 'question'), 'provide') (('com c riiid test answer prediction discussion', 'now just 10'), 'feature') (('previous I', 'encoding'), 'cv') (('three', 'all task_container_id'), 'share') (('AI tutor', 'many valuable things'), 'be') (('mean', 'wrong answers'), 'be') (('at least temporarily I', 'memory error'), 'seem') (('0 we', '0 users'), 'have') (('I', 'Baseline model'), 'see') (('Below I', '200'), 'plot') (('CV', 'two features'), 'go') (('Content_id', 'user interaction'), 'be') (('such user', 'mid question'), 'remain') (('type_of brief description', 'type_of'), 'have') (('Therefore I', 'validation'), 'go') (('it', 'questions'), 'be') (('answers', '5 tags'), 'note') (('round v 2 color white fontweight', 'train'), 'v') (('Rohan Rao', 'kernel https www'), 'be') (('question', 'when train'), 'see') (('percent', 'prior_question_had_explanation'), 'help') (('year company', '100 student more than million interactions'), 'release') (('which', 'individual question'), 'find') (('it', 'about 16 seconds'), 'do') (('story', 'content'), 'feature') (('TrainThe columns', 'row'), 'explore') (('content_id content when type', 'train foreign test'), 'key') (('content_id content when type', 'train foreign test'), 'be') (('percent', 'first 9 answers'), 'be') (('I', 'also timestamp'), 'want') (('also tag', '250 only about 000 answers'), 'realize') (('1 event', 'lecture'), 'code') (('about 1 3', 'questions'), 'see') "}
{"name": "tps6 eda comparison to tps5 ", "full_name": " h1 About h1 Data Overview h1 Target Variable Analysis h1 Duplicates h1 Feature Value Distributions h1 Feature Value Analysis h1 Viz per Feature h1 Sample Analysis h1 Set Baseline ", "stargazers_count": 0, "forks_count": 0, "description": "there are 5422 rows where 27 features have entries to be preceise non zero entries. Viz per Feature Sample AnalysisIn the training data there are 9 rows where all features are 0. That is rows where features and target match. But we also have 118 feature duplicates here. and there are 9 rows where no features have entries add the target column back to check for target when all features are 0 repeat for test data get the number of entries that are not 0 in each row dont assign directly to df_train this will inclued number_nz in sum_nz learning by mistakes. Like in TPS5 0 is by far the most common value for any feature. If we combine the training and testing set we have 101 rows with identical features. read_csv plotting machine learning algorithms Input data files are available in the read only. Would be interesting to check exactly those predictions. These 9 rows have different target classes 5x Class_2 2x Class_6 1x Class_5 1x Class_3. Target Variable AnalysisThe target variable is imbalanced with Class_6 and Class_8 sharing half of the values. So no use trying to make sense out of those rows just decide how to deal with them. The feature with the lowest number of zeros has 28. plot kind barh figsize 16 12. So the model gets the exact same data in the test set that it learned from in the training phase. Data OverviewWe can see here that there are no missing values. AboutThis notebook is my EDA for the Tabular Playground Series June 2021. input directory For example running this by clicking run or pressing Shift Enter will list all files under the input directory You can write up to 20GB to the current directory kaggle working that gets preserved as output when you create a version using Save Run All You can also write temporary files to kaggle temp but they won t be saved outside of the current session read competition data files number of rows with any values below zero check the target variable check for true duplicates i. Some further investigation made me believe that this is an artifact from making a synthetic dataset. I am still puzzeld what to make out of this observation. So at least train and test have the same properties. DuplicatesIn the training data we have 106 true duplicates. Although the number of zero features is a big higher than expected in the test set. This is much higher than the highest value in TPS5. There are many features with a seizable difference between their value range and their number of unique features. Ids 221601 232129 245875 250216 284469 295642. Set Baseline This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python Docker image https github. There are also 6 rows with 0 for all features in the test set. com kaggle docker python For example here s several helpful packages to load linear algebra data processing CSV file I O e. Only 10 features have less than 50 of zeros. For the May EDA please see my notebook TPS5 EDA raising more questions than answers https www. While TPS5 with a low number of feature duplicates led me to just drop them I will think twice if this is a good approach here for TPS6. Most features are in a range from 0 to 100 with a few exceptions. Now in TPS6 there are no low cardinality features. com melanie7744 tps5 eda raising more questions than answers. The June competitions has quite some similarities to the May competition. Feature Value DistributionsWe can see here that all distributions are right skewed. Any ideas There feature with the highest number of zeros has 86. there is 1 row where 65 features have entries. row 66469 Class_3And just by counting the target variable values for the feature dupliates it can be seen that they do not match. The variable statistics are comparable between training and testing data. get the sum of the entered values in each row check for all zero samples predict like train set probabilites. Here is a summary of my findings please find the details below. Some further investigation made me believe that this is an artifact from making a synthetic dataset. Comparing them to the number of dupicates in the train set 106 118 224 their number is a bit lower than expected. The most obivous similarities are multi class classification problem mulit class log loss as evaluation metric anonymized obfuscated features most feature values are 0 there are no binary features The differences lie in the details 9 classes vs 4 in TPS5 75 features vs 50 in TPS5 training and testing data are twice as big as in TPS5 the features do not have any negative values there are much more feature duplicates than in TPS5If you like my analysis please upvote Let s load the environment and look at training and testing data. get the sum of the entered values in each row. Feature Value AnalysisHere we see a quite different picture than in TPS5. The highest value of any feature is 352. In the test set we have 79 rows indicated as duplicates. That is rows where the features are the same but the target variable is different An example would be row 131686 Class_2 vs. where features and target match drop duplicates check for duplicates in the feature columns only possible for training data look at test set only check for samples with identical features in train and test data this shows the rows from the training data keep last would show the rows from the testing data thanks to Maxim Kazantsev maximkazantsev for this function I adapted it slighty let s check if there are as many unique feature values as the range of values use df_all df_test here depending on what you want to see check how many of feature values are 0 choose feature for a closer look create figure add subplot 1 2 rows 1columns first plot just an alternative with sns instead of plt read again because of dropped duplicates store the target column it interfers with the calcluations below if the id is still present remove it beause it screws computations enter the row you want to analyse get the number of entries that are not 0 in each row dont assign directly to df_train this will inclued number_nz in sum_nz learning by mistakes. ", "id": "melanie7744/tps6-eda-comparison-to-tps5", "size": "3878", "language": "python", "html_url": "https://www.kaggle.com/code/melanie7744/tps6-eda-comparison-to-tps5", "git_url": "https://www.kaggle.com/code/melanie7744/tps6-eda-comparison-to-tps5", "script": "seaborn if last duplicate is kept numpy if first duplicate is kept matplotlib.pyplot make_data_plots pandas StandardScaler sklearn.preprocessing ", "entities": "(('this', 'mistakes'), 'show') (('Here summary', 'details'), 'be') (('competition data files number', 'duplicates true i.'), 'list') (('this', 'synthetic dataset'), 'make') (('we', 'identical features'), 'have') (('Class_6', 'values'), 'imbalance') (('5422 where 27 features', 'entries'), 'be') (('number', '118 106 224'), 'compare') (('training 9 where features', 'Feature Viz Sample'), 'AnalysisIn') (('There feature', '86'), 'have') (('it', 'training phase'), 'get') (('twice this', 'good here TPS6'), 'lead') (('Most features', 'few exceptions'), 'be') (('get', 'train set probabilites'), 'predict') (('9 rows', 'target different classes'), 'have') (('Feature Value AnalysisHere we', 'TPS5'), 'see') (('they', 'feature dupliates'), 'see') (('this', 'mistakes'), 'be') (('It', 'kaggle python Docker image https github'), 'Set') (('Only 10 features', 'zeros'), 'have') (('notebook', 'answers https www'), 'see') (('variable statistics', 'data'), 'be') (('we', 'feature also 118 duplicates'), 'have') (('feature', '28'), 'have') (('So at least train', 'same properties'), 'have') (('number', 'test big set'), 'be') (('read_csv', 'read'), 'be') (('eda', 'answers'), 'com') (('79 rows', 'duplicates'), 'have') (('June competitions', 'May competition'), 'have') (('s', 'data'), 'be') (('we', '106 true duplicates'), 'duplicatesin') (('1 where 65 features', 'entries'), 'be') (('AboutThis notebook', 'Tabular Playground Series'), 'be') (('I', 'observation'), 'be') (('So use', 'just how them'), 'decide') (('This', 'TPS5'), 'be') "}
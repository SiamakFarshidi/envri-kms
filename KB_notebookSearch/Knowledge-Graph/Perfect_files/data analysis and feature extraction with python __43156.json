{"name": "data analysis and feature extraction with python ", "full_name": " h1 Exploratory data analysis and feature extraction with Python h1 0 Belfast an earlier incubator h2 Imports h2 Functions h1 1 The lean data set h2 1 1 Doing the pitch h2 1 2 Showing the numbers h2 1 3 Filling the gaps h2 1 4 Minimum viable model h3 1 4 1 Preparing the data h3 1 4 2 Launching the model h3 1 4 3 Assessing model performance h1 2 The chubby data set h2 2 1 Imputation of Age missing data h2 2 2 Exploratory data analysis h3 2 2 1 Pclass h3 2 2 2 Name Title h3 2 2 3 Sex h3 2 2 4 Age h3 2 2 5 FamilySize h3 2 2 6 Fare h3 2 2 7 Embarked h2 2 3 Feature extraction h3 2 3 1 Feature engineering h4 Data preparation h4 Box Cox transformations h4 Polynomials h3 2 3 2 Feature selection h4 Univariate statistics h1 3 Unicorn model h2 3 1 Fit model for best feature combination h2 3 2 Learning curve h2 3 3 Validation curve h2 3 4 Submit predictions h1 4 Conclusion h2 Now it s your turn Make this work yours Select a part of this kernel and play with it Why not trying a different feature selection process Or what about applying a different imputation method There are a hundred different ways to steal this work like an artist Do it After all all unicorns started with a MVP h1 You might also like h1 References h1 Acknowledgements ", "stargazers_count": 0, "forks_count": 0, "description": "In SoutheastCon 2016 pp. Nonetheless it seems that it would be enough to just distinguish between children and adults. Submit predictions 3. Feature engineeringFeature engineering is the art of converting raw data into useful features. There are several strategies to deal with missing data. The main advantage of Box Cox transformations is that they optimally normalize the chosen variable. It addresses the problem of attaining the most informative and compact set of features to improve the performance of machine learning models. Regarding Mme and Mlle we can see here https www. An introduction to variable and feature selection. Select a performance metric and a target value for this metric. The Model and the Train Wreck A Training Data How To. Our hypothesis is that children are more prone to survive while people in its adult life may have a lower rate of survival. Feature extractionIn the book How Google Works https amzn. to 2M9hvv7 Eric Schmidt and Jonathan Rosenberg refer that Google s secret sauce is technical insight. PclassOur hypothesis is that the higher the class the higher the chances of survival. A comprehensive list of them is presented by Heaton 2016 https arxiv. html preprocessing categorical features. Validation curves in a nutshell Validation curves are a tool that we can use to improve the performance of our model. Ticket class 1 1st 2 2nd 3 3rd. Giving a quick look to our values there s nothing that looks like obviously wrong. The pitch is important because investors are more willing to invest when they understand what you re doing. It needs to be parsed. pdf Videos Rogati M. Through a series of anecdotes and stories Ries teaches us all we need to know about agility and lean methodology in the startup world. Finally we will make incremental changes to improve the system s performance Learn. Our new category Other should be more discretized. Based on these principles the aim of this study was to improve data quality through exploratory data analysis and feature extraction. The rule seems to be last name title other names Bar plot gives us an estimate of central tendency for a numeric variable height of each rectangle and an indication of the uncertainty around that estimate error bars in black. Consequently it reduces the size of the data set and is a possible source of bias since some non random mechanism can be generating the missing data. For example a low standard deviation suggests that data points tend to be close to the mean. Let s see if that makes sense using our beautiful and only friend https youtu. In those cases the learning curves will converge to a low score value. According to the authors it is fundamental technical insight that allows companies to create great products which provide real value to the customers. Exploratory data analysis 2. Validation curveWe used C 1 which is on the edge of overfitting. For example PageRank http www. For example we are using unrealistic replacement values which are out of range and distort data distribution. Worst case scenario we name this model as beta version POk let s prepare the data for the MVM launching fit a logistic regression to it and analyse the performance of the model through learning and validation curves http scikit learn. This means that we are looking for features that can characterize the behaviour of what we are trying to model. This metric will guide your work and allow you to know how well you re performing. Conclusion Warning This will be a long read. As he said sometimes a cigar is just a cigar Freud used to smoke cigars. Monitor the system to understand its behaviour in particular to understand whether its poor performance is related to underfitting overfitting or defects. Here we can apply feature engineering tune hyperparameters or even change the algorithm according to the outputs of our monitoring system. Journal of the Royal Statistical Society. Validation curve 3. Not that I m a believer in their power to make someone laugh but just because they are terrific icebreakers. This may suggest that our hypothesis should be revised when FamilySize is higher than 3. Data will be studied and enriched through exploratory data analysis and feature extraction to improve the performance of our machine learning model. Otherwise we will be penalizing the predictive power of our model. Impute data using values from similar cases or using the mean value. Age can be imputed. ly 2oYzJ7U let me show you how to apply it. Through a complete analysis of the Kaggle s Titanic problem we will see what to do where to begin and how to proceed in a data science problem. In our case our performance metric will be accuracy because it is the one defined by Kaggle https www. We already have some clues that in Titanic women had a higher survival rate. If you re right you succeed fast if you re wrong you fail fast. We will follow the common practice and say that our minimum value is zero and our maximum value is one. Let s see how this work before you start with sinking feelings. Exploring data to understand which features can have impact in the model and how they can be manipulated to boost that impact. Make this work yours. com joaopcoelho and Jo\u00e3o Rico https www. Now step by step let s perform our analysis. We will follow this methodology. This way we introduce a nonlinear dimension to our data set which can improve the predictive power of our model. With a little bit of creativity we can say that the plot has three regions 1. People that are travelling alone have a lower survival rate than people who are travelling with one two or three people more. This means that we have to choose the number of features that we want in the model. Feature selection which regards the choice of a compact set of features. We will use the chi squared test for feature selection. Although our model does better predictions than a flip a coin strategy https en. Moreover concerning the practical methodology that we mentioned before we can say that 1. Learning curveNo signs of overfitting or underfitting. Survival 0 No 1 Yes. A simple plot can enlighten us. We didn t use a clever algorithm but we explored clever techniques to make our data better. We will just do the minimum viable effort to implement a reasonable model. com interpreting error bars. Showing the numbersNumbers are crucial to set goals to make sound business decisions and to obtain money from investors. In my mind I still keep a picture of all those people outside the cinema in the queue to buy tickets. Binary variable that will be our target variable. Since there s nothing shocking about the variables let s proceed to the next step missing data. It goes through the following phases 1. In this section we start the assemblage of our work by importing some libraries and general functions. Overview Descriptive statistics Analyse missing data Drop Cabin Fill missing values in Age with a specific value Delete observations without Embarked Get index of points where Embarked is null Data types Drop PassengerId Define categorical variables Create Family feature Drop SibSp and Parch Drop Name and Ticket Transform categorical variables into dummy variables To avoid dummy trap Create data set to train data imputation methods Debug Fit logistic regression Model performance Plot learning curves Plot validation curve Restart data set Family size feature Drop SibSp and Parch Drop irrelevant features Inspect names Extract titles from name Use REGEX to define a search pattern Unique titles Plot bar plot titles age and sex Means per title To simplify data handling Transform means into a dictionary for future mapping Impute ages based on titles Identify imputed data Plot Count how many people have each of the titles Map of aggregated titles Group titles Transform into categorical Plot Transform into categorical Plot Plot Plot Bin data Plot Plot Plot Plot Plot Compare with other variables Relationship with age Relationship with sex Overview Drop feature Check features type Transform object into categorical Transform categorical features into dummy variables Get training and test sets Apply Box Cox transformation Rescale data Get polynomial features Debug Select features using chi squared test Select i features Model with i features selected Save results if best score Print the number of features Select features Fit model Model performance Plot learning curves Plot validation curve Get test data set Transform data set based on Chapter 2 There is one missing value in Fare Make predictions Generate submission file. Probably one of the problems is that we are mixing male and female titles in the Other category. Feature extraction is our technological insight in machine learning. Topics like data visualization missing data imputation feature engineering feature selection and logistic regression will be addressed serving you repeatedly because after you see what s involved you ll be able to apply these techniques to any kind of data science problem. This can be done by Improving the way how we handled Age missing data. To visualize if there is a relationship between Pclass and Survival let s do a bar plot. To successfully apply machine learning techniques we need to start with a simple model that we can master and understand. be F7iopLnhDik added that better data beats more data. We need to parse Name and Ticket. Thus they avoid the need to randomly try different transformations and automatize the data transformation process. Now it s time to turn all this work into a highly accurate model our unicorn model. Draw conclusions from the experiment and decide what to do next. The plot shows that children have a higher survival rate. Since I m a true believer of the transforming power of startups and seeing obvious similarities between what startups do and what a data scientist does several references to startup methods are present in the text. com pt PT pubs archive 35179. Feature extraction 3. Let s keep an eye on this. As a result we Increase speed. As the authors point out the successful application of machine learning techniques goes beyond the knowledge of algorithms and their principles. Only then we should move to more complex algorithms. In our case I d say that the most important is to reduce overfitting. Then we will test those hypothesis through a set of exploratory data analysis tools. Note that right now it doesn t matter much how well the model performs. Exploratory data analysisExploratory data analysis is often mentioned as one of the most important steps in the data analysis process. 2013 https amzn. Our hypothesis seems to be right. EmbarkedThe hypothesis regarding Embarked is that it doesn t influence the chances of survival. This model should allow us to quickly understand the problem and the data. collecting a different set of features. people embarking on C were mostly women. The hypothesis driven approach consists in establishing hypothesis about the variables behaviour and their relationships early in the process to then focus on using data to prove or disprove those hypothesis. Discussion of our results The model doesn t overfit. These two main issues are addressed in the following sub sections 1. To sink or not to sink is the question of this exercise. Polynomial expansion creates interactions between features as well as creates powers e. Pop quiz was the Titanic a MVP 1. Play with them according to your needs test them and you should be fine. The main conclusion is that we already have a set of features that we can easily use in our machine learning model. Exploratory data analysis and feature extraction with PythonUsing data visualization feature engineering and feature selection to make a simple logistic regression look powerful Pedro Marcelino http pmarcelino. Since now we want to establish comparisons across different levels of a categorical variable we will use a box plot instead of a bar plot. Analyse the data you collected when testing the product with your customers. One between age 15 and 48 3. Feature selection is about chosing the relevant information. It just wasn t that unsinkable. An empirical analysis of feature engineering for predictive modeling. For now I ll ignore these features. Yes in Darwin https en. Accordingly we will not group them. org stable modules linear_model. For now I will not delete the variable because I feel that I m a little bit biased and trying to force a conclusion. org stable modules learning_curve. First we are talking about informative. org wiki Natural_selection we believe. For now we will not make any change because there is a theoretical rationale behind this categorization. Select a part of this kernel and play with it. However let s keep in mind that maybe Embarked doesn t affect Survived. Such an incorrect generalization from an irrelevant feature of the training set would result in a machine learning model that fits a particular set of data but fails to predict future observations reliably overfitting. Titles with a survival rate higher than 50 are those that correspond to female Miss or Mrs or children Master titles. Some of the most common are Use only valid data deleting the cases where data is missing. This is just an unique identification of each passenger. We will try to fail fast and cheap by quickly building a working end to end pipeline Build. Discussion of our results The figure shows that there is no huge difference in model s performance as far as we choose a C value of 10 1 or higher. Our final score is about 0. Also the more you use and refine these techniques the more you ll develop your problem solving intuition. First class should have a higher survival rate. edu media programs ghana summer 2013 materials problem_solving_grand_slam_7_steps_to_master_training_deck. Preambles aside what we really need to know is if sometimes a cigar is just a cigar or not. First thoughts Cabin has too many missing values 25. be F7iopLnhDik Kleon A. However the point is that this categories split fits into what we know about the way our society is organized childrens adults and elders. org wiki Multicollinearity which can make our estimates very sensitive to minor changes in the model. Doing the pitchStartups use pitches to sell their idea. In contrast only approximately 25 of the people travelling in the third class survived. For now I ll associate a value that allows me to know that I m imputing data. Doing the pitch 1. Let s get started PassengerId. org contents guidelines. html one billion is a big number. com pmarcelino comprehensive data exploration with python I was a kid when the movie Titanic was released. pdf Polynomials generation through non linear expansions. Finally we will group all the other titles in a new title named Other. The lean data set 1. Before the application of these techniques we will just make some adjustments to the data in order to prepare it for the modelling process. Same logic as Pclass. Series B Methodological pp. For each title get people s average age and use it to fill missing values. This process emphasizes rapid iteration as a critical ingredient to product development. org wiki Flipism it is still far from being an intelligent model. The chubby data set 2. Imputation of Age missing data 2. In contrast if there is no gap but the score value is low we can say that the model underfits. We need to understand its structure first. Name TitleOur assumption is that people s title influences how they are treated. After all all unicorns started with a MVP. Submit predictions 4. This kernel does something similar. Let s return the first rows of our data set to get a clear and concise picture of what is there and what we can do with it. PolynomialsOne standard way to enrich our set of features is to generate polynomials. Note that in a logistic regression C is the only model parameter that we can change see scikit learn documentation http scikit learn. Belfast an earlier incubatorIncubators are companies that support the creation of startups and their first years of activity. Accordingly their pitch should be clear and concise answering questions such as what do you do what do you want and who s on your team. Just like the Titanic I told you. We ve been through a long journey since we started solving this problem. The intuition is that features that are independent from the target variable are irrelevant for classification. The word uncertainty is key in this definition and it s also key in missing data. Is based on a logistic regression. It counts as a way of tuning our hyperparameters. That said let s say goodbye to the lean approach and welcome the chubby approach 2. It should play with SibSp. Accordingly we will start by listing each of the variables and generate hypothesis about their relationship with the target variable Survived. I have some dogmas e. It should make a difference. These terms tend to produce multicollinearity https en. Ice is important because cola always goes down well with ice. com articles dummy variable trap regression. Once the problem to solve is figured out the focus of the startup should be in the development of a solution the MVP as fast as they can. However it s fairly easy to fall into a data diving trap especially if you re solving problems about sunken ships and get lost into the process. They are different from the learning curves. Accordingly now that we are improving the model it makes sense to develop a different imputation method. Missing data occurs when no data value on one or more variables is available. When that happens your analysis can end up like this https youtu. Names are a form of social tagging especially when accompanied by a title. htm gave an incredible competitive advantage to Google in relation to other search engines by providing a far better way to rank search results on the web. Two common solutions for overfitting are reducing the complexity of the model and or collect more data. Apart from Rev and Dr which have a larger error bar the mean value seems to accurately represent the data of all the other features. The model underfits. Therefore employing the information in Name we can improve our imputation method. According to engineers a class to which I proudly belong the Titanic was the unsinkable ship. Imputation of Age missing dataOur initial approach to estimate Age missing values was to fill with a placeholder value 1000. For instance if we want to model the weather features like temperature humidity and wind are informative they are related to the problem. It was beautiful luxurious and fitted with the best of the technology. As a consequence only the fourth and last step of the practical methodology is missing to improve the model by iteration. It is good to add and generate features but at some point we need to exclude irrelevant features. Port of Embarkation C Cherbourg Q Queenstown S Southampton. Improve the system by iteration. In this work we will use a univariate statistics approach. Later we will try to beat this model by enriching our data. Our results suggest that People with the title Mr survived less than people with any other title. This variable seems to be more complex than expected. For now we will not make any changes but we will keep these two situations in our mind for future improvement of our data set. There are several perspective about the topic but I must confess that Freud s perspectives had a significant impact on me because they have shown me the subject in a new perspective. SibSp could be grouped with Parch to create a Family feature. Since our start with a lean model we ve been scaling our startup we imputed missing data we performed an exploratory data analysis and we extracted features. They are important because they help entrepreneurs solve some issues commonly associated with running a business such as workspace training and seed funding. Unique identification of the passenger. Feature selectionThe next step is to perform feature selection. Let s go step by step. org papers volume3 guyon03a guyon03a. Ok now that I convinced you that the hypothesis driven approach is the last coke in the desert http bit. FareThe same logic applied to Pclass should work for Fare higher fares higher survival rate. com 2018 03 26 china titanic artificial intelligence sensetime that apply deep learning to distinguish Titanic s romantic scenes from disaster scenes or you can find extensive exercises of creative thinking regarding what really happened with the Titanic https www. Regarding compact what we mean is that we want to exclude irrelevant features from our model. ConclusionAs Halevy et al. com blog french culture madame or mademoiselle a delicate question that they correspond to the categories Mrs and Miss respectively. A good introduction to the subject can be found in Hair et al. of parents children aboard the Titanic. Accordingly our aim will be to get an initial model that we can use as a first baseline approach. Accordingly we will not make any transformation in this variable and we will leave it as a continuous variable to preserve all the information it has. Fit model for best feature combination 3. There are three aspects that usually catch my attention when I analyse descriptive statistics 1. Univariate statistics 3. Categorical feature that should be encoded. Back then Leonardo DiCaprio and Kate Winslet were just two young kids with nice haircuts and online tickets were science fiction. This can play for both sides either people help elders because they are more vulnerable or they they are not able to cope with the challenges posed by the wreck of a ship. be qX0D7xkF33s victory. Minimum viable model 1. As we can see about 60 of the people travelling in the first class survived. Minimum viable model 2. IEEE Intelligent Systems 24 2 pp. This is the ticket number. square of a feature. Impute data using model based methods in which models are defined to predict the missing values. What s new about Freud is that he associated many normal behaviours to sexual drives almost to the point of making us question everything we do. It seems that people embarking on C were paying more and travelling in a better class than people embarking on Q and S. edu chazelle courses BIB pagerank. In other words this is a validated learning process that quickly builds tests and rebuilds products according to users feedback. Unless it has some information about places it shouldn t be important for prediction purposes. com Comprehensive data exploration in Python https www. It shouldn t be necessary for the machine learning model. It seems that Fare doesn t make difference in terms of survival if you are travelling in second or third class. As a result missing data introduces uncertainty in our analysis. For example if we want to have three features in our model the method will select the three features with highest chi 2 score. Bring your notebook sit on your favorite chair and pour Cola into a glass full of ice. This book has a practical summary about missing data and provides a framework that you can apply in almost all situations. For now it s just an artificial model. We can avoid this by following a hypothesis driven approach. Also I wrote a technical paper comparing different imputation techniques which I can share with you if you want. The plot suggests that those who survived paid a higher fare. Go to your customers and measure their reactions and behaviors against your product. This is the ticket class. From the results above we can see that Titles like Master Miss Mr and Mrs appear several times. I usually exclude variables with more than 25 of missing data but what usually guides my analysis is intuition critical thinking and need sometimes we need to leave our dogmas at the door if we want to generate some results. Since we believe this variable is connected with Pclass let s see how they work together. org 2013 07 the only japanese who survived the titanic lost his job because he was known as a coward in japan for not dying with the other passengers I would say that this variable is not important. This reduces your market risks by failing fast and cheap to get you closer and closer to what the market really needs. The chubby data setAt this point our model Can achieve a 0. pdf noted invariably simple models and a lot of data trump more elaborate models based on less data. As a consequence we will assign them to those titles. As we can see when FamilySize is between 0 and 3 our hypothesis finds some support. My practical advice to handle missing data is to learn a different set of tools. We need to parse before using it. Taking the weather example again we know that football scores do not affect weather but suppose that all rain instances in our training set happen to occur after a Benfica https youtu. to 2JsIMH3 Hair J. be LsQtnBu3p7Y the bar plot. Dogma We need to delete this variable right away. Considering the results above I feel tempted to say that the embarkment point doesn t influence the survival rate. This approach selects features based on univariate statistical tests between each feature and the target variable. In our lean approach we decided to replace missing data by a unique value but now we can go deeper and search for a better imputation strategy. My expectation is that after reading this kernel you can start compiling a cookbook of techniques in exploratory data analysis and feature extraction. One region that goes between age 0 and 15 2. Filling the gapsOne of my favourite definitions of startup belongs to Eric Ries a startup is a human institution designed to create a new product or service under conditions of extreme uncertainty. Assessing model performanceLearning curves in a nutshell Learning curves allow us to diagnose if the is overfitting or underfitting. com p 6 titanic conspiracy theories that are still fascinating today 28519. org stable modules preprocessing. org library drmath view 52579. Looking to Name values we can see person s name and title. html proposes an analogous approach for the application of machine learning models. Building new features that can increase the predictive power of our model. After 100 years the Titanic still remains a discussion subject in the most diverse areas. Monica Rogati https youtu. As we already know the bar plot shows us an estimate of the mean value height of each rectangle and an indication of the uncertainty around that central tendency error bars. Keep Your Eyes On the Horizon Business Lessons from Unsinkable Titanic https amzn. It seems that people embarking on C were selected by a superior entity to survive. Joking the true reason why Age matters is this one http www. SexSex is one of the most discussed topics in Human history. be _YzNZE287QQ Extra What is the dummy variable trap http www. Number of parents children aboard the Titanic. to 2sHpnvP Eric Ries tells us his personal experiences adapting lean management principles to high tech startup companies. We will also use Titanic for a specific purpose to learn exploratory data analysis and feature extraction techniques. html logistic regression. However if at the outset you can generate an educated guess of what the answer of your problem is I think that you should test your hypothesis and learn from it as fast as you can. I know that this division is arguable especially in what concerns the last two categories. We will only try to improve the performance of our model by enriching our data. Once again if there is a gap between the training and the validation score the model is probably overfitting. We also had to deal with terrible Titanic jokes that take some time to sink in. Since our goal was to have a working end to end pipeline as fast as possible this approach was ok. This allowed us to quickly get a complete data set in which was easy to identify imputed values. On the other hand underfitting means that the model is not able to perform well in either training or validations sets. In the same way we will generate the descriptive statistics to get the basic quantitative information about the features of our data set. be 1qzzYrCTKuk Parch. Until today I ve never found a one size fits all solution. It s not expected to be relevant to our analysis. It also shows that in terms of survival there is not a significant difference between the categories Adult and Elder. One way to improve our imputation method is to estimate the missing values based on known relationships. As a consequence it can lead to different forms of treatment. Due to the low percentage of missing values I ll delete the observations where we don t know Embarked. In the end Freud realized that not everything was about sex. This model will be our Minimum Viable Model. 2016 a book you can access for free here http www. Accordingly the model is not able to generalize to unseen data. Personally I don t have any special intuition about elders since they are the most vulnerable. Name of the passenger. to 2JwpsIT Papers Heaton J. To give an example we know that a person with the title Master is someone under 13 years old since a boy can be addressed as master only until age 12 http bit. The learning and validation curves allow us to monitor system s performance. be oww7oB9rjgw AcknowledgementsThanks to Jo\u00e3o Coelho https www. It s not expectable that people coming from Cherbourg are more unlucky than people coming from Southampton. Quickly set up a working end to end pipeline. pdf you can find one of my favourite PowerPoint presentations about the benefits and procedures of a hypothesis driven approach in problem solving. No significant differences can be found. The authors propose a practical four steps methodology 1. The unreasonable effectiveness of data. Turn your best idea into a Minimum Viable Product MVP. FamilySizeRegarding family size our hypothesis is that those who travel alone have a lower survival rate. Here we can see that some Age data is missing. Multivariate data analysis https amzn. Here we have an interesting result. To scale the features we will transform the data so that it lies between a given minimum and maximum value. Thanks to the MVP it is possible to begin the learning process and improve the solution towards users needs. Regardless of whether it is a European or American billion http mathforum. This is important to give us a first perception about the volume of missing data. We should scale our features when we have polynomial or interaction terms in our model. As a result we ll end up with a comprehensive view about the variables that should belong to our prediction model. I d say that it s easier to survive if you re with your family than if you re travelling alone. In our case we have several titles but only some of them are shared by a significant number of people. According to Karl Marx this should affect our target variable. Why not trying a different feature selection process Or what about applying a different imputation method There are a hundred different ways to steal this work like an artist https youtu. This model will be our Minimum Viable Model MVM. Regarding underfitting there are no signs of it since the model performs well. Launching the modelReady. Now that we can see the tip of the iceberg let s dive into the subject. As we can see by the error bar black line there is a significant uncertainty around the mean value. Since we don t know the ideal number of features we will test the method with all the possible number of features and choose the number of features with better performance. When the sun rises it rises for everyone. For now let s proceed this way. com April 2018Other Kernels Comprehensive data exploration in Python https www. We should proceed with a more detailed analysis to sort this out. 2009 https static. Then we will define Title as a categorical feature and plot it to see how it looks like. But nothing better than a plot to see what s going on. The first part deals with the development of a baseline model. While a set of important principles are taught throughout the book the truth is that the lean startup methodology always ends up in an attempt to answer to the question Should this product be built To answer this question the lean startup approach relies on a Build Measure Learn process. uk sciencetech article 1254788 Why women children saved Titanic Lusitania. Journal of machine learning research 3 Mar pp. This validates our approach. When the model overfits it means that it performs well on the training set but not not on the validation set. In our case we can do this by using the information in the variable Name. A last one between age 48 and 80. When the model underfits gathering more data is not helpful because the model is already not being able to learn the training data. com pmarcelino comprehensive data exploration with python References Books Ries E. What really seems to be influencing is the class where people were travelling and how much they were spending. Note that this practical methodology was adapted from Goodfellow et al. Unless there is some second order effect like refusing to run away to keep your honor as a man http www. Let s analyse the title and see if we can can find a sensible way to group them. This can give us an idea about the range of values and is helpful to detect outliers. These transformations are an alternative to the typical transformations such as square root transformations log transformations and inverse transformations. The Lean Startup How Today s Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses https amzn. Figure out the problem that needs to be solved generate ideas about how to solve it and select the best one. Person s title is a relevant information to estimate ages. com c titanic evaluation. The amount of data and the number of tests will be only what is needed to verify your hypothesis. Feature engineering which is related to the generation of informative features 2. Data preparation Box Cox transformationsBox Cox transformations aim to normalize variables. Other features like Name Ticket and Fare require an additional effort before we can integrate them. If it looks ok we will proceed with this new categorization. Also the category Master seems to have a similar problem. The only exception could eventually be the max value of Fare but for now we will leave it as it is. Number of siblings spouses aboard the Titanic. com in joaomiguelrico for reading drafts of this. This kernel has been divided into four parts. There are several reasons to exclude irrelevant features. Initially we will not invest much time with exploratory data analysis. to 2Gie0Pv where the author take leadership lessons from the Titanic to apply in business you can find interesting AI projects http fortune. These techniques will help you to obtain confidence in your data and engage with any data science problem. Also you ll find some Titanic jokes. This should allow you to estimate the selected performance metric. We just need a starting point. Showing the numbers 1. Age Age is the next variable in the list. It is hard to imagine a scenario in which people from Southampton for instance would such a competitive advantage that it would make them more apt for survival than people from Queensland. Import libraries Put this when it s called Create table for missing data analysis Plot learning curve Plot validation curve Import data Save original data set just in case. Then our model might learn that rain is related to Benfica s victories which is not true. Our current model can work as a baseline model and resulted from a working end to end pipeline. Teamwork https youtu. For example you can find books https amzn. Finally some conclusions will be drawn from this kernel and its impact in our data science journey. Uses Pclass Age Fare FamilySize Sex and Embarked as inputs and Survived as output. Definitions and quick thoughts PassengerId. The mean shows us the central tendency of the distribution while the standard deviation quantifies its amount of variation. For example children are usually evacuated first in a disaster so that we can think about a solution in silence. Sex Embarked and Pclass should be categorical. The cabin number can indicate where people were during the disaster. Then we test our new groups and if it works in an acceptable way we keep it. Min and max values. Let s call the usual suspect bar plot to help us understanding the situation. Categorical variable that should be encoded http scikit learn. All in all we re entrepreneurs. of siblings spouses aboard the Titanic. Our engineering masterpiece also needs a starting point. html you can find a short and sweet intro to error bars interpretation. This means that a person travelling in the first class has a higher chance of survival than a person traveling on the second or third class. We will use just two techniques Box Cox transformations Box Cox 1964 https www. However if you are travelling in first class the higher the fare the higher the chances of survival. An analysis of transformations. There are several feature engineering techniques that you can apply to be an artist. Preparing the data We don t need PassengerId for prediction purposes so we will exclude it. Imports Functions 1. Accordingly it would be interesting if we could group some of the titles and simplify our analysis. The choice of the performance metric is a closed topic because we re following Kaggle s specifications. As we can see the curves converge and no gap between the training and the validation score exists in the last points of the curve. Plot a figure with both features and confirm that there is a connection between titles and age. However when FamilySize is between 4 and 10 things start to change. Cases like the one we have are easy targets for the hypothesis driven approach because we don t have many variables so we can more or less guess their impact. This makes our analysis very objective because we will be collecting just enough data to test specific hypothesis. By contrast the result of a football game will not be an informative feature because it doesn t affect the weather. Considering this it would make sense to create interaction features between Fare and Pclass. You might also like My blog http pmarcelino. Afterwards we will go into detail. Actually it is so big and rare that when we find startups with such value we associate them to those mythical creatures that are the unicorns. For now optimization will not be a goal. The lean data setIn the book The Lean Startup https amzn. This is strange and may be hidding some relationship that is not obvious with this plot e. Steal like an artist. However it has several limitations. Filling the gaps 1. With numbers you can project the future of your startup so that everyone can understand which are the expectations around your idea. For now I ll just identify if the passenger is travelling alone or with family. This will lead us to a heavy data analysis process which aims to improve model s performance just by the data quality side. The world belongs to women and so does the Titanic. Later I ll revise this strategy. Titanic was the state of the art cruiser. You can find a concise introduction to the feature selection subject in Guyon Elisseeff 2003 http www. I ll not consider Survived as categorical because it s the output variable. The idea is that people with family can collaborate and help each other escaping. It wouldn t be surprising if it had some influence in survival chances but this variable was excluded due to the high percentage of missing values. to 2JtC1Vm Asefeso A. The focus is on getting something that can improve our current situation. Mean and standard deviation. Despite the large variability of the results the survival rate drops. Therefore the best approaches for these cases are to improve the model e. Scaling features to a range allow us to reduce multicollinearity and its problems. Unicorn modelStartups use the term unicorn to describe a startup that is valued at one billion dollars or more. In other words we will not change our learning algorithm neither we will try to improve its parameters. Minimum viable modelThe Minimum Viable Product MVP is a key concept for any lean startup. Then we will instrument the system to evaluate its performance Measure. Accordingly this plot suggests that the class in which people travel affects the chances of survival. Feature extraction 2. tuning the hyperparameters or to improve the quality of the data e. The steps to implement this new imputation method are Extract titles from Name. Here the goal is to see how the model parameter impacts the training and validation scores. This allow us to choose a different value for the parameter to improve the model. Please note that particularly when you really need to learn about the data set it makes sense to put the diving cylinder and go dive into the depths of data analysis. In our case all the min and max values seem reasonable and in a reasonable range of values. If the model is overfitting the learning curve will present a gap between the training and validation scores. Since we will limit our analysis to some hypothesis and move forward. ", "id": "pmarcelino/data-analysis-and-feature-extraction-with-python", "size": "43156", "language": "python", "html_url": "https://www.kaggle.com/code/pmarcelino/data-analysis-and-feature-extraction-with-python", "git_url": "https://www.kaggle.com/code/pmarcelino/data-analysis-and-feature-extraction-with-python", "script": "sklearn.feature_selection train_test_split cross_val_score boxcox numpy seaborn chi2 validation_curve sklearn.linear_model learning_curve matplotlib.pyplot MinMaxScaler plot_validation_curve sklearn.model_selection pandas SelectKBest LogisticRegression PolynomialFeatures scipy.stats draw_missing_data_table plot_learning_curve sklearn.preprocessing ", "entities": "(('Leonardo Back then DiCaprio', 'Kate just two young nice haircuts'), 'be') (('how they', 'impact'), 'have') (('point model', '0'), 'achieve') (('We', 'just two techniques'), 'use') (('when we', 'model'), 'scale') (('entrepreneurs', 'workspace such training'), 'be') (('they', 'how much'), 'be') (('We', 'data'), 'try') (('just they', 'power'), 'm') (('informative it', 'weather'), 'be') (('we', 'statistics univariate approach'), 'use') (('It', 'technology'), 'be') (('process', 'product development'), 'emphasize') (('Age Age', 'next list'), 'be') (('models', 'missing values'), 'datum') (('edu media programs', 'summer'), 'ghana') (('Pedro Marcelino', 'pmarcelino'), 'look') (('you', 'almost all situations'), 'have') (('title', 'relevant ages'), 'be') (('several references', 'text'), 'be') (('blog culture com french delicate they', 'categories'), 'madame') (('very we', 'specific hypothesis'), 'make') (('we', 'irrelevant features'), 'be') (('s', 'situation'), 'let') (('we', 'Other category'), 'be') (('you', 'you'), 'write') (('that', 'current situation'), 'be') (('us', 'quickly problem'), 'allow') (('we', 'https here www'), 'see') (('Age missing values', 'placeholder value'), 'miss') (('division', 'especially last two categories'), 'know') (('you', 'what'), 'be') (('s', 'missing data'), 'let') (('transformations', 'root transformations log such square transformations'), 'be') (('future observations', 'data'), 'result') (('this', 'target variable'), 'affect') (('we', 'results'), 'exclude') (('society', 'childrens organized adults'), 'be') (('unicorns', 'MVP'), 'start') (('Otherwise we', 'model'), 'penalize') (('where data', 'cases'), 'Use') (('gap', 'curve'), 'exist') (('We', 'reasonable model'), 'do') (('terms', 'multicollinearity https'), 'tend') (('we', 'them'), 'require') (('We', 'data exploratory analysis'), 'use') (('model', 'well training sets'), 'mean') (('It', 'machine learning models'), 'address') (('first part', 'baseline model'), 'deal') (('them', 'Queensland'), 'be') (('we', 'data set'), 'make') (('person', 'second class'), 'mean') (('where people', 'disaster'), 'indicate') (('model how parameter', 'training scores'), 'be') (('we', '1'), 'concern') (('it', 'treatment'), 'lead') (('that', 'https beautiful youtu'), 'let') (('people', 'superior entity'), 'seem') (('that', 'prediction model'), 'end') (('learning validated that', 'users feedback'), 'be') (('you', 'customers'), 'Analyse') (('Also category', 'similar problem'), 'seem') (('kernel', 'four parts'), 'divide') (('embarkment point doesn t', 'survival rate'), 'tempt') (('It', 'significant categories'), 'show') (('what', 'better plot'), 'nothing') (('sink', 'exercise'), 'be') (('pdf', 'less data'), 'note') (('rain instances', 'Benfica https youtu'), 'know') (('we', 'parameters'), 'change') (('We', 'structure'), 'need') (('I', 'little bit conclusion'), 'delete') (('better data', 'more data'), 'add') (('who', 'survival alone lower rate'), 'be') (('Feature which', 'informative features'), 'engineering') (('maximum value', 'common practice'), 'follow') (('that', 'model'), 'build') (('pdf you', 'problem solving'), 'find') (('It', 'analysis'), 'expect') (('we', 'that'), 'apply') (('AI interesting projects', 'fortune'), 'find') (('aim', 'data exploratory analysis'), 'be') (('they', 'new perspective'), 'be') (('method', 'highest chi 2 score'), 'select') (('authors', 'steps practical four methodology'), 'propose') (('we', 'problem'), 'be') (('comprehensive list', 'https Heaton 2016 arxiv'), 'present') (('we', 'imputation method'), 'improve') (('s', 'analysis'), 'let') (('analysis', 'https youtu'), 'end') (('scikit', 'model'), 'scenario') (('when I', 'descriptive statistics'), 'be') (('we', 'them'), 'let') (('that', 'mythical creatures'), 'be') (('I', 'imputing data'), 'associate') (('only some', 'people'), 'have') (('steps', 'Extract Name'), 'be') (('we', 'everything'), 'be') (('when FamilySize', '3'), 'suggest') (('Titles', 'Master Miss Mr'), 'see') (('we', 'it'), 'exclude') (('Then we', 'performance'), 'instrument') (('Data preparation Box Cox transformationsBox Cox transformations', 'variables'), 'aim') (('You', 'blog http also pmarcelino'), 'like') (('we', 'data science where how problem'), 'see') (('how you', 'feelings'), 'let') (('We', 'hypothesis driven approach'), 'avoid') (('we', 'it'), 'test') (('Polynomial expansion', 'as well powers'), 'create') (('learning curves', 'score low value'), 'converge') (('One that', 'age'), 'region') (('they', 'optimally chosen variable'), 'be') (('1 which', 'overfitting'), 'use') (('who', 'one two people'), 'have') (('we', 'libraries'), 'start') (('Only then we', 'more complex algorithms'), 'move') (('the more you', 'intuition'), 'use') (('Two common solutions', 'more data'), 'reduce') (('hypothesis driven approach', 'last desert'), 'ok') (('as fast they', 'solution'), 'be') (('startup', 'extreme uncertainty'), 'belong') (('you', 'family'), 'say') (('variable', 'other passengers'), 'org') (('you', 'second class'), 'seem') (('children', 'survival higher rate'), 'show') (('You', '2003 www'), 'find') (('we', 'hypothesis'), 'limit') (('We', 'pipeline Build'), 'try') (('we', 'model'), 'mean') (('the', 'Learning curves'), 'allow') (('what', 'https really Titanic www'), 'com') (('which', 'data quality just side'), 'lead') (('html', 'machine learning models'), 'propose') (('Eric 2sHpnvP Ries', 'startup high tech companies'), 'tell') (('how we', 'data'), 'do') (('They', 'learning curves'), 'be') (('just passenger', 'alone family'), 'identify') (('we', 'first baseline approach'), 'be') (('Finally conclusions', 'data science journey'), 'draw') (('who', 'higher fare'), 'suggest') (('they', 'elders'), 'have') (('only approximately 25', 'third class'), 'survive') (('variable', 'missing values'), 'wouldn') (('Feature which', 'features'), 'selection') (('market', 'what'), 'reduce') (('how they', 'Pclass'), 'let') (('we', 'what'), 'mean') (('Feature selection', 'relevant information'), 'be') (('model', 'training already data'), 'be') (('model', 'training scores'), 'present') (('Doing', 'idea'), 'use') (('it', 'information'), 'make') (('mean value', 'other features'), 'apart') (('we', 'titles'), 'assign') (('techniques', 'data science problem'), 'help') (('min values', 'values'), 'seem') (('non random mechanism', 'missing data'), 'reduce') (('Feature engineeringFeature engineering', 'useful features'), 'be') (('Feature extraction', 'machine technological learning'), 'be') (('t', 'Survived'), 'let') (('htm', 'web'), 'give') (('s', 'subject'), 'now') (('how well you', 'work'), 'guide') (('you', 'data science problem'), 'address') (('we', 'silence'), 'evacuate') (('closed we', 'specifications'), 'be') (('model doesn', 'results'), 'discussion') (('people', 'other escaping'), 'be') (('Showing', 'investors'), 'be') (('SexSex', 'Human history'), 'be') (('variable dummy trap', 'www'), 'be') (('successful application', 'algorithms'), 'go') (('plot', 'three regions'), 'say') (('which', 'victories'), 'learn') (('we', 'better performance'), 'know') (('we', 'new categorization'), 'proceed') (('how it', 'it'), 'define') (('Lean How Entrepreneurs', 'https amzn'), 'Startup') (('who', 'team'), 'be') (('Data', 'machine learning model'), 'study') (('we', 'theoretical categorization'), 'make') (('you', 'them'), 'play') (('uk sciencetech women 1254788 Why children', 'Titanic Lusitania'), 'article') (('cigar just Freud', 'cigars'), 'be') (('as fast possible approach', 'pipeline'), 'be') (('users', 'needs'), 'be') (('more people', 'Southampton'), 's') (('Titanic', 'art cruiser'), 'be') (('s', 'chubby approach'), 'say') (('lean data', 'book'), 'setIn') (('Bar last title other plot', 'error bars'), 'seem') (('people', 'survival'), 'suggest') (('Feature selectionThe', 'feature next step selection'), 'be') (('it', 'Fare'), 'make') (('now we', 'imputation deeper better strategy'), 'decide') (('us', 'performance'), 'allow') (('survival rate', 'results'), 'drop') (('which', 'range'), 'use') (('It', 'hyperparameters'), 'count') (('you', 'free here www'), 'http') (('me', 'how it'), 'let') (('really sometimes cigar', 'aside what'), 'be') (('a', 'coin strategy https'), 'do') (('Here we', 'monitoring system'), 'apply') (('only what', 'hypothesis'), 'be') (('man', 'www'), 'be') (('which', 'customers'), 'be') (('we', 'startup lean world'), 'teach') (('Thus they', 'data transformation process'), 'avoid') (('so Titanic', 'women'), 'belong') (('we', 'more impact'), 'be') (('particular poor performance', 'underfitting overfitting'), 'monitor') (('t', 'machine learning model'), 'shouldn') (('We', 'feature selection'), 'use') (('startup lean approach', 'Build Measure Learn process'), 'be') (('I', 'tickets'), 'keep') (('FareThe same logic', 'survival Fare higher fares higher rate'), 'work') (('most important', 'overfitting'), 'say') (('which', 'model'), 'introduce') (('we', 'modelling process'), 'make') (('it', 'imputation different method'), 'make') (('we', 'name'), 'look') (('This', 'missing data'), 'be') (('about 60', 'first class'), 'survive') (('it', 'everyone'), 'rise') (('we', 'bar instead plot'), 'use') (('hypothesis', 'support'), 'find') (('movie when Titanic', 'pmarcelino data com comprehensive python'), 'exploration') (('Therefore best approaches', 'model e.'), 'be') (('that', 'one billion dollars'), 'use') (('we', 'machine learning easily model'), 'be') (('you', 'data exploratory analysis'), 'be') (('modelThe Minimum Viable Product Minimum viable MVP', 'key lean startup'), 'be') (('they', 'problem'), 'feature') (('you', 'books https amzn'), 'find') (('everything', 'sex'), 'realize') (('one size', 'solution'), 'find') (('However you', 'the higher survival'), 'chance') (('Mr', 'other title'), 'suggest') (('it', 'also missing data'), 'be') (('it', 'survival'), 'be') (('data points', 'mean'), 'suggest') (('we', 'variable Name'), 'do') (('Accordingly we', 'target variable'), 'start') (('data analysisExploratory data Exploratory analysis', 'data analysis process'), 'mention') (('people', 'Q'), 'seem') (('only fourth step', 'iteration'), 'miss') (('it', 'prediction purposes'), 'be') (('more they', 'ship'), 'play') (('which', 'idea'), 'project') (('you', 'feature engineering several that'), 'be') (('that', 'plot e.'), 'be') (('we', 'features'), 'perform') (('First Cabin', 'too many missing values'), 'thought') (('it', 'Kaggle https www'), 'be') (('data', 'clever techniques'), 'use') (('that', 'classification'), 'be') (('more people', 'survival'), 'be') (('bar already plot', 'tendency error central bars'), 'show') (('especially you', 'process'), 's') (('we', 'it'), 'let') (('quickly complete data', 'imputed values'), 'allow') (('predictions', 'submission file'), 'Analyse') (('that', 'best one'), 'figure') (('Create data analysis Plot', 'just case'), 'put') (('This', 'outliers'), 'give') (('us', 'multicollinearity'), 'allow') (('approach selects', 'feature'), 'feature') (('We', 'survival higher rate'), 'have') (('Now it', 'highly accurate model'), 's') (('Then we', 'data analysis exploratory tools'), 'test') (('First class', 'survival higher rate'), 'have') (('that', 'time'), 'have') (('cola', 'always well ice'), 'be') (('two main issues', 'sub following sections'), 'address') (('PolynomialsOne standard way', 'polynomials'), 'be') (('it', 'just children'), 'seem') (('estimates', 'model'), 'Multicollinearity') (('one', 'www'), 'be') (('data', 'analysis'), 'introduce') (('This', 'just unique passenger'), 'be') (('Names', 'especially when title'), 'be') (('current model', 'pipeline'), 'work') (('I', 'proudly Titanic'), 'be') (('PclassOur hypothesis', 'the higher the higher survival'), 'be') (('Finally we', 'new title'), 'group') (('13 years old boy', 'http only age 12 bit'), 'know') (('we', 'model'), 'be') (('it', 'it'), 'be') (('it', 'validation set'), 'mean') (('Accordingly model', 'unseen data'), 'be') (('we', 'contrast'), 'say') (('s', 'bar plot'), 'let') (('documentation http scikit', 'model only that'), 'note') (('Later we', 'data'), 'try') (('standard deviation', 'variation'), 'show') (('it', 'data analysis'), 'note') (('data when value', 'one variables'), 'occur') (('We', 'this'), 'proceed') (('engineering masterpiece', 'starting also point'), 'need') (('Titanic', 'discussion still most diverse areas'), 'remain') (('earlier that', 'first activity'), 'be') (('it', 'given minimum value'), 'transform') (('html you', 'bars interpretation'), 'find') (('we', 'analysis'), 'be') (('practical advice', 'tools'), 'be') (('as far we', '10 1'), 'discussion') (('that', 'obviously wrong'), 's') (('as fast you', 'it'), 'think') (('we', 'significant mean value'), 'be') (('hypothesis driven approach', 'hypothesis'), 'consist') (('don t', 'observations'), 'delete') (('parameter', 'model'), 'allow') (('practical methodology', 'Goodfellow et al'), 'note') (('Finally we', 'performance Learn'), 'make') (('we', 'data set'), 'generate') (('Dogma We', 'variable'), 'need') (('that', 'Master titles'), 'be') (('SibSp', 'Family feature'), 'group') (('model', 'it'), 'be') (('good introduction', 'Hair'), 'find') (('One way', 'known relationships'), 'be') (('Initially we', 'data exploratory analysis'), 'invest') "}
{"name": "gans form scratch to advanced ", "full_name": " h2 Generative Adversarial Networks h3 1 What is a GAN h3 2 MNIST using GAN in TensorFlow h4 build a generator and discriminator h3 3 Deep convolutional GAN DCGAN h3 5 GAN architectures h4 a SRGAN Super Resolution GANs h3 What is a Perceptual Loss Function h3 How does a Perceptual Loss Function work h3 b CycleGAN h3 CycleGAN in TensorFlow 2 0 h4 Load dataset h4 Build our Generator h3 c InfoGAN ", "stargazers_count": 0, "forks_count": 0, "description": "The idea is shown as follows To train the combined GANs the authors added besides the conventional GANadversarial loss a forward cycle consistency loss left figure and a backward cycleconsistency loss right figure. We are following the samearchitecture of discriminator and discriminator as in the paper by Zhu et al. The final output of the convolutional layer is flattened and feeds a one neuronclassifier layer. This is done sothat finally we get an output of size 28 28 the standard size of MNIST handwrittendigits. Theupsampled image is passed to a convolutional layer. The following figure shows the architecture of the InfoGAN The concatenated vector Z c is fed to the generator. 02 Plot the loss from each batch plt. Before going into the details of the DCGAN architecture and its capabilities let us point out the major changes that were introduced in the paper The network consisted of all convolutional layers. In the GAN we ensure that the discriminator weights are fixed by setting the trainableargument to FalseThe trick to train the two is that we first train the discriminator separately weuse binary cross entropy loss for the discriminator. The CycleGAN s ability to perform image translation in the absence of training pairs is what makes it unique. Eachdiscriminator is trained to distinguish between real images and synthesized images. The process isrepeated iteratively for a few thousand epochs. The pooling layers were replaced by strided convolutions in the discriminator and transposed convolutions in the generator. The function is used to compare high level differences like content and style discrepancies between images. A perceptual loss function is very similar to the per pixel loss function as both are used for training feed forward neural networks for image transformation tasks. 0Here we will use a paired datasets for CycleGANs from TensorFlow s Dataset API dataset name is summer2winter_yosemite which contains imagesof Yosemite USA in summer Dataset A and winter Dataset B Load datasetSet hyperparameters normalize images in the range 1 1 for better performanceapply normalize to our train and test datasets and create a data generator thatwill provide images for training in batchesthe argument num_parallel_calls allows one to take benefitfrom multiple CPU cores in the system one should set its value to the numberof CPU cores in your systemlet us see an example of imagesTo construct the generator and discriminator we will require three sub modules theupsampling layer which will take in an image and perform a transpose convolutionoperation a downsampling layer which will perform the convention convolutionaloperation and a residual layer so that we can have a sufficiently deep model. Generative Adversarial NetworksThis notebook is consists of code and some explanation from this awsome book Deep Learning with TensorFlow 2 and Keras Second Edition link https www. GAN architectures a. The final output is obtained froma pure convolutional layer with 3 filters and tan hyperbolic activation yieldingan image of size 28 28 1 5. SRGAN Super Resolution GANs GAN is trained in such a way that it can generate a photorealistic high resolution image when given a low resolution image. Thefirst layer is a dense layer that takes the noise of 100 dimensions as an input. Q c X is also a neural network. The generator is built by adding the layers sequentially. The goal of training the discriminator D Y is to maximize D Y for every imagefrom the true data distribution and to minimize D Y for every image not fromthe true data distribution. The GAN is trained such that it maximizesthe mutual information between the latent code c and the generated image G Z c. Thetraining follows in the same manner as before that is we first train the discriminatoron a mini batch then freeze the discriminator and train the generator. So G and D play opposite games hence the nameadversarial training. The InfoGAN uses theconcepts from information theory such that the noise term is transformed into latentcode that provides predictable and systematic control over the output. We want the imagesgenerated by the generator to be detected as real by the discriminator so we usea random vector noise as input to the generator this generates a fake imageand then trains the GAN such that the discriminator perceives the image as real 3. png epoch get number of cores in your machine Downsampling through the model print skips Upsampling and establishing the skip connections bs 30 30 1 to use tf graph Translate images back to original domain. Please remember thatin the paper the test network was trained for 200 epochs so our results will not bethat good c. In general a value close to 1 denotes real while a value close to 0 denotes forgery. The neural network model is trained on images where the perceptual loss function is optimized based upon high level features extracted from already trained networks. Conventionally people set it to 100For ourimplementation we tried a value of 10. In the following diagram you can see the discriminatorThe generator and the discriminator are combined together to form the DCGAN. We next add another Dense layer with512 hidden neurons followed by the third hidden layer with 1024 neurons andfinally the output layer with 784 neuronswe build a discriminator. The generator in an InfoGAN takes two inputs the latent space Z and a latent code c thus the output of the generator is G Z c. The important new idea isto backpropagate through both the discriminator and the generator to adjust thegenerator s parameters in such a way that the generator can learn how to fool thediscriminator more often. png epoch Create a wall of generated MNIST images plt. The generative model continues to improve its forgery capabilities andthe discriminative model continues to improve its forgery recognition capabilities. savefig images gan_loss_epoch_ d. This vector is thenupsampled using TensorFlow Keras UpSampling2D layer. CycleGAN A CycleGAN performs the image translation that is transfers an image given in one domain sceneryfor example to another domain in the absence of training examples. shape generatedImages Labels for generated and real data One sided label smoothing Train discriminator Train generator we are saving the losses for each epoch and generating images after every 20 epochs Plot losses from every epoch input shape Build and compile the discriminator Build the generator The generator takes noise as input and generates imgs For the combined model we will only train the generator The discriminator takes generated images as input and determines validity The combined model stacked generator and discriminator Trains the generator to fool the discriminator load the data Rescale 1 to 1 Adversarial ground truths Train Discriminator Select a random half of images Sample noise and generate a batch of new images Train the discriminator real classified as ones and generated as zeros Train Generator Train the generator wants discriminator to mistake images as real Plot the progress If at save interval save generated image samples Rescale images 0 1 fig. Note that we train G and D in an alternating manner whereeach one of their objectives is expressed as a loss function optimized via a gradientdescent. The loss this time is also binary cross entropyperform the training. MNIST using GAN in TensorFlowLet us build a simple GAN capable of generating handwritten digitswill use a simple multi layered perceptron MLP and we will feed it an imageas a flat vector of size 784 build a generator and discriminatorThe purpose of thegenerator is to take in a noisy input and generate an image similar to the trainingdataset. using the preceding defined generator and discriminator we construct the 2 CycleGANs We next define the loss and optimizers create placeholders for the labels of real and fake images define the function that trains the generator and discriminator in a batch a pair of images at a time. This is in contrast to a per pixel loss function which sums all the absolute errors between pixels. The following diagram shows the generatorarchitecture The discriminator network takes in the images either generated by the generatoror from the real dataset and the images undergo convolution followed by batchnormalization. Later we freeze the weights ofthe discriminator and train the combined GAN this results in the training of thegenerator. The layer has no weights so it is computationally cheap. The discriminator network usually a standard convolutional neural network tries to classify if an input image is real or generated. shape imageBatch np. The batch normalized output thenundergoes ReLU activation in all the intermediate layers. keras Helper libraries Set the seed for reproducible result normalize the input values such that each pixel has a value in range 1 1 Optimizer input dim. We repeat the structure that is upsampling convolution batch normalization ReLUIn the followinggenerator we have two such structures the first with 128 filters and the secondwith 64 filters in the convolution operation. The generator of thesecond GAN performs an inverse mapping F Y X resulting in X F Y. This ensures that if an image X is given as input thenafter the two translations F G X X the obtained image is the same X similarly thebackward cycle consistency loss ensures that G F Y Y. At the end the generator will learn how to produce imagesthat are indistinguishable from the real ones 2. Please note that this layersimply scales up the image by doubling rows and columns. The perceptualloss is defined as the weighted sum of content loss and adversarial loss What is a Perceptual Loss Function https deepai. Deep convolutional GAN DCGAN The main idea in the design was using convolutional layerswithout the use of pooling layers or the end classifier layers. savefig images gan_generated_image_epoch_ d. Combined with the generator it works to form a mapping between random noise Zand its latent code c_hat. org machine learning glossary and terms perceptual loss functionPerceptual loss functions are used when comparing two different images that look similar like the same photo but shifted by one pixel. savefig images dcgan_mnist_ d. D Y takes an input Y for instance an image andexpresses a vote to judge how real the input is. This is achieved by adding aregularization term to the objective function of the conventional GANThe term Vg D G is the loss function of the conventional GAN and the second termis the regularization term where \u03bb is a constant. The basic idea of DCGANs is same as the vanilla GAN we have a generator thattakes in noise of 100 dimensions the noise is projected and reshaped and then ispassed through convolutional layers. The size of the noisy input is decided by the variable randomDim youcan initialize it to any integral value. The perceptual loss function is a more commonly used component as it often provides more accurate results regarding style transfer. Generator kernel_initializer initializers. The SRGAN architectureconsists of three neural networks a very deep generator network which usesResidual modules a discriminator network and a pretrained VGG 16 network. Notice now that the discriminator takes in theimages either from the training set or images generated by generator thus its inputsize is 784. The fully connected classifying layers after the convolutions are removed. G Z takes an input from randomnoise Z and it trains itself to fool D into thinking that whatever G Z produces is real. CycleGAN in TensorFlow 2. This input is fed to a Dense layer with256 neurons with LeakyReLU activation. Besides perceptualloss the authors further added content loss and an adversarial loss so that imagesgenerated look more natural and the finer details more artistic. This convolutional layer learnsto fill in the details in the upsampled imageThe output of convolution is passedto batch normalization for better gradient flow. InfoGANInfoGAN provides control over various attributes of the images generated. We first see thecode for the generator. The generator G Z is the one that makes the forgery and the discriminator D Y is the one that can judge how realistic the reproductions are based on its observations ofauthentic pieces of art and copies. Theselayers are defined in the functions downsample upsample and class basedon the TensorFlow Keras Model API ResnetIdentityBlock Build our GeneratorNow define the discriminator too. SRGANs use the perceptual loss function. To achieve image translation the authors used a very simple and yet effective procedure. At each convolution step the images get downsampled using strides. To help with the gradient flow batch normalization is done after every convolutional layer. The vector is reshaped to a tensor of size 7 7 128. RandomNormal stddev 0. The100 dimensional input is expanded to a flat vector of size 128 7 7. Its value was set to 1 in the paper and I c G Z c is the mutual information between the latent code c and the generator TensorFlow and tf. com gb data deep learning with tensorflow 2 0 and keras second edition 1. How does a Perceptual Loss Function work In short the perceptual loss function works by summing all the squared errors between all the pixels and taking the mean. The convolutionalstrides and transposed convolutions are employed for the downsampling andupsampling of images. For each epoch we take a sample of random noisefirst feed it to the generator and the generator produces a fake image. What is a GAN GANs train two neural nets simultaneously. The two discriminators and the two generators are trainedvia this function with the help of the tape gradient define checkpoints to save the model weightsnow combine it all and train the network for 50 epochs. The difference in the feature mapactivations in high layers of a VGG network between the network output part andthe high resolution part comprises the perceptual loss function. The authors found that we get morestable results with the Adam optimizer and a learning rate of 0. They made use of two GANs the generator of each GAN performing the image translation from one domain to anotherTo elaborate let us say the input is X then the generator of the first GAN performsa mapping G X Y thus its output would be Y G X. It aims to estimate c given X. 2016 argues that perceptual loss functions are not only more accurate in generating high quality images but also do so as much as three times faster when optimized. png epoch Get a random set of input noise and images Generate fake MNIST images print np. The Upsampling2D layer will now double the rows and columns of the 7 7 128 rows columns channels image yielding an output of size 14 14 128. The output of the discriminator however is a single bit with 0 signifyinga fake image generated by generator and 1 signifying that the image is from thetraining datasetcombine the generator and discriminator together to form a GAN. CGAN for MNIST digitsLet us now build a DCGAN for generating handwritten digits. We combinethe generated fake images and the actual training images in a batch with theirspecific labels and use them to train the discriminator first on the given batchin the same for loop we will train the generator. ", "id": "muhammedfathi/gans-form-scratch-to-advanced", "size": "13925", "language": "python", "html_url": "https://www.kaggle.com/code/muhammedfathi/gans-form-scratch-to-advanced", "git_url": "https://www.kaggle.com/code/muhammedfathi/gans-form-scratch-to-advanced", "script": "ZeroPadding2D Activation Reshape IPython.display tensorflow.keras.datasets tensorflow.keras.layers ResnetIdentityBlock(Model) discriminator_loss tensorflow.keras.losses tensorflow.keras.models Image initializers numpy Adam Dropout train BatchNormalization Dense LeakyReLU mean_absolute_error plotLoss Generator build_generator upsample tensorflow build_discriminator DCGAN() matplotlib.pyplot tensorflow_datasets Sequential Conv2D downsample call Model Discriminator UpSampling2D Input train_batch mean_squared_error tensorflow.keras saveGeneratedImages mnist __init__ normalize tensorflow.keras.optimizers Flatten save_imgs ", "entities": "(('network', 'convolutional layers'), 'let') (('that', 'output'), 'use') (('images', 'strides'), 'downsample') (('Later we', 'thegenerator'), 'freeze') (('it', 'latent code'), 'work') (('vector', 'size'), 'reshape') (('Eachdiscriminator', 'real images'), 'train') (('Perceptual Loss Function loss How short perceptual function', 'mean'), 'work') (('how reproductions', 'ofauthentic art'), 'be') (('we', 'convolution secondwith 64 operation'), 'repeat') (('InfoGANInfoGAN', 'images'), 'provide') (('fill', 'passedto batch better gradient flow'), 'be') (('vector Z concatenated c', 'generator'), 'show') (('generator', 'how thediscriminator'), 'backpropagate') (('vector', 'TensorFlow Keras layer'), 'thenupsample') (('png epoch', 'MNIST images generated plt'), 'create') (('it', 'resolution when low image'), 'SRGAN') (('Upsampling', 'back original domain'), 'get') (('adversarial What', 'content loss'), 'define') (('pooling layers', 'generator'), 'replace') (('thus output', 'then first GAN performsa mapping'), 'make') (('dimensional input', 'size'), 'expand') (('such it', 'latent code maximizesthe mutual c'), 'train') (('both', 'image transformation tasks'), 'be') (('batch normalized output', 'ReLU intermediate layers'), 'thenundergoe') (('this', 'rows'), 'note') (('So G', 'opposite games'), 'play') (('png epoch', 'np'), 'get') (('details', 'content further loss'), 'add') (('results', 'good c.'), 'remember') (('input', 'with256 LeakyReLU activation'), 'feed') (('purpose', 'similar trainingdataset'), 'build') (('more commonly used it', 'style transfer'), 'be') (('that', 'one pixel'), 'use') (('loss where perceptual function', 'already trained networks'), 'train') (('authors', 'cycle consistency forward left figure'), 'show') (('separately binary', 'discriminator'), 'ensure') (('which', 'pixels'), 'be') (('it', 'weights'), 'have') (('noise', 'then convolutional layers'), 'be') (('mini batch', 'generator'), 'follow') (('discriminator', 'real 3'), 'want') (('we', 'learning 0'), 'find') (('Upsampling2D layer', 'size'), 'double') (('final output', 'activation yieldingan tan hyperbolic size'), 'obtain') (('convolutionalstrides', 'images'), 'employ') (('gb data', 'deep tensorflow'), 'com') (('images', 'batchnormalization'), 'show') (('loss', 'time also binary training'), 'be') (('discriminatorThe generator', 'together DCGAN'), 'see') (('we', 'generator'), 'generate') (('discriminator', 'image samples Rescale generated images'), 'side') (('how input', 'vote'), 'take') (('Generative Adversarial NetworksThis notebook', 'Deep TensorFlow'), 'be') (('image', 'together GAN'), 'be') (('We', 'discriminator'), 'add') (('code latent thus output', 'generator'), 'take') (('dense that', 'input'), 'be') (('We', 'Zhu et al'), 'follow') (('thus inputsize', 'generator'), 'notice') (('generator', 'layers'), 'build') (('residual we', 'sufficiently deep model'), 'be') (('GAN Deep convolutional main idea', 'pooling layers'), 'DCGAN') (('finally we', 'MNIST handwrittendigits'), 'do') (('whereeach one', 'gradientdescent'), 'note') (('produces', 'whatever'), 'take') (('thebackward cycle consistency same X similarly loss', 'two translations'), 'ensure') (('we', '10'), 'set') (('generator very deep which', 'discriminator usesResidual network'), 'network') (('process', 'iteratively a few thousand epochs'), 'isrepeate') (('us', 'handwritten digits'), 'build') (('Theupsampled image', 'convolutional layer'), 'pass') (('two function', '50 epochs'), 'be') (('difference', 'resolution loss andthe high perceptual function'), 'comprise') (('GAN GANs', 'two neural nets'), 'be') (('loss perceptual functions', 'quality only more high images'), 'argue') (('how imagesthat', 'real ones'), 'learn') (('value', 'close to 1 denotes'), 'real') (('downsample TensorFlow Keras Model ResnetIdentityBlock Build', 'discriminator'), 'define') (('function', 'images'), 'use') (('youcan', 'integral value'), 'decide') (('where \u03bb', 'regularization term'), 'achieve') (('goal', 'data true distribution'), 'be') (('andthe discriminative model', 'forgery recognition capabilities'), 'continue') (('generator', 'fake image'), 'take') (('that', 'training examples'), 'cyclegan') (('mapping F Y inverse X', 'X F Y.'), 'perform') (('that', 'time'), 'construct') (('authors', 'very simple yet procedure'), 'use') (('final output', 'one neuronclassifier layer'), 'flatten') (('such pixel', 'range'), 'librarie') (('help', 'convolutional layer'), 'do') (('it', 'training pairs'), 'be') (('I', 'c G Z latent code mutual c'), 'set') "}
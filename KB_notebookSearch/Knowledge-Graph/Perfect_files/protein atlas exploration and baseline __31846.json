{"name": "protein atlas exploration and baseline ", "full_name": " h1 Welcome to the Human Protein Atlas Competition h2 Latest important updates h2 Planned updates h3 Our goal h2 Table of contents h1 Preparation h2 Kernel settings h2 Improved model settings h2 Loading packages and data h2 Extract test names for submission h2 Helper code h2 Extract train targets h1 Exploratory data analysis h2 Which proteins occur most often in train images h3 Take Away h2 How many targets are most common h3 Take away h2 Which targets are correlated h3 Take away h2 How are special and seldom targets grouped h3 Lysosomes and endosomes h3 Rods and rings h3 Peroxisomes h3 Microtubule ends h3 Nuclear speckles h3 Take away h2 How do the images look like h3 Peek into the directory h2 How do images of specific targets look like h3 Take Away h1 Building a baseline model h3 K Fold Cross Validation h3 Collecting ideas h3 Shared Parameter class h3 Image Preprocessor h4 Looking at a preprocessed example image h3 Data Generator h3 CNN Baseline model using keras h3 Training the baseline on the first cv fold h3 What do the results tell us h3 Take Away h3 To which targets do the high and small predicted probabilities belong to h3 Take Away h1 One Step Improvement Model h3 The target wish list h3 Plug and Play h3 Add scoring metrics h3 Track losses and scores h3 More epochs h3 What does the loss tell us h3 Does our model try to classify h3 Make a test submission h3 Choosing the decision thresholds h2 How can we tackle gradient jiggles h3 Dropout Layer h2 Where to go next ", "stargazers_count": 0, "forks_count": 0, "description": "You can see that in my baseline model I m already using dropout. who knows Consequently it could be nice to introduce some further statistical quantities like min as well as max and the standard deviation. Due to this confusion we will make less accurate predictions on the minor classes. This means that we already start learning without passing the whole dataset. and sometimes they could lead to the opposite. For example we can see that rods and rings have something to do with the nucleus whereas peroxisomes may be located in the nucleus as well as in the cytosol. In my case I chose a batch_size of 200. If we take a look at the true target label count we can see that most of our targets are filled with zero. We compute the gradients with respect to the weights after processing each batch this way partial_ w_ i j E sum_ m 1 M partial_ w_ i j E_ m Looking at the sum we can see one disadvantage. Perhaps we can expand its functionality during improvement of the baseline model. Sometimes the whole image is covered with cells and sometimes there are only a few. read_csv Any results you write to the current directory are saved as output. The images differ in their intensities and the target proteins are not always located the same way. input_shape self. If we like to detect same targets out of different bright images this will cause problems as we expect them to be in a similar value range. Let s turn the Ids given in the validation labels as index as well Ok great. Hence changing the weights with batches of imbalanced classes can lead to jiggles. Ok currently we haven t made any predictions and except from Id all entries are filled with 0. Even for the most common target nucleoplasm there are only 40 of samples that show it and 60 not. For this purpose we re going to extend the class we have already written. edu shervine blog keras how to generate data on the fly Thank you CNN Baseline model using keras Training the baseline on the first cv foldFirst of all let s choose one partition of train and validation data Next we have to setup our data generators We need two during training one for the train images and one for the validation images. The mean is not robust towards outliers and consequently not very informative to understand the distribution of f1 scores for each target class. Imagine we would try to distinguish dogs from cats. How does our model update gradients After each batch After one epoch If we take a look at simple feedforward networks that are close related to CNNs add gradient descent we can see that learning means to compute the derivatives of the loss with respect to the weights over all samples w_ i j new w_ i j old eta cdot partial_ w_ i j E With a set of independent observation samples we can obtain the gradients this way partial_ w_ i j E sum_ n 1 N partial_ w_ i j E_ n We are computing the change of the loss with respect to a change in the weights for each sample one after another. Encoding of binary target labels out of the given multilabel list per image 2. During call of predict generator its basepath of the images is changed from train to testpath What do the results tell us Let s have a look at predicted probabilites per target class Even though this accuracy looks nice it s an illusion We are far away from a good model. In contrast small components like the lipid droplets peroxisomes endosomes lysosomes microtubule ends rods and rings are very seldom in our train data. This splitter is now a generator. Their label values are one whereas all others are zero. The latter I like to do in a plug and play style Setting the flag improve True adds a change to our model whereas improve False uses the old concept we already used in the baseline. Image PreprocessorLet s write a simple image preprocessor that handles for example the rescaling of the images. This would be great at it indicates that the model starts solving the problem of binary classification for this target No it does not seem that our model starts to separate well. For the test submission data we need to create a new instance of an ImagePreprocessor with same model parameters. If we are not able to predict them we can go home and stay in bed. After that we continue by computing the gradients with the next batch. Take away We can see that many targets only have very slight correlations. Exploratory data anylsis explore Which proteins occur most often How many targets are most common Which targets are correlated How are special and seldom targets grouped How do the images look like How do images of specific targets look like 3. values This method just avoids the direct pass to y i the targets per image in a batch. Visual analysis of target protein distribution in the train set 3. Take a look at the loss values for train and validation data the notebook saved after learning It does not contain losses that are obtained after computing each batch. add Conv2D 16 kernel_size 3 3 activation relu input_shape self. As far as I know this means one epoch. Bulding a baseline model baseline Define the model How well does our model perform 4. use_dropout self. Especially in the red channel we can see morphological differences. Consequently if we choose n_repeats 2 we will end up with 6 Folds in total 3 Folds for the first cross validation and again 3 Folds for the repeated cross validation. How many targets are most common Take away Most train images only have 1 or two target labels. Explore some further concepts like batch normalization4. Hence beside image outliers the target distribution itself influences the learning as well. As our initial weights are not sufficent to solve the classification task we need many such update steps. drop Id Target number_of_targets axis 1. Choosing the decision thresholdsFor this purpose we need the validation data again. This can be bad especially in the case of outlier images that are not representative to explain the pattern in the data. With a batch_size of 128 and number of epochs 10 we obtain these losses Dropout LayerI often read that dropout helps to avoid overfitting but for me it seems that there is one more useful advantage Imagine the cat problem above Given a batch full of cats we only compute gradients for making the predictions of cats better. Our goal Predict various protein structures in cellular images there are 28 different target proteins multiple proteins can be present in one image multilabel classification 27 different cell types of highly different morphology Table of contents1. Let s create an instance of this preprocessor and pass it to the data generator. Luckily the predict generator runs through the ids given in partition validation one after another and we can easily add them as index. Some ideas on how to proceed. Due to performance reasons I will only use one cv fold to explore results and one repeat Collecting ideasNext we need to setup a simple baseline model. I m going to use a small class that hold parameters that are used or shared between the data loader the image preprocessor and the baseline model. The target wish listTo introduce a target wishlist that we can change whenever we want we need to improve the data generator. Now let s transform our prediction back into the target column How can we tackle gradient jiggles Let s try to dive deeper into the problem. Then the jump was so big that we escaped from nice regions that lead to a local minimum of loss. If you like to dive deeper into target correlations you may like to take a look at my kernel notebook about target clustering. But what if the dataset it too large to wait a long time just for one of these steps Perhaps it would be sufficient and already good to use only some M N of the N samples to compute the gradients partial_ w_ i j E partial_ w_ i j E sum_ m 1 M partial_ w_ i j E_ m This way we could use only a batch of samples compute the gradients and perform the update of weights. But before turning happy and starting to use dropout frequently we should think about its downside Dropping neruons during training and learning with a thinned kind of networks means that we freeze learning each step a bit. Well there is one problem with the competition score that we can use to measure the performance of our model The f1 mean. Hence before playing with further strategies we should make a step backwards again. coming soon Latest important updatesBeside building competition code I m still updating this kernel with ideas and code. General better reading flow. But we can try to find out by improving our model adding new features and playing with different parameter settings. This can cause jiggles as well. Helper code Extract train targetsOk great now we can directly work with binary target values. It could be advantegous to write a small class that does simple preprocessing per image. This becomes more robust with more samples per batch. org papers volume15 srivastava14a srivastava14a. One question on my mind draws circles What happened to the loss after each batch during one epoch Does it converge Has our model started to learn or does nothing happen Currently we obtain a history after calling fit_generator but this history only contains the loss of train and validation data after one epoch. All probabilities are close to zero and there are only a few with targets where our model predicted a protein structure with higher than 10. Some ideas on validation. But even though our next goal should be to find out what to tune in such a way that our model really starts learning One Step Improvement Model Ok again let s go one step back and choose the most common target proteins that are present in our data nucleoplasm cytosol and plasma membrane. com guglielmocamporese macro f1 score keras. We should attach more importance to true positives. com allunia in depth protein correlations How are special and seldom targets grouped Lysosomes and endosomesLet s start with these high correlated features Rods and rings Peroxisomes Microtubule ends Nuclear speckles Take away We can see that even with very seldom targets we find some kind of grouping with other targets that reveal where the protein structure seems to be located. Consequently we find a positive correlation between these targets. After doing so I have used each sample once and this means the whole dataset was passed through gradient descent. The train data is splitted into k chunks and each chunk is used once for testing the prediction performance whereas the others are used for training. Tune hyperparameters5. The other images are like references showing microtubules nucleus and endoplasmatic reticulum. The first image you can get by the loader shows endosomes that are spread all over the cells and in the second and third you can find endosomes and lysosomes more concetrated around the nucleus. And in this process microtubules and thier ends are active and participate as well. In this example you can see a maximum amount of 3 images at one iteration. Welcome to the Human Protein Atlas Competition I started this kernel notebook to explore the data and build a simple baseline model to play with. inside the for loop over temp list ids image identifiers of the batch. This choice was somehow arbitrarily as I used an example network that can be found to classify mnist digits as a starting point. my_metrics my_metrics self. But even with that score we should be careful We have 28 different classes that are very different in their frequency of being present. Perhaps we have prevented the success of a learning step given one batch and improved learning given another batch. In addition we can now say that we want to shuffle the samples before doing weight updates after each batch again in the next epoch. If you don t like to wait for compution you can set fit_baseline and or fit_improved_baseline of the KernelSettings class to False This way the prediction probabilities of the corresponding model are loaded as csv from added data source. This way our model sees a different set computes some other gradients and hence the loss minimziation could be more robust. To make things easier I added a small method to the DataGenerator we already had def get_targets_per_image self identifier return self. To make it easier to understand which improvements you currently use let s set them here in front of the analysis Loading packages and dataHow many samples do we have Extract test names for submissionThere are 11702 test images we are asked to make predictions. Hence if you call splitters split method it will yield one Fold of the repeated K Folds. For this purpose I highly follow a descprition of a post in the www for which you will find the link below. That s not nice Sometimes these jumps could even lead to exploding losses as well. For example it could be occupied with cats only. This is great as this would mean that some weight that could be good for predicting dogs will not change after we process a batch with cats only. In addition we can see that some images have higher values whereas others are sallow with overall low values. At least the flat tail gives hope that learning could be in progress. And this can be done to the detriment of the dogs as both classes share weights. We don t acutally now how informative they are and in our current state they would blow up our neural network with a huge amount of network weigths that we might not need. Shared Parameter classOk now we will create an instance of this class and pass it to the DataGenerator the BaseLineModel and the ImagePreprocessor. It looks like if the cells are of different types. Nonetheless one question remains Has our model started learning Can we see a separating force that tries to split zero and one predictions Does our model try to classify If this is the case and our model starts learning we should see more bimodal distributions of the predicted probability per target label Jeahy This looks far better than the distributions we obtained with the baseline model Thus increasing epochs while decreasing the batch size helped our model as we made more learning steps. This way we can see the worst and gain some insights how the scores are spread over the classes. This is just an assumption but perhaps one could use the red channel information to reveal cell types. Clicking this code tab again with other targets you can observe that the images can contain different cell densities. This way we can see the point of change when train loss is decreasing and validation loss is increasing. One step we try to improve nucleoplasmn and the next perhaps cytosol but with a downgrade of the nucleoplasmn predictions and the next steps it could be the other way round. And the randomness of frosty the dropout snowman can turn to a problem difficult to graps Which neurons should be dropped are there some for which dropping is good and some for which it is bad After which layer in our network does it make sense to use it Perhaps it would have been better to use some neurons that were dropped a random dropout session during one batch learning step. Taking a closer look at the base generator you can see that there is just one line code in def data_generation self list_IDs_temp we have to change namely the part with y i. Taking a look at this paper http www. In our case this means that each learning step some weights will be untouched and not used to compute gradients. With a total number of samples of around 20000 in my training set this means that I have already done 200 weight updates. A simple image generator that yields images of a target protein wishlist. This need not be very complex or very good. Computing the gradient with batches is a stochastic process Depending on the batch samples the gradients may sometimes lead to some good update directions in weight space that points to some minimum of loss. Here we know for each wishlist prediction the true target value. The mode is close to the fraction of one hot counts over all samples. As our targets show relationships seemed to be grouped somehow the performance per test chunk probably highly depends on the target distribution per test chunk. To make it easier for you to checkout new content here is an update summary of the latest changes Started to add a table of contents. With this knowledge we could start setting thresholds manually by comparing the probability distributions for hot and zero representations for each target in the wishlist. More than 3 targets are very seldom Which targets are correlated Let s see if we find some correlations between our targets. As our test data is 38 of size compared to the train set it makes sense to use 3 Fold cross validation where the test set is 33 of size compared to the train set. There is no deviation no difference between them. add MaxPooling2D pool_size 2 2 if self. To reduce this effect we will repeat the K Fold several times and look at scoing distributions in the end. add Flatten self. It suffers under overfitting and looses it s ability to make good predictions on the validation images. we can see a lot of noise after 100 batches during loss decrease. More epochs Improve We can already see that we might need more than 1 epoch to learn the pattern in the data. Now let s consider a dropout layer It randomly selects a given percentage of input neurons and drops them during the current training step. This way we may already see that some proteins often come together. Consequently accuracy is not the right score here to measure your performance and validation strategy should be very fine. Improved model settingsWithin this kernel you can play with different improvement steps of the baseline model in a plug and play style. Looking into the data description of this competition we can find that Each image is actually splitted into 4 different image files. This way we can easily change something of this phase without producing chaos in the model itself or during data loading. A baseline model build with keras that is supported by A modelparameter class that holds all parameters that are necessary to build the model to load the data and to preprocess the images. Building a baseline model K Fold Cross ValidationLet s see how many test and train samples we have in this competition To understand the performance of our model we will use k fold cross validation. Consequently our high accuracy belongs to the high correct prediction of the absence of target proteins. There was a tradeoff we made. Make a test submissionOk now as our model started learning let s make a submission for the leaderboard. As 1 is the best we can only achive 0. An image in the batch that causes very high positive or negative gradients for the weight w_ i j have more impact on the overall gradient than images with low absolute values. We gained more learning speed but payed with a reduced gradient quality. The information flow through the network is somehow a blackbox for us and this randomness of thinned network learning makes it more difficult to understand what s going on. This makes sense as both are participants for cellular division. These 4 files correspond to 4 different filter a green filter for the target protein structure of interest blue landmark filter for the nucleus red landmark filter for microtubules yellow landmark filter for the endoplasmatic reticulum Each image is of size 512 x 512Let s check if the number of files divided by 4 yields the number of target samples How do images of specific targets look like While looking at examples we can build an batch loader Let s try to visualize specific target groups. This imbalance becomes even more dramatic for seldom targets like rods and rings. A data generator that can be used with CPU GPU computing to perform training and validation. The competition says that it shows the stained target proteins and consequently it s hopefully the most informative one. In this situation the model learns too much details out of the training images. In addition we like to make predictions for the validation data and for the test submission data. 1071 which are 3 28 in our best case. As we are working with neural networks that can be demanding in computational resources let s only use 2 repetitions. How to solve this jiggle wiggle problem Well first of all we might choose a higher batch_size again Decreasing the batch size we made a tradeoff We increased the learning speed but increased the risk of low quality gradients. Taking a look at the standard deviation we can see that all samples have nearly the same predicted values. Before we can transform our binary targets back to the submission target column we need to choose threshold for the absence and presence for each of them. I have never mind that the results are useful for many kagglers that like to start with the competition but need some starter code or some inspiration. Let s create a dataframe for the test ids as well that we will use later to make our submission. X n_samples dim n_channels Initialization Generate data Store sample Store class Generate indexes of the batch Find list of IDs Generate data Datasets Run computation and store results as csv If you already have done a baseline fit once you can load predictions as csv and further fitting is not neccessary in contrast to the base DataGenerator we add a target wishlist to init Run computation and store results as csv If you already have done a baseline fit once you can load predictions as csv and further fitting is not neccessary Run computation and store results as csv If you already have done a baseline fit once you can load predictions as csv and further fitting is not neccessary Run computation and store results as csv If you already have done a baseline fit once you can load predictions as csv and further fitting is not neccessary. Gradient clippingThese two will be the next improvement steps. For these classes the prediction will be very difficult as we have only a few examples that may not cover all variabilities and as our model probably will be confused during ins learning process by the major classes. One Step Improvement onestep The target wishlist Add scoring metrics Track losses and scores More epochs Preparation Kernel settingsThis notebook contains model fitting that may take some time. Using transfer learning3. Well this really depends on the samples within one batch. use_dropout use_dropout def build_model self self. Hence let s improve again and turn dropout to a plug and play feature class ImprovedModel BaseLineModel def __init__ self modelparameter my_metrics f1_mean f1_std f1_min f1_max use_dropout True super. This tools makes it easy for us to build and train neural networks. Perhaps we will make nice predictions for Cytosol but bad ones for Nucleoplasmn. Passing an instance of this class to them reduced the risk of setting different parameters and obtaining mismatch errors for example during build compile of the network layers. This makes sense For each image we have a high probability to contain either 1 or 2 target protein structures. This way we can pass both to the model and observe how the validation performance changes during training on the train images. Consequently we make large jumps in weight space with each update step batch per batch. This way we can easily load images and targets given the chunk ids. What can we expect Well we are only working with 3 targets so far. Ok now let s increase the number of epochs and decrease the batch_size. pdf linked at keras documentation you can see that the forward and backward propagation is done only with this reduced thinned kind of network. Looking at a preprocessed example imageYou can see that we have lost a lot of information by downscaling the image Data GeneratorI highly build upon the nice data generator presented by Shervine Amidi. Consequently our model may try to learn from exotics. For example there could be chunks with very seldom targets that may obtain a bad score and some chunks with very common targets and a very good score. Each sample that has at least one match with this list is returned. Hence our model learns faster. add Conv2D 32 3 3 activation relu self. Its our first attempt to play with and to figure out how to improve. Weight regularization2. But then we will need even more epochs as we make less weight updata aka learning steps But even if this stochastic gradient descent looks wiggly it has an advantage too It can escape from local minima of the loss function. Preparation preparation Kernel settings Improved model settings Loading packages and data Extract test names for submission Helper code Extract train targets2. Hyperlinks still needed Planned updates 1. This way you can run the cell until you have seen all images of your group without polluting the kernel Take Away Looking at this few examples we can already obtain some insights The staining of target proteins in the green channel was not equally successful. What will happen if we do not use our dropout layers Where to go next optimization objective alias loss choice hyperparameter search linear algebra data processing CSV file I O e. Set target values of your choice and the target group iterator will collect all images that are subset of your choice To keep the kernel dense the target group iterator has a batch size which stands for the number of examples you like to look at once. This way we can see if the loss decreases during weight update steps And we can see if we need more epochs or if the loss has already converged and settled down. Exploratory data analysis Which proteins occur most often in train images Take Away We can see that most common protein structures belong to coarse grained cellular components like the plasma membrane the cytosol and the nucleus. Ideas on how to improve the baseline model by tracking loss with a keras callback. Using tensorflow estimators perhaps this helps with slow prediction process 2. __init__ modelparameter self. In this example we will see images that contain the protein structures lysosomes or endosomes. This would yield gradients that try to improve the detection of cats thereby changing the weights we might need to identify dogs. Let s take a look at the predicted probabilities Ah I have forgotten to plug in the Ids as index such that we can easily compare with the true validation labels. Before we improve the model using more epochs and smaller batches let s implement a new feature a loss callback. Track losses and scoresOk after adding the metrics we like to observe we should try to obtain more insights into the learning process of our model. In addition we have to be very careful with small batches as its target distribution might not reflect the overall pattern. In addition we have to deal with highly imbalanced classes per single target. First of all we should collect some ideas To stay simple let s use only the green channel image of our images per id. add Dense 64 activation relu if self. Add scoring metricsWe have already seen that the accuracy score is an illusion and does not help to figure out how good our predictions are. Take Away We can see that our model was always very uncertain to predict the presence of a target protein. Let s take a closer look to the competition scoring and alternatives F1 macro score Check out this nice implementation of Guglielmo Camporese https www. In contrast we weren t able to predict the presence of a target protein which is the most relevant part Now a bell should ring Have you ever heard about imbalanced classes and model confusion To which targets do the high and small predicted probabilities belong to Take Away Our baseline model seemed to learn something even if this something does not look very nice. For this purpose let s use the deep learning library keras https keras. This is of course very bad Let s go one step deeper and take a look at the Cytosol choose another feature if you like. Consequently in original gradient descent we need to pass the whole dataset once for just one single update step of gradient descent. To observe the next 3 examples of your target group just run the cell below again. With a batch size of 10 we are likely to fill up these places with imbalanced targets. Consequently if you have a problem with overfitting learning too much out of your training data and loosing generalization performance or you have very small imbalanced batches you should consider dropout as a strategy. An image preprocessor that rescales reshapes and normalizes the images for feeding into the model. Before increasing the batch size again and waiting too long for predictions we might improve by choosing another way 1. Perhaps this patterns might help to build a more robust model How do the images look like Peek into the directoryBefore we start loading images let s have a look into the train directory to get an impression of what we can find there Ah ok great It seems that for one image id there are different color channels present. Here we can see a higher standard deviation than for all other samples and perhaps its corresponding distribution starts to diverge trying to get bimodal. Let s use generators to only load data images of our batch and not all in once. This way we use more weight update steps and hopefully makes our model learn more than before What does the loss tell us The loss is very noisy While decreasing the batch size we increased the number of learning steps. Now we can overwrite this method in our ImprovedDataGenerator without loosing functionality Plug and Play This part makes fun Actually I don t know if our model learns something meaningful. with smaller batch size there are fewer samples to learn from to compute gradients from The gradients we obtain may be very specific to the images and class labels that are covered by the batch of the current learning step. Ok you can see that beside our wishlist targets all others are filled with zero. In contrast endosomes and lysosomes often occur together and sometimes seem to be located at the endoplasmatic reticulum. Thank you for pushing this kernel that far If you have just found this kernel here is a short summary of what you can find 1. In addition we find that the mitotic spindle often comes together with the cytokinetic bridge. Let s try to understand why. This corresponds to an absence of corresponding target proteins. Using keras fit_generator evaluate_generator and predict_generator we can directly connect them to keras without worrying much about how keras does its job. num_classes activation sigmoid Our last losses were obtained by using dropout with high percentage 25 and 50 of dropped neurons. This could be done in sequence of samples or random with replacement. model Sequential self. it s mainly driven by high contributions. We will perform the splitting on the image ids. Thank you very much We can easily add it to our model. ", "id": "allunia/protein-atlas-exploration-and-baseline", "size": "31846", "language": "python", "html_url": "https://www.kaggle.com/code/allunia/protein-atlas-exploration-and-baseline", "git_url": "https://www.kaggle.com/code/allunia/protein-atlas-exploration-and-baseline", "script": "ModelParameter PredictGenerator skimage.transform RepeatedKFold check_subset keras.layers ImprovedDataGenerator(DataGenerator) preprocess keras.models os predict TrackHistory(keras.callbacks.Callback) make_image_row listdir set_generators accuracy_score Image numpy ImagePreprocessor seaborn MaxPooling2D Dropout Adadelta transform_to_target binary_crossentropy save find_matching_data_entries on_epoch_end Dense build_model imread compile_model f1_max on_train_begin keras.backend keras.initializers base_f1 keras.optimizers tensorflow __data_generation matplotlib.pyplot find_counts TargetGroupIterator DataGenerator(keras.utils.Sequence) Sequential PIL sklearn.model_selection pandas resize keras.losses ImprovedModel(BaseLineModel) scipy.misc Conv2D get_loader load f1_min Flatten fill_targets __len__ KernelSettings reshape f1_std __init__ normalize learn BaseLineModel get_targets_per_image sklearn.metrics f1_mean on_batch_end VarianceScaling __getitem__ score make_title load_image accuracy_score as accuracy ", "entities": "(('it', 'mainly high contributions'), 'drive') (('weights', 'gradients'), 'mean') (('we', 'more learning steps'), 'remain') (('imbalance', 'rods'), 'become') (('we', 'learning steps'), 'way') (('model', 'training images'), 'learn') (('we', 'index'), 'run') (('endosomes', 'more nucleus'), 'show') (('that', 'batch learning one step'), 'turn') (('more what', 'network thinned learning'), 'be') (('it', 'validation images'), 'suffer') (('we', 'them'), 'transform') (('Consequently we', 'batch'), 'make') (('we', 'minor classes'), 'make') (('you', 'examples'), 'collect') (('s', 'only 2 repetitions'), 'let') (('it', 'cats'), 'occupy') (('we', 'already whole dataset'), 'mean') (('we', 'model'), 'try') (('model', 'something'), 'overwrite') (('them', 'value similar range'), 'cause') (('Data GeneratorI', 'Shervine Amidi'), 'see') (('we', 'dogs'), 'yield') (('we', 'test submission data'), 'like') (('Consequently we', 'targets'), 'find') (('perhaps corresponding distribution', 'bimodal'), 'see') (('others', 'overall low values'), 'see') (('mean', 'target class'), 'be') (('we', 'wishlist'), 'start') (('we', 'imbalanced targets'), 'be') (('others', 'zero'), 'see') (('Perhaps we', 'improved batch'), 'prevent') (('we', 'that'), 'don') (('We', 'reduced gradient quality'), 'gain') (('mode', 'samples'), 'be') (('Passing', 'network layers'), 'reduce') (('staining', 'green channel'), 'run') (('This', 'target corresponding proteins'), 'correspond') (('you', 'csv'), 'dim') (('it', 'K repeated Folds'), 'yield') (('i', 'low absolute values'), 'image') (('such we', 'validation easily true labels'), 'let') (('we', 'loss decrease'), 'see') (('that', 'loss'), 'be') (('I', 'already dropout'), 'see') (('It', 'loss function'), 'need') (('we', 'data generator'), 'wish') (('Sometimes whole image', 'cells'), 'cover') (('Hyperlinks', 'Planned still updates'), 'need') (('Consequently high accuracy', 'target proteins'), 'belong') (('We', 'far away good model'), 'change') (('already we', 'data'), 'improve') (('we', 'only 3 targets'), 'expect') (('peroxisomes', 'as well cytosol'), 'see') (('Hence s', 'feature class ImprovedModel BaseLineModel'), 'let') (('both', 'cellular division'), 'make') (('we', 'target protein 1 structures'), 'make') (('this', 'one batch'), 'depend') (('next it', 'nucleoplasmn predictions'), 'try') (('smaller s', 'loss callback'), 'let') (('class that', 'learning current step'), 'be') (('samples', 'nearly same predicted values'), 'see') (('target distribution', 'learning'), 'influence') (('s', 'deeper problem'), 'let') (('consequently it', 'target stained proteins'), 'say') (('you', 'target clustering'), 'like') (('model', 'major classes'), 'be') (('now s', 'batch_size'), 'let') (('test where set', 'train set'), 'make') (('you', 'link'), 'follow') (('now we', 'again next epoch'), 'say') (('s', 'target specific groups'), 'correspond') (('we', 'baseline simple model'), 'use') (('s', 'index'), 'let') (('that', 'protein structures lysosomes'), 'see') (('you', 'strategy'), 'consequently') (('us', 'neural networks'), 'make') (('K', 'end'), 'repeat') (('mitotic spindle', 'often together cytokinetic bridge'), 'find') (('It', 'training current step'), 'let') (('f1', 'model'), 'mean') (('Shared classOk now we', 'DataGenerator'), 'Parameter') (('that', 'batch'), 'take') (('we', 'gradient descent'), 'need') (('model', 'target protein'), 'take') (('entries', '0'), 'make') (('how scores', 'classes'), 'see') (('validation how performance', 'train images'), 'pass') (('model Improved you', 'style'), 'settingswithin') (('Consequently it', 'min'), 'know') (('We', 'validation images'), 'kera') (('history', 'one epoch'), 'draw') (('now we', 'target directly binary values'), 'train') (('that', 'starting point'), 'be') (('j E _ We', 'one another'), 'gradient') (('target distribution', 'overall pattern'), 'have') (('how keras', 'job'), 'connect') (('whole dataset', 'gradient descent'), 'use') (('60', 'it'), 'be') (('Perhaps we', 'baseline model'), 'expand') (('very much We', 'model'), 'thank') (('we', 'single target'), 'have') (('that', 'list'), 'return') (('How images', '3'), 'explore') (('I', 'baseline simple model'), 'welcome') (('observe', 'just cell'), 'run') (('last losses', '25 dropped neurons'), 'sigmoid') (('you', 'contents'), 'be') (('we', 'step'), 'make') (('s', 'leaderboard'), 'make') (('that', 'starter code'), 'mind') (('method', 'batch'), 'value') (('way we', 'chunk ids'), 'load') (('perhaps this', 'prediction slow process'), 'help') (('F1 macro score', 'Guglielmo Camporese https www'), 'let') (('we', 'class'), 'go') (('s', 'batch'), 'let') (('even something', 'something'), 'weren') (('as well we', 'later submission'), 'let') (('you', 'one iteration'), 'see') (('test 11702 we', 'predictions'), 'make') (('that', 'images'), 'write') (('This', 'batch'), 'become') (('where model', 'higher 10'), 'be') (('we', 'one disadvantage'), 'compute') (('I', 'weight already 200 updates'), 'mean') (('that', 'data nucleoplasm cytosol'), 'but') (('we', 'cats'), 'imagine') (('just perhaps one', 'cell types'), 'be') (('simple s', 'i d'), 'collect') (('cells', 'different types'), 'look') (('that', 'images'), 'build') (('contrast endosomes', 'often together sometimes endoplasmatic reticulum'), 'occur') (('Sometimes jumps', 'even losses'), 's') (('We', 'true positives'), 'attach') (('Preparation preparation Kernel Improved model Loading packages', 'data names'), 'setting') (('image that', 'model'), 'preprocessor') (('many targets', 'only very slight correlations'), 'take') (('classes', 'weights'), 'do') (('rods', 'train very seldom data'), 'end') (('we', 'optimization alias loss choice hyperparameter search linear algebra data processing CSV Where next objective file'), 'happen') (('that', 'data'), 'be') (('learning', 'progress'), 'give') (('you', 'feature'), 'be') (('model', 'target'), 'be') (('we', 'update many such steps'), 'be') (('other images', 'microtubules nucleus'), 'be') (('s', 'data generator'), 'let') (('we', 'already baseline'), 'add') (('we', 'home bed'), 'be') (('target 28 different multiple proteins', 'contents1'), 'predict') (('other gradients', 'set different computes'), 'see') (('images', 'cell different densities'), 'click') (('purpose we', 'validation data'), 'choose') (('prediction way probabilities', 'data added source'), 'set') (('we', 'next batch'), 'continue') (('protein most common structures', 'plasma membrane'), 'analysis') (('we', 'cats'), 'obtain') (('you', 'output'), 'read_csv') (('Hence changing', 'jiggles'), 'lead') (('we', 'return already def get_targets_per_image self identifier self'), 'add') (('somehow performance', 'test chunk'), 'depend') (('that', 'image'), 'be') (('forward propagation', 'network'), 'see') (('loss', 'more epochs'), 'see') (('I', 'ideas'), 'come') (('others', 'training'), 'splitte') (('that', 'very common targets'), 'be') (('we', 'morphological differences'), 'see') (('This', 'replacement'), 'do') (('We', 'image ids'), 'perform') (('image', 'image actually 4 different files'), 'find') (('j E _ way we', 'weights'), 'large') (('we', 'step'), 'think') (('we', 'targets'), 'be') (('Consequently accuracy', 'right here performance'), 'be') (('we', 'way'), 'before') (('we', 'cats'), 'be') (('that', 'very frequency'), 'be') (('Consequently model', 'exotics'), 'try') (('2 we', 'cross again 3 repeated validation'), 'end') (('that', 'time'), 'onestep') (('that', 'training'), 'compute') (('protein where structure', 'other targets'), 'allunia') (('Visual analysis', '3'), 'set') (('we', 'model same parameters'), 'need') (('i', 'one image'), 'help') (('that', 'image preprocessor'), 'm') (('we', 'parameter different settings'), 'try') (('how predictions', 'metricsWe'), 'see') (('most', 'zero'), 'see') (('train most common away Most images', 'target only 1 labels'), 'be') (('we', 'cross k fold validation'), 'build') (('we', 'y i.'), 'see') (('We', 'quality low gradients'), 'wiggle') (('Perhaps we', 'bad Nucleoplasmn'), 'make') (('sometimes they', 'opposite'), 'lead') (('image simple that', 'target protein wishlist'), 'generator') (('How model', '4'), 'bulde') (('Here we', 'target true value'), 'know') (('way we', 'data loading'), 'change') (('s', 'learning library keras https deep keras'), 'let') (('validation loss', 'change'), 'see') (('target proteins', 'intensities'), 'differ') (('you', 'here short what'), 'thank') "}
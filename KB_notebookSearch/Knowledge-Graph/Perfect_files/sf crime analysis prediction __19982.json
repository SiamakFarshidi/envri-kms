{"name": "sf crime analysis prediction ", "full_name": " h1 Introduction h1 Definition h2 Project Overview h2 Problem Statement h2 Metrics h1 Analysis h2 Data Exploration h3 Dates Day of the week h3 Category h3 Police District h3 Address h3 X Longitude Y Latitude h2 Exploratory Visualization h2 Algorithms and Techniques h2 Benchmark h1 Methodology h2 Data Preprocessing h3 Data Wrangling h3 Feature Engineering h3 Feature Scaling h3 Feature Selection h2 Building the Initial Model h2 Refinement h2 Building the final model h1 Model Evaluation and Validation h1 Conclusion h2 Free Form Visualization h2 Reflection h2 Improvements ", "stargazers_count": 0, "forks_count": 0, "description": "That being said we could say that the results are satisfactory. Insights like this are possible with the use of the SHAP library. 68015 and 2 better than the benchmark. 5 Min_data_in_leaf uniformly in the range 10 25 Num_leaves uniformly in the range 20 45 Max_bin uniformly in the range 200 500 Learning_rate uniformly in the range 0. This prediction will be a baseline score to compare with our model s score to evaluate if we have any significant progress. We can see that although the epicenter of most of the crimes resides on the northeast of the city each crime has a different density on the rest of the city. Today the city is known more for its tech scene than its criminal past. Dates timestamp of the crime incident Category category of the crime incident. 58856 XGBoost Default Scikit Learn Parameters 2. In layman terms the algorithm works like this 1. com yannisp sf crime analysis prediction base model notebook scriptVersionId 9334889 base_model https i. The first one presents the geographic density of 9 random crime categories. Let s see if our model aligns with our intuition. 92716 AdaBoost Default Scikit Learn Parameters 3. com sergeylebedev with score 2. Definition Project Overview Crime is a social phenomenon as old as societies themselves and although there will never be a free from crime society just because it would need everyone in that society to think and act in the same way societies always look for a way to minimize it and prevent it. Police District There are significant differences between the different districts of the City with the Southern district having the most incidents 17. We can solve this issue and understand even deeper our model by using Partial Dependencies. The duplicates removed and the outliers imputed. To get a little more intuition on the metric for a specific incident We get 0 loss from the categories of crimes that did not happen since yij 0 yijlog pij no matter our predicted probability. Both of these are aligned again with our intuition making us more confident about the validity of our model. Taking into account the low margin between the naive and the benchmark we knew that we would probably have a small improvement. Analysis Data Exploration The dataset is in a tabular form and includes chronological geographical and text data and contains incidents derived from the SFPD Crime Incident Reporting system. Use embeddings or any other text processing technique for the addresses. ImprovementsWe are sure there is space for improvement. com yannisp sf crime analysis prediction optimiz ex First we optimized a few basic hyperparameters including Boosting selection between gbdt and dart Max_delta_step uniformly in the range 0 2 Min_data_in_leaf uniformly in the range 10 30 Num_leaves uniformly in the range 20 40 After the model converged a second round of tuning followed Boosting gbdt Max_delta_step uniformly in the range 0. 0 we decided to work with LightGBM due to its efficiency and versatility in the hyperparameters tuning. Two additional techniques we would like to implement if there was the necessary time would be Create ordinal representations for the features that present a kind of cyclicity Month Weekday Hour Minute. 87 followed by Mission 13. Go to step 2 lightgbm https lightgbm. X Longitude Y Latitude We have tested that the coordinates belong inside the boundaries of the city. To identify if any of them increased the complexity of the model without adding significant gain to the model we used the method of Permutation Importance. 4 In the following figure we present the performance of the best model from each step of optimization. After cleaning the dataset from outliers and duplicates we examine the variables. Model selection and evaluation. Problem StatementTo examine the specific problem we will apply a full Data Science life cycle composed of the following steps 1. 86631 K Nearest Neighbors Default Scikit Learn Parameters 23. Feature Engineering to create additional variables from the existing. 29263 Random Forest Default Scikit Learn Parameters 2. It also contains 2323 duplicates that we should remove. Although longitude does not contain any outliers latitude includes some 90o values which correspond to the North Pole. Feature EngineeringThen we created additional features. In a Multiclass Classification the best way to calculate the baseline is by assuming that the probability of each category equals its average frequency in the train set. This is our target variable. 53743 and by removing the DayOfWeek feature the loss increased to 2. Conclusion Free Form VisualizationAn interesting visualization would be to depict how each feature affects a specific prediction. ReflectionAs described in the previous sections a full cycle data processing have been followed and lead us to a satisfactory prediction model. We can conclude that the model is aligned with our intuition. A way to solve it is to imagine the hour in a real clock and take their projections on the axes passing from the center of the clock. Building the Initial ModelTo build the model we used the LightGBM s Python API. Increase the weight to the incorrect samples. Choose the leaf with max delta loss to grow. Since the 1990s however crime in the United States has declined steadily. In other words if for an incident we change only the value of one feature how will this affect the probability of each crime category As an example we can evaluate how the Hour affects the probabilities of three different crimes. We did not notice any anomalies on these variables. Doing this would require re training an estimator for each feature which can be computationally intensive. That being said we present two diagrams to visualize the importance of these variables. Also we created a custom callback function so we can write proper logs that can be read by Tensorboard. Descript detailed description of the crime incident DayOfWeek the day of the week PdDistrict the name of the Police Department District Resolution The resolution of the crime incident Address the approximate street address of the crime incident X Longitude Y LatitudeThe dataset contains a lot of object variables aka strings that we will need to encode. The reasoning behind this is that if we take the Hour as an example the default representation implies that 23 and 00 midnight are 23 units away although in reality they are 1 unit apart. SF Crime Analysis Prediction Base Model https www. Dates Day of the week These variables are distributed uniformly between 1 1 2003 to 5 13 2015 and Monday to Sunday and split between the training and the testing dataset as mentioned before. This way the distance between 23 and 00 is the same as between 00 and 01. 91656 LIghtGBM Default Scikit Learn Parameters 2. First we created the dataset by combining the features the target and declaring the PdDistrict as a categorical variable using lightgbm. This technique speeds up training and reduces memory usage. As an example let s select a row from the testing dataset This incident has taken place in 03 30 in the night in a block. To do that we can remove each feature from the dataset re train the estimator and check the impact. This is a hard problem to solve with a heavily unbalanced dataset and the unpredictability up to some point of the human factor. The Permutation importance is a great tool to understand how much a specific feature affect our prediction but it does not tell us anything about the direction it affects it. It is evident that different crimes have different frequency during different times of the day. As before these are sharp pieces of evidence that the time parameters will have a significant role also. io en latest _images leaf wise. com sergeylebedev initial benchmark need tuning by the user Sergey Lebedev https www. We can achieve this with functions like Hx sin 2 \u03c0 H 23 Hy cos 2 \u03c0 H 23 for the hour and accordingly for the rest. Based on the Permutation Importance analysis we performed before the model should be susceptible to changes in Minute and the coordinates and less sensitive to changes in Day Year or Day of the week. From the Address field we extracted if the incident has taken place in a crossroad or on a building block. The baseline calculated this way is 2. The above was up to some point an iterative process. The problem with the two techniques mentioned above is that they do not use previous results to pick the next input values. Until recently crime prevention was studied based on strict behavioral and social methods but the recent developments in Data Analysis have allowed a more quantitative approach in the subject. Data Wrangling to audit the quality of the data and perform all the necessary actions to clean the dataset. The implementation of the above technique showed that there is no need for any feature removal since all of them have a positive impact in the dataset. Indeed by removing the Minute feature from the dataset we had an increase of loss to 2. Training Testing data creation to evaluate the performance of our models and fine tune their hyperparameters. Another critical benchmark is usually the Human Performance as a proxy for the Bayes error rate. png Refinement Instead of the most popular methods of Exhaustive Grid Search and Randomized Parameter Optimization we selected another more efficient way to tune the hyperparameters of the algorithm Bayesian optimization. example of the process here https www. png Benchmark There are two types of benchmarks we need to set. IntroductionSan Francisco was infamous for housing some of the world s most notorious criminals on the inescapable island of Alcatraz. Finally from the algorithms that scored under 3. As we saw in the Partial Dependencies graphs before BURGLARY has a higher probability and burglaries happen by definition in blocks. 9 Min_data_in_leaf 21 Num_leaves 41 Max_bin 465 Learning_rate 0. This way we were able to monitor the validation process in real time. The small distance between the baseline score and the Bayes error rate indicate that this is a hard problem with a low margin of improvement. org wiki Bayes_error_rate we will use the score of the best kernel so far which is initial benchmark need tuning https www. Data Exploration for understanding the variables and create intuition on the data. Instead in this project we will use it to extract if the incident has happened on the road or in a building block. The probability model also called the surrogate or response surface is easier to optimize than the actual objective function. The frequency can be calculated easily by dividing the sum of incidents of each category by the number of rows of the training set. Then we stopped and evaluated the results and move to the next iteration. Violent crime nearly quadrupled between 1960 and its peak in 1991. The second diagram presents the average number of incidents per hour for five of the crimes categories. 67 and Northern 12. SHAP SHapley Additive exPlanations is a unified approach to explain the output of any machine learning model. We get log pij loss from the category that happened where pij is our predicted probability for the specific category. SHAP connects game theory with local explanations uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations see the SHAP NIPS paper http papers. Data Normalization and Data Transformation for preparing the dataset for the learning algorithms if needed. Bayesian methods select the next values to evaluate by applying a criterion usually Expected Improvement to the surrogate. In contrast during the night the probability for BURGLARY class 4 increases up to 2 and during the day the probability for DISORDERLY CONDUCT class 5 decreases. Instead we can replace it with noise by shuffle values for a feature. Fit a decision tree to the data2. From Sunset to SOMA and Marina to Excelsior this project analyzes 12 years of crime reports from across all of San Francisco s neighborhoods to create a model that predicts the category of crime that occurred given time and location. For each incident we will predict a set of predicted probabilities one for every class and we will calculate the average deviation from the real values. For this reason we had to be creative and use advanced techniques during the hyperparameter optimization to make a difference. png 1 Building the final model Model Evaluation and ValidationThe final model scored 2. We run the optimization process until we noticed in Tensorboard that the models converge. com yannisp sf crime analysis prediction naive prediction Notebook. Feature SelectionAfter the feature engineering described above we ended up with 11 features. Algorithms and Techniques The specific problem is a typical multiclass classification problem and there are several categories of algorithms for solving it. The first will be a naive prediction. Address Address as a text field requires advanced techniques to use it for the prediction. Feature ScalingDeciding to continue with a tree based algorithm there was no need for scaling on the final dataset. We can see that there is a 10 probability for BURGLARY and that this is mostly increased because it takes place to a block not on a crossroad and from the time hour and minute. 49136 on the testing set. Also there is no significant deviation of incidents frequency throughout the week. The specific problem does not belong to a field that humans excel like computer vision or NLP so as a proxy for the Bayes error rate https en. Details in SF Crime Analysis Prediction Naive Prediction https www. By extracting if the incident has happened to a block or a crossroad we have extracted the minimum gain from this feature and maybe there are some patterns to exploit and give us even better score. 98336 SGD scored the best initial result but after a lengthy hyperparameter tuning it was not able to pass a 2. In other words the metric evaluates the certainty of our model for each category of crime incident. The median frequency of incidents is 389 per day with a standard deviation of 48. We can notice that this baseline is already lower than the initial score of our classifiers. 25697 on the training set which is 16 lower from the naive prediction 2. The data ranges from 1 1 2003 to 5 13 2015 creating a training dataset with nine features and 878 049 samplesMore specifically it includes the following variables. Then we used Cross Validation with early stopping 10 rounds and parameters Objective multiclass Metric multi_logloss Num_class 39 The above setup achieved 2. 46799 cross validation score after 23 epochs and 2. The idea is that the importance of a feature can be measured by looking at how much the loss decreases when a feature is not available. To conclude to the final model we used five folds Cross Validation for 100 epochs and early stopping with Bayesian Optimization. Downloading the shapefile of the area Unzipping it Loading to a geopandas dataframe Defining the coordinate system to longitude latitude Merging our train dataset with the geo dataframe Transforming the coordinate system to Spherical Mercator for compatibility with the tiling background Calculating the incidents per day for every district Ploting the data restore original x y limits Adding the background Adding the name of the districts Loading the data Data cleaning Feature Engineering Encoding the Categorical Variables Creating the model Submitting the results Create object that can calculate shap values Calculate Shap values. Some points are misplaced. 1 2 Finally we concluded to the following hyperparameters Boosting gbdt Max_delta_step 0. Category There are 39 discrete categories that the police department file the incidents with the most common being Larceny Theft 19. We will replace the outlying coordinates with the average coordinates of the district they belong. This fact is a reliable indication that the location coordinates Police District will be a significant factor for the analysis and the forecasting. We will also evaluate the position of the data points using the coordinates. LightGBM is a decision tree boosting algorithm uses histogram based algorithms which bucket continuous feature attribute values into discrete bins. More specifically From the Dates field we extracted the Day the Month the Year the Hour the Minute the Weekday and the number of days since the first day in the data. Logarithmic loss measures the performance of a classification model where the prediction output is a probability value between 0 and 1. We have to note here that since all the probabilities for a specific incident sum to 1 each probability we predict for a category that did not happen creates an indirect loss since it decreases our predicted probability for the category of crime that happened. Initially we evaluated several appropriate algorithms from Linear Models Stochastic Gradient Descent Nearest Neighbors K nearest neighbors Ensemble methods Random Forests AdaBoost and Boosting Algorithms XGBoost LIghtGBM using basic feature engineering and the default parameters to evaluate if any of them has a significant head start Algorithm Parameters Logloss Stochastic Gradient Descent Default Scikit Learn Parameters with log loss 2. 91 Non Criminal 10. Property crime more than doubled over the same period. Thus we do not expect this variable to play a significant role in the prediction. Some examples are that prostitution picks during the evening and all through the night Gambling incidents start late at night until the morning and Burglary picks early in the morning until the afternoon. The most challenging part was that due to the nature of the features there was a little room for feature engineering. Exploratory VisualizationBased on the Project s statement we need to predict the probability of each type of crime based on time and location. This will be the final goal creating a model that predicts the probability of each type of crime based on the location and the date. The concept is to limit the evaluations of the objective function by spending more time choosing the next values to try. We will explore a dataset of nearly 12 years of crime reports from across all of San Francisco s neighborhoods and we will create a model that predicts the category of crime that occurred given the time and location. cc paper 7062 a unified approach to interpreting model predictions for details. Methodology Data Preprocessing Data WranglingFollowing the methodology described in the Problem Statement we identified 2323 duplicate values and 67 wrong latitudes. In the modern United States history crime rates increased after World War II peaking from the 1970s to the early 1990s. MetricsThe most appropriate evaluation metric for such problems is the multi class logarithmic loss. Instead Bayesian optimization also called Sequential Model Based Optimization SMBO implements this idea by building a probability model of the objective function that maps input values to a probability of a loss p loss input values. We can see that the hour does not affect the probability for BRIBERY class 3. Let s see how many they are. ", "id": "yannisp/sf-crime-analysis-prediction", "size": "19982", "language": "python", "html_url": "https://www.kaggle.com/code/yannisp/sf-crime-analysis-prediction", "git_url": "https://www.kaggle.com/code/yannisp/sf-crime-analysis-prediction", "script": "lightgbm train_test_split geopandas Point pyplot pyplot as plt cm SimpleImputer numpy seaborn shapely.geometry LGBMClassifier add_basemap feature_engineering geoplot matplotlib.pyplot pdp info_plots sklearn.model_selection pandas PermutationImportance create_gdf contextily get_dataset matplotlib sklearn.impute eli5.sklearn LabelEncoder pdpbox sklearn.preprocessing ", "entities": "(('crime', 'city'), 'see') (('that', 'loss p loss input values'), 'call') (('models', 'Tensorboard'), 'run') (('we', 'variables'), 'say') (('we', 'Permutation Importance'), 'identify') (('20 model', 'Boosting gbdt uniformly range'), 'com') (('prediction where output', 'probability 0'), 'measure') (('Then we', 'next iteration'), 'stop') (('we', '2'), 'by') (('variables', 'training'), 'distribute') (('cycle data full processing', 'prediction satisfactory model'), 'follow') (('Insights', 'SHAP library'), 'be') (('Today city', 'criminal past'), 'know') (('we', 'week'), 'perform') (('most challenging part', 'feature little engineering'), 'be') (('all', 'dataset'), 'show') (('we', 'Bayesian Optimization'), 'stop') (('that', 'yijlog yij 0 pij'), 'get') (('societies', 'it'), 'be') (('it', '2'), 'score') (('concept', 'next values'), 'be') (('probability', 'CONDUCT DISORDERLY class'), 'in') (('we', 'difference'), 'for') (('Instead we', 'feature'), 'replace') (('AdaBoost Default Scikit', 'Parameters'), '92716') (('we', 'optimization'), '4') (('1 Building', 'ValidationThe final 2'), 'score') (('evaluation most appropriate metric', 'such problems'), 'be') (('we', 'data'), 'extract') (('incident', 'building block'), 'use') (('Address Address', 'prediction'), 'require') (('we', 'probably small improvement'), 'know') (('morning', 'afternoon'), 'be') (('we', 'also 2323 duplicates'), 'contain') (('metric', 'crime incident'), 'evaluate') (('they', '23 away reality'), 'be') (('we', 'impact'), 'remove') (('above', 'iterative process'), 'be') (('we', 'significant progress'), 'be') (('model', 'intuition'), 'let') (('Bayesian methods', 'usually Expected surrogate'), 'select') (('This', 'human factor'), 'be') (('time parameters', 'significant role'), 'be') (('We', 'variables'), 'notice') (('that', '3'), 'from') (('feature we', '11 features'), 'end') (('Create that', 'Calculate Shap values'), 'download') (('we', 'that'), 'detailed') (('we', 'hyperparameters'), '0') (('specific problem', 'it'), 'Algorithms') (('which', 'feature'), 'require') (('SHAP SHapley Additive exPlanations', 'machine learning model'), 'be') (('we', 'following steps'), 'examine') (('Random Forest Default Scikit', 'Parameters'), '29263') (('when feature', 'how much'), 'be') (('which', '16 naive prediction'), '25697') (('where pij', 'predicted specific category'), 'get') (('we', 'Python API'), 'build') (('recent developments', 'subject'), 'study') (('Training Testing data creation', 'fine hyperparameters'), 'tune') (('baseline', 'classifiers'), 'notice') (('LIghtGBM Default Scikit', 'Parameters'), '91656') (('Bayes error this', 'improvement'), 'indicate') (('which', 'discrete bins'), 'be') (('We', 'Partial Dependencies'), 'solve') (('hour', 'BRIBERY class'), 'see') (('model', 'intuition'), 'conclude') (('we', 'png two benchmarks'), 'Benchmark') (('mostly it', 'time hour'), 'see') (('46799', '23 epochs'), 'cross') (('we', 'time'), 'VisualizationBased') (('First we', 'lightgbm'), 'create') (('how feature', 'specific prediction'), 'form') (('second diagram', 'crimes categories'), 'present') (('functions', 'accordingly rest'), 'achieve') (('first one', 'crime 9 random categories'), 'present') (('also surrogate surface', 'actual objective function'), 'call') (('that', 'cyclicity Month Weekday Hour Minute'), 'be') (('Violent crime', '1991'), 'quadruple') (('Metric Num_class 39 above setup', '2'), 'use') (('it', 'it'), 'be') (('that', 'time'), 'explore') (('we', 'real values'), 'predict') (('different crimes', 'day'), 'be') (('that', 'crime'), 'have') (('technique', 'memory usage'), 'speed') (('way', 'clock'), 'be') (('Algorithm Parameters Logloss Stochastic Gradient Descent Default Scikit', 'log loss'), 'evaluate') (('humans', 'Bayes error rate https en'), 'belong') (('incident', 'block'), 'take') (('however crime', 'United States'), 'decline') (('probability', 'train set'), 'be') (('that', 'time'), 'analyze') (('they', 'district'), 'replace') (('how Hour', 'three different crimes'), 'change') (('way we', 'real time'), 'be') (('World War II', 'early 1990s'), 'increase') (('Property crime', 'more than same period'), 'double') (('frequency', 'training set'), 'calculate') (('us', 'model'), 'align') (('loss', '2'), 'feature') (('some', 'Alcatraz'), 'be') (('878 049 samplesMore specifically it', 'following variables'), 'range') (('that', 'Tensorboard'), 'create') (('we', 'variables'), 'examine') (('We', 'coordinates'), 'evaluate') (('K Nearest Neighbors Default Scikit', 'Parameters'), '86631') (('algorithm', '1'), 'work') (('incident', 'building block'), 'extract') (('Feature EngineeringThen we', 'additional features'), 'create') (('SHAP', 'expectations'), 'see') (('1 Finally we', 'gbdt'), 'conclude') (('that', 'location'), 'be') (('which', 'North Pole'), 'include') (('Analysis Data dataset', 'SFPD Crime Incident Reporting system'), 'Exploration') (('Randomized Parameter we', 'algorithm Bayesian optimization'), 'select') (('BURGLARY', 'blocks'), 'see') (('we', 'maybe even better score'), 'extract') (('XGBoost Default Scikit', 'Parameters'), '58856') (('above they', 'input next values'), 'be') (('variable', 'prediction'), 'expect') (('critical benchmark', 'Bayes error rate'), 'be') (('so far which', 'benchmark https initial www'), 'use') (('median frequency', '48'), 'be') (('we', '2323 duplicate values'), 'Data') (('Police District', 'significant analysis'), 'be') (('ImprovementsWe', 'improvement'), 'be') (('police Category 39 discrete department', 'most common being'), 'be') (('coordinates', 'city'), 'test') (('way distance', 'between 00'), 'be') "}
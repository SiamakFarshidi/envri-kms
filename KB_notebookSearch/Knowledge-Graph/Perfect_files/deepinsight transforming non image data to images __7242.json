{"name": "deepinsight transforming non image data to images ", "full_name": " h1 DeepInsight Transforming Non image data to Images for CNN Architectures h1 Load MoA Data h1 Feature Encoding h1 Create Stratified Multi label K folds h1 DeepInsight Transform t SNE 2D Embeddings h2 Implementation h2 Norm 2 Normalization h2 t SNE Transformation h2 Convex Hull Algorithm h2 Visualization of Feature Map h3 Resolution 50 x 50 h3 Resolution 100 x 100 h2 Visualization of Feature Images h3 nfkb inhibitor h3 dna inhibitor h1 EOF ", "stargazers_count": 0, "forks_count": 0, "description": "DeepInsight Architecture https storage. It seems clear that _ the larger the perplexity the greater the level of feature overlaps _. DeepInsight Transform t SNE 2D EmbeddingsBased on https github. Here we randomly select four samples from the top 1 and top 5 class. It was published in _Scientific Reports_ of Nature in 2019 and I occasionally discovered it while searching for related deep learning materials to Mechanisms of Action. To see if the feature images could give a good representation of the raw features in different MoA targets we select the top 6 most frequent classes in the dataset and visualize a sample image for each of them. For the ease of visualization here the resolution is set to 50. In this notebook the outlook of feature maps for all MoA features is demonstrated by t SNE. nfkb_inhibitor dna_inhibitorIn the two runs of views to the feature map images we can clearly see distinguishable patterns across different MoA target classes. com alok ai lab DeepInsight but with some corrections to the norm 2 normalization. png Source https www. DeepInsight Transforming Non image data to Images for CNN Architectures This notebook introduces an interesting and useful preprocessing method for non image data to be applicable in Convolutional Neural Networks CNN architectures. for this small gene expression dataset. The similarity of features are estimated by cosine distance. of training set Modified from DeepInsight Transform https github. Lower resolution will cause more features to be gathered into the same pixel location. You can also separate the transformation process for different groups of features e. com alok ai lab DeepInsight blob master pyDeepInsight image_transformer. _DeepInsight A methodology to transform a non image data to an image for convolution neural network architecture_ Scientific Reports nature. Their implementation was in Matlab but in the public Github repository they shared it also includes a Python version for the transformation part. of training set from X_norm Min. py The resolution of transformed image Transpose to get n_features n_samples Perform dimensionality reduction Get the convex hull for the points Determine the minimum bounding rectangle Rotate the matrix Save the rotated matrix in case user wants to change the pixel size Determine feature coordinates based on pixel dimension plot rotation diagram if requested Create subplots recalculate coordinates if already fit Group by location x1 y1 of each feature Tranpose to get n_features n_samples x1 y1 Group by location x1 y1 of each feature Tranpose to get n_features n_samples x1 y1 Calculate edge angles Find rotation matrices Apply rotations to the hull Find the bounding points Find the box with the best area Return the best box Generate coordinates Create subplots Transpose to get n_features n_samples Transpose to get n_features n_samples Plot image matrix with feature counts per pixel Update image size Create subplots Feature Overlapping Counts x1 y1 Plot image matrix with feature counts per pixel Create subplots Select the random row of each class cmap hot Plot image matrix with feature counts per pixel Create subplots Select the random row of given class cmap hot. gene expressions cell viabilities There is a discrepancy between the Matlab version aligned with the paper and Python version regarding feature normalization therefore some minor adjustments have been done here. of training set from X_norm Normalized again by global max. Here several values of perplexity are being set to see the difference typical values are between 5 and 50. Modified from DeepInsight Transform https github. To make the features separated to some extent while still keeping their neighboring relationships perplexity 5 is chosen for the deepinsight transformation process. The effect of perplexity is also being studied. The idea is very straightforward Instead of doing feature extraction and selection for collected samples N samples x d features we would like to find a way of arranging similar or correlated features into the neighboring regions of a 2 dimensional feature map d features x N samples to ease the learning of their complex relationships and interactions. The following diagram outlines the key steps. First of all a non linear dimensionality reduction technique like t SNE or Kernel PCA is applied to transform raw features into a 2D embeddings feature space. t SNE TransformationIn the nice post of How to Use t SNE Effectively we have seen that the choice of perplexity a guess about the number of close neighbors each point has in the t SNE algorithm is tricky and its visual output in the embeddings feature space could be misleading. The rotation will be applied by considering the gradient of two of the corner coordinates of the box. Most of the credits should be given to the original authors ImplementationCheckout DeepInsight paper supplementary information for more details. Finally the raw feature values are mapped into the pixel coordinate locations of the feature map image. host GPU memory storage. Load MoA Data Feature EncodingAs we only have three metadata features a quick manual encoding process is done. Secondly the convex hull algorithm is used to find the smallest rectangle containing all features and a rotation is performed to align the feature map frame into a horizontal or vertical form. This is a good news to the potentials of applying CNN based models in this competition EOFThanks for reading through this post I hope you gain some good ideas for the improvement and diversity of your models. Also a great source of model diversity for the ensembles Please upvote or cite this notebook if you like it thanks Next Reading DeepInsight EfficientNet B3 Infernece Notebook Reference Sharma Alok Edwin Vans D. Norm 2 NormalizationAgain raw features are normalized into the value range of 0 1. This kind of transformation should open up the gates of transfer learning ResNeSts EfficientNets DenseNets and creative data augmentation techniques CutMix Mixup etc. of training set per feature Log normalized X by log X _min0 1 Global max. With this general approach in theory we could transform any kind of non image data into feature map images as a friendly representation of samples to CNNs which provide several unique benefits compared with other neural network architectures such as automated feature extraction from raw features and memory footprint reduction by effective weight sharing. Visualization of Feature MapFeature maps under different resolutions are visualized. Create Stratified Multi label K foldsHere only the first fold is used as training and validate sets for demonstration. All features are normalized into the value range of 0 1. Let s compare more samples of the same classes. of training set Adjust min. of each feature of X by _min0 Log normalized X by log X _min0 1 Normalized again by global max. com kaggle markpeng MoA deepinsight_architecture. Resolution 50 x 50 Resolution 100 x 100 Visualization of Feature ImagesOnce we got the feature map the raw feature values can be mapped to the corresponding pixel locations in the image. Convex Hull AlgorithmThe convex hull algorithm is applied to find the minimum box covering all features. com articles s41598 019 47765 6The authors had tested the method with a parallel CNN architecture on different kinds of datasets including RNA seq data gene expressions Text data and Speech data and showed positive results. Note that the resolution of feature map image affects the ratio of feature overlaps the features mapped to the same location are averaged which is a trade off between the level of lossy compression and computing resource requirements e. The generation of feature map only relies on the training set to ensure the generalization of preprocessed data and further trained models. ", "id": "markpeng/deepinsight-transforming-non-image-data-to-images", "size": "7242", "language": "python", "html_url": "https://www.kaggle.com/code/markpeng/deepinsight-transforming-non-image-data-to-images", "git_url": "https://www.kaggle.com/code/markpeng/deepinsight-transforming-non-image-data-to-images", "script": "MultilabelStratifiedKFold plot_feature_images plot_embed_2D feature_density_matrix pyplot pyplot as plt _calculate_coords plot_class_feature_images iterstrat.ml_stratifiers KernelPCA pixels numpy seaborn sklearn.manifold plot_feature_density ConvexHull PCA transform matplotlib.pyplot pandas scipy.spatial fit LogScaler matplotlib DeepInsightTransformer __init__ TSNE sklearn.decomposition tsne_transform fit_transform _minimum_bounding_rectangle ", "entities": "(('similarity', 'cosine distance'), 'estimate') (('Norm 2 NormalizationAgain raw features', '0'), 'normalize') (('effect', 'perplexity'), 'study') (('I', 'Action'), 'publish') (('feature Finally raw values', 'feature map image'), 'map') (('com alok', 'norm 2 normalization'), 'ai') (('you', 'Reading'), 'source') (('which', 'memory footprint weight effective sharing'), 'transform') (('here resolution', '50'), 'set') (('Most', 'ImplementationCheckout DeepInsight paper supplementary more details'), 'give') (('rotation', 'horizontal form'), 'use') (('You', 'features e.'), 'separate') (('visual output', 'embeddings feature space'), 't') (('which', 'lossy compression'), 'note') (('rotation', 'box'), 'apply') (('typical values', '5'), 'set') (('kind', 'data augmentation creative Mixup'), 'open') (('generation', 'preprocessed data'), 'rely') (('minimum box', 'features'), 'apply') (('Plot image matrix', 'class cmap given hot'), 'py') (('_', 'feature overlaps the greater _'), 'seem') (('outlook', 't SNE'), 'demonstrate') (('Visualization', 'different resolutions'), 'visualize') (('com 019 47765 6The authors', 'positive results'), 'article') (('we', 'MoA target different classes'), 'dna_inhibitorin') (('feature raw values', 'image'), 'Resolution') (('features', 'transformation 5 deepinsight process'), 'choose') (('notebook', 'Convolutional Neural Networks'), 'Transforming') (('we', 'them'), 'see') (('following diagram', 'key steps'), 'outline') (('only first fold', 'demonstration'), 'label') (('N we', 'complex relationships'), 'be') (('more features', 'pixel same location'), 'cause') (('you', 'models'), 'be') (('it', 'transformation part'), 'be') (('Here we', 'top 1'), 'select') (('features', '0'), 'normalize') (('therefore minor adjustments', 'feature normalization'), 'viability') (('s', 'same classes'), 'let') "}
{"name": "g2net searching the sky pytorch effnet w meta ", "full_name": " h1 Searching the Sky Explore Understand h1 1 Introduction h3 Libraries h3 Custom Functions h1 2 The Data h2 2 1 The Target is there a black hole h2 2 2 The npy files h1 3 u200d Explore h2 3 1 The Gravitational Waves h3 GW when there is NO signal present h3 GW when there IS a signal present h2 3 2 Signals in time h2 3 3 The MEL Spectrogram h3 Sample h3 GW Signals Spectrogram With Target vs No Target h2 3 4 nnAudio h1 4 Basic Feature Engineering Site Comparisons h2 4 1 In depth analysis h3 Overall Means h3 Overall Minim and Maxim h1 PyTorch EffNet Model Feature Metadata h3 Competition Metric h3 More Libraries Functions h1 5 u200d PyTorch Dataset h3 Test the Dataset function h1 6 PyTorch EfficientNet h3 How it works h1 7 Training h2 7 1 Training Function h3 Full Training Function below h2 7 2 Experiments h3 W B Dashboard h1 8 Submission h3 Submission h1 My Specs ", "stargazers_count": 0, "forks_count": 0, "description": "You can find my W B Dashboard here https wandb. We start the training loop epochs train on the training data model. Steps to submission Retrieve the pretrained model s Create a new Dataset Dataloader careful here you don t have the target anymore Predict using the trained models Blend the predictions if you want into a final output Submit Have a snack you re done Submission Note For the purpose of this notebook running faster I ll make the prediction on only the first 20 observations within the test data. As a summary First we initiate a new W B experiment where we store all the hyperparameters we ll be using this way we know how to reproduce everything afterwards. 0001 weight_decay 0. Note This function will be used to quickly and efficiently convert the signals from the 3 sites to spectrograms. Below is a sample example the goal is tu have the Area Under the Curve AUC be as big as possible meaning that the line should aim to be as closer to the X and Y axis as possible. 3 The MEL Spectrogram What is a Spectrogram A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. factor LOOP TRAIN EVAL UPDATES class VAR name 60k_samples splits 3 epochs 2 batch_size 64 no_neurons 250 lr 0. head 20 line to get the full prediction which is save within my G2net dataset as well. SubmissionWe re at the end of the line folks I ve put here a simple submission code for this notebook. 1 The Gravitational WavesLet s take a look at the Gravitational Waves and see what insights we can find about them before starting creating an actual model. 4 nnAudio nnAudio is an audio processing toolbox using PyTorch CNN as its backend. List of all metrics we want to compute for each site Create empty columns of the metrics Compute for each ID these metrics First extract the cronological info For each site compute the metrics Add it to the dataframe Process the entire data This took a while and cannot be done in the Kaggle Environment So I made it locally processed get_site_metrics df train_df processed. 000001 patience 1 factor 0. Note You can notice that it is very hard to observe any kind of difference between the images as the fluctuation is so unperceptable by the naked eye. Competition Goal detect GW Gravitational Wave signals from the mergers of binary black holes from simulated GW time series data created from a network of Earth based detectors. Let s get started Libraries Note If this line throws an error try using wandb. SampleFirst let s look at how the function above works on a simple sample from the data. 1 In depth analysis Overall Means Note We can now explore the means of all observations per site and the differences between them. Then we split the data into folds For each fold We initiate a G2Dataset the model loss criterion optimizer etc. Bonus I added the features from the 3 sites too on a later iteration now we can use the additional information for better serults. lr weight_decay VAR. ROC is a probability curve and AUC represents the degree or measure of separability. Higher the AUC the better the model is at predicting the classes. csv index False Import the data with basic features Save data to W B Dashboard Plot Separate minim maxim values Plot Images End this experiment Libraries Generate Sample Dataset no skill prediction Fit Ensemble Predict probabilities Comparison Plot Set FUNCTIONS Create an image with 3 channels for the 3 sites Load the numpy file Create the spectrograms Select the features Return the images target if available Sample Initiate the Dataset Initiate the Dataloader Output of the Dataloader NN for the spectrogram out layer 2560 NN for the features Final NN for classification Combination of spectrogram features Spectrogram Features Combine Layers Create an example model Effnet We ll use previous datasets dataloader example for 1 batch Outputs Criterion Unsqueeze 1 from shape 3 shape 3 1 W B Experiment CV Split To go quicker through validation Datasets Dataloader Model Optimizer Criterion Scheduler scheduler ReduceLROnPlateau optimizer optimizer mode max verbose True patience VAR. Haven t done some proper artistic EDA in a while and the theme of this competition is absolute perfection. We have 560 000 observation x 3 sites x 4 096 time series length 6 881 280 000 that s 6 billion datapoints. Besides the bigger values between Site1 Site2 vs Site3 the distributions look very similar and uniform. weight_decay sample VAR. What is a Mel Spectrogram A mel spectrogram is a spectrogram where the frequencies are converted to the mel scale. The length of 4096 spans for 2 seconds and it is sampled at 2 048 Hz. splits batch_size VAR. This class is also helpful within the Dataloader tool so we can iterate through multiple files at once. This is how they look 6. train we compute the loss and then optimize evaluate how the model did model. My Specs Z8 G4 Workstation 2 CPUs 96GB Memory NVIDIA Quadro RTX 8000 Zbook Studio G7 on the go CSS STYLE Libraries Librosa Environment check Secrets Custom colors Set Style Read in the training data Print some useful information Save data to W B Dashboard Create W B Plot Add info about total number of observations Get the full paths to the files and create a df Append the full path as a new column Get a sample data with TARGET 0 Plot Get a sample data with TARGET 1 Plot Target Sample No Target Sample size 6. to_csv training_labels_features. This frequency warping can allow for better representation of sound. 1 Training FunctionUsually this part can get quite long and weird this is why I usually choose to visualize it with a schema so I can better know at a later date what I did here. com KinWaiCheuk nnAudio. Overall Minim and Maxim PyTorch EffNet Model Feature Metadata Competition Metric AUC ROC curve is a performance measurement for the classification problems at various threshold settings. However these diferences are very tiny. Nakama and his notebook here from where I took my inspiration to use this library. Searching the Sky Explore Understand 1. ai andrada g2net workspace user andrada Below is a sneak peak of the dashboard 8. batch_size no_neurons VAR. com headsortails when stars collide g2net eda. csv file contains the file id and the target meaning a flag that is 0 if there is no signal 1 is there is any signal 2. 1 The Target is there a black hole Note The targets are splitted almost 50 50. Basic Feature Engineering Site ComparisonsNow let s see some differences similarities between our 3 main sites LIGO Hanford LIGO Livingston and VIRGO. PyTorch DatasetFirst we must create the PyTorch Dataset which will be a class that will take the paths and targets compute the numpy arrays spectrograms and return the result. or CQT kernels can be trained more info on this pachage here https github. Note Keep in mind this data is becoming pretty big. More Libraries Functions 5. This is because the data itself is simulated so there s the benefit that you can purposely simulate a black hole as many times as you want. npy files Note The simulated GW Gravitational Waves are coming from 3 different Observatories LIGO Hanford below in purple LIGO Livingston below in yellow VIRGO below in greenOK Each file has a shape of 3 4096 meaning 3 different GW coming from the 3 sites around the globe of a length of 4096. 2 Experiments W B DashboardYou can check the evolution of the experiments here https wandb. 01 sample 60000 train_effnet name VAR. GW when there IS a signal present The distributions look similar however there is some more fluctuation at the peak of density and and the extremes especially for Site 2. Why should we use it In sound processing the mel frequency cepstrum MFC is a representation of the short term power spectrum of a sound based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. How it works Goooood Let s see how it works Below is a schema to help you better grasp how the model works 7. To do that we are going to take some basic metrics and compute them for each observation and site mean std var min mode max 4. eval Compute a roc_auc score and if better than the last one we save the model Repeat Full Training Function below 7. 2 Signals in timeOk now we can look at how these waves look in time comparing the 3 sites we already know and are familiar with LIGO Hanford LIGO Livingston and VIRGO. It will ask for the API key to login which you can get from your W B profile https wandb. ai site click on Profile Settings scroll to API keys. GW Signals Spectrogram With Target vs No TargetGood Looks nice Now we can do a proper comparison between a few samples that contain the Target Signal vs samples that don t. sample TEST CELL runs faster Sample submission containing extracted features Retrieve all pretrained models Test Dataset Dataloader Loop Disable gradients Predict with each of the 3 models Blend the predictions TODO make KFold Validation DONE TODO Change graph representation DONE TODO create train function DONE TODO create schema for train function DONE TODO preprocess submission data DONE TODO train on more data submit with model DONE TODO dataset add spectrogram augmentation. GW when there is NO signal present The 3 sites have fairly similar distribution with the third one having fewer outliers than the rest. The signals with no target have bigger fluctuations while the other ones have smaller more consistent ones. Special thanks to Y. However as the description tells us signals of black holes are very rare. The DataThe training_labels. com headsortails did in his notebook right here https www. with a B Hence I will rename these 3 as Site1 Site2 and Site3 like the one and only Heads or Tails https www. Note There are indeed some differences that can be seen a bit more clear than by looking only at histograms. Convert a power spectrogram amplitude squared to decibel dB units Get the spectrogram Plot it Samples per category Sample 6 paths with target and no target available Plot Enumerate plot Save to W B This function is to calculate the CQT of the input signal. Test the Dataset function Good Now that we ve created our Dataset class we can test it by using a simple sample of 4 observations 4 distinct paths pointing to the numpy arrays split in 2 batches of size 2 4 distinct targets which are the labels of these paths Note I am also lotting here the 3 channel spectrogram that is created from the 3 sites hence we re making 1 image with 3 channels instead of 3 images with only 1 channel. IntroductionUiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii I was hoping to have some fun with a notebook. PyTorch EfficientNetNow we need to create a Module class which will help us take the output from the Dataset class and train it to predict out target variable. ai andrada g2net workspace user andrada Custom Functions 2. By doing so spectrograms can be generated from audio on the fly during neural network training and the Fourier kernels e. 3e20 Plot Images Get the waves from the 3 sites Loop and make spectrogram Compute a mel scaled spectrogram. ", "id": "andradaolteanu/g2net-searching-the-sky-pytorch-effnet-w-meta", "size": "9865", "language": "python", "html_url": "https://www.kaggle.com/code/andradaolteanu/g2net-searching-the-sky-pytorch-effnet-w-meta", "git_url": "https://www.kaggle.com/code/andradaolteanu/g2net-searching-the-sky-pytorch-effnet-w-meta", "script": "torch.nn.functional G2Dataset(Dataset) matplotlib.image get_site_metrics DataLoader train_test_split IPython.core.display torch.autograd css_styling OffsetImage nnAudio.Spectrogram numpy melspectrogram seaborn _show_on_single_plot create_wandb_hist make_classification Adam torch.cuda.amp set_seed CQT1992v2 sklearn.datasets VAR show_values_on_bars nn model_selection as sk_model_selection save_dataset_artifact tqdm roc_auc_score EfficientNet create_nnAudio_graph matplotlib.patches matplotlib.offsetbox get_npy_df Variable ReduceLROnPlateau sklearn StratifiedKFold plot_loss_graph __transform__ G2EffNet(nn.Module) matplotlib.pyplot kaggle_secrets get_auc_score AnnotationBbox forward sklearn.model_selection pandas autocast librosa.feature matplotlib.gridspec RandomForestClassifier roc_curve GradScaler train_effnet color efficientnet_pytorch torch.optim model_selection matplotlib torch.utils.data __len__ HTML pylab UserSecretsClient create_wandb_plot make_spectrogram Dataset __init__ torch offset_png sklearn.metrics __getitem__ sklearn.ensemble text torch.optim.lr_scheduler ", "entities": "(('com when stars', 'g2net eda'), 'headsortail') (('mel frequency cepstrum MFC', 'frequency'), 'use') (('ROC', 'separability'), 'be') (('better how model', '7'), 'work') (('faster I', 'test data'), 'step') (('function', 'spectrograms'), 'note') (('We', 'training data model'), 'start') (('distributions', 'bigger values'), 'look') (('I', 'what'), '1') (('GW when signal distributions', 'especially Site'), 'look') (('we', 'std var'), 'go') (('when 3 sites', 'rest'), 'gw') (('theme', 'competition'), 'do') (('data', 'Note mind'), 'keep') (('CQT kernels', 'https here github'), 'train') (('here where I', 'library'), 'Nakama') (('TODO', 'spectrogram augmentation'), 'run') (('frequency warping', 'sound'), 'allow') (('signals', 'black holes'), 'tell') (('280 6 881 000 that', '560 000 observation'), 'have') (('fluctuation', 'so naked eye'), 'note') (('0 Plot', 'TARGET'), 'NVIDIA') (('hence we', 'instead 3 only 1 channel'), 'test') (('com headsortails', 'https right here www'), 'do') (('model', 'classes'), 'high') (('optimize then how model', 'model'), 'compute') (('spectrogram Compute', 'sites 3 Loop'), 'get') (('that', 'samples'), 'Spectrogram') (('which', 'G2net dataset'), 'head') (('that', 'file'), 'contain') (('it', '2 048 Hz'), 'sample') (('we', 'Repeat Full Training 7'), 'Compute') (('Overall We', 'them'), '1') (('Overall EffNet Feature Metadata Competition Metric AUC ROC curve', 'threshold various settings'), 'Minim') (('we', 'actual model'), '1') (('W B Experiment CV validation Datasets Dataloader Model Optimizer Criterion scheduler ReduceLROnPlateau optimizer optimizer mode 3 3 1 quicker Scheduler max', 'patience True VAR'), 'Import') (('us', 'target variable'), 'EfficientNetNow') (('model loss criterion optimizer', 'G2Dataset'), 'split') (('I', 'notebook'), 're') (('line', 'as X'), 'be') (('we', 'multiple files'), 'be') (('Experiments W B 2 DashboardYou', 'experiments'), 'check') (('how function', 'data'), 'let') (('we', 'how everything'), 'know') (('df train_df', 'locally get_site_metrics'), 'create') (('Competition Goal', 'Earth'), 'detect') (('IntroductionUiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii I', 'notebook'), 'hope') (('ai workspace user g2net Below', 'sneak dashboard'), 'andrada') (('other ones', 'smaller more consistent ones'), 'have') (('Hence I', 'Site1 Site2'), 'rename') (('line', 'wandb'), 'let') (('Hanford', 'Livingston'), 'let') (('it', 'time'), '3') (('as many times you', 'purposely black hole'), 'be') (('3 different GW', '4096'), 'file') (('Hanford', 'Livingston'), 'signal') (('so spectrograms', 'network neural training'), 'generate') (('where frequencies', 'mel scale'), 'be') (('nnAudio 4 nnAudio', 'backend'), 'be') (('you', 'W B profile https wandb'), 'ask') (('function', 'input signal'), 'get') (('factor LOOP TRAIN EVAL UPDATES class VAR 60k_samples', '3 epochs'), 'name') (('You', 'W B Dashboard'), 'find') (('now we', 'better serults'), 'add') (('targets', 'result'), 'create') (('indeed that', 'bit more only histograms'), 'note') "}
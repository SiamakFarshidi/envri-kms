{"name": "hubmap efficientnet and linknet train ", "full_name": " h1 Versions h1 Refferences h1 tpu h1 todo h1 Init parameters packages gcs paths tpu h2 GCS PATHS h1 Datasets pipeline h1 Model h1 Model fit ", "stargazers_count": 0, "forks_count": 0, "description": "com baesiann glomeruli hubmap external 1024x1024 v60 tuning params for optimizer adam look forward v64 tpu tensorboard for analysis only find tpu profiler for gcp Refferences 1. Versions V1 V3 efficientnetb4 unet v4 efficientnetb0 linknet dce_jacobian loss v5 efficientnetb0 unet bce_jacobian v6 v8 add guassian data augmentation v14 efficientnetb0 unet 256 tiles v15 efficientnetb0 linknet v9 fix shuffbug v10 v49 try to find best learning rate for batchsize 1024 is about 1e 3 to 5e 4 version 43 best backbone is efficientnet b2 due to image resolution gpu with batchsize 32 run over 9 hours limit in version 48 v50 read paper and try more loss function v54 add extennal data https www. com tensorflow tensorflow issues 38762 tpu traning guide1. ipynb tpu Issue tpu doesn t support numpy_function 1. com wrrosa hubmap tf with tpu efficientunet 512x512 train training pipeline 3. com vgarshin kaggle_kidney blob master kidney_train. org guide distributed_training todo 1. image to tf sequence layer https www. \u5c1d\u8bd5\u591a\u79cdloss https github. tf \u7684\u7279\u6027 \u6d41\u7684\u6982\u5ff5 session \u7684\u6982\u5ff5 \u7ef4\u5ea6\u5bf9\u9f504. com JunMa11 SegLoss Init parameters packages gcs_paths tpu GCS_PATHS Datasets pipeline Model Model fit. issue https github. org tutorials images data_augmentation resizing_and_rescaling2. com wrrosa hubmap tf with tpu efficientunet 512x512 subm inference with submission 4. com wrrosa hubmap tf with tpu efficientunet 512x512 tfrecs how to create training and inference tfrecords 2. \u8bed\u8a00\u7279\u6027 tf \u7279\u6027 \u548c np \u7684\u5dee\u5f02 3. com vgarshin kidney unet model keras inference scriptVersionId 58536838 and https github. org guide data_performance2. ", "id": "drzhuzhe/hubmap-efficientnet-and-linknet-train", "size": "1860", "language": "python", "html_url": "https://www.kaggle.com/code/drzhuzhe/hubmap-efficientnet-and-linknet-train", "git_url": "https://www.kaggle.com/code/drzhuzhe/hubmap-efficientnet-and-linknet-train", "script": "tversky_loss _parse_image albumentations tensorflow_addons load_dataset get_training_dataset kaggle_datasets functools numpy _parse_image_function tversky bce_dice_loss backend as K aug_fn dice_coe KaggleDatasets tensorflow tensorflow.keras.utils KFold tensorflow_datasets matplotlib.pyplot backend sklearn.model_selection pandas count_data_items get_validation_dataset datetime focal_tversky_loss partial get_custom_objects tensorflow.keras dice_loss segmentation_models.losses bce_jaccard_loss segmentation_models ", "entities": "(('loss function more v54', 'data https extennal www'), 'add') (('tpu ipynb Issue', 'tpu t numpy_function'), 'support') (('com wrrosa hubmap', 'train training pipeline'), '512x512') (('gcs_paths', 'packages'), 'parameter') (('com baesiann glomeruli 1024x1024 v60 tuning hubmap external params', 'gcp Refferences'), 'find') "}
{"name": "house price predict decision tree random forest ", "full_name": " h3 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "Though there remains other regression model which can bring out the best of the dataset. Dataset contains Id a notation for a house Date Date house was sold Price Price is prediction target Bedrooms Number of Bedrooms House Bathrooms Number of bathrooms House Sqft_Living square footage of the home Sqft_Lot square footage of the lot Floors Total floors levels in house Waterfront House which has a view to a waterfront View Has been viewed Condition How good the condition is Overall Grade overall grade given to the housing unit based on King County grading system Sqft_Above square footage of house apart from basement Sqft_Basement square footage of the basement Yr_Built Built Year Yr_Renovated Year when house was renovated Zipcode Zip Lat Latitude coordinate Long Longitude coordinate Sqft_Living15 Living room area in 2015 implies some renovations This might or might not have affected the lotsize area Sqft_Lot15 lotSize area in 2015 implies some renovations Null Value Detection Let s Check for null values in the dataset Finding Unique Values From the above it is clear that the dataset have no null values present so lets check how many unique values is present for each feature. Dropping of the particular column value We don t require the column id and date at this point so we will be dropping them from the dataset. ConclusionFrom the above it is clear that random forest accuracy is 88 and also expalined variance score is 0. Data Visulaization using seaborn So all the column data remains the same except the two column is dropped. View the modified dataset Let s now again view the dataset using the same head command we used earlier. Check whether there is any null values Lets find out how many unique values are present in each column X Independent variables and y target variables Splitting the data into train test data Let s have a tabular pandas data frame for a clear comparison. The below will give us the 5 record of our dataset. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. So Random Forest is a suitable model for predicting the price of the house. We will loop through the dataset for checking the unique values present. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. Since we have loaded the data now we will read our data. Let s now forward with data visualization using a pairplotFrom the above plot it is clear for a linear regression for sqft_living price So lets plot them in a joint plot to explore more on the data. First 5 rows of data. Please upvote if you like my work this motivates me to work better This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. read_csv Input data files are available in the. Load the Data Let s import the kc_house_data. Co relation between Variables We wil use heatmap to view the co relation between variables Model on the train data We will start building our model using different regression models Multiple Linear Regression Fitting the train set to multiple linear regression and getting the score of the model Decision Tree Random Forest Regression Model Calculate Model Score Let s calculate the model score to understand how our model performed along with the explained variance score. I will name the variable as dataset. ", "id": "subhradeep88/house-price-predict-decision-tree-random-forest", "size": "3083", "language": "python", "html_url": "https://www.kaggle.com/code/subhradeep88/house-price-predict-decision-tree-random-forest", "git_url": "https://www.kaggle.com/code/subhradeep88/house-price-predict-decision-tree-random-forest", "script": "seaborn sklearn.linear_model explained_variance_score matplotlib.pyplot train_test_split LinearRegression sklearn.metrics confusion_matrix sklearn.model_selection pandas DecisionTreeRegressor sklearn.ensemble sklearn.tree RandomForestRegressor numpy ", "entities": "(('column So data', 'two column'), 'Visulaization') (('how many unique values', 'feature'), 'contain') (('forest random accuracy', 'variance also score'), 'ConclusionFrom') (('we', 'head same command'), 'view') (('So lets', 'data'), 'let') (('It', 'python docker image https kaggle github'), 'upvote') (('so we', 'dataset'), 'drop') (('s', 'clear comparison'), 'check') (('regression other which', 'dataset'), 'remain') (('We', 'unique values'), 'loop') (('now we', 'data'), 'read') (('s', 'kc_house_data'), 'load') (('you', 'output'), 'list') (('how model', 'variance explained score'), 'relation') (('read_csv Input data files', 'the'), 'be') (('Random So Forest', 'house'), 'be') (('below', 'dataset'), 'give') "}
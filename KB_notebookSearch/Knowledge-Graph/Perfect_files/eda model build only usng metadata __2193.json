{"name": "eda model build only usng metadata ", "full_name": " h3 Libraries h3 User Defined Functions h3 Import Data h4 1 records and features h4 How does each of the datasets look like h4 train dataset h4 test dataset h4 submission dataset h4 Let s check the unique values in the targets of training and submission datasets h3 EDA h4 Target Class Distribution h4 Gender Distribution h4 anatom site general challenge Distribution h4 Age Distribution of Patients according to target h3 Data Preprocessing h4 Let s check the null values h4 Missing Values h4 Imputation h4 Categorical Feature Handling h2 Feature Selection h3 Training Validation Test Data Preparation h3 Imbalanced Data Handling h4 Oversampling h4 Undersampling h4 Training Validation data split h3 Model Build h4 Random Forest h4 Cross Validation h4 XGBoost Model h4 Cross validation score h3 Predictions h3 Work in Progress h4 Future Work h2 Upvote if you find this useful ", "stargazers_count": 0, "forks_count": 0, "description": "Libraries User Defined Functions Import Data 1. So while building any algorithm we will not be able to use these 2 features. I will try to make as small as possible the validation set as 33k records are there in training dataset. shape define undersampling strategy print X_under. isnull sex df_test sex. sex Imputation Training Data Test Data Categorical Feature Handling Training Data Test Data Feature Selection Training Validation Test Data Preparation We need to prepare a validation set for simple baseline accuracy calculation. Label Encoding feature set dependent and independent features of training and test datasets define oversampling strategy print X_over. median inplace True sex_array df_test df_test sex. Will try after running the baseline model Gender Distribution Train data consists a very balanced gender distribution of patients. anatom_site_general_challenge 2. Let s check the unique values in the targets of training and submission datasets target values in training dataset looks good and in submission each and every image is assumed as benign. shape Oversampled train and validation split Undersampled train and validation split Insample train and validation split Random Forest Model Parameters used by the current forest cv_auc cross_val_score rf_base_model x_val y_val cv 5 scoring roc_auc print AUC scores computed using 5 fold cross validation. records and features Need to analyse how more than 1 feature is less in test data than in training data. Tune model Upvote if you find this useful Basic numerical and other libraries Display option Handle warnings during execution of code Datetime Visulisation statsmodel Imbalanced Data Handling sklearn xgboost lightgbm Calculate the percentage of target 1 per category value shape of training test and submission data training dataset submission dataset Gender Distribution anatom_site_general_challenge Distribution Age Distribution of Patients according to target Calculate missing value count and percentage Calculate missing value count and percentage Replace age with median Replace sex and anatom_site_general_challenge with mode Replace age with median for test data age_array df_test df_test age_approx np. shape print y_under. Imbalanced Data Handling Oversampling Undersampling Training Validation data split Oversampled Undersampled Insample Without imbalanced class treatment Model Build Random Forest Cross Validation XGBoost Model Cross validation score Predictions Work in Progress Future Work 1. We may use some sampling techniques to treat the class imbalance. predict X_test Compute cross validated AUC scores cv_auc df_sub target list rf_pred_test. nan age_approx df_test age_approx. submission dataset Here we may need to replace target with the predicted values from the trained model. Our job is to predict the probability of an image being malignant. Label Encoding Need to convert the datatypes of the feature to category before Label encoding. values 0 inplace True Unique values for feature sex Need to convert the datatypes of the feature to category before Label encoding. anatom_site_general_challenge Distribution Age Distribution of Patients according to target This can help in distinguishing between benign and malignant as median is less for benign Data Preprocessing Let s check the null values Missing Values Training Data Test Data we need to impute these 3 features 1. shape print y_over. format cv_auc fit model no training data y_pred xgb_model. EDA Target Class Distribution Huge Class imbalance is there. How does each of the datasets look like train dataset test dataset diagnosis and benign_malignant are missing in test dataset. ", "id": "ashutosh3060/eda-model-build-only-usng-metadata", "size": "2193", "language": "python", "html_url": "https://www.kaggle.com/code/ashutosh3060/eda-model-build-only-usng-metadata", "git_url": "https://www.kaggle.com/code/ashutosh3060/eda-model-build-only-usng-metadata", "script": "imblearn.under_sampling plot_stats train_test_split IPython.display LeaveOneOut statsmodels.stats.outliers_influence stats xgboost numpy cross_val_score XGBClassifier seaborn imblearn.over_sampling tree roc_auc_score RandomOverSampler scipy sklearn auc get_rocauc RandomUnderSampler StratifiedKFold KFold matplotlib.pyplot timedelta statsmodels.api sklearn.model_selection pandas datetime RandomForestClassifier roc_curve pprint statsmodels.discrete.discrete_model RandomizedSearchCV variance_inflation_factor display HTML GridSearchCV sklearn.metrics sklearn.ensemble ", "entities": "(('Imbalanced Data Handling', 'Progress Future Work'), 'oversample') (('sex Imputation Training Data Test Categorical Feature Handling Training Data Test Data Feature Selection Training Validation Test Data We', 'baseline accuracy simple calculation'), 'Data') (('Display option Handle warnings', 'test data age_array'), 'Upvote') (('We', 'class imbalance'), 'use') (('How each', 'test dataset'), 'look') (('Label Encoding feature', 'test strategy oversampling print'), 'set') (('as possible validation', 'training there dataset'), 'try') (('we', '3 features'), 'Distribution') (('how more than 1 feature', 'training data'), 'record') (('submission Here we', 'trained model'), 'dataset') (('job', 'image'), 'be') (('AUC scores', 'cross 5 fold validation'), 'shape') (('Compute X_test cross', 'AUC scores cv_auc df_sub target list rf_pred_test'), 'predict') (('image', 'submission'), 'let') (('we', '2 features'), 'be') "}
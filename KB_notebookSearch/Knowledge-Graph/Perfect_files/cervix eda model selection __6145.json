{"name": "cervix eda model selection ", "full_name": " h1 Cervix EDA h2 Image types h2 Image dimensions h1 TSNE embedding h3 3D t SNE with cervix indicators h1 Image clustering with TSNE embedding h1 Clustering of pairwise image distances h1 Image neighbourhood h1 Model Selection h2 Confusion matrix h2 Confusion matrix on training set ", "stargazers_count": 0, "forks_count": 0, "description": "Cervix EDAIn this competition we have a multi class classification problem with three classes. For the multi class problem we are faced with here we ll use standard approach of OVR one vs rest meaning we will train three models where each of them is designed to distinguish class 1 2 and 3 from the others respectively. The images seem to vary alot in they formats the first two samples have only a circular area with the actual image the last sample has the image in a rectangle. normalize each uint8 image to the value interval 0 1 as float image rgb to gray downsample image to rescaled_dim X rescaled_dim L2 norm of each sample 1 pca translate each sample to its color upper triangle of matrix set to np. For that we ll use scipy s pdist method. This decision is very important for the healthcare provider and critical for the patient. These different types of cervix in our data set are all considered normal not cancerous but since the transformation zones aren t always visible some of the patients require further testing while some don t. From the data description In this competition you will develop algorithms to correctly classify cervix types based on cervical images. Image clustering with TSNE embeddingLet us now use the compressed images and the distance preserving transformation of TSNE to get an understanding of what image clusters there are. Confusion matrix on training setLooking at the train confusion matrix we can see that we almost only predict class 1. The image on the left has quite a lot of blue in it which I would not expect to be present in the majority of samples. This will result in a matrix where each row are all flattened pixel for the grayscale images. The yellow somewhat clustered area tells us there are a few images that have relatively high distance to all other images in the sample of our training images we read. Lets first count them for each class. Let us first see how many images there are for each cervix type and which file types they have. fit_transform gray_imgs_mat. For that we will use matplotlib to replace the previously red green and blue points with the actual images that were input to the TSNE transformation. 3D t SNE with cervix indicatorsNow let s project the 100x100x3 images to three dimensions to check for low dimensional patterns. Model SelectionNow that we ve established a basic idea about the data let s do the most straightforward approach where we take the resized color images and labels and train a most likely quite heavily regularized linear model like logistic regression on it. Image neighbourhoodGiven the pool of cervix images and the similarity matrix above we will now plot the extrem cases of the similarity matrix. On the left and top of the clustermap we find one of three colors for each row and column this color indicates the type of cervix. To do that we find the image that has maximal distance on average compared to the all other images minimal distance on average compared to the all other imagesand compare both candidates to the mean image from out set of images. Per default each image will now keep its RGB information and therefore will be transformed to a 100 100 3 30. nan maximally dissimilar image maximally similar image now compute the mean image no need for normalizing we already did this earlier Normalizer. We are asked given an image to identify the cervix type. Image dimensionsNow in order to get an idea of how many different shapes of images by class there are lets have a look at. Clustering of pairwise image distancesTo get a different view of how images relate to each other from a purely numerical point of view lets now look at pairwise distances. Now lets read the files for each type to get an idea about how the images look like. Also we are giving only very few images per class that TSNE can work with to find a good distance preserving embedding. I think it is a good representation of maximally dissimilar. To be able to cope with that we ll most likely end up using L1 regularization. The original images have as we have seen earlier quite a high resolution so scaling them down to 100 x 100 is resulting in a great loss of information so the embedding to two dimensions is likely not going to have a good structure where we can separate visually by cervical cancer types. To reduce runtime take only a subsample per class. All of the images in our sample have three channels we can ignore this information for now. We can clearly see that there is a big heterogeneous cluster and a few quite distant outliers. It is quite important to understand that we only have read a few training instances 108 and have thousands of dimensions. I ve added the option to choose to convert them to grayscale before passing them to TSNE. We can see that our models have a great problem with confusing class zero with class two. Identifying the transformation zones is not an easy task for the healthcare providers therefore an algorithm aided decision will significantly improve the quality and efficiency of cervical cancer screening for these patients. In this notebook we will be looking at basic dataset stats like number of samples per class image sizes different embeddings of RGB image space pairwise distances and a clustermap of images in RGB space linear model selection with basic multi class evaluation metrics. Type 1 Red Type 2 Green Type 3 BlueHere is the unclustered distance matrix. Confusion matrixThe confusion matrix is a standard analysis tool in binary and multi class classification where in each entry C_ i j corresponds to the number of samples that have true class label i and are predicted as j. Image typesNow that we have the data in a handy dataframe we can do a few aggregations on the data. If you like this kernel please give an upvote thanks We are given training images for each of cervix types. All files are in JPG format and Type 2 is the most common one with a little bit more than 50 in the training data in total Type 1 on the other hand has a little bit less than 20 in the training data. The submission format is asking for a probability for each of the three different cervix types. Now lets build a barplot to get an idea of the distribution of image dimensions by cervix type. 000 dimensional vector. TSNE embeddingWe will now take all of the sample images rescale them convert them to grayscale. ", "id": "philschmidt/cervix-eda-model-selection", "size": "6145", "language": "python", "html_url": "https://www.kaggle.com/code/philschmidt/cervix-eda-model-selection", "git_url": "https://www.kaggle.com/code/philschmidt/cervix-eda-model-selection", "script": "transform_image train_test_split confusion_matrix imscatter squareform OffsetImage numpy seaborn preprocessing subprocess Normalizer sklearn.manifold glob imread matplotlib.offsetbox sklearn sklearn.linear_model scipy.spatial.distance plotly.tools skimage.io matplotlib.pyplot AnnotationBbox plotly.offline plotly.graph_objs pandas defaultdict sklearn.model_selection pdist LogisticRegression imshow TSNE check_output LabelEncoder GridSearchCV sklearn.metrics collections sklearn.preprocessing ", "entities": "(('quite we', 'dimensions'), 'be') (('reduce', 'class'), 'take') (('We', 'cervix type'), 'ask') (('I', 'samples'), 'have') (('s', 'low dimensional patterns'), 'let') (('that', 'TSNE transformation'), 'use') (('that', 'images'), 'find') (('2 most common one', 'training data'), 'be') (('now all', 'grayscale'), 'take') (('we', 'data'), 'typesNow') (('we', 'already earlier Normalizer'), 'compute') (('we', 'training images'), 'tell') (('we', 'L1 most likely regularization'), 'end') (('We', 'cervix types'), 'give') (('color', 'cervix'), 'find') (('that', 'j.'), 'be') (('decision', 'patient'), 'be') (('we', 'class evaluation basic multi metrics'), 'look') (('competition we', 'three classes'), 'cervix') (('how images', 'pairwise now distances'), 'get') (('Now lets', 'cervix type'), 'build') (('always some', 'further testing'), 'consider') (('images', 'how'), 'read') (('submission format', 'cervix three different types'), 'ask') (('where we', 'cancer visually cervical types'), 'have') (('similarity we', 'similarity matrix'), 'neighbourhoodgiven') (('you', 'cervical images'), 'develop') (('image', 'therefore 100 100 3 30'), 'keep') (('where each', '1 2 others'), 'use') (('I', 'TSNE'), 'add') (('therefore algorithm aided decision', 'patients'), 'be') (('they', 'file types'), 'let') (('where row', 'grayscale images'), 'result') (('us', 'understanding'), 'use') (('we', 'almost only class'), 'matrix') (('where we', 'it'), 'SelectionNow') (('last sample', 'rectangle'), 'seem') (('we', 'information'), 'have') (('models', 'class'), 'see') (('lets', 'look'), 'dimensionsnow') (('it', 'good maximally dissimilar'), 'think') (('TSNE', 'embedding'), 'give') "}
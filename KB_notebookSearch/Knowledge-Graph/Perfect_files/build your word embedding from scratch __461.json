{"name": "build your word embedding from scratch ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. linear algebra data processing CSV file I O e. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. read_csv Input data files are available in the. read_csv Split train in train and validate evaluate the model evaluate the model stands for background positive subgroup negative stands for background negative subgroup positive. Tutorial to build a word embedding from scratch Preparing the data Tokenization Creating word embedding Evaluation on a local test with Jigsaw s metric Predict test set Process to prepare the data Tokenization Create my own word embedding Look at the loss and the gain in accuracy for each epochRun final model with the right number of iteration Test my word embedding on my local test with Jigsaw metric Apply the model on the test This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. ", "id": "francoisdubois/build-your-word-embedding-from-scratch", "size": "461", "language": "python", "html_url": "https://www.kaggle.com/code/francoisdubois/build-your-word-embedding-from-scratch", "git_url": "https://www.kaggle.com/code/francoisdubois/build-your-word-embedding-from-scratch", "script": "optimizers keras.engine TweetTokenizer lightgbm keras.layers Activation keras.preprocessing.sequence train_test_split keras.models gensim.models keras callbacks compute_bias_metrics_for_model GlobalAveragePooling1D compute_subgroup_auc nltk.tokenize cross_val_score numpy initializers Adam TfidfVectorizer Dropout SpatialDropout1D Word2Vec compute_bpsn_auc BatchNormalization Dense sklearn.feature_extraction.text regularizers Bidirectional backend as K pad_sequences layers GlobalMaxPooling1D Tokenizer Embedding calculate_overall_auc add LSTM keras.optimizers sklearn Layer CuDNNGRU tensorflow CuDNNLSTM Add matplotlib.pyplot Sequential backend metrics set_random_seed sklearn.model_selection pandas load_model InputSpec keras.preprocessing.text Model compute_auc concatenate get_final_metric Input power_mean constraints seed_everything sent_tokenize compute_bnsp_auc Conv1D word_tokenize MaxPooling1D GlobalMaxPool1D Flatten GRU ", "entities": "(('It', 'python docker image https kaggle github'), 'set') (('read_csv Input data files', 'the'), 'be') (('model', 'background negative subgroup positive'), 'evaluate') (('you', 'output'), 'list') "}
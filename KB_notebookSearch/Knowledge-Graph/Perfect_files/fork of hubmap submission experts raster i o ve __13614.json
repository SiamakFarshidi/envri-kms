{"name": "fork of hubmap submission experts raster i o ve ", "full_name": " h1 Introduction h1 Training Tricks h2 Disclamer h2 Color spaces augmentation trick h2 Multi scale input tiles h2 Pseudo labelling h2 Short training pipeline h1 Inference h2 Inference in a nutshell h2 Parameters h2 Models h1 Detailed Description of our Inference Approach h2 Data Preprocessing h3 Loading and Downsampling Whole Slide Images h3 Separate Slices between FFPE and Fresh Frozen h2 Making Predictions h3 Padding h3 Dividing the Image into Tiles h3 Generating the Segmentation Mask h3 Saving the Segmentation Mask h2 Generating Final Predictions h1 Submission h1 Insights ", "stargazers_count": 0, "forks_count": 0, "description": "We use a TTA approach with four transformations from D4 we finally did not use rotations even though our code allows us to do it. ParametersHere are the parameters that we use for inference. com bguberfain memory aware rle encoding watch out for the bug This simplified method requires first and last pixel to be zero. For that purpose we apply the following _reconstruct_img function. You can see normal tiles with the cutmix augs color spaced without cutmix and color spaced with cutmix. The median area perimeter\u00b2 describing how complex the shape of the glomeruli were has been found to be correlated to the weight 0. 070 3589adb90 27831 624 0. import cv2cspaces cv2. The first line with needs to be removed for that function to work. We copy our group finding code for information. In order to handle the WSI images size we used memmap to load the images and also used temporary saving of processed patches to perform the ensembling. COLOR_RGB2HSV cv2. COLOR_BGR2LUV cv2. png attachment 0e0ed513 8f0e 459a 8f93 61152ceeafac. Data PreprocessingData preprocessing consists in downsampling images. Then we select tiles on which we will make predictions based on their color saturations. Loading and Downsampling Whole Slide ImagesThe main issue with WSI is that they are very big. COLOR_RGB2YUV In the batch sampling part if self. Before the data update the best one was of 1024 and after 512 while the training is performed on 256x256. png attachment 9408f479 08ca 46fa 8d25 2f090fdbeadf. At that moment the mask is already upsampled to match the original image. COLOR_BGR2Luv cv2. However by some reasons we did not discover which this stopped working after the data update at least for the public LB. We import them as follows. All put together the result is the following load_resize function. Dividing the Image into TilesThe following _split_image function allows us to divide images into tiles. On the images below one could see how the naturally looked tiles are transformed being augmented with this method. Inference in a nutshell We make an inference on the bigger patch size than was used for training. ModelsThe models that we can use for inference are defined below. Additionally we observed interesting behaviour such as robust segmentation even of some suspicious glomeruli in the d48 sample from public test set. This DataLoader is based on the HuBMAPTestDataset class below. 33 that wasn t used because of the inference time constraints. First the make_predictions function generates mask tiles using the aforementioned get_mask_tiles function. Very important point that we wanted to highlight that we were able to split all test images into two groups with respect to the ffpe ff type using the PhysicalSizeY from the tiff. 069 b9a3865fc 15859 483 0. csv file containing all our predictions. sum 0 keepdims True if random. 068 8242609fa 32320 683 0. 071 1e2425f28 8768 356 0. csv file that is provided. We also share the code as we implemented this idea. The aforementioned DataLoader is generated using the following _make_tiles_dataloader function. id median area \u00b5m\u00b2 median perimeter \u00b5m median area perimeter\u00b2 0486052bb 5610 309 0. That approach was giving us very good results on the public leaderboard and on cross validation before the change of test data but unfortunately for some reason we could not see that improvement afterwards. Then we must reconstruct the image from resampled tiles that we saved. This also gave us significant boost both in CV and LB. com bguberfain memory aware rle encoding https www. COLOR_BGR2RGB cv2. Therefore we initially tried to apply different models with respect to the type of WSI that we were processing. InferenceIn this section we describe how we make predictions. Image names from public and private test sets are retrieved from the sample_submission. COLOR_BGR2HLS cv2. We found indeed that fresh frozen tissue images had a physical spacing of 0. 069 aaa6a05cc 13466 436 0. Then we generate masks for each image in the test set. The _generate_masks function outputs a zero padded mask. Detailed Description of our Inference ApproachIn this section we describe our approach version 1. COLOR_RGB2HLS cv2. Imports TODO remove PARAMETERS Printing parameters Data processing Input data directory Reduce the original images by x times check 1024 Size of tiles on which inference is done 256 x 256 on all tiles Models MODELS_FRESH_FROZEN f. Training Tricks DisclamerWe used NO hand labelling and manual annotation since in our vision it is not consistent with the initial goal and objective of the competition. 067 e79de561c 33504 704 0. The goal of the competition was to provide with automated glomeruli segmentation models for WSI of human kidneys. png attachment a124c589 2fe5 46c4 93e2 d2f5257806d8. The _generate_masks function is based on the Model_pred iterator like class that is used to generate predictions. COLOR_BGR2Lab cv2. COLOR_RGB2Lab cv2. 069 54f2eec69 32392 684 0. In this competition these WSI can be divided into two categories those containing fresh frozen FFPE tissues and those containing formalin fixed paraffin embedded tissues. Multi scale input tilesWe used multiple image reduction rates 3 4 5 6 and 8 in order to create the tiles from original images. In particular we were interested in the median area per patient the median perimeter per patient and the median ratio area perimeter\u00b2 per patient. cvtColor img cspace if self. Pseudo labellingPublic test set pseudo labeled with own models and included in the training procedure Short training pipelineUnet with resnext50_32x4d resnext101_32x16d efficientnet b7 b5 backbones ASPP and FPN modules complex loss combination of FocalLoss DiceLoss SymmetricLovasz OneCycleLR Heavy Augmentations CutMix ColorSpaced augs 5 fold patient based CV. If PUBLIC_ONLY True then we only make the prediction for public test data. We obtained that information from the metadata of TIFF images. After discussion we decided not to follow that approach in our final submissions. But it still demonstrated higher CV when models were trained independently for each group. com iafoss 256x256 images Saturation blancking threshold Threshold for the minimum number of pixels Inference Make predictions only on public LB Overlap between tiles during prediction X axis Overlap between tiles during prediction Y axis Reduction for two types of models Threshold for positive predictions Number of bins when saving mask tiles Final prediction Size of saved mask tiles m torch. pth for i in range 4 MODELS_PATHS MODELS_FRESH_FROZEN MODELS_FFPE Tiles selection https www. Here are the values we obtained based on the GT for images in the training set and based on our predictions for images in the test set. png Tiles with Color Space augmentation image. 069 26dc41664 28316 649 0. 065 c68fe75ea 34348 720 0. The following _get_group function allowed to get the group of a given image 0 if the slice has been fresh frozen and and 1 if it has been formalin fixed paraffin embedded. 068 2ec3f1bb9 33462 692 0. Saving the Segmentation MaskThe segmentation mask is then saved as tiles containing scores it is not binarized yet. The second version using a two pass segmentation is described in a separate notebook. exp K K elif random. After loading the image using the load_image function above we apply the _tile_resize_save function below. Such approach naturally increases the training dataset and enriches variation of glomeruli size and its proportion in the considered tile of fixed size. Here is how we load an image using NumPy MemMap. input models 256 cutmixup color nostoch model_ i. COLOR_RGB2LAB cv2. png Tiles with both augmentations image. 067 4ef6695ce 22636 574 0. InsightsThanks to our predictions we could compute some metrics about glomeruli. png This methodology demonstrated its effectiveness and power during both stages of the competition but mostly with the first set of the data maybe due to the different test sets since we dont know yet results on the private test data. The RLE conversion is done using the following rle_encode_less_memory function obtained from https www. However these findings must be confirmed on more patients as they are based on a very small sample of people that is not necessarily representative of the general population. Locally we used smaller step of 0. It is not yet binarized. load facebookresearch semi supervised ImageNet1K models resnext50_32x4d_ssl aspp with customized dilatations aspp with customized dilatations m torch. Segmentation mask tiles are generated for all possible sets of padding parameters using on the following get_mask_tiles function. Making PredictionsIn this section we describe how we make predictions. Eventually the obtained mask is binarized and converted into RLE format. IntroductionThis kernel contains the inference code of the submission_experts team for the 2021 HuBMAP competition version 1. Separate Slices between FFPE and Fresh FrozenAs both types of slices have different properties we found beneficial to apply a different model for FFPE slices and Fresh Frozen slices. COLOR_RGB2LUV cv2. Eventually we need a DataLoader to feed data to our model. Then the mask is reconstructed based on these tiles computed with different padding parameters. 65 in the standard pipeline up to 0. 071 b2dc8411c 24430 594 0. 046 d488c759a 9560 388 0. These predictions are upsampled to match the original image. Generating the Segmentation MaskThe segmentation mask is then generated. The median perimeter was similarly correlated respectively 0. All these functions are combined in make_one_prediction that aims at saving segmentation mask tiles based on an image and a given set of padding parameters. Color spaces augmentation trick For the training we found and decided to use various Color Space Augmentations in combination with custom stochastic kernel this is one of the most important things that allowed our models to stay robust and segment glomeruli despite the data source type of the images FFPE fresh frozen even others and color related variations. COLOR_RGB2XYZ cv2. We also used classical TTA based on transformations of the D4 group but we were limited by the kernel inference time. Tiles with CutMix augmentation image. The next step is logically to remove that padding. We added zero padding to make the dimensions of the image dividable by the tile size. 071 095bf7a1f 29992 651 0. 068 cb2d976f4 13378 435 0. We used overlapping step of 0. COLOR_BGR2XYZ cv2. COLOR_RGB2Luv cv2. 65 \u03bcm whereas FFPE tissue images had a physical spacing of 0. This information was crucial before the data update and allowed us to get different models that worked for each of the groups. COLOR_RGB2BGR cv2. einsum ijk kl ijl img stoch This method also allowed to obtain much more focused predictions we observed very high soft dice metrics even without proper binarization threshold. random 1 len cspaces cspace random. Generating Final PredictionsFinal predictions are generated as follows. And finally we generate a submission. Obvious visual differences can be noticed in both types of WSI the structure of FFPE tissues is better preserved than fresh frozen ones. COLOR_BGR2YUV cv2. 069 afa5e8098 21632 577 0. 89 Dice depending on the fold. We also initially wanted to find to which group fresh frozen vs FFPE they belonged to but as we said before we finally did not follow that approach. load facebookresearch semi supervised ImageNet1K models resnet50_swsl aspp with customized dilatations Import models Get tile Reduce if needed Save tile Return dimension after reduction Tiles are deleted when read X overlap padding Y overlap padding Check that width is OK Check that height is OK Generate tmp directory if needed Remove black or gray images based on saturation check Iterator like wrapper that returns predicted masks List of models Dataloader Half precision Reduction on reduced image Prepare input Make predictions Upsample to initial shape Quantize probablities to save memory Output predictions Add padding to make the image dividable into tiles Split image into tiles using the reshape transpose trick Final shape nb_x nb_y TILE_SZ TILE_SZ 3 Select tiles for running the model Make tiles dataset Generate masks Reshape tiled masks into a single mask and crop padding A little bit of cleaning. 071 aa05346ff 48216 1064 0. SubmissionHere is the final part of this kernel dealing with the actual submission of a CSV file containing generated masks. Some additional insights are provided at the end of the notebook. 072 57512b7f1 11356 400 0. Dealing with such big images is not convenient we found that we should downsample data for better performance. Ensembling predictions with different padding dimensions allows us to avoid bad predictions due to glomeruli located on edges of the tiles. 5xtile_size in both X and Y directions to cut the patches from test images. Final submissions are ensembles of models trained with and without Color Space Augmenatations and Cutmix in order to increase the robustness. PaddingAs images are very big we must divide them into tiles. choice cspaces img cv2. For example improvement is from 0. COLOR_BGR2LAB cv2. 063 We found that the median area of glomeruli was negatively correlated to the weight correlation coefficient of 0. 059 2f6ecfcdf 34158 708 0. Additionally we used only non empty tiles of the bigger reduction rates to balance more the training dataset. com bguberfain memory aware rle encoding. COLOR_BGR2HSV cv2. Save tiles in HDD memory First generate mask tiles Then reconstruct mask from tiles Eventually convert to rle https www. rand 3 3 K stoch. pth for i in range 4 MODELS_FFPE f. sqrt K stoch stoch K img np. ", "id": "vladimirgroza/fork-of-hubmap-submission-experts-raster-i-o-ve", "size": "13614", "language": "python", "html_url": "https://www.kaggle.com/code/vladimirgroza/fork-of-hubmap-submission-experts-raster-i-o-ve", "git_url": "https://www.kaggle.com/code/vladimirgroza/fork-of-hubmap-submission-experts-raster-i-o-ve", "script": "torch.nn.functional ConvLayer # TODO: remove make_predictions DataLoader Unet50(nn.Module) _reconstruct_img UnetBlock(nn.Module) _get_nored_pads segmentation_models_pytorch load_resize _add_padding Image fastai.vision.all numpy _reshape_depad_mask _make_tiles_dataloader UneXt101(nn.Module) HuBMAPTestDataset(Dataset) UneXt50(nn.Module) __iter__ FPN(nn.Module) _ASPPModule(nn.Module) _init_weight torch.nn tqdm _get_group _select_tiles ResNet ASPP(nn.Module) rle_encode_less_memory matplotlib.pyplot PixelShuffle_ICNR __getitem__ forward PIL make_one_prediction get_mask_tiles pandas tqdm.notebook Bottleneck _split_image _generate_masks torch.utils.data __len__ _save_mask_tiles Dataset __init__ img2tensor Model_pred _tile_resize_save read_tiff torchvision.models.resnet load_image ", "entities": "(('WSI', 'formalin fixed paraffin embedded tissues'), 'divide') (('aforementioned DataLoader', '_ make_tiles_dataloader following function'), 'generate') (('Eventually we', 'model'), 'need') (('Additionally we', 'training more dataset'), 'use') (('how shape', 'weight'), 'describe') (('predictions', 'original image'), 'be') (('This', 'CV'), 'give') (('Final submissions', 'robustness'), 'be') (('Such approach', 'fixed size'), 'increase') (('it', 'scores'), 'save') (('we', 'better performance'), 'be') (('when models', 'independently group'), 'demonstrate') (('training', '256x256'), 'update') (('next step', 'logically padding'), 'be') (('we', 'improvement'), 'give') (('we', 'idea'), 'share') (('how we', 'predictions'), 'inferencein') (('that', 'groups'), 'be') (('section we', 'approach version'), 'description') (('we', 'inference'), 'be') (('we', 'ensembling'), 'use') (('us', 'tiles'), 'allow') (('You', 'cutmix'), 'see') (('scale', 'original images'), 'use') (('put', 'together result'), 'be') (('Eventually obtained mask', 'RLE format'), 'binarize') (('goal', 'human kidneys'), 'be') (('Segmentation mask tiles', 'get_mask_tiles function'), 'generate') (('we', '_ tile_resize_save function'), 'apply') (('group', 'information'), 'copy') (('we', 'kernel inference time'), 'use') (('we', 'that'), 'reconstruct') (('Then mask', 'padding different parameters'), 'reconstruct') (('inference', 'training'), 'inference') (('dimensions', 'tile size'), 'add') (('how naturally looked tiles', 'method'), 'see') (('how we', 'predictions'), 'make') (('very we', 'tiles'), 'divide') (('PUBLIC_ONLY then we', 'test public data'), 'make') (('we', 'final submissions'), 'decide') (('load', 'NumPy MemMap'), 'be') (('Then we', 'test set'), 'generate') (('inference', 'tiles'), 'remove') (('RLE conversion', 'https www'), 'do') (('SubmissionHere', 'generated masks'), 'be') (('_ generate_masks function', 'zero padded mask'), 'output') (('they', 'WSI'), 'Slide') (('make_predictions First function', 'get_mask_tiles aforementioned function'), 'generate') (('Additionally we', 'test public set'), 'observe') (('Image names', 'sample_submission'), 'retrieve') (('we', 'tiff'), 'point') (('we', 'glomeruli'), 'InsightsThanks') (('function', 'work'), 'line') (('load facebookresearch semi', 'dilatations m customized torch'), 'supervise') (('DataLoader', 'HuBMAPTestDataset class'), 'base') (('particular we', 'ratio median patient'), 'be') (('that', 'predictions'), 'base') (('models', 'fresh even others'), 'trick') (('we', '_ reconstruct_img following function'), 'apply') (('mask First tiles', 'rle https Eventually www'), 'save') (('IntroductionThis kernel', 'HuBMAP competition 2021 version'), 'contain') (('additional insights', 'notebook'), 'provide') (('tissue indeed fresh frozen images', '0'), 'find') (('we', 'test set'), 'be') (('we', 'finally approach'), 'want') (('Generate masks Reshape', 'cleaning'), 'supervise') (('we', 'inference'), 'define') (('we', 'color saturations'), 'select') (('this', 'at least public LB'), 'discover') (('fresh it', 'given image'), 'allow') (('Inference', 'prediction mask tiles m Final saved torch'), 'iafoss') (('we', 'that'), 'try') (('second version', 'separate notebook'), 'describe') (('simplified method', 'first pixel'), 'aware') (('it', 'competition'), 'use') (('We', 'TIFF images'), 'obtain') (('that', 'necessarily general population'), 'confirm') (('Generating', 'Segmentation MaskThe segmentation mask'), 'generate') (('that', 'padding given parameters'), 'combine') (('us', 'it'), 'use') (('wasn t', 'inference time constraints'), '33') (('median area', '0'), '063') (('we', 'FFPE slices'), 'slice') (('we', 'binarization even proper threshold'), 'stoch') (('we', 'test private data'), 'demonstrate') (('FFPE tissue 65 images', '0'), '\u03bcm') (('structure', 'better fresh frozen ones'), 'notice') (('mask', 'already original image'), 'be') (('ColorSpaced CutMix augs', '5 patient based CV'), 'set') "}
{"name": "real breast cancer and undersampling ", "full_name": " h1 Importing Real Breast Cancer data set h1 PRE Processing h1 Visualization of Data h1 Classification Technic h1 Conclusion h1 Under Sampling h1 Conclusion After Under Sampling ", "stargazers_count": 0, "forks_count": 0, "description": "Under Sampling Conclusion After Under SamplingSVM Linear with the highest Accuracy of 68. 7 after 10 epochs Conclusion Stochastic Gradient Descent with an Highest Accuracy of 80. Importing Real Breast Cancer data set PRE Processing Taking only female data Visualization of Data Converting all the data which are Alphabets Classification Technic Accuracy of Random Forest 79. But when we see Confusion matrix of XG boost we see it tough for Algo to predict Alive patient because data set is uneven so we do under sampling which will result in less accuracy but it will predict both class. 42 split data train 72 and test 28 random forest classifier with n_estimators 10 default Divide by class split data train 70 and test 30 random forest classifier with n_estimators 10 default. ", "id": "sanketbose97/real-breast-cancer-and-undersampling", "size": "632", "language": "python", "html_url": "https://www.kaggle.com/code/sanketbose97/real-breast-cancer-and-undersampling", "git_url": "https://www.kaggle.com/code/sanketbose97/real-breast-cancer-and-undersampling", "script": "RepeatedKFold classification_report train_test_split cross_val_predict plotly.express confusion_matrix accuracy_score cross_val_score numpy sklearn.svm seaborn SGDClassifier recall_score f1_score SVC sklearn.neighbors sklearn sklearn.linear_model matplotlib.pyplot metrics sklearn.model_selection pandas RandomForestClassifier KNeighborsClassifier sklearn.metrics sklearn.ensemble ", "entities": "(('which', 'Alphabets Classification Technic Random Forest'), 'set') (('it', 'class'), 'see') (('42 split data', 'n_estimators 10 default'), 'train') "}
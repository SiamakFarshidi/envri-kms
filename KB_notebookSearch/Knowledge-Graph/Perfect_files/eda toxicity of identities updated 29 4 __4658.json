{"name": "eda toxicity of identities updated 29 4 ", "full_name": " h1 Toxicity EDA work in progress h2 Content h2 References h1 Target Distribution h1 Comment Length h1 No of Toxicity Annotators vs Comment Length h1 Annotators Distribution h1 Identity Distribution h1 Toxic vs Non toxic Words by Identity h3 To be continued let me know your thoughts and give me an upvote if you find the EDA useful interesting ", "stargazers_count": 0, "forks_count": 0, "description": "Toxicity EDA work in progressBeginner here trying to give my 0. 1 Interesting bin 0. 5 will be a critical area to look at the comments in this bin are likely prone to misclassifications by the machine learning models. Annotators Distribution Key Findings Identity annotator distribution peaks at around 1200 1500 1700 probably an artifact of how the annotations were conducted. of Toxicity Annotators vs Comment Length Annotators Distribution New added on 29 Apr Identity Distribution New added on 29 Apr Toxic vs Non toxic Words by Identity New added on 29 Apr References Preprocessing https www. Key Findings As the comment gets longer the number of annotators get lesserBe wary of the correctness of long comments as these tend to have lesser annotators and thus a less reliable score. Content Target Distribution Comment Length No. 02 cents on the data exploratory analysis any comments feedbacks are welcome. Note that there are still some comments with length 1000. Key Findings Similar distribution for word and character level just the way English is A peak at character length 1000 and minimal data with length 1000. I would think that if a comment is labelled by more annotators its target score is more reliable. Top 10 words that are associated with the toxic samples are plotted. If you are going to work on BPSN and BNSP metrics on individual identities it is wise to spend more time on the related pairs Black White Male Female as well as the most common identities. of Toxicity Annotators vs Comment LengthThe main motivation is to check out how diligent the annotators are reliable or should I say less biased the labels of the comments are. I shall work on a more in depth analysis on this bin in subsequent versions. Just wondering if how diligent our annotators are lol Check out how the selected identities are related to each other Set the criteria for dataframe query get the concatenated string for both positive toxic and negative non toxic samples for an identity as negative samples are much larger in population there is a need to normalize them to the positive sample size Word Cloud plot Line plot of the term frequencies. Perhaps we should take special note of the truncated comments The toxic may not occure before the truncation. To check if the non toxic word frequency distributions for the identity is similar the normalized frequency is plotted out of vocab word frequency are set to 0 Key Findings 30 of the samples identified with Homosexual_gay_or_lesbian Black White are toxic which is much higher than the remaining identities Toxic and Non toxic words frequency distribution for Male Female and Christian have more variations which means traditional bags of words approach Tf Idf Count Vector can probably distinguish between the toxic and non toxic samplesFor the remaining identities with similar words frequency distirbution for toxic and non toxic samples other strategies will likely be needed if you were to work on the sub group AUC. Off my mind I can think of the following methods that could help Negation tagging Sentence structure analysis Dependency parsing To be continued let me know your thoughts and give me an upvote if you find the EDA useful interesting Note I m using the custom train test file I created which contains the original cols additional columns of POS tags Referene benchmark kernel for the competition remove other non alphabets symbols with space i. Toxic vs Non toxic Words by IdentityFor each of the selected identities the word frequency distributions of the adjectives nouns proper nouns and verbs which are chosen as they tend to convey more semantics and sentiments are obtained and plotted. This is probably due to different character truncation selection during the data collection. com theoviel improve your score with some text preprocessing notebook currently not used Target DistributionLooking at the raw target output with bins 10 distribution a few things can be observed Majority of the comments are non toxic target 0. And after binarization our dataset becomes a highly imbalaned Comment LengthWe will analyse the comment length at word and character level. keep only alphabets and whitespaces. I m guessing the bin 0. 5 where some annotators find the comments toxic we aren t sure how toxic they find these comments though. Toxicity annotator distribution peaks near 0 which means a lot of the comments have very little annotators and hence less reliable Identity Distribution Key Findings Female Male and Christian are the most common identities For samples with identity_annotator_count 0 60 of them are not identified with the identities used for metrics Of the remaining 40 about 28 have a single identity 9 have double identities From the pair wise venn diagram it is observed that Male and Female tend to occur together Black and White as well. ", "id": "chewzy/eda-toxicity-of-identities-updated-29-4", "size": "4658", "language": "python", "html_url": "https://www.kaggle.com/code/chewzy/eda-toxicity-of-identities-updated-29-4", "git_url": "https://www.kaggle.com/code/chewzy/eda-toxicity-of-identities-updated-29-4", "script": "clean_text venn_diagram_subplot parallelize_dataframe FreqDist matplotlib_venn numpy seaborn preprocessing correct_spelling clean_special_chars venn2 Pool text_processing tqdm get_pos_neg_string get_word_freq_and_plot matplotlib.pyplot nltk pandas stopwords convert_to_bool nltk.corpus clean_contractions WordCloud multiprocessing convert_dataframe_to_bool wordcloud ", "entities": "(('toxic', 'truncation'), 'take') (('comments feedbacks', 'data exploratory analysis'), 'be') (('they', 'more semantics'), 'obtain') (('t how toxic they', 'comments'), '5') (('Male', 'together Black'), 'be') (('Majority', 'comments'), 'improve') (('less labels', 'comments'), 'of') (('target score', 'more annotators'), 'think') (('likely you', 'sub group'), 'plot') (('This', 'data collection'), 'be') (('it', 'related pairs'), 'be') (('these', 'lesser annotators'), 'Findings') (('5', 'machine learning models'), 'be') (('negative samples', 'Word Cloud plot Line term frequencies'), 'lol') (('character just way English', '1000 minimal length'), 'distribution') (('dataset', 'word'), 'analyse') (('1500 1700 probably how annotations', 'Annotators Distribution Key Findings Identity annotator distribution around 1200'), 'peak') (('which', 'space i.'), 'think') (('I', 'subsequent versions'), 'work') (('that', 'toxic samples'), 'Top') "}
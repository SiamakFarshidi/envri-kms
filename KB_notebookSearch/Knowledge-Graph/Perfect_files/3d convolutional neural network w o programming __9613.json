{"name": "3d convolutional neural network w o programming ", "full_name": " h2 Step 1 Get Access h2 Step 2 Enable Cached Dataset h2 Step 3 Create and Open a New Project h2 Step 4 Select Dataset and do training validation set division h2 Step 5 Build model h2 Step 6 Training and Results h1 3 Pre processing Code h1 Summary ", "stargazers_count": 0, "forks_count": 0, "description": "After trying out 2 epochs I was able to get loss of about 0. Traditionally convolution neural network operate on a 2D image possibly comprising of 1 or 3 color channels. com deepcognition 3dconvnet_cached_dataset. jpg 8 https s3 us west 2. I hope to share more details about these experiments with you in coming days. Use Convolutional LSTM neural network that combines both CNN and LSTM for analyzing sequence of images. com deepcognition 3dconvnet_model. This is useful if you do not want color to change between different scan slices. Please feel free to send your suggestions and comments. def get_model Input_1 Input shape 256 512 512 1 MaxPooling3D_27 MaxPooling3D pool_size 1 3 3 Input_1 Convolution3D_1 Convolution3D kernel_dim1 4 nb_filter 10 activation relu kernel_dim3 4 kernel_dim2 4 MaxPooling3D_27 Convolution3D_7 Convolution3D kernel_dim1 4 nb_filter 10 activation relu kernel_dim3 4 kernel_dim2 4 Convolution3D_1 BatchNormalization_28 BatchNormalization Convolution3D_7 MaxPooling3D_12 MaxPooling3D pool_size 2 2 2 BatchNormalization_28 SpatialDropout3D_1 SpatialDropout3D p 0. Step 6 Training and Results Now you can go to Hyperparameters tab and make sure batch size is set to 1. These files must be uploaded for to verify that user is infact has access to Kaggle dataset Follow markers 1 to 4 Enable Access to Cached Dataset 2 Step 3 Create and Open a New Project Let s build a new project by going to project menu on left and clicking on button. jpg 6 https s3 us west 2. At the end of convolutional network we do Global max pooling to pool the features which then go into three dense layers to bring the final dimension to 2 which is the size of our output label cancer or no cancer. Today we will try 3D Convolutional Neural Network for this problem. Divide all values with 1100 to bring the range between 1 and 1 You can find full source code for pre processing in section 3. First Experiment 3D Convolutional Neural Networks Convolutional neural networks have been very successful in image classification and other types of imaging tasks. If you liked this post please give it a upvote Thank you Please check excellent notebook of Guido Zuidhof for full explanation of this code For Kaggle I have added sample_image directory only fix random seed for reproducibility Simple Function to show the slice at full resolustion normal imshow would downscale this image. 5 MaxPooling3D_12 Convolution3D_9 Convolution3D kernel_dim1 2 nb_filter 20 activation relu kernel_dim3 2 kernel_dim2 2 SpatialDropout3D_1 Convolution3D_11 Convolution3D kernel_dim1 2 nb_filter 20 activation relu kernel_dim3 2 kernel_dim2 2 Convolution3D_9 BatchNormalization_9 BatchNormalization Convolution3D_11 MaxPooling3D_14 MaxPooling3D pool_size 2 2 2 BatchNormalization_9 SpatialDropout3D_4 SpatialDropout3D p 0. com deepcognition 3dconvnet_open_project. Which means that we must process all slices together and then let network correct itself in the end. Code for these steps is mostly borrowed from excellent notebook of Guido Zuidhof. But let s make a network and give it a shot. jpg 3 https s3 us west 2. My aim will be to transfer my knowledge and make it easy for others to follow along. 5 BatchNormalization_23 GlobalMaxPooling3D_1 GlobalMaxPooling3D SpatialDropout3D_5 Dense_1 Dense activation relu output_dim 10 GlobalMaxPooling3D_1 Dropout_14 Dropout p 0. Please feel free to modify and experiment with it. Basic imshow only shows scaled version of scan. Summary In this post we built a working convolutional 3D neural network without programming. Currently I am working on following two more appoarches 1. Open Project 4 Step 4 Select Dataset and do training validation set division We will do training with 1200 samples and we will use 197 samples for validation for this example. Full discloure I am one of the cofounder of the company who developed Deep Learning Studio software. Click on Start Training. Convolutional networks learns to extract low level features of image automatically. TVOur CT scan dataset is actually comprise of set of slices each slice is 512x512 pixel image. We will try different experiments as we move forward with this competition. Here I will just list major high level preprocessing that we will do on the dataset. com deepcognition 3dconvnet_hyperparameters. It allows to use multi CPU to do segmentation. This ability comes in handy when tackling with complex real world images. Note that by no mean this is the best architecture but I wanted to share my experiment with you guys in the hope it can help you build even better network. Pre processing We will do following preprocessing on given CT Scans to make our life easier. Make a figure big enough to accomodate an axis of xpixels by ypixels as well as the ticklabels etc. Following experiment uses this preprocessed data as input. You can watch following video to get gentle introduction to convolutional neural network. Our architecture is based on stacking multiple blocks of following Conv3D Conv3D BatchNorm MaxPooling3D SpatialDropout3DPurpose of first two Conv3D layers is to extract features from input. Note that training is going to be very slow because of sheer size of dataset and computations needed. Pad or Trim slices at the end such that every scan has exactly 256 slices. Select GPU K80 as instance and click on Start Instance. Make the axis the right size. For Testing feed just load one scan Multi threaded processes to utilize all available CPUs for this task. Architecture 6 You will also need to set the parameters of the layers. Please refer to that Guido Zuidhof notebook to understand these steps in detail. com deepcognition 3dconvnet_dataset_selection. Now open the project by clicking on box arrow icon on project bar. Deep Learning Studio has a free monthly plan and it offers 2 hours of complementary training time on best GPU available in the Cloud Nvidia K80 with 12GB RAM 1. Reduce dimensionality of scans using autoencoders to make it easy to process the dataset using some other neural network. SpacialDropout3D is added added to make system more robust and less prone to over fitting. Load and Convert DICOM file to NUMPY array. Cleanup For demo reduce number of slices to 5 to save time For Convnet we will need one extra dimension representing color channel Save output file to compressed npz file for easy reading. Below is the actual generated source code using view code button in Model tab for the model that I built and you can reference it to get parameter values. 3 Dense_1 Dense_6 Dense activation relu output_dim 10 Dropout_14 Dense_2 Dense activation softmax output_dim 2 Dense_6 return Model Input_1 Dense_2 Rationale for this architecture First MaxPooling3D layer is done to reduce size of the scan kind of downscaling because even the GPUs like K80 with 12GB RAM are not able to fit this scan with reasonable model in memory. It can accept either image_width image_height array or image_width image_height 1 numpy as input. ai 1 Step 2 Enable Cached Dataset Enable cached dataset in your account by uploading two small files that you must download from your Kaggle account. Training and Validation Split 5 Step 5 Build model Once dataset is selected click on Model Tab and start building model as shown below by dragging layers from left menu bar to the canvas and connecting these layer blocks. MaxPool is added to reduce spacial dimensions for future blocks. 5 MaxPooling3D_14 Convolution3D_12 Convolution3D kernel_dim1 2 nb_filter 40 activation relu kernel_dim3 2 kernel_dim2 2 SpatialDropout3D_4 Convolution3D_13 Convolution3D kernel_dim1 2 nb_filter 40 activation relu kernel_dim3 2 kernel_dim2 2 Convolution3D_12 MaxPooling3D_23 MaxPooling3D pool_size 2 2 2 Convolution3D_13 BatchNormalization_23 BatchNormalization MaxPooling3D_23 SpatialDropout3D_5 SpatialDropout3D p 0. jpg 7 https s3 us west 2. com deepcognition 3dconvnet_training_dashboard. Instead we will use drag and drop GUI based platform Deep Learning Studio to build and train neural network. Threshold values to below 1100 to 1100 and values above 700 to 700 5. Talking about easy we will in fact be building and training our neural networks without doing programming. This will bring values between 1 and 1 For full preprocessing you should to set demo False. ai 2 https s3 us west 2. 3D convolutional neural network fit the bill but they tend to consume a lots of GPU memory and are difficult to converge. Creation of the internal Marker Creation of the external Marker Creation of the Watershed Marker matrix Creation of the Sobel Gradient Watershed algorithm Reducing the image created by the Watershed algorithm to its outline Performing Black Tophat Morphology for reinclusion Creation of the disk kernel and increasing its size a bit Perform the Black Hat Use the internal marker and the Outline that was just created to generate the lungfilter Close holes in the lungfilter fill_holes is not used here since in some slices the heart would be reincluded by accident Apply the lungfilter note the filtered areas being assigned 30 HU Maximum absolute value of any pixel. Once Instance has been started. 5 of the width height of the figure. Optional Value range is a tuple of fixed max value and min value. I will try to documents as much details as I can on this notebook. Do Lung Segmentation on these scans. Load the scans in given folder path Convert to int16 from sometimes int16 should be possible as values should always be low enough 32k Set outside of scan pixels to 0 The intercept is usually 1024 so air is approximately 0 Convert to Hounsfield units HU make total 256 slices fill in 1100 as exterme value Ignore all slices later than 255 if required. jpg 5 https s3 us west 2. com watch v JiN9p5vWHDY ab_channel DeepLearning. enter image description here 3 Give a name and description to your project. We have information if the CT scan contain the cancer or not as a whole. This is important because anything bigger will not fit GPUs memory and training will fail. Training Dashboard 8 1 http deepcognition. com deepcognition 3dconvnet_new_project. BatchNormalization layer is added to accelerate the training. jpg 4 https s3 us west 2. Welcome everyone to my post that will describe my experiments to get good scores for this problem. Pre processing Code This notebook converts DICOM scans to Numpy array along with doing segmentation normalization etc. Step 1 Get Access Sign up and get access to Deep Learning Studio at http deepcognition. Hyperparameters 7 Finally you can move to Training tab. Your suggestions are welcome. slow_slice function is designed to show scan at full resolution. Note that many threads will block on IO so creating more than number of CPUs. ", "id": "deepman/3d-convolutional-neural-network-w-o-programming", "size": "9613", "language": "python", "html_url": "https://www.kaggle.com/code/deepman/3d-convolutional-neural-network-w-o-programming", "git_url": "https://www.kaggle.com/code/deepman/3d-convolutional-neural-network-w-o-programming", "script": "preprocess_all_scans_mp keras.layers keras.models train_test_split Poly3DCollection IPython.display importlib stats show_slice numpy segment_pad_and_save_ct_scan_as_npz skimage preprocessing mpl_toolkits.mplot3d.art3d scipy.ndimage sklearn.preprocessing keras.layers.normalization keras.callbacks load_scan_as_HU_nparray Pool threshold_and_normalize_scan scipy keras.optimizers sklearn segmentation keras.layers.convolutional tensorflow seperate_lungs_and_pad matplotlib.pyplot Sequential sklearn.model_selection pandas keras.regularizers load_model Model Input morphology multiprocessing display keras.layers.core keras.layers.pooling measure sklearn.metrics StandardScaler reload ", "entities": "(('convolution neural Traditionally network', 'color possibly 1 channels'), 'operate') (('of even GPUs', 'memory'), 'output_dim') (('filtered areas', '30 HU Maximum absolute pixel'), 'Watershed') (('that', 'problem'), 'welcome') (('Today we', 'problem'), 'try') (('we', 'easy reading'), 'reduce') (('you', 'False'), 'bring') (('it', 'GB 12 RAM'), 'have') (('You', 'neural convolutional network'), 'watch') (('s', 'button'), 'have') (('MaxPooling3D SpatialDropout3DPurpose', 'input'), 'base') (('such scan', 'exactly 256 slices'), 'slice') (('ability', 'world handy when complex real images'), 'come') (('Currently I', 'two more appoarches'), 'work') (('together then network', 'end'), 'mean') (('training', 'dataset'), 'note') (('Instead we', 'neural network'), 'use') (('I', 'coming days'), 'hope') (('you', 'parameter values'), 'be') (('total 256 slices', 'value exterme slices later 255'), 'be') (('notebook', 'etc'), 'pre') (('which', 'output label cancer'), 'do') (('Multi', 'task'), 'load') (('Basic imshow', 'scan'), 'show') (('def get_model', 'Input_1 Convolution3D_1 Convolution3D activation 1 3 3 4 10 kernel_dim3'), 'shape') (('we', 'example'), 'Dataset') (('batch sure size', '1'), 'training') (('You', 'section'), 'find') (('MaxPool', 'future blocks'), 'add') (('others', 'knowledge'), 'be') (('LSTM neural that', 'images'), 'network') (('you', 'even better network'), 'note') (('Code', 'Guido Zuidhof'), 'borrow') (('I', 'image'), 'give') (('they', 'GPU memory'), 'fit') (('you', 'Kaggle account'), 'ai') (('we', 'forward competition'), 'try') (('figure', 'ypixels'), 'make') (('BatchNormalization layer', 'training'), 'add') (('Following', 'input'), 'use') (('slice', 'slices'), 'be') (('Optional Value range', 'max fixed value'), 'be') (('7 Finally you', 'Training tab'), 'hyperparameter') (('slow_slice function', 'full resolution'), 'design') (('I', 'notebook'), 'try') (('anything', 'GPUs bigger memory'), 'be') (('CT scan', 'whole'), 'have') (('Convolutional networks', 'image'), 'learn') (('many threads', 'CPUs'), 'note') (('color', 'different scan slices'), 'be') (('s', 'shot'), 'let') (('we', 'dataset'), 'list') (('we', 'programming'), 'Summary') (('Step', 'http deepcognition'), 'get') (('here 3', 'project'), 'enter') (('I', 'about 0'), 'be') (('who', 'Deep Learning Studio software'), 'discloure') (('Experiment 3D Neural Networks First Convolutional Convolutional neural networks', 'other imaging tasks'), 'be') (('It', 'segmentation'), 'allow') (('system', 'more less fitting'), 'add') (('Architecture 6 You', 'layers'), 'need') (('it', 'other neural network'), 'reduce') (('life', 'CT Scans'), 'process') (('we', 'programming'), 'build') (('dataset', 'layer blocks'), 'Split') (('It', 'image_width 1 input'), 'accept') "}
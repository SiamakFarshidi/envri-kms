{"name": "keras convnet lb 0 0052 w visualization ", "full_name": " h1 The Idea h1 Data Augmentation h1 Combining the Image CNN with the Pre Extracted Features MLP h2 Wait I don t know what a convolutional neural network is h2 Keras Functional API h1 Visualization h1 Conclusion h2 Thank you for reading ", "stargazers_count": 0, "forks_count": 0, "description": "As the leaf goes through the convolutional neural net will apply many filters each looking for something in the image. And now we create our submission. The first few layers will do really simple stuff like edge and shape detection but the deeper you go the more abstract it gets. ConclusionFor the first convolutional layer we can sort of tell that most of the filters are doing edge detection on the leaf. index_array The transformation of images is not under thread lock so it can be done in parallel Define the image input Pass it through the first convolutional layer Now through the second convolutional layer Flatten our array Define the pre extracted feature input Concatenate the output of our convnet with our pre extracted feature input Add a fully connected layer just like in a normal MLP Get the final output How we create models with the Functional API Get the image batch and labels This is where that change to the source code we made will come in handy. shape 1 uncomment this. Below I ll outline the process of getting this model working along point out some nice resources to learning about convolutional nets and do some visualization of what the neural network is actually doing. This variance in the results could definitely be improved upon with some k fold validation but I ll leave the implementation up to the reader. shape 2 uncomment this Insert into image matrix NOTE Theano users comment line below and X i 0 1 h1 h2 w1 w2 x uncomment this Scale the array values so they are between 0 and 1 Load the pre extracted features Load the image data Split them into validation and cross validation Load the pre extracted features Load the image data A little hacky piece of code to get access to the indices of the images the data augmenter is working with. But you might ask now what is the neural network actually learning One easy way to tell what the convolutional portion of the neural net is learning is through visualization of the hidden layers. To do this in Keras we ll build a Keras function as outlined in the Keras FAQ https keras. autosave best Model Get the names of the column headers Converting the test predictions in a dataframe as depicted by sample submission Display the submission Function by gcalmettes from http stackoverflow. NOTE the change to the source code is not the only way to get around the problem of matching the indices of our two inputs images and pre extracted features. Keeps under lock only the mechanism which advances the indexing of each batch see http anandology. We ll try to emphasize this in our dataset by randomly performing a rotation or zoom transformation to each leaf image as the image is passed to the neural network. The IdeaI started this competition by simply feeding the pre extracted features into a multi layer perceptron with one hidden layer and got surprisingly good results but I still had all this image data that I wasn t using. Instead of samples rows cols channels it should be samples channels rows cols Keras stuff A large amount of the data loading code is based on najeebkhan s kernel Check it out at https www. com c leaf classification forums t 24764 create gif based on leaf class on the forum containing a GIF of each training sample for each species you ll notice that for a given species most of the leaves look very similar except that the leaf is rotated slightly or is slightly larger in scale. This API is just as straightforward but instead of having a model we add layers to we ll instead be passing an array through a layer and passing that output through another layer and so on. Once the filter is applied we ll grab the new image of the leaf and the white portions of the image will tell us where the filter activated and the black will tell us where it didn t. Combining the Image CNN with the Pre Extracted Features MLPNow that we ve gotten all the data preparation work out of the way we can actually construct our model. EDIT I would run this somewhere other than Kaggle locally for 150 epochs instead of 89 like I have it set to below 89 is the best I could do without the script timing out. That actually makes a lot of sense since pretty much all of the species specific information of a leaf is stored in the shape of its edge. html Keras Functional APIFor basic neural network architectures we can use Keras s Sequential API but since we need to build a model that takes two different inputs image and pre extracted features in two different locations in the model we won t be able to use the Sequential API. shape 1 uncomment this width x. com najeebkhan leaf classification neural network through keras Read data from the CSV file Since the labels are textual so we encode them categorically standardize the data by setting the mean to 0 and std to 1 standardize the data by setting the mean to 0 and std to 1 Get the axis with the larger dimension Scale both axes so the image s largest dimension is max_dim Initialize the output array NOTE Theano users comment line below and X np. But before we do that let s just get all the data loading out of the way. You can think of each layer as a function and the array we give it as its argument. Instead we ll be using the Functional API. We can now access the indicies of the images that imgen gave us. Click here https keras. Since we don t really have enough data to go that deep most of our filters look pretty tame. Below is the code for the data augmentation image generator along with a slight change to the source code to help us out later on. Using some form of kfold validation reduces this variance. In addition to questions I m very open to any feedback both in general about kernel writing and specifically about this kernel. empty len ids 1 max_dim max_dim uncomment this Turn the image into an array Get the corners of the bounding box for the image NOTE Theano users comment the two lines below and length x. me 2016 08 11 intuitive explanation convnets http neuralnetworksanddeeplearning. From the last version s submission created from running this on Kaggle I got a 0. io getting started functional api guide for more info about the functional API. This is actually pretty common with convnets. 01672 LB but I had managed to get a 0. You can also manually shuffle the indices set the shuffle parameter for the ImageDataGenerator to False and flow the generator from the manually shuffled images. 00520 LB score with this exact same code after running for 100 epochs though the best model occurred at the 89th epoch for me on an AWS p2. com blog using iterators and generators We changed index_array to self. It s MUCH faster to run it locally if you have a GPU or on an AWS instance with a GPU. Thus for each leaf image we should get a set of 8 and another set of 32 new images. If you take a look at our architecture for the neural net you ll notice we created 8 filters for the first convolutional layer and 32 for the second one. format i conv_img_filt i for i in range conv_img_filt. I did set the random seeds but there is still randomness somewhere. io convolutional networks https ujjwalkarn. You can find more by just googling convolutional neural network explained. Keras s functional API gives us a really easy way to do this. Data AugmentationOne trick we are going to use to improve the robustness of our model is image data augmentation allowing it to perform better on the test set. Judging by our LB score though I think we can assume what it s doing is fairly constructive. Now we re finally ready to actually train the model Running on Kaggle will take a while. io getting started faq how can i visualize the output of an intermediate layer. VisualizationGreat So we ve got our combined model working that incorporates both the raw binary images of the leaves and the pre extracted features. My immediate thought then was to simply combine a convolutional neural network on the images with the pre extracted features MLP and train the entire model end to end. 0052 with this code but due to some randomness still in the script the score varies between 0. The second convolutional layer is also mainly edge detection along with some point and edge shape detection I noticed with some leaves that have particularly special shapes. If you take a look at Rhyando Anggoro Adi s post https www. Well that s all If you ve made it this far that means you ve read my first kernel and I hope it helps if you re stuck and don t know how to improve your score. com questions 11159436 multiple figures in a single window Load the best model Get the convolutional layers Pick random images to visualize Use a keras function to extract the conv layer data Also get the prediction so we know what we predicted Loop through each image disply relevant info Get top 3 predictions Get the actual leaf species Display the top 3 predictions and the actual species Show the original image For Theano users comment the line below and imshow X_img_val img_to_visualize 0 cmap gray uncomment this Plot the filter images Get it ready for the plot_figures function For Theano users comment the line below and fig_dict flt 0. Wait I don t know what a convolutional neural network is No worries I ve linked below a few great places to get an overview of convnets. First we ll pick a few random leaves from our validation set and we ll pass each one through the neural network. NOTE I managed to get an LB of 0. Thank you for reading If you want to use Theano all you need to change is the dim ordering whenever you are dealing with the image array. ", "id": "abhmul/keras-convnet-lb-0-0052-w-visualization", "size": "6577", "language": "python", "html_url": "https://www.kaggle.com/code/abhmul/keras-convnet-lb-0-0052-w-visualization", "git_url": "https://www.kaggle.com/code/abhmul/keras-convnet-lb-0-0052-w-visualization", "script": "math keras.layers Activation NumpyArrayIterator2(NumpyArrayIterator) keras.models keras to_categorical get_dim array_to_img keras.preprocessing.image numpy keras.utils.np_utils load_numeric_test MaxPooling2D img_to_array Dropout load_train_data ImageDataGenerator ImageDataGenerator2(ImageDataGenerator) next load_img Dense resize_img backend as K keras.callbacks load_numeric_training combined_generator load_image_data StratifiedShuffleSplit matplotlib.pyplot load_test_data NumpyArrayIterator ModelCheckpoint backend sklearn.model_selection pandas flow load_model Model Convolution2D plot_figures Input combined_model merge LabelEncoder sqrt Flatten StandardScaler sklearn.preprocessing ", "entities": "(('we', 'layer'), 'be') (('neural network', 'what'), 'outline') (('functional API', 'this'), 'give') (('I', 'convnets'), 'wait') (('I', 'reader'), 'improve') (('we', 'Sequential API'), 'architecture') (('that', 'particularly special shapes'), 'edge') (('script', 'below 89'), 'run') (('we', 'neural network'), 'pick') (('learning', 'hidden layers'), 'ask') (('imgen', 'us'), 'access') (('neural just convolutional network', 'more'), 'find') (('pre', 'leaves'), 'VisualizationGreat') (('doing', 'what'), 'judge') (('I', 't using'), 'start') (('very leaf', 'slightly slightly scale'), 'create') (('I', 'random seeds'), 'set') (('just data', 'way'), 'let') (('image', 'neural network'), 'try') (('large amount', 'https www'), 'row') (('specific information', 'edge'), 'make') (('I', '0'), 'from') (('Instead we', 'Functional API'), 'use') (('it', 'line'), 'question') (('don t', 'how score'), 's') (('I', 'specifically kernel'), 'in') (('data augmenter', 'images'), 'comment') (('image NOTE Theano users', 'two lines'), 'ids') (('you', 'Rhyando Anggoro'), 'take') (('sort of most', 'leaf'), 'ConclusionFor') (('deep most', 'filters'), 'have') (('Using', 'variance'), 'reduce') (('we', 'Keras FAQ https keras'), 'build') (('We', 'index_array'), 'blog') (('image data it', 'test better set'), 'go') (('dim whenever you', 'image array'), 'be') (('Running', 'while'), 're') (('NOTE Theano users', 'line'), 'network') (('score', '0'), 'vary') (('This', 'actually pretty convnets'), 'be') (('we', 'second one'), 'notice') (('change', 'features'), 'NOTE') (('we', 'actually model'), 'get') (('best Model', 'http stackoverflow'), 'autosave') (('how i', 'intermediate layer'), 'faq') (('immediate thought', 'end'), 'be') (('each', 'image'), 'apply') (('we', 'argument'), 'think') (('more it', 'edge detection'), 'do') (('we', '32 new images'), 'get') (('which', 'http anandology'), 'see') (('locally you', 'GPU'), 's') (('best model', 'AWS p2'), '00520') (('Below code', 'us'), 'be') (('where it', 't.'), 'grab') (('we', 'source code'), 'index_array') (('You', 'manually shuffled images'), 'shuffle') "}
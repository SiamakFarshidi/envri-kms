{"name": "t2i synthesis with generative adversarial ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "to device text_encod text1 transforms. word_to_index 128 256 total_loss_T_E 0 D_real disc img Enc_right_text D_wrong disc img Enc_wrong_text D_wrong_img disc wrong_img Enc_right_text loss_D_real criterion D_real ones loss_D_wrong criterion D_wrong zeros loss_D_wrong_img criterion D_wrong_img zeros loss_T_E loss_D_real loss_D_wrong loss_D_wrong_img 2 optimizer_T_E. __init__ self. Module def __init__ self num_word embeding_size hidden_size super. tensor right_text device device None right_text. eval Enc_test_sentence_numeric text_encod test_sentence_numeric print Enc_test_sentence_numeric. tensor test_sentence_numeric device device None print test_sentence_numeric. to device break image gen torch. append loss_T_E print right_text None. shape noise torch. shape total_loss_T_E loss_T_E. V context_vector shape after sum batch_size hidden_dim gen Generator disc Dicriminator text_encod TextEncoder len d_set. npy allow_pickle True. append Total_data word_to_index word print test_sentence_numeric test_sentence_numeric 0 Total_data max_sequence_length len test_sentence_numeric test_sentence_numeric test_sentence_numeric torch. RNN embeding_size hidden_size batch_first True def forward self text text self. hidden_size 1 1 return hidden score batch_size max_length hidden_dim attention_weights batch_size max_length 1 we get 1 at the last axis because we are applying score to self. rnn text hidden hidden. split for word in test_sentence if word in Total_data word_to_index test_sentence_numeric. item print f loss_D loss_D loss_G loss_G scheduler_T_E. state_dict for img right_text _ in d_set text1 wrong_text. input t2i synthesis with generative adversarial data. Please note This kernel is for practice purposes only. item test_sentence_numeric test_sentence input. step avg_total_loss_T_E total_loss_T_E dataloader_len loss_T_E_hist. shape enc_text check_point models text_encoder right_text None print enc_text. shape gen_image models fold generator noise enc_text. shape for key in models 0 models 0 key. eval del check_point img img Nun. data 50000 return 1000 class Text_encoder nn. hidden_size hidden_size self. shape Enc_right_text text_encod right_text noise torch. randn 1 100 1 1 device device gen_img gen noise Enc_right_text transforms. squeeze Total_data np. shape text_encod. randn 1 100 1 1 device device generated_img gen noise Enc_test_sentence_numeric transforms. backward optimizer_T_E. ToPILImage image 26. The references used are mentioned below. Reference links Paper Git repo hand written sentence to generatation list f train print text print type text t t unique text img_name self. zero_grad loss_T_E. step print fake_image. to device right_text. Embedding num_word 1 embeding_size padding_idx 0 1 for padding idx self. embedding text text hidden self. cpu print gen_image. shape right_text torch. ", "id": "avikbanik/t2i-synthesis-with-generative-adversarial", "size": "190", "language": "python", "html_url": "https://www.kaggle.com/code/avikbanik/t2i-synthesis-with-generative-adversarial", "git_url": "https://www.kaggle.com/code/avikbanik/t2i-synthesis-with-generative-adversarial", "script": "TextEncoder(nn.Module) Train_dataset numpy Image Text_encoder(nn.Module) nn tqdm transforms torchvision matplotlib.pyplot Generator(nn.Module) forward PIL pandas Discriminator(nn.Module) attention Train __len__ __init__ torch visualize __getitem__ ", "entities": "(('we', 'score'), 'score') (('shape gen_image models', 'generator noise enc_text'), 'fold') (('kernel', 'practice purposes'), 'note') (('data', 'class Text_encoder 50000 1000 nn'), 'return') (('gen noise', '1 device 1 100 1 device'), 'randn') (('right_text None', 'enc_text'), 'print') "}
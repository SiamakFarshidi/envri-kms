{"name": "mydensenet implementation ", "full_name": " h1 CIFAR 10 Yet another DenseNet implementation h3 Data preparation and augmentation after its loading h3 Visualizing some images after transformation h2 My DenseNet implementation DenseNet class h3 My DenseNet implementation h3 Model training function h2 Training a DenseNet h3 Training Validation losses and accuracy development over the number of epochs h2 Testing the best parameters obtained h2 Conclusion h3 Acknoledgemets ", "stargazers_count": 0, "forks_count": 0, "description": "AcknoledgemetsDuring the comparison I performed on this implementation of the network it occured to me to check other solutions on the Cifar10 competition and I stumbled upon this network from Aleksandra Deis aleksandradeis which uses also an implementation of DenseNet which is the one I have already mentioned at the begining of this kernel. So in my implementation I use the character for my own comments and I use for the paper s extracts. disabling dropouts during the forward pass numpy array to hold all the final predictions i. Here some of the test images and their classes according to the modDN DneseNet model we trained. I want to mention that I tried to write my implementation as loyal to the paper as my understanding of it allowed me. 001 to avoid an extremly slow optimization keep track of training and validation loss start counting the elapsed time clear the gradients of all optimized variables forward pass compute predicted outputs by passing inputs to the model calculate the batch loss backward pass compute gradient of the loss with respect to model parameters finally perform one optimization step an update of the parameters towards the disminution of error direction update training loss calculating train top 1 accuracy calculating train top 3 accuracy check how much time has elapsed forward pass compute predicted outputs by passing inputs to the model calculate the batch loss update average validation loss calculating validation top 1 accuracy calculating validation top 3 accuracy calculate average losses print training validation statistics save model if validation loss has decreased as loss function cross entropy loss will be used and the optimizer. At last training and validation sub sets are prepared out of the training images together with data loaders which will be providing batches of training and validation images to the training process. create the main sequentail module Before entering the first dense block a convolution with 16 or twice the growth rate for DenseNet BC ouput channels is performed on the input images. 02 bigger than the best result I got using the BC variant. At the end I hope that by making these exercises I get to learn something beyond the readings of a paper. I liked her idea of collecting all the training and validation information to plot it later which I definitely took from her. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. Next the data is loaded into numpy arrays. a linear transformation is used here as a Softmax layer. batches are built out of random sampled elements prepare loaders the following test loader is used to load all the test images into the model for their classification unnormalize the picture convert from Tensor image get a batch of training images convert images to numpy for display plot the iamges of the batch validate parameters. My DenseNet implementation DenseNet class My DenseNet implementation. ConclusionI am quite happy with the gotten results. This transformation is passed to the CifarDataset instance created so that when samples are taken from that dataset the returnedimages will be training ready. feature maps and how they can learn different patterns from each one of those channels. we are collect some characteristic data from the training process to check some statistics plot the train and validation losses plot the train and validation accuracies plot the train and validation top 3 accuracy get a batch of test images convert images to numpy for display plot the iamges of the batch can we move the tensors to GPU I evaluate the availability of cuda here again so that the user can use only this cell to predict the classes of the test images provided there is a. There are two reasons behind my decision There have been other users who have tried the BC variant of a DenseNet on the Cifar 10 dataset Based on the comparison I did it seams to me that the last DenseNet network I used could yield to a better result. Training Validation losses and accuracy development over the number of epochs Testing the best parameters obtainedThe model will try to predict the classes of data that has not been seen by it by the model. For this notebook I decided to go with a regular DenseNet network if the not BC variant can be called a standard DenseNet network. add the just built dense block to the main sequential module i. This has become for sure my favorite network architecture so far. This last dense block was previously left aside because after this last dense block comes no transition layer. For the images labels a numpy array is constructed with the corresponding index of the classes list also defined in the hidden cell. Let s get the accuracy on this model on such unseen images. I find my implementation in general but especially of the construction of the DenseNet to be more interesting as well as to follow in a better way the paper allowing the user to decide whether to construct DenseNet BC or just a regular DenseNet network without compression factor and without bottleneck layers. So this is my own implementation of DenseNet. At the end I compared my implementation against this other implementation https github. Model training function Training a DenseNetWe must now build an instance of a DenseNet class specify a loss function and an optimizer to then train our network. I wanted to make my own implementation of DenseNet and see it working. This exercise is more about having a working implementation of DenseNet and less about finding a solution for CIFAR 10. This exercise has been very satisfying and it has proven the simplicity and the power of DenseNets. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. Visualizing some images after transformationThis section serves both to demonstrate the usage of the loaders as well as to make sure the transformations are performed to the images. save the compression factor value needed to further build the network save the compression factor value needed to further build the network check that nLayers is either of type int or list if nLayer is of type list check that it is not empty track chane in validation loss const value. Thanks for checking this kernel out and as always if there are observation and or suggestions I will be more than happy to read from you. FloatTensor define transformations for the test images which means only converting them to Tensors and normalizing them creating the cifar dataset training indices to be used for validation purposes split the training dataset into a real training dataset and a validation set we take 24 percent of the training dataset for validation define samplers they sample obtain batches from a list of indices. 001 we reset it to 0. For example a frog could be misclassified as a bird given that the context of the frog s picture shares some commonalities with the context of a bird s pictures i. the name of the class an image belongs to draw batches of images from the test loader until all of them have been drawn get predictions of the classes of the iamges on this batch release the GPU memory prepare the submission of the predictions get 20 random indexes get a test image corresponding to the random index recently drawn get numpy images out of the images batch. read_csv Input data files are available in the. I checked the evaluation loss without these layer first and with these layers after and it works best wtih them. Yet another DenseNet implementationAfter readeing the DenseNet paper https arxiv. Instead a global average pooling takes place together with a fully connected network performing a softmax classifier. Previous to this notebook I did a very simple comparison of the performance of this implementation using two DenseNet BC networks and two DenseNet not BC variants networks. It is interesting to see the misclassified images and intuitively see what could have led the model to a wrong prediction. A train loader iterator is here created to draw batches of images which have been processed by the transforms transformations. I must mentioned that I liked the way that other implementation includes extracts of the paper on the relevant corresponding code lines allowing the reader to make a direct link between the code and the paper. Once the images and its labels are loaded in numpy arrays the cifar dataset is constructed by using thedefined CifarDataset class. 06993v5 I was as impressionable as a beginner can be surprised by its simple architecture and its powerful performance when compared agains other very well known image classification networks. get the number of inputs constructor of the class constructor of the class constructor of the class validate the parameters given to the main class creator to ensure a minimum degree of sane functionality check for the type of layer to be used. densenet add a transition layer right after a dense block do not forget to explicitly add the compression factor argument update the number of input feature maps of the next Dense Block create and add the last dense block. I have created a github repository as well which is found here https github. These are some of the images the densenet network will try to predict. pt file containing the trained parameters and that they are loaded to a similar DenseNet model as the model such parameters were trained i. First a class that takes numpy arrays that encode images and their labels is defined. densenet With adaptive pooling the output can be reduced to any feature map size although in practice it is often choosen size 1 in which case it does the same thing as global pooling but first a batch and relu layer I included this two layers after checking the implementation I refer to at the begining of this notebook. I wanted to try differen configuration on the amount of layers and dense blocks and see if I could find a configuration that could be beat the DenseNet BC network that got the best validation loss in the forementioned comparison I did. I am both glad and kind of sad to find out that most parts of my implementations were written basically identically. Data preparation and augmentation after its loading In the following hidden cells a dataset consisting of the images and its labels is being constructed. initialize all weights and biases for every linear layer in a model. I have no doubts I will get a good score like everybody else have already gotten but really this is more a playground to experiment with my implementation of the paper. Also I am still a beginner and based much of my training code on notebooks I developed during the Deep Learning nanodegree from Udacity which I pretty much recommend if you can afford it. same mode architecture release the GPU memory set the DenseNet model for evaluation only i. Those images are converted to a numpy arrays so they can be plotted. Then I d have a much clearer idea of how powerful this network really is. It would be nice to see how much a DenseNet architecture needs to change to get similar results in the Cifar 100 dataset. create the dense blocks according to the size of the nLayers list I define for clarity readability reasons a innerChanns variable whose value is initialized to preprocess_outmaps we skip here the creation of the last dense block. com armhzjz DenseNet. com armhzjz DenseNet tree master performance_Analysis. build a dense block with the number of layers according to the index indx of the nLayers list add the just built dense block to the main sequential module i. For this a transformation has also been defined to process the images. Such comparison can be found in here https github. green backgrounds or green leaves as backgrounds. com weiaicunzai pytorch cifar100 blob master models densenet. I liked that so I took that idea from the author. Displaying the image below is really irrelevant for this exercise but it is usefull to understand how convolutional networks see different pictures in different channels i. start updating the learning rate at this percentage of the nEpochs epoch at which the last learning rate update will be done reaching its minimum value percentage of epochs at which the optimization will reach its minimum learning rate check if CUDA is available release the GPU memory Encapsulate the model in case the learning rate update went a bit below 0. Its average train accuracy improved in a very stable way after epoch 30 and its best training loss is just 0. samples per batch number of subprocesses to use for data loading CifarDataset is a class that construct a dataset out of training images stored as numpy arrays and its corresponding training labels also stored as numpy arrays This CifarDataset class serves also to provide testing images converted Tensors in a way that they can be provided via a DataLoader specify the image classes loading the images and training labels we need to correctly transpose the numpy arrays so they can be converted to PIL images later while they are being drawn from the data loaders numpy array where the training labels are going to be stored as integer value convert data to a normalized torch. For example running this by clicking run or pressing Shift Enter will list all files under the input directory Any results you write to the current directory are saved as output. ", "id": "ahernandez1/mydensenet-implementation", "size": "7049", "language": "python", "html_url": "https://www.kaggle.com/code/ahernandez1/mydensenet-implementation", "git_url": "https://www.kaggle.com/code/ahernandez1/mydensenet-implementation", "script": "DataLoader __Validate_params __InitW_uniCenter Image numpy __Bottleneck(nn.Module) CifarDataset(Dataset) torch.nn datasets transforms torchvision __H_layer(nn.Module) matplotlib.pyplot DenseNet(nn.Module) forward PIL torch.utils.data.sampler pandas showImage SubsetRandomSampler torch.optim torch.utils.data __len__ Dataset __init__ __Transition_layer(nn.Module) TrainModel __getitem__ ", "entities": "(('ConclusionI', 'quite gotten results'), 'be') (('linear transformation', 'Softmax here layer'), 'use') (('intuitively what', 'wrong prediction'), 'be') (('previously aside last dense block', 'transition layer'), 'leave') (('reader', 'code'), 'mention') (('Instead global average pooling', 'softmax classifier'), 'take') (('numpy array', 'also hidden cell'), 'label') (('minimum degree', 'layer'), 'get') (('context', 'pictures i.'), 'misclassifie') (('corresponding', 'images batch'), 'belong') (('So this', 'own DenseNet'), 'be') (('such parameters', 'DenseNet similar model'), 'file') (('learning rate update', 'bit 0'), 'start') (('as well which', 'https here github'), 'create') (('how much DenseNet architecture', 'Cifar'), 'be') (('Such comparison', 'https github'), 'find') (('understanding', 'me'), 'want') (('densenet network', 'images'), 'be') (('transformation', 'also images'), 'define') (('pretty much you', 'it'), 'be') (('which', 'transforms transformations'), 'create') (('they', 'numpy arrays'), 'convert') (('as well transformations', 'images'), 'visualize') (('BC variant', 'DenseNet regular network'), 'decide') (('very it', 'DenseNets'), 'be') (('always I', 'more than you'), 'be') (('how network', 'much clearer idea'), 'have') (('I', 'kernel'), 'AcknoledgemetsDuring') (('when samples', 'returnedimages'), 'pass') (('it', 'best wtih'), 'check') (('else already really this', 'paper'), 'have') (('integer value', 'normalized torch'), 'be') (('I', 'paper'), 'hope') (('I', 'extracts'), 'use') (('batch', 'batch validate parameters'), 'build') (('read_csv Input data files', 'the'), 'be') (('we', 'DneseNet modDN model'), 'some') (('that', 'model'), 'try') (('exercise', 'CIFAR'), 'be') (('training 30 best loss', 'epoch'), 'improve') (('it', 'DenseNet'), 'want') (('as beginner', 'simple architecture'), '06993v5') (('they', 'indices'), 'define') (('cifar arrays dataset', 'CifarDataset thedefined class'), 'load') (('Model training DenseNetWe', 'then network'), 'function') (('It', 'python docker image https kaggle github'), 'come') (('here again user', 'test images'), 'be') (('you', 'output'), 'list') (('it', 'track validation loss const empty value'), 'save') (('feature how they', 'channels'), 'map') (('I', 'BC variant'), 'big') (('I', 'forementioned comparison'), 'want') (('both kind of most parts', 'implementations'), 'be') (('I', 'implementation https other github'), 'compare') (('number', 'last dense block'), 'add') (('so I', 'author'), 'like') (('s', 'such unseen images'), 'let') (('I', 'definitely her'), 'like') (('user', 'bottleneck layers'), 'find') (('how convolutional networks', 'channels different i.'), 'be') (('I', 'better result'), 'be') (('we', 'last dense block'), 'create') (('Next data', 'numpy arrays'), 'load') (('encode images', 'numpy arrays'), 'class') (('which', 'training process'), 'prepare') (('Data preparation', 'images'), 'construct') (('entropy loss', 'model'), 'start') (('GPU memory', 'evaluation'), 'release') (('I', 'DenseNet BC two networks'), 'previous') (('growth 16 rate', 'input images'), 'create') (('I', 'notebook'), 'reduce') "}
{"name": "multiclass classification wine quality beginner ", "full_name": " h1 Exploring the dataset h1 EDA h1 Heatmap for correlation between all features h1 Treating outliers h1 Checking for skewness h1 Preprocessing the data h1 Multiclassification h1 Standarisation h1 PCA for dimension reduction h1 SMOTE h1 Training the data ", "stargazers_count": 0, "forks_count": 0, "description": "residual sugar Fixing skewness using boxcox 3. total sulfur dioxide 5. Instead of checking one by one we can use correlation matrix and heat map to analyse the correlation between each feature at once volatile acidity VS Quality PH VS Quality Heatmap for correlation between all features Treating outliers I am going to use IQR method remove the outlier. Checking for null values 3. Residual sugar VS Quality we can see that there is no correlation between the residual sugar and quality. boxcox transofrm the skewed data into normal distribution. Checking for skewness Skewd diustribution gives bias result on training. We will first check the data for each features is following normal distribution or not using distplot. Your professor sticks to the normal grading scale out of 100 so you got a grade of 84 the test has a mean of 77 and a standard deviation of 6. Both of you scored above average but who did better While the main data points might not be immediately comparable there is a way to standardize and compare the data points. alcohol Preprocessing the data Multiclassification Standarisation Why we need standarisation Data standardization is about making sure that data is internally consistent that is each data type has the same content and format. So we will drop this column as it has not contribution in determining the qulaity. free sulfur dioxide 4. Your friend s professor though uses his own grading scale so she got a grade of 452. class1 bad qulaity 3 4 Class2 Avergae qulaity 5 6 7 Class3 Good qulaity 8 plot the graph to find the principal components AS per the graph we can see that 8 principal components attribute for 90 of variation in the data. if it is not following then we will use the boxcox to treat the skewness. read_csv Input data files are available in the read only. So we are removeing all those value from selected columns. Converting them to percentages shows that you came out ahead with an 84 compared to your friend s 60. of rows and columns 2. com kaggle docker python For example here s several helpful packages to load linear algebra data processing CSV file I O e. 5IQR are considers as Outliers. of rows mean value of each rows std and five number summary EDA Quality count Alcohol VS Quality we can see that as we are increasing the alcholo the quality of wine is improving. fixed acidity Fixing skewness using boxcox 2. The value which is above the Q3 1. PCA for dimension reduction pca removes features which has less contribiuton in Spliting the data in train and test SMOTE fixing the imbalance dataset we need to fix imbaalnce dataset becuase imbalamce dataset gives biased result Training the data Random forest classifier Checking the accuracy This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python Docker image https github. Her test has a scale of 750 mean of 400 and standard deviation of 100. Checking the data types of each feautes and nows of rows and null count 4. input directory For example running this by clicking run or pressing Shift Enter will list all files under the input directory You can write up to 20GB to the current directory kaggle working that gets preserved as output when you create a version using Save Run All You can also write temporary files to kaggle temp but they won t be saved outside of the current session Fixing skewness using boxcox Fixing skewness using boxcox Fixing skewness using boxcox dividing the target variable quality into 3 class. Importing Required Libraries Loading the red wine quality dataset Exploring the dataset 1. we shall pick the first 8 components for our prediction. So it need to be fixed before training it. For example suppose you and your friend went to different universities. One day you both got your midterm grades for your Physics 101 classes. ", "id": "inzamamsafi/multiclass-classification-wine-quality-beginner", "size": "2918", "language": "python", "html_url": "https://www.kaggle.com/code/inzamamsafi/multiclass-classification-wine-quality-beginner", "git_url": "https://www.kaggle.com/code/inzamamsafi/multiclass-classification-wine-quality-beginner", "script": "Counter train_test_split SMOTE sklearn.ensemble stats accuracy_score boxcox numpy seaborn imblearn.over_sampling norm scipy PCA matplotlib.pyplot sklearn.model_selection pandas RandomForestClassifier scipy.stats sklearn.decomposition sklearn.metrics collections StandardScaler sklearn.preprocessing ", "entities": "(('we', 'prediction'), 'pick') (('it', 'qulaity'), 'drop') (('you', 'standard 6'), 'stick') (('read_csv Input data files', 'read'), 'be') (('boxcox', 'normal distribution'), 'transofrm') (('sugar VS Residual we', 'residual sugar'), 'Quality') (('you', 'different universities'), 'suppose') (('We', 'distplot'), 'follow') (('we', 'data'), 'class1') (('Checking', 'training'), 'give') (('you', 'friend'), 'show') (('One day you', 'Physics 101 classes'), 'get') (('So it', 'it'), 'need') (('test', '100'), 'have') (('then we', 'skewness'), 'use') (('I', 'outlier'), 'of') (('t', '3 class'), 'list') (('she', '452'), 'use') (('So we', 'selected columns'), 'remove') (('data type', 'same content'), 'alcohol') (('It', 'kaggle python Docker image https github'), 'remove') (('data better main points', 'data immediately points'), 'score') (('quality', 'wine'), 'value') "}
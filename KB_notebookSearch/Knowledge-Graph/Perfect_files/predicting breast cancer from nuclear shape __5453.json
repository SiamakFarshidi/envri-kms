{"name": "predicting breast cancer from nuclear shape ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "Predicting Breast Cancer From Nuclear Shape The nucleus is an organelle present within all eukaryotic cells including human cells. Next I will try using neural networks in order to make these same predictions. pap smear tests and the diagnosis of cervical cancer. Next I will scale the values by using the sklearn. Next I will try building a custom neural network using the Keras library. We had our best results when we used SVM MLPC or a VotingClassifier where we combined both SVM and MLPC. scale function which functions by subtracting the mean and then dividing by the standard deviation in order to generate values that are centered around zero. Step 1 Import Modules Step 2 Explore Data See Column Titles Raw Data and Null Counts Step 3 Plot Data Compare the size and shape of the nuclei from malignant samples to the size and shape of the nuclei from benign samples. html cross validation Step 5 Define Helper Functions for Plotting Learning Curve and Confusion Matrix Step 6 Evaluate Classification Models Now I will try running a few different classification algorithms such as Logistic Regression and Support Vector Machines. This type of data is compatible with a wide variety of different classification algorithms. Abberant nuclear shape can be used to identify cancer cells e. With PCA we transform our features to make them less correlated via a process that involves dimensionality reduction. We want a learning curve where the vali score gets close to converging with the training score but does not quite converge. Next I will plot confusion plots for SVM where the Y Axis represents the True labels Malignant or Benign while the X Axis represents the Predicted labels generated by the Support Vector Machine. Furthermore we had the best results when we used data scaling and we did not see much of a difference when we used PCA. This confirms my prediction that healthy nuclei are typically circular elliptical and that cancer cells are mishapen and have lots of concave points. Here in this document I demonstrate a methodology to predict if a sample is benign or malignant given measurements of nuclear shape that were made from digital images of fine needle aspirates of breast tissue masses from clinical samples. For more information see the following documentaion http scikit learn. html pcaFurthermore we will also need to split up our training data setting aside 20 of the training data for testing such that we can avoid potentially overfitting the data. Step 4 Preprocess Data Next I will pre process the data so that it is ready for analysis. The learning curve for Support Vector Machine looks pretty good. scale function at the following link http scikit learn. In the future tools like this can be used to save time cut costs and increase the accuracy of imaging based diagnostic approaches in the healthcare industry. By looking at the size and shape of the nuclei present within these tissue samples doctors can determine whether a given sample appears to be benign B or malignant M. This confirms my prediction that healthy nuclei have a default size and that cancer cells have a wide range of sizes typically greater than the default size. html By doing this we will have data with numerical Y values and X values that are centered around zero. I will do this both with and without the data scaling step in order to illustrate the importance of this preprocessing step. I will do this to make sure that we are not overfitting the training data. First I will convert the labels B and M to 0 and 1 respectively. org stable modules generated sklearn. You can learn more about the sklearn. Another data preprocessing step that we can do is Principal Component Analysis PCA. org stable modules cross_validation. Let s explore the Support Vector Machine SVM approach in a little more detail. As such the quantitative analysis of nuclear size and shape has important biomedical applications. io models sequential This is just to compare what we would do in Keras to what we would do in Sklearn Next I will try a voting classifier where we combine the best two models SVM and MLPC. Likewise a growing body of literature suggests that there is some connection between the shape of the nucleus and human disease states such as cancer and aging. html http scikit learn. htmlhttp scikit learn. My apologies to the small percentage of patients with malignant tumors who were told that their tumors were benign. org stable modules decomposition. In order to choose between these classification algorithms I will plot learning curves where I illustrate the relationship between the accuracy score and the cross validation score for increasing sample sizes. Besides that we were consistently accurate. The train_test_split function accomplishes this as described in the following documentation http scikit learn. In addition to being larger than healthy cells cancer cells are often mishapen. It would be hepful to have an automated method that can quickly determine if a sample is benign or malignant. Technicians can use a microscope to observe tissue samples that were taken from patients who are suspected to have breast cancer. ", "id": "paultimothymooney/predicting-breast-cancer-from-nuclear-shape", "size": "5453", "language": "python", "html_url": "https://www.kaggle.com/code/paultimothymooney/predicting-breast-cancer-from-nuclear-shape", "git_url": "https://www.kaggle.com/code/paultimothymooney/predicting-breast-cancer-from-nuclear-shape", "script": "runVotingClassifier plotSizeDistribution plotLotsOfLearningCurves keras.layers Activation keras.models train_test_split keras.wrappers.scikit_learn confusion_matrix sklearn.discriminant_analysis accuracy_score numpy sklearn.svm seaborn SGD Adam MLPClassifier preprocessing Adadelta Dropout KerasRegressor defineModels Dense SVC LinearSVC selectParametersForSVM GaussianNB sklearn.neighbors sklearn.naive_bayes sklearn.tree GradientBoostingClassifier sklearn.neural_network RMSprop plot_confusion_matrix compareABunchOfDifferentModelsAccuracy keras.optimizers sklearn PCA learning_curve sklearn.linear_model runSimpleKeras matplotlib.pyplot KerasClassifier DecisionTreeClassifier plot_learning_curve Sequential LinearDiscriminantAnalysis sklearn.model_selection pandas MLPClassifier as MLPC describeData Adagrad print_function RandomForestClassifier LogisticRegression model_selection __future__ plotConcaveDistribution plotPNG VotingClassifier KNeighborsClassifier sklearn.metrics sklearn.decomposition GridSearchCV selectParametersForMLPC make_scorer sklearn.ensemble diagnosisToBinary ", "entities": "(('where we', 'SVM'), 'have') (('Likewise growing body', 'such cancer'), 'suggest') (('that', 'clinical samples'), 'demonstrate') (('such we', 'potentially data'), 'need') (('given sample', 'tissue present samples'), 'determine') (('who', 'breast cancer'), 'use') (('where I', 'cross validation sample sizes'), 'plot') (('we', 'training data'), 'do') (('X Malignant Axis', 'Support Vector Machine'), 'plot') (('scikit', 'more information'), 'see') (('scikit', 'documentation following http'), 'accomplish') (('Next I', 'sklearn'), 'scale') (('where we', 'best two models'), 'sequential') (('when we', 'PCA'), 'have') (('X that', 'zero'), 'have') (('First I', '0'), 'convert') (('learning curve', 'Support Vector Machine'), 'look') (('quickly sample', 'automated method'), 'be') (('data', 'preprocessing step'), 'do') (('Column Titles Raw Plot Data Null Step 3 Data', 'benign samples'), 'step') (('it', 'analysis'), 'Data') (('s', 'little more detail'), 'let') (('cancer typically circular cells', 'concave points'), 'confirm') (('vali where score', 'training close score'), 'want') (('Abberant nuclear shape', 'cancer cells e.'), 'use') (('Next I', 'same predictions'), 'try') (('that', 'zero'), 'function') (('Next I', 'Keras library'), 'try') (('cancer cells', 'default typically greater size'), 'confirm') (('quantitative analysis', 'important biomedical applications'), 'have') (('scikit', 'link following http'), 'learn') (('Now I', 'Logistic such Regression'), 'cross') (('type', 'classification different algorithms'), 'be') (('tumors', 'malignant tumors'), 'apology') (('nucleus', 'human cells'), 'predict') (('we', 'that'), 'be') (('that', 'dimensionality reduction'), 'transform') "}
{"name": "students performance eda and prediction ", "full_name": " h4 Descriptive Analytics h3 Checking for missing values h3 Feature Classification h4 KDE plot h4 Scatterplots for the numerical variables h4 Group with most number of people h3 Categorical Scatterplots h4 Education level of Parents h4 Gender Lunch and Test preperation h4 The group of people who scored the highest number of total marks h4 Parents educational levels and students performance h4 How does gender effect the students performance individually h3 Which subject has the most number of failures h4 Grading the Students h4 Male and Female Students Grades h4 Relationship between grades and lunch h4 Test Preperation Course and Grades h3 Creating dummy variables h3 Training the Models h4 Evaluating the performance of our regression models h4 Linear Regression h4 Decision Tree Regression h4 RandomForest Regression h4 Feature Importance Plot for Random Forest h4 Comparing the performance h4 My other notebooks h3 References h3 Do upvote the kernel if you find it useful Feedback is highly appreciated Thank You ", "stargazers_count": 0, "forks_count": 0, "description": "Categorical ScatterplotsAs we cannot see the parental level of education clearly I will plot it again. Descriptive Analytics Checking for missing valuesThere are no missing values present in our dataset. My other notebooks 1 https www. com ruthvikpvs heart attack analysis eda and prediction References1. The students who have completed any course are less than the students who did not prepare. 24 and the predictions are not accurate most of the time. So decision tree regression is not suitable for our data. We can observe from the above graphs that most of the students score above 150 marks. Skewness and kurtosis Math and reading scores Mathematics and Writing Scores Reading and writing Scores color highlight color highlight color highlight color highlight Number of students who passed in math Number of students who passed in reading Number of students who passed in writing. Gender Lunch and Test preperationWe can observe from the above figures that 1. Feedback is highly appreciated. Male and Female Students Grades Relationship between grades and lunch Test Preperation Course and Grades Creating dummy variablesWe use One Hot Encoding to encode categorical variables. MSE Mean Square Error is an absolute measure of the goodness for the fit. If skewness is between 0. If skewness is between 1 and 0. Even though Linear Regression performs better than these models the r_squared value is only 0. com running random forests inspect the feature importances with this code 2b00dd72b92e. Most of the scores fall between 40 100 range. Parents educational levels and students performance How does gender effect the students performance individually Which subject has the most number of failures 1. We can observe that 1. Parents who hold a master s degree are very few in number. Linear Regression Decision Tree Regression RandomForest Regression Feature Importance Plot for Random Forest Comparing the performanceIf we compare the three models we used for predictions. R squared Measures how much of variability in dependent variable can be explained by the model. com josephchan524 studentperformanceregressor rmse 12 26 r2 0 26 Do upvote the kernel if you find it useful. The scores increases linearly with each other. Use the shape method to see the number of rows and columns in our dataset. com ruthvikpvs stroke data eda and prediction2 https www. com spscientist student performance in exams2. There are 1000 rows and 8 columns in our dataset. KDE plotAs a general rule of thumb If skewness is less than 1 or greater than 1 the distribution is highly skewed. We can see that our numerical data follows the normal distribution. The info method gives the summary of our data. com subinium kaggle 2020 visualization analysis4. Females students are more than male students. Scatterplots for the numerical variablesWe can see from the above figure that 1. Students who prefer standard lunch are more in number than students who prefer free reduced lunch. MAE Gives us the difference between the actual value and predicted value. Importing the libraries Adding a column for the total marks. Random Forest performs better than Decision Trees but not as good as Linear Regression. For One Hot Encoding we use pd. This us useful as we can check if there are any missing values present or not. We use histograms to observe how the scores of students are distributed. get_dummies Training the Models Evaluating the performance of our regression models. Grading the StudentsMost of the students achieved a B Grade followed by Grade C. Encoding is necessary because machine learning models do not work with categorical variables. So dividing by 3 gives the. The R squared value of Decision Tree Regression is negative. Eg If the actual value is 10000 and the predicted value is 5000 then we can say that the actual value is 5000 more than the predicted value. Students percentage Percentage number 100 here the highest marks 300. The group of people who scored the highest number of total marksThe students in Group C scored the most number of marks among all the groups followed by groups D B E and group A. com what are the best metrics to evaluate your regression model 418ca481755b If squared True then its MSE if squared False then its RMSE https towardsdatascience. The Mean Square Error value of Linear Regression is 1436 on average the predictions have 1436 difference from the actual values 3. 5 and 1 the distribution is moderately skewed. Overall the number of students who failed are significantly less than the students who passed. Linear regression performed far better than Decision Trees and Random Forest algorithms. The number of people who failed in mathematics are more than other subjects. Only a small portion of students scored less than 40. 5 the distribution is approximately symmetric. Feature ClassificationIt is good practice to categorize the numerical and categorical variables. Group with most number of peopleGroup C has the most number of people and Group A has the least amount of people. com subinium simple matplotlib visualization tips3. Education level of ParentsMost of the parents attended some college 226 and almost the same amount of people have an associate s degree. Importing the libraries Splitting the data into training and testing sets https towardsdatascience. R squared values less than 0 means a horizontal line fits the data better than our model. ", "id": "ruthvikpvs/students-performance-eda-and-prediction", "size": "4911", "language": "python", "html_url": "https://www.kaggle.com/code/ruthvikpvs/students-performance-eda-and-prediction", "git_url": "https://www.kaggle.com/code/ruthvikpvs/students-performance-eda-and-prediction", "script": "EvaluatingModels train_test_split LinearRegression stats RandomForestRegressor numpy seaborn mean_absolute_error norm sklearn.tree scipy sklearn.linear_model matplotlib.pyplot sklearn.model_selection GetGrade pandas DecisionTreeRegressor r2_score mean_squared_error matplotlib scipy.stats sklearn.metrics sklearn.ensemble ", "entities": "(('average predictions', 'actual values'), 'be') (('clearly I', 'it'), 'ScatterplotsAs') (('who', 'free reduced lunch'), 'be') (('lunch Test Preperation Grades Creating', 'categorical variables'), 'Relationship') (('com running random forests', 'code'), 'inspect') (('machine learning models', 'categorical variables'), 'be') (('it', '12 26 r2 0 26 kernel'), 'rmse') (('most', '150 marks'), 'observe') (('Only small portion', 'less than 40'), 'score') (('who', 'other subjects'), 'be') (('who', 'groups D B E'), 'score') (('we', 'predictions'), 'Plot') (('who', 'very number'), 'be') (('who', 'writing'), 'skewness') (('who', 'students'), 'be') (('MAE', 'actual value'), 'give') (('who', 'significantly students'), 'be') (('Group', 'people'), 'have') (('Feature ClassificationIt', 'good numerical variables'), 'be') (('how much', 'model'), 'square') (('info method', 'data'), 'give') (('best metrics', 'RMSE https then towardsdatascience'), 'com') (('that', '1'), 'observe') (('actual value', '5000 predicted value'), 'say') (('value', 'Decision Tree Regression'), 'square') (('Descriptive Analytics Checking', 'valuesThere missing present dataset'), 'be') (('r_squared value', 'better models'), 'be') (('predictions', 'time'), 'be') (('Linear regression', 'Decision far better Trees'), 'perform') (('226 almost same amount', 'degree'), 'attend') (('how scores', 'students'), 'use') (('less than 0 horizontal line', 'better model'), 'square') (('Random Forest', 'Linear as Regression'), 'perform') (('scores', 'linearly other'), 'increase') (('Scatterplots', '1'), 'see') (('numerical data', 'normal distribution'), 'see') (('MSE Mean Square Error', 'fit'), 'be') (('Grading', 'Grade C.'), 'achieve') (('individually subject', 'failures'), 'level') (('less than 1 than 1 distribution', 'KDE general thumb'), 'rule') (('Females students', 'male students'), 'be') (('Most', '40 100 range'), 'fall') (('decision tree So regression', 'data'), 'be') "}
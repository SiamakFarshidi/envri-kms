{"name": "whale recognition model with score 0 78563 ", "full_name": " h1 Whale Classification Model h1 Abstract h1 Overview h2 Content h1 Duplicate image identification h1 Image preprocessing h2 Image rotation h2 Convert to black and white h2 Affine tranformation h1 Siamese Neural Network architecture h2 Head model h2 Branch model h2 Code h1 Training data construction h2 Image selection h2 Matching whale examples h2 Different whales examples h2 Code h1 Training procedure h1 Generating the submission file h1 Bootstrapping and ensemble h2 Bootstrapping h2 Ensemble h1 Visualization h2 Feature weights h2 Pseudo distance function h2 Feature activation h1 Off topic h2 Training Scalability h2 Interesting results and scores h2 Validation set ", "stargazers_count": 0, "forks_count": 0, "description": "The random matrix has values uniformly distributed between 0 and K. However greater accuracy can be achieved by retraining the model using all the data repeating he procedure that was successful on the validation set. By testing each image from the test set against every image from the training set the most likely whales can be identified by sorting the pictures in likelihood for a match. CodeThe following is the Keras code for the model. shuffle the training pictures Map whale id to the list of associated training picture hash value Map training picture hash value to index in train array Compute the match score for each picture pair Train the model for step epochs Collect history data epoch 10 epoch 150 epoch 200 epoch 240 epoch 250 epoch 300 epoch 350 epoch 390 epoch 400 Not computing the submission in this notebook because it is a little slow. ca gkoch files msc thesis. Fortunately only the head model must be computed for all pairs and it is very fast. For each whale of the training set compute a derangement https en. For each feature I compute the sum the product the absolute difference and the difference squared x y x y x y x y 2. The left side image is the original image fluke pointing down. VisualizationThis section explores the model through some visualizations. Both images have the same Perceptual Hash http www. Training lasts 400 epochs with the following quantities changing as the training progresses Learning rate L2 regularization Constant K measuring the scale of the random component of the score matrix used to match similar images to construct tough training cases. This notebook essentially describes this final retraining and thus there is no validation set involved. Training the large model from random weights is difficult. The simplest solution was to convert all images to black and white which did not reduce the accuracy even when comparing originally colored images. The smaller K the more difficult the pairing is for the model. During development I used a validation set composed of 570 images from the training set to test ideas and to tune the training procedure. Sort the whales in decreasing score. During training data augmentation is performed by adding a random transformation that composes zoom shift rotation and shear. More than 50 of the time is spent solving the Linear Assignment Problem because the algorithm used has complexity O n 3 and provides an exact solution. Training data construction most of the secret sauce is here 1. 78563 submission to the Humpack Whale identification Challenge. However the code is still provided in the notebook as reference even if it is not executed by default. These convolutions are less memory intensive then the subsequent ResNet blocks and are used to save memory. The list is in no way exhaustive. 58 061 150 64. For this experiment I selected all images from the test set for which the mpiotte standard model provides a single whale prediction with a score 0. 325 new_whale submission0. Head modelThe head model compares the feature vector from the branch model to decide if the pictures show the same or different whales. This could be that we match uniform unicolor flukes which is less likely to be correct that mathing flukes with multiple caracteristic markings. have the same size and 1. Generate the subsmission file. Still I feel there is more postive signal in the active features than in the negative ones especially with ReLU Rectified Linear Unit activation concept that is lost by the distance measure. The similarity between each pair of image is computed using the current model state. The assembly strategy consist in compute a score matrix or dimension test by train that is a linear combination of the standard and bootstrap model. During training these images are rotated 180 degrees to normalize them with the fluke pointing up. We want the Siamese Neural Network to pick the one correct whale from all the possible whales from the training set. It is not enough to have a random whale score low. The center image does the test transformation. Essentially we forcus the training on pairs that he model is getting wrong as a form of adversarial training. Because algorithm is O n 3 small batches are much faster. Affine tranformationThe affine transformation https en. This is inspired from adversarial training find pairs of images that are from different whales but that are still very similar from the model perspective. If a picture is used more often in negative examples the model risks simply learning to guess a mismatch whenever this picture is present without learning how to compare the whales correctly. Visualization everyone s favorite 1. Use only identified whales For each whale find the unambiguous images ids. Initial noise Gradient step Construct the function Stimulate the 4 central cells Use gradient descent to form image Blurring a little creates nicer images by reducing reconstruction noise Clip the image to improve contrast Show the first 25 features of 512. The branch model is composed of 6 blocks each block processing maps with smaller and smaller resolution with intermediate pooling layers. With Windows 10 and a GTX 1080 card there is about 6. Similarly training starts with no L2 regularization. We can also check how per feature network behave for different feature values. When y is None score is a packed upper triangular matrix. This has complexity frac n n 1 2 where n is the size of the training set. Branch modelThe branch model is a regular CNN model. Off topic why add this unless it is interesting Duplicate image identificationThis section describes the heuristic used to identify duplicate images. At the same time we want the model to recognize whales and not pictures. For each picture from the test set 1. We can verify that we see a combination of positive and negative weights that confirm that some features when matched reduce the probability of matching whales. A list of training image ids Associate the image ids from train to each whale id. I call the CNN the __branch model__. Find elements from training sets not new_whale Use only identified whales Dictionary of picture indices Evaluate the model. The right image adds a random data augmentation transformation. Oops this is HUGE Find all the whales associated with an image id. In this context bootstrapping means using the model to automatically generate additional training example and retrained the model over this larger dataset. A ResNet like architecture is more economical than a VGG https arxiv. model and mpiotte bootstrap. com books deep learning with python by Francois Chollet. Each training epoch is composed of a sequence of image pairs A B such that Exactly 50 of the pairs are for matching whales and 50 for different whales Each image from the training set is used exactly 4 times per epoch A and B images of matching whales A and B images of different whale pairs Pairs of images of different whales are selected to be difficult for the network to distinguish at a given stage of the training. The four values are passed through a small neural network which can learn how to weigh between matching zeros and close non zero values. Trial and error suggest a weight of 0. Epochs LR K L2 1 10 64. Feature weightsAs was discussed in the model description the head model makes a weighted sum of the features allowing for negative weights. phash that differ by at most 6 bits and 1. OverviewThis notebook describes all the different elements of the submission. Consider a case where if both images have feature X they must be the same whale unless they also both have feature Y in which case X is not as clear. Block 1 384x384 Block 2 96x96 Block 3 48x48 Block 4 24x24 Block 5 12x12 Block 6 6x6Block 1 has a single convolution layer with stride 2 followed by 2x2 max pooling. org wiki Assignment_problem algorithm is used to find the most difficult matching. To randomize the selection and control the matching difficulty we add a random matrix to the cost matrix from step 1. match len train len self. Generating the submission file re zzzzz. 00 0151 200 16. The element that generated the largest accuracy improvement is the procedure used to generate image pairs during training. L_1 with a contrastive loss function but there are a few reasons to try something different A distance measure will consider two features with value zero as a perfect match while two features with large but slightly different values will be seen as good but not quite as good since they are not exactly equal. The p2h dictionary associate a unique image id phash for each picture. 744 with a threshold 0. Use only unambiguous pictures Skip excluded images Find the list of training images keep only whales with at least two images. Because algorithm is O n 3 small partitions are much faster but not what produced the submitted solution Maximizing the score is the same as minimuzing score. pdf with a few modifications that will be covered in details later. To prevent this the data presented to the model must be unbiased. 78563 using a threshold of 0. This confirms are initial assumptions. Duplicate image identification not much to see here keep moving 1. The larger K the more random the matching. Another approach to training scalability would be to partition the training data into different subset each subset being processed separately to match image pairs. Some images are perfect binary copies while other have been altered somewhat contrast and brightness size masking the legend etc. Training procedure zzzzz. 55 for the bootstrap model. However to scale this approach a less costly randomized matching heuristic would be more effective. Interesting results and scoresScore Description 0. Solve the linear assignment problem Compute a derangement for matching whales Construct unmatched whale pairs from the LAP solution. org wiki Derangement of its pictures. The 512 feature vectors can be pre computed once for each image i. 752 VGG like CNN trained like standard model0. Both images have 1. The following algorith is used to generate the pairs 1. A Convolutation Neural Network CNN transforms an input image into a vector of features describing the whale. To force all the other whales to a low probability the training algorithm presents pairs of pictures with increasing difficulty as evaluated by the model at any given time. For each whale from the training set compute the whale score as the maximum image score for this whale. By presenting each image an equal number of times with 50 positive and 50 negative examples the model has no incentive in learning to recognize specific pictures and thus focuses on recognizing whales as desired. model also included in the dataset. Generation of the submission using the score matrix is unchanged. The same neural net with the same weights is used for each feature. Given the small number of pictures in the training dataset it is not irrealistic to imagine the model recognizing a specific picture using the shape of a wave or a bird flying by. Image selectionTo begin we reduce the number of images from the training set Images from the blacklist are removed Duplicate images are removed All new_whale images are removed All whales with a single image are removed. This model as a slightly better score of 0. To speed things up the results of some slow computations are included as a dataset instead of being recomputed here. Other details contribute somewhat to the accuracy but have a much smaller impact. EnsembleThe best score is obtained by an ensemble of the mpiotte standard. 10 5 infty 011 15 64. 999999 score is just a number use to rank whales it is not a probability. Image preprocessingTraining is performed on images subjected to the following operations 1. The prefered image is the one with the highest resolution or any one if they have the same resolution. Pseudo distance functionNot very easy to see but still the largest output best whale match occurs for matching features with large values. It takes about 15 minutes on setup with a GTX 1080. the pixelwise mean square error between the normalized images is below a given threshold. The right side image is rotated 180 degrees. Two images are considered duplicate if they meet the following criteria 1. Obviously to cover everything it has to be fairly long. The fact that the training and test set have duplicate images has already been well documented. Block 2 has two 3x3 convolutions similar to VGG. Because the training data set is small and the test set is larger bootstrapping is a good candidate to improve the score. Set a large value for matching whales eliminates this potential pairing This is a match Different whales Skip this on the last epoch. However the score matrix is randomized so investing a lot of time to compute an exact solution to a randomized input is wasteful. If the image duplicates one or more training set images add the whales possibly more than one from the training image as the top candidates. Add new_whale with a fixed new whale score of threshold. Different whales examplesDifferent whales examples are generated by computing a derangement of all pictures from the training set subject to The image pairs must belong to different whales The pairs formed must be difficult for the model to distinguish. As the model ability to distinguish between whales increases K is gradually reduced presenting harder training cases. Reasons could be the underside of the fluke is not visible or we see only dead fluke fragments on the a beach there are two whales in the picture etc. Entry that correpond to pair of images from the same whale are set with similarity infty. In fact if the model is initially fed examples that are too hard it does not converge at all. Training procedureThis scection describes the procedure used to train the model. At the time I am writing this kaggle kernel with custom package fail to commit. The typical approach is to use a distance measure e. The value of the weight is redundant because the weight is just a scaling factor of the feature which could be learned by another layer however it allows for negative weights which cannot be produced otherwise when using ReLU activation. The following table shows the exact schedule used for the learning rate LR L2 regularization L2 and randomized score matrix K. 50 0200 240 4. scipy can be used as a fallback but it is too slow to run this kernel under the time limit As a workaround use scipy with data partitioning. 10 4 Generating the submission fileThe basic strategy is this. For each image not new_whale from the training set compute the image score which is the model score for the image pair. It computes only the upper triangular matrix of the cost matrix if y is None. 45 for the standard model and 0. Bootstrapping and ensemble classic but short 1. To address these concerns i proceed as follow 1. 8GB VRAM available and this limit has constrained the model choice. The left image is the original picture. Pushed to the extreme it it possible to construct a training dataset for which pairs of pictures of different whales appear to the model more similar than pairs of pictures from the same whale making the model learn to classify similar images as different whales and dissimilar images as same whales To prevent this early training is executed with a large value of K making the negative examples essentially random pairs of pictures of different whales. Feature activationThis section attempts to reconstruct image that maximally activate a feature. Here are the key elements of its design Because the training dataset is small I tried to keep the number of learned parameter relatively small while keeping the model expressive enough. 0 the mean square error does not exceed 0. Adding these files to the training set and re running the training from scratch generates the mpiotte. The output is a weighted sum of the converted features with a sigmoid activation. The subset can be reconstructed randomly each time the cost matrix is computed. However comparing a colored image with a black and white image resulted in much lower accuracy. Convert to black and whiteIn my early experiments I noticed that my models achieved approximately the same accuracy when comparing two colored images or two black and white images. 15 close to the average picture aspect ratio. The bootstrap model is trained on more data however the tagging accuracy is lower since the bootstrap data is only 93 accurate. com martinpiotte bounding box model notebook which describes separately the strategy for image cropping. Siamese Neural Network architectureThe Siamese Neural Network compares two images and decides if the two images are taken from the same whale or different whales. Bootstrapping and ensembleThe mpiotte standard. The resulting ensemble as an accuracy of 0. At the same time there is this implicit assumption that swapping the two images must produce the same result if A is the same whale as B B must be the same whale as A. Using slow scipy. Image preprocessing just the regular stuff 1. In the context of this competition with no constraint on runtime and a small dataset it was a pragmatic choice. Transform to black and white 1. Use the original order as picture A and the derangment as picture B. While scoring the correct whale high it must simultaneously score all other whales lower. Find all images associated with a given phash value. To produce different matching for successive epochs the selected entries in the matrix are overwritten with infty to force an alternate selection for the next matching. AbstractThe approach used for this submission is essentially a Siamese Neural Network http www. The list is not exhausitve there are probably more case that I have not noticed. 25 0251 300 64. Show an example of a duplicate image from training of test set For each images id select the prefered image Select the image with highest resolution Read the bounding box data from the bounding box kernel see reference above Suppress annoying stderr output when importing keras. The position in train of each training image id First try to use lapjv Linear Assignment Problem solver as it is much faster. Unpack and transpose to form the symmetrical lower triangular matrix. The same CNN with the same weights is used for both images. At the same time very dissimilar values must be penalized. Generate the transformation matrix Read the image transform to black and white and comvert to numpy array Apply affine transformation Normalize to zero mean and unit variance Reduce the number of features to filter Extend the feature field no activation Restore the number of original features Add the bypass connection BRANCH MODEL 384x384x1 96x96x64 48x48x64 48x48x128 24x24x128 24x24x256 12x12x256 12x12x384 6x6x384 6x6x512 512 HEAD MODEL Per feature NN with shared weight is implemented using CONV2D with appropriate stride. What I call the __head model__ is used to compare the feature vectors from the CNN and decide if the whales match or not. 714 standard model without exclusion list rotation list and bounding box model i. It can be ambiguous as duplicate images may have different whale ids. Matching zeros get llower value. First pair is for matching whale Second pair is for different whales A Keras generator to evaluate only the BRANCH MODEL A Keras generator to evaluate on the HEAD MODEL on features already pre computed. Finally the image is normalized to zero mean and unit variance. Read the dataset description Determise the size of each image Read or generate p2h a dictionary of image name to image id picture to hash Two phash values are considered duplicate if for all associated image pairs 1 They have the same mode and size 2 After normalizing the pixel to zero mean and variance 1. The rectangular area has a width over height aspect ratio of 2. Note that after this the tensor has dimension 96x96x64 the same volume as the initial 384x384x1 image thus we can assume no significant information has been lost. Siamese Neural Network architecture some interesting thoughts 1. It should be studied in conjunction with the Bounding Box Model http www. A Siamese Neural Network is composed of two parts. I used a custom model mostly inspired from ResNet https www. org openaccess content_cvpr_2016 papers He_Deep_Residual_Learning_CVPR_2016_paper. 25 0241 250 10 5 0. 10 4 301 350 16. Off topic Training ScalabilityAs described training the base model takes about 2 days and the bootstrap version a little under 3 days using a i7 8700 CPU and GTX 1080 GPU. com martinpiotte bounding box model as computed in the model defined in a separate kernel The idea is that clipping the edges of the fluke is more harmful than the gain obtained by fitting it exactly thus a margin is preferred. It is interesting to note how the threshold value for the ensemble is much lower which is consistent with the fact that both models make different errors and thus the ensemble scores are typically lower than the individual models which are grossly optimistic about they guesses. unmatch len train Test on a batch of 32 with random costs. 1 Compute phash for each image in the training and test set. Blocks 3 to 6 perform ResNet like convolution. The output of these convolutions is then added to the original tensor bypass connection. At this point L2 regularization is applied learning rate is reset to a large value and training continues for an additional 150 epochs. The problem turned out to be memory bound with most memory being taken to store activations from the feedforward pass used to compute the gradient during backpropagation. Implementing this strategy while training a Siamese Neural Network is what makes the largest contribution to the model accuracy. no manual judgement on the training set 0. Both of these models make different errors because of their nature which make them good candidate for ensembling The standard model is trained on the smallest training set and thus has more potential for overfitting. Linear sum assignment https en. Duplicate image are free answers assuming there is no tagging error. Also a distance measure does not provide for features to be negatively correlated. By fixing the subset size to a reasonable value the complexity then grows linearly with the number of subsets allowing larger training datasets. The random transform is skipped when testing. In the context here hard examples are similar images belonging to different whales. 107 duplicate images only Validation setI have not discussed validation data until now. Apply an affine transformation. The h2p dictionary associate each unique image id to the prefered image to be used for this hash. This would be effective not only for the Linear Assignment Problem part but also when computing the cost matrix which still has complexity O n 2. Because of the high resolution it uses a lot of memory so a minimum of work is done here to save memory for subsequent blocks. This creates a random number of matching image pairs with each image taken exactly two times. 786 best score obtained by a linear combination of the standard model with the bootstrap model0. threshold is selected through trial and error although most model variants perform best with a value of threshold that results in 7100 test images with new_whale as first choice something that can be measured without submitting a prediction to Kaggle. I suggest reading the original paper but the idea is to form a subblock with a 1x1 convolution reducing the number of features a 3x3 convolution and another 1x1 convolution to restore the number of features to the original. Construct the head model with linear activation Evaluate the model for constant vectors. The blacklist was constructed manually by spotting images unhelpful to training. 774 bootstrapped model0. Also note that the score matrix for the Linear Assignment Problem is computed at every 5 epochs starting with epoch 10. Force a different choice for an eventual next epoch. Training data constructionAs highlighted in the abstract section this is the part that makes a big difference in the model accuracy. BootstrappingSubmitting these 1885 pictures as a submission show that this set if over 93 accurate. The image shape used by the model The horizontal compression ratio The margin added around the bounding box to compensate for bounding box inaccuracy If an image id was given convert to filename Determine the region of the original image we want to capture based on the bounding box. 10 4 351 390 4. Whenever I encountered such instance in the training set not in the test set I would add it to a list. The final step of the branch model is a global max pooling which makes the model robust to fluke not being always well centered. CodeThe described logic is essentially implemented by the TrainingData class that performs just in time data augmentation as well as computing the matching. SIAMESE NEURAL NETWORK Complete model is constructed by calling the branch model on each input image and then the head model on the resulting 512 vectors. I use 4 such subblocks by block plus a single 1x1 convolution to increase the feature count after each pooling layer. The procedure itself has evolved from many previous experiments trial and errors on earlier versions of the model. After 250 epochs trainings accuracy is fantastic but it also grossly overfits. 728 standard model without L2 regularization result after 250 epochs 0. Find all distinct phash values If the images are close enough associate the two phash values this is the slow part n 2 algorithm Group together images with equivalent phash and replace by string format of phash faster and more readable For each image id determine the list of pictures Notice how 25460 images use only 20913 distinct image ids. The rectangle is taken to be slightly larger than the computed bounding box https www. However this does not find the real optimum just an approximation. 10 4 391 400 10 5 0. Matching whale examplesHalf the examples used during training are for pair of images. The code to generate images is modified from examples found in Deep Learning with Python https www. Just the colormap is probably easier to see. Weighted sum implemented as a Dense layer. Rotate the image if it is in the rotate set 1. model is good for a 0. I encourage everyone to skip ahead directly to whatever you are most interested in without necessarily going through everything. For new_whale the algorithm will chose high confidence prediction first then insert new_whale then low confidence predictions. Image rotationI noticed that some pictures have the whale fluke pointing down instead of up as usual. org wiki Affine_transformation maps a rectangular area of the original image to a square image with resolution 384x384x1 only one channel for black and white. 423 duplicate images and new_whale submission0. 1556 like network for example. This provides some insight on the filtering process. 766 standard model0. Whale Classification ModelThis notebook describes the strategy behind the 0. What we expect to see is that equal zero feature should produce a smaller output than similar large values. ", "id": "martinpiotte/whale-recognition-model-with-score-0-78563", "size": "23828", "language": "others", "html_url": "https://www.kaggle.com/code/martinpiotte/whale-recognition-model-with-score-0-78563", "git_url": "https://www.kaggle.com/code/martinpiotte/whale-recognition-model-with-score-0-78563", "script": "build_transform read_cropped_image imagehash keras.layers scipy.optimize make_steps prepare_submission cm match Lambda show_filter img_to_array regularizers build_model tqdm_notebook matplotlib.pyplot PIL Model Axes3D __getitem__ TrainingData(Sequence) Activation keras.models keras prefer ScoreGen(Sequence) show_whale MaxPooling2D phash Adam get_lr scipy.ndimage matplotlib.ticker os.path affine_transform lapjv pandas MaxNLocator matplotlib __len__ isfile FeatureGen(Sequence) sqrt math Reshape plot_model keras.preprocessing.image numpy Image read_raw_image BoundaryNorm BatchNormalization subblock on_epoch_end keras_tqdm Sequence keras.engine.topology keras.optimizers mpl_toolkits.mplot3d GlobalMaxPooling2D lap set_lr score_reshape Conv2D read_for_validation read_csv Flatten Image as pil_image array_to_img Concatenate Dense backend as K TQDMNotebookCallback tqdm compute_score Add read_for_training backend matplotlib.colors gaussian_filter Input keras.utils linear_sum_assignment __init__ expand_path ", "entities": "(('pictures', 'same whales'), 'compare') (('org wiki Affine_transformation', 'resolution'), 'map') (('Skip', 'at least two images'), 'use') (('model', 'thus whales'), 'by') (('here hard examples', 'similar different whales'), 'be') (('that', 'shift rotation'), 'perform') (('good quite as they', 'large slightly values'), 'L_1') (('they', 'following criteria'), 'consider') (('Matching examplesHalf examples', 'images'), 'whale') (('high it', 'simultaneously other whales'), 'score') (('that', 'model still very perspective'), 'inspire') (('problem', 'backpropagation'), 'turn') (('2 5 1 96x96 Block 3 Block 4 24x24 Block 12x12 Block', 'max 2 2x2 pooling'), 'block') (('K', 'training gradually harder cases'), 'as') (('y', 'cost matrix'), 'compute') (('most likely whales', 'match'), 'identify') (('too it', 'initially examples'), 'feed') (('notebook', 'essentially final retraining'), 'describe') (('Image preprocessingTraining', 'following operations'), 'perform') (('that', 'Kaggle'), 'select') (('that', 'validation set'), 'achieve') (('score Also matrix', 'epoch'), 'note') (('which', 'even when originally colored images'), 'be') (('they', 'same resolution'), 'be') (('minimum', 'subsequent blocks'), 'use') (('We', 'feature different values'), 'check') (('which', 'guesses'), 'be') (('rectangle', 'bounding box https slightly computed www'), 'take') (('h2p dictionary unique image i', 'hash'), 'associate') (('Different whales', 'last epoch'), 'eliminate') (('we', 'step'), 'randomize') (('VisualizationThis section', 'visualizations'), 'explore') (('which', 'how matching zeros'), 'pass') (('i', 'picture'), 'associate') (('Siamese Neural essentially Network', 'www'), 'be') (('4 central cells', '512'), 'construct') (('However this', 'real optimum'), 'find') (('it', 'pairs'), 'compute') (('which', 'still complexity'), 'be') (('training set one images', 'top candidates'), 'add') (('whales', 'CNN'), 'use') (('less mathing', 'multiple caracteristic markings'), 'be') (('However scale', 'matching less costly randomized heuristic'), 'be') (('it', 'notebook'), 'shuffle') (('752 VGG', 'standard model0'), 'train') (('absolute difference', 'y'), 'compute') (('it', 'number just whales'), 'be') (('negative examples', 'different whales'), 'appear') (('model', 'adversarial training'), 'forcus') (('ResNet', 'VGG https more arxiv'), 'be') (('it', 'Obviously everything'), 'cover') (('training', 'training tough cases'), 'last') (('typical approach', 'distance measure e.'), 'be') (('base model', 'bootstrap little under 3 days i7 8700 CPU'), 'describe') (('it', 'data partitioning'), 'use') (('I', 'pooling layer'), 'use') (('similarity', 'model current state'), 'compute') (('Generation', 'score matrix'), 'be') (('blacklist', 'unhelpful training'), 'construct') (('that', 'details'), 'pdf') (('speed', 'dataset'), 'include') (('i', 'stderr annoying when keras'), 'show') (('Finally image', 'unit zero mean variance'), 'normalized') (('I', 'list'), 'add') (('algorithm', 'confidence then low predictions'), 'insert') (('Perceptual same Hash', 'www'), 'have') (('smaller the more difficult pairing', 'model'), 'k') (('which', 'image cropping'), 'martinpiotte') (('mean square error', '0'), 'exceed') (('scection', 'model'), 'describe') (('branch model', 'pooling intermediate layers'), 'compose') (('head model', 'negative weights'), 'discuss') (('CodeThe following', 'Keras model'), 'be') (('Whale Classification ModelThis notebook', '0'), 'describe') (('even it', 'default'), 'provide') (('same neural net', 'feature'), 'use') (('Training', 'random weights'), 'be') (('which', 'ReLU otherwise when activation'), 'be') (('Convolutation Neural Network CNN', 'whale'), 'transform') (('values', 'uniformly 0'), 'have') (('that', 'distance measure'), 'feel') (('we', 'two picture'), 'be') (('what', 'model accuracy'), 'be') (('network', 'training'), 'compose') (('test set', 'larger good score'), 'be') (('Validation only setI', 'validation data'), 'discuss') (('Siamese Neural Network', 'two parts'), 'compose') (('that', 'as well matching'), 'implement') (('image Duplicate identification', 'here 1'), 'much') (('output', 'sigmoid activation'), 'be') (('most', 'secret sauce'), 'be') (('model', 'branch model'), 'be') (('algorithm', 'n 3 exact solution'), 'spend') (('it', 'wave'), 'be') (('Block', 'similar VGG'), 'have') (('learning rate', 'additional 150 epochs'), 'apply') (('i', 'follow'), 'address') (('side right image', '180 degrees'), 'rotate') (('training', 'duplicate images'), 'document') (('subset', 'image separately pairs'), 'be') (('single image', 'whales'), 'begin') (('This', 'filtering process'), 'provide') (('whenever picture', 'how whales'), 'learn') (('significant information', 'initial 384x384x1 image'), 'note') (('Adding', 'mpiotte'), 'generate') (('output', 'tensor bypass then original connection'), 'add') (('it', 'lapjv Linear Assignment Problem First solver'), 'position') (('It', 'whale random score'), 'be') (('following table', 'score matrix K.'), 'show') (('it', 'rotate'), 'rotate') (('that', 'most 6 bits'), 'phash') (('feature 512 vectors', 'image once i.'), 'compute') (('limit', 'model choice'), 'available') (('convolutions', 'ResNet less memory then subsequent memory'), 'be') (('HUGE', 'image'), 'be') (('Pseudo distance whale very easy still largest output best match', 'large values'), 'functionNot') (('1 They', 'zero mean'), 'determise') (('org wiki Assignment_problem algorithm', 'most difficult matching'), 'use') (('that', 'training'), 'be') (('EnsembleThe best score', 'mpiotte standard'), 'obtain') (('square error', 'given threshold'), 'mean') (('small it', 'runtime'), 'be') (('features', 'matching whales'), 'verify') (('how 25460 images', 'image only 20913 distinct ids'), 'find') (('ids', 'whale'), 'list') (('Blocks', 'convolution'), 'perform') (('score However matrix', 'randomized input'), 'randomize') (('that', 'model accuracy'), 'highlight') (('It', 'GTX'), 'take') (('I', 'custom package'), 'write') (('complexity', 'training larger datasets'), 'grow') (('notebook', 'submission'), 'describe') (('This', 'image'), 'create') (('same CNN', 'images'), 'use') (('rectangular area', '2'), 'have') (('over 93', 'submission'), 'show') (('code', 'Python https www'), 'modify') (('that', 'linear standard model'), 'consist') (('It', 'www'), 'study') (('I', 'training procedure'), 'use') (('duplicate images', 'whale different ids'), 'be') (('Similarly training', 'L2 regularization'), 'start') (('good standard model', 'overfitting'), 'train') (('com books', 'Francois Chollet'), 'learning') (('following algorith', 'pairs'), 'use') (('models', 'when two colored images'), 'convert') (('presented', 'model'), 'be') (('somewhat contrast size', 'legend'), 'be') (('very dissimilar values', 'same time'), 'penalize') (('I', 'ResNet https mostly www'), 'use') (('that', 'maximally feature'), 'attempt') (('fluke', 'them'), 'rotate') (('Other details', 'much smaller impact'), 'contribute') (('SIAMESE NEURAL NETWORK Complete model', 'head then resulting 512 vectors'), 'construct') (('Entry', 'similarity infty'), 'set') (('right image', 'data augmentation random transformation'), 'add') (('fileThe basic strategy', '10 4 submission'), 'generate') (('BRANCH HEAD 384x384x1 96x96x64 24x24x128 12x12x256 6x6x384 6x6x512 512 MODEL', 'appropriate stride'), 'generate') (('Use', 'images unambiguous ids'), 'identify') (('I', 'relatively small model'), 'be') (('model', 'different whales'), 'generate') (('Duplicate interesting section', 'duplicate images'), 'describe') (('center image', 'test transformation'), 'do') (('produced', 'minimuzing score'), 'be') (('you', 'most necessarily everything'), 'encourage') (('two images', 'same whale'), 'compare') (('procedure', 'model'), 'evolve') (('equal zero feature', 'similar large values'), 'be') (('bootstrap data', 'more data'), 'train') (('1 2 where n', 'training set'), 'have') (('Siamese Neural Network', 'training set'), 'want') (('idea', 'original'), 'suggest') (('training algorithm', 'given time'), 'force') (('selected entries', 'next matching'), 'overwrite') (('exactly thus margin', 'it'), 'martinpiotte') (('Dictionary', 'model'), 'find') (('X', 'case'), 'consider') (('manual judgement', 'training'), 'set') (('we', 'bounding box'), 'shape') (('larger K', 'the more matching'), 'random') (('image which', 'model image pair'), 'for') (('Keras generator', 'features'), 'be') (('mpiotte standard model', 'score'), 'select') (('B same B', 'same A.'), 'be') (('model', 'whales'), 'want') "}
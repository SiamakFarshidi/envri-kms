{"name": "patterns of colorectal cancer wally ", "full_name": " h2 What can you find in this kernel h3 Table of contents h3 In progress or planned h3 Short overview h3 Sense and meanings of a baseline model h2 Loading packages and data h2 Setting up the loss h3 The cancer target distribution h3 The likelihood function h3 Why is it good to know something about likelihood functions h3 Where to go next h2 Exploring the data h3 How many samples per cancer class are present h3 Take Away h3 How bright or dark are images per cancer class h3 Take away h2 Split into train test and validation h2 Building a model with tensorflow Wally h3 Wallys Code h2 Data Preprocessing h3 One hot encoding of cancer targets h3 Image normalization h3 Take Away h4 Per Image Mean Centering and Unit Variance h4 Min Max Scaling h2 Going live A robot starts to learn h3 Setup information h2 What has Wally learnt h3 Do we need more learning steps h3 Take Away h3 How do the learnt convolutional kernels look like h3 Take Away h3 How good is Wally in classifying cancer h2 Going deeper Can we improve Wallys visual range h2 Reduce overfitting It s not about details Wally h2 What features are highlighted by the weight kernels ", "stargazers_count": 0, "forks_count": 0, "description": "In addition we need a very simple model to play with. Setup informationAnd let s define some further information Wally needs to learn like How many pixels features does an image have How is the height and width of each image How many color channels does it have How big should the learning rate step size be How many learning steps epochs should be performed Ok now let s wake up Wally. This kernel has not the goal to answer all these questions but by writing it I will hopefully gain more insights and more intuition of the learning process and perhaps find some answers by the way. This way we could try out different strategies to solve problems that are caused by such imbalance. What about a bigger receptive field Perhaps we need to stack a second convolutional layer on top of the first. Using the dataset of colorectal cancer images I like to understand how convolutional neural network learn and what I can do to improve their success. Hence instead of values from 0 up to 255 bring them to 0 up to 1. For each class there are 12. The one of debris looks even trimodal. Take a look at the first two images. Min Max ScalingScaling to min of 0. Why is it good to use this scaling method To find an answer we should take a look at the activation function we are working with. Going live A robot starts to learn. How good is Wally in classifying cancer Going deeper Can we improve Wallys visual range That s pretty interesting The last time we obtained a score of 0. Where to go next If you are new to the likelihood concept this way probably full of new stuff. 5 of samples with the corresponding type of cancer. If you have never written software in tensorflow you might be confused as you can find two different parts in Wally 1. Choose a scaling normalisation method you like to discover Take Away under construction Per Image Mean Centering and Unit VarianceWe can see that this kind of normalization causes some problems. A build Wally method that calls all important methods that we need to build up our tensorflow model. How do the learnt convolutional kernels look like If you take a look into the code you can see that I stored the weight values of the first convolutional layer after learning. By fitting a model to our data we are trying to maximize how likely it is that our predictions suite to target values. It describes how things have to be computed but the compution is not done. Regardless if we can do this procedure analytically by hand or using numerical optimization we need to find the first derivative of our likelihood function with respect to neural network parameters theta for each layer l and each connection between neurons i and j partial_ theta_ i j l p T Y frac partial partial theta_ i j l prod_ n 1 N prod_ k 1 K y_ n k t_ n k Due to the products this job is infeasible. so far I can t conclude something out of it. In contrast the test loss has sattled down. Hence before going deeper it might be better to reduce overfitting. The latter has k elements with one hot and all others zero. In contrast the bright values 200 of the second image are now given by values higher than 4. Hence our first question is. Whereas the distributions of tumor stroma complex and lympho are still similar they are completely different from debris mucosa adipose and empty. For this purpose we can add regularization terms to our loss What features are highlighted by the weight kernels You probably know that the weight kernels we learnt for our convolutional layers act like kernels one can use for image preprocessing. Exploring the data explore 4. This way it is much easier to figure out how to improve and which steps are necessary to build a simple but powerful model that is able to generalize as well. Data Preprocessing Before we start let s transform all labels to a binary representation with one hot encoding as only one cancer class is true for each image. theta MLE max_ theta p T X theta Probably you know that optimizing a function with respect to some variable means that we need to compute its first and second dervative. Where to go next For our case study and baseline model we are almost done. We should find out their meanings as aidpose may be very tough to distinguish from empty. How do the kernel weights look like that were learnt by a CNN How do they change when we add more layers Can I analyse exploding or vanishing gradients Why are some network architectures better than others How should I preprocess the images given this specific medical problem Etc. Class wise normalizationLet s take a look at each kind of normalization and let s try to figure out what they are doing and if it makes sense to use them to improve speed or model prediction performance. As the target distribution is often the origin to setup an objective function or loss it s worth to look at it. We would set the further to zero and would check the solution found given the second derivative. After normalization we can see that the bright regions 200 of the first image now have lower values higher than 3. com allunia patterns of colorectal cancer image clustering Split into train test and validation Building a model with tensorflow Wally Following this nice tutorial http cs231n. loss_op the code knows that all parts of our skeleton that are needed to compute the loss have to be run. Subtract the overall mean and scale to unit variance from this mean. Do we need more learning steps Take AwayWe can see that we started to overfit badly after roughly 50 steps. Hence the target per sample is following a one hot coding scheme All elements of t are zero except from the true class that holds one. Going deeper Can we improve Wallys visual range bigeye 9. But the accuracy scores are still low. The function we build this way is often called an objective function. What has Wally learnt We can see from the print output that Wally has learnt something as loss was decreasing for train and test. x_ N and target cancer classes T t_ 1. Hence our normalization has caused a shift Similar bright regions of the originals are now different from each other. Cool You might have already detected that the log likelihood looks like a cross entropy apart from a missing minus sign. What has Wally learnt results 8. One hot encoding of cancer targets Image normalizationWe should normalize the images to improve convergence speed. What can you find in this kernel This kernel is part of a series of notebooks that correspond to my personal deep learing journey. Exploring the data How many samples per cancer class are present Take Away We can see that the target distributions are balanced. Wally uses relu as activation function. To make it tractable we can use the natural logarithm. To cool down let s switch do data exploration. what are Wallys kernels doing Well. One can see that the choice of the cross entropy below is not arbitrary and has some deeper motivation. It somehow reminds me of the small robot WALL E https en. I hope this makes it easier to understand for you as well. partial_ theta_ i j l ln p T Y frac partial partial theta_ i j l sum_ n 1 N sum_ k 1 K t_ n k cdot ln y_ n k Now the derivative acts on sums which can be done for each summand separately. It s not a good idea to clinch bright images and to strech dark ones. Fully connected Layer Output As this is our first session with our baseline model and start simply we will set N and K to 1. As we have already seen during dataset overview the resolution of them is sufficient to recognize different tissues and cancer classes. This comes especially clear for the third image. Consequently the mean of the first image is higher than of the second. This way we could say if the solution found is a maximum minimum or a saddle point for example. Debris and mucosa have broad distributions. The variation of image intensity distributions between classes motivates further analysis based on image statistics. Build and setup a model quicky that can already detect some patterns Understand key concepts and difficulties of your task Experimental platform to increase performance step by step Loading packages and data For the baseline model we may start with the 64x64 grayscaled images given in hmnist_64_64_L. With adding this minus sign our task changes to minimization of the negative log likelihood which is our well known loss function. If we like we could split the data such that we will enforce imbalanced classes. Reduce overfitting It s not about details Wally regularisation In progress or planned Regularisation. But before we can do this for cancer classification we should describe all data samples all images their predictions and target cancer classes. Setting up the loss Before we start with building a small baseline model let s discover the data we are working with. As it s a monotonically increasing function the maximization of the log likelihood is equivalent to maximization of the likelihood. Hence weights are shared over all samples regardless if we are computing predictions for the first image of our dataset or for the last one. Thus let s have a look at the overall intensitiy distribution per class Take away The intensity values of all samples in the data are distributed very differently. Let s describe all weights and biases by one parameter theta. Wallys CodeIf you unfold the hidden code you can find the network as described above. In addition it subpresses underflow of numerical precision of the computer caused by products of a large number of very small single sample probabilites. Loading packages and data load 2. E ln p T Y sum_ n 1 N sum_ k 1 K t_ n k cdot ln y_ n k Why is it good to know something about likelihood functions Within this kernel you have seen that one can build a loss function out of a distribution that describes the data. If you perform session. Or choose some other min max range like 0. But how to do it I often find these kind of techniques but the motivation for them often seem to be unclear Subtract the mean of each image and scale to unit variance. We have found a suitable loss function. Going live A robot starts to learn live 7. Our baseline model to discover and learn will be a small working unit nothing amazing. The cancer target distributionFor each image there is only 1 possible true target class t_ k out of 8 classes. Consequently building a deeper network was not the key This time overfitting is even more bad Reduce overfitting It s not about details Wally Ok going deeper was not advantegous. Consequently we can describe the target distribution by a multinomial distribution this way p t prod_ k 1 8 y_ k t_ k Given an image our model tries to predict which cancer class is true and for each possible class it yields a probability y_ k. Building a model with tensorflow Wally wally 5. 5 does only act on the value range but leaves the shape of the distribution the same as in the original cases. And does empty meen no image at all We should try to unterstand if each sample is distributed that way of if we have high variance between samples. Images of adipose and empty are of very high intensity. If we do this normalization we would end up with different valued cancers that were similar once. But we have observed jumps in the loss and overfitting on the training images in both cases. Consequently images with bright regions always will be normalized to lower values and their distributions are clinched. In our case this means to begin with grayscaled data instead of colored and a middle ranged resolution that is sufficient to work with but does not necassarily lead to computation performance issues. Data preprocessing preprocessing 6. Let s assume that all N samples were drawn independently from the same distribution. 6 for test images but this time we only reached 0. Both have similar skewed intensity distributions in their originals. Consequently we should not suffer under model confusion caused by imbalanced classes. Using our multinomial distribution we are able to describe how well the model predictions fit to our target values. io convolutional networks I like to start with a very reduced network architecture 1. Once we find estimated its weights theta MLE by learning they are fixed and the neural network doesn t change. Thus my first questions is. What you obtain is like a skeleton a dead shell without life. How bright or dark are images per cancer class As the cancer types are probably located in different tissue types the images between classes could differ in their intensities. Calling this so called tensorflow operations via session. This shift was caused by the skewness of the distribution as the mean is not robust towards outliers and shifted towards higher values. org wiki Kernel_ image_processing for example. Then we compute all predictions Y given the images X and weights theta Y Y X theta By using a neural network we try to find weights that are able to describe the mapping between images predictions and targets for all samples. As this is a topic of its own is covered by a new kernel notebook image clustering. During improvement of the baseline we will explore different additional layers and concepts like dropout batch normalization weight regularization different activation layers and much more. The likelihood functionNow we are given a data set of observed images X x_ 1. The training loss is still decreasing if you ignore th jumps. Only the probability of the true class contributes with y_ k 1 y_ k. Using the log everything turns out to be nice and smart. Setting up the loss with maximum likelihood loss 3. This is the case of a perfect prediction Then our model is sure with 100 that this image belongs to the true class. With this independence assumption we can split into n factors and describe the target distribution of our data set as follows p T Y prod_ n 1 N prod_ k 1 K y_ n k t_ n k Our goal now is to maximize this function by computing nice predictions that fit well to the targets. Take a look at these kernels https en. org wiki WALL E so let s name it similar. We don t know if cancer cells are always similar bright. t_ N whereby each x_ n stands for one image and t_ n for its corresponding target vector. One example What if you have a mutlilabel classification problem to solve but with couplings between target variables What if independence assumption between observations is not true If you like you can but something on top and customise your objective as you need it. After that we will go one step back to find out how the derivatives alias gradients of our model will look like and how the model will be influenced during learning. Let s start simple by forcing the weights of the neural net to be small. Table of contents1. As a take away we can say that we can setup a so called likelihood function by probability distributions that tell us how well predictions Y fit to our targets T. Looking at the equation you can see that all classes that are not the target class yield y_ k 0 1. Consequently p t reaches its maximum value of 1 when y_ k 1. A learn method that calls some attributes of our class that act like ports to breathe life into Wally. linear algebra data processing CSV file I O e. Knowing this way can be an entry point to build own likelihoods that suite better to your current problem. If you compare the structure of edge detecting kernels with our learnt kernels we can concluce that ours are different. This skeleton is called the tensorflow graph. build it and start learning. In case of neural networks this is done by adjusting the model parameters the weights between neurons. I like this imagination of some aritifical organism that you can feed with data and fill with life by running specific functions. Just bring the image into a new range. Fully connected Layer Activation cdot K4. run fills in life to our robot. My acutal level is what you call a beginner in this field and I m currently interested in details like. Improve reproducibility Explore Classification results Short overview 8 classes of cancer tissues multiclass classification Kather_texture_2016_image_tiles_5000 150 x 150 pixel in size 5000 samples Sense and meanings of a baseline modelA general strategy to solve complex problems is to start simple and grow complex during the analysis. read_csv The number of pixels per image Image dimensions The number of unique cancer classes The learning rate of our loss optimizer Let s define a method to feed Wally with data and fill in placeholders. This way we can visualize for some example images what wally tried to extract Take Away We can see that all kernels are different and weight spacial positions differently. Convolutional Layer Activation cdot N3. I think this does not make sense. It looks balanced somehow but perhaps this was not enough and we need more feature maps in our first convolutional layer. But we are dependent on this similarity as our kernel weights only can work this way. ", "id": "allunia/patterns-of-colorectal-cancer-wally", "size": "17968", "language": "python", "html_url": "https://www.kaggle.com/code/allunia/patterns-of-colorectal-cancer-wally", "git_url": "https://www.kaggle.com/code/allunia/patterns-of-colorectal-cancer-wally", "script": "tell_fortune OneHotEncoder wonder train_test_split get_convolutional_block os listdir numpy seaborn sleep Id \\n {} body get_output_block norm_image tensorflow matplotlib.pyplot create_placeholder BigEyeWally(Wally) sklearn.model_selection pandas build_wally feed blood get_dense_block __init__ learn heart_beat min_max_scaling Wally sklearn.preprocessing ", "entities": "(('N samples', 'independently same distribution'), 'let') (('you', 'network'), 'unfold') (('it', 'sample very small single probabilites'), 'subpresse') (('that', 'data'), 'sum') (('we', 'activation function'), 'be') (('choice', 'below deeper motivation'), 'see') (('test loss', 'contrast'), 'sattle') (('you', 'it'), 'example') (('this', 'neurons'), 'do') (('everything', 'log'), 'turn') (('Both', 'originals'), 'have') (('still you', 'jumps'), 'decrease') (('likelihood we', 'observed images'), 'functionnow') (('we', 'very simple model'), 'need') (('job', '_ _ _ 1 products'), 'need') (('latter', 'zero'), 'have') (('neural network doesn', 'MLE'), 'estimate') (('you', 'specific functions'), 'like') (('s', 'placeholders'), 'read_csv') (('still they', 'debris mucosa completely adipose'), 'be') (('t _ x _ whereby n', 't _ target corresponding vector'), 'N') (('which', 'summand'), 'theta') (('we', 'hmnist_64_64_L.'), 'understand') (('Hence deeper it', 'overfitting'), 'be') (('cancer cells', 't'), 'don') (('s', 'parameter one theta'), 'let') (('Images', 'very high intensity'), 'be') (('Unit kind', 'problems'), 'choose') (('we', 'data'), 'let') (('regardless we', 'last one'), 'share') (('that', 'well targets'), 'split') (('I', 'first convolutional layer'), 'look') (('that', 'different valued cancers'), 'end') (('image', 'true class'), 'be') (('we', 'first dervative'), 'p') (('obtain', 'dead life'), 'be') (('200', 'higher 4'), 'in') (('baseline we', 'case Where next study'), 'do') (('we', 'cases'), 'observe') (('Y', 'targets'), 'say') (('loss', 'skeleton'), 'know') (('Consequently we', 'imbalanced classes'), 'suffer') (('simply we', '1'), 'connected') (('that', 'learing personal deep journey'), 'find') (('that', 'better current problem'), 'be') (('ours', 'learnt kernels'), 'concluce') (('loss', 'train'), 'learn') (('that', 'equation'), 'see') (('It', 'Wally progress'), 'reduce') (('kernel weights', 'similarity'), 'be') (('It', 'small robot'), 'remind') (('Image normalizationWe', 'convergence speed'), 'normalize') (('Perhaps we', 'first'), 'need') (('that', 'simple model'), 'be') (('it', 'speed'), 'normalizationLet') (('This', 'especially third image'), 'come') (('I', 'network very reduced architecture'), 'io') (('that', 'Wally'), 'method') (('how model', 'learning'), 'go') (('I', 'way'), 'have') (('Where next you', 'way probably new stuff'), 'go') (('topic', 'kernel notebook image new clustering'), 'cover') (('so far I', 'it'), 'conclude') (('that', 'one'), 'follow') (('motivation', 'unit variance'), 'find') (('s', 'neural net'), 'let') (('we', 'badly roughly 50 steps'), 'need') (('kernels', 'example images'), 'visualize') (('we', 'natural logarithm'), 'use') (('it', 'you'), 'hope') (('that', 'samples'), 'compute') (('samples 5000 Sense', 'analysis'), 'be') (('deeper we', 'Wallys visual range'), 'go') (('you', 'Wally'), 'confuse') (('cancer only one class', 'image'), 'Preprocessing') (('5', 'same original cases'), 'act') (('Similar bright regions', 'now other'), 'cause') (('resolution', 'different tissues'), 'be') (('which', 'log negative likelihood'), 'with') (('images', 'intensities'), 'be') (('we', 'samples'), 'empty') (('instead middle ranged that', 'computation performance necassarily issues'), 'mean') (('time we', 'only 0'), '6') (('cross', 'apart missing minus sign'), 'cool') (('200', 'higher 3'), 'see') (('org WALL so s', 'it'), 'wiki') (('I', 'success'), 'use') (('Consequently mean', 'second'), 'be') (('all', 'predictions'), 'describe') (('target distributions', 'cancer class'), 'explore') (('p Consequently t', '1'), 'reach') (('Debris', 'broad distributions'), 'have') (('switch', 'data exploration'), 'let') (('variation', 'image statistics'), 'motivate') (('I', 'currently details'), 'be') (('model how well predictions', 'target values'), 'be') (('it', 'it'), 's') (('distributions', 'always values'), 'normalized') (('cancer target', 'image'), 'distributionFor') (('monotonically increasing maximization', 'likelihood'), 'be') (('we', 'first convolutional layer'), 'look') (('solution', 'saddle maximum example'), 'say') (('we', 'tensorflow model'), 'build') (('one', 'image preprocessing'), 'add') (('intensity away values', 'data'), 'let') (('pretty last time we', '0'), 'be') (('predictions', 'values'), 'try') (('that', 'such imbalance'), 'try') (('How I', 'specific medical problem'), 'look') (('it', '_ k.'), 'describe') (('we', 'imbalanced classes'), 'split') (('We', 'second derivative'), 'set') (('mean', 'higher values'), 'cause') (('It', 'dark ones'), 's') (('now s', 'color How many channels'), 'let') (('we', 'dropout batch normalization weight activation regularization different layers'), 'explore') (('We', 'aidpose'), 'find') (('going', 'details'), 'be') "}
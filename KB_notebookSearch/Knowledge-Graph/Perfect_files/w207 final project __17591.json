{"name": "w207 final project ", "full_name": " h1 W207 Applied Machine Learning h2 Summer 2018 Final Project h4 Kaggle Datasets h4 Running this Notebook Locally h4 Credits h4 Libraries to Install h3 1 Introduction h3 2 Exploration Data Analysis h3 3 Images Pre processing h4 3 1 Extracting R G and B h4 3 2 Gaussian blur h4 3 3 Edge Detection h3 4 Feature Engineering Dimensionality Reduction with PCA h3 5 Model Development h4 5 1 K Nearest Neighbors h4 5 2 Bagged Trees h4 5 3 Support Vector Machines h3 6 Convolutional Neural Network h3 6 1 Data Processing Set Up h3 6 1 Model Specification h3 6 2 Validation Against Real World Data h3 7 Other Classifiers h4 Random forest h4 Naive Bayes h3 8 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "Feature Engineering Dimensionality Reduction with PCAAs the dimensions 7 500 of our training data are still quite large after re sizing the images we try to reduce the dimensions using PCA in order to see if we can make the algorithms run more efficiently and if we can improve the accuracy for some of the classifiers. Yet the accuracy at 45 is low 8. In the final code block we tune the bagged trees classifier by trying a few more parameters for the number of estimators including 50 70 80 100. The model performs quite well on the original validation set as seen below Running predictions on another set of data however shows that the feature engineering is insufficient to have a reasonable success rate though the predictions are better than pure chance. For this first we need to break down the third dimension and reshape to a 2d array Reshape train data Reshape dev data This function will take a data set as an input and perform a gaussian blur to the data. Our goal is to retain 95 of the variance. Convolutional Neural NetworkThe following section shows another methodology we tried out. This could mean a few things such as maybe the blue pixels did a better job at hiding images in the background and brining out the hand and shadows in the foreground. To combat some of this noise we used filtering techniques such as gaussian blurs cropping edge detection and even breaking the images down by their red green and blue pixels. ConclusionUsing 29 different classes we looked to take an image of a hand and predict the letter or symbol it was trying to sign. com grassknoted asl alphabet and is an example of a convolutional neural network. Running this Notebook Locally1. On the other hand as the number of estimators increases the accuracy rate increases accordingly. IntroductionOur dataset contains 29 classes one for each letter from A to Z space delete and nothing. The parameters we try for tree size include 100 500 and 800 and number of estimators include 10 20 30 50. Support vector machines work by placing hyperplanes through the data in N dimensional space when a simple linear line can not separate the data. In fact it was only about half as good. As the data size is huge instead of reading all the images we read in only a sample. Maybe increasing the brightness would be a further option for us to consider in future iterations of this model. com 2015 04 06 zero parameter automatic canny edge detection with python and opencv 3. For the purpose of this project in the step where the images are loaded from their corresponding sub folder we re size the images to 50 x 50 x 3 and 64 x 64 x 3 in the section on convolutional neural networks to make the run times of training more managable and reduce the number of pixels from 120 000 to 7 500. In addition to a manual edging using parameters provided we also use a function to detect the image edges automatically. In fact it s apparent that there are a few letters that do extremely well while others struggle. Therefore we proceed to tune the bagged trees classifier without dimensionality reduction. Create subplots and titles. It had good results with some minor preprocessing converting images using the Sobel method. The length of the hands extent of background images color intensity and brightness all vary from image to image. Download the datasets from the links above and update the directory paths accordingly in the relevant cell blocks. The plot below shows the number of principal components vs. Because if this it seemed like a good idea to validate that the models were not overfitting to images in this controlled environment. As evident from the results accuracy increases steadily as the number of estimators increases until it starts to decrease again after the number of estimators reaches 80. In the first code block we train the bagged trees classifer with both the dataset with original dimensions and the dataset with reduced dimensions without tuning any parameters aside from setting the random state. fit_transform traindata Define gridsearch parameters Call function once on data without PCA and one without Place data into lists to make it iterable for use in loops when running algorithms. After this initial processing we used PCA to reduce the dimensionality of our images down to 110 components which explained 95 of the variance. Below we fit the KNN classifiers with both the dataset with original dimensions and the dataset with reduced dimensions. After determinig the optimal value of k is 1 with the mini training data and PCA lead to a slightly higher accuracy we ran the k nearest neighbors algorithm against 8 different variations of our mini train data with our optimal k value. As can be seen the bagged trees classifer does much worse with dimensionality reduction. From the output result we conclude that limiting the size of the underlying tree i. This is a fairly easy one to classify though as it means no hand is found in the image. This technique was used on a few different algorithms such as k nearest neighbors and support vector machines with varying degrees of success which will be discussed further on in our report. For small values of C it will look for a larger margin hyperplane even if that means misclassifying points. When splitting up the dataset we collapse the three dimensional feature arrays 50X50X3 into one dimensional feature arrays 7 500 so they can be used for training. The training exmmples are spread out far from each other. We next tried a convolutional neural network. The Gaussian blur takes the average of a pixel s 8 nearest neighbors and returns the average as its new pixel value. The 3d images will be used for color based pre processing and plotting while the 2d arrays will be used for other analyses. 6 accuracy increase over our original mini training data. Random sampling of filtered data with the number of examples specified. A low gamma means points far from the likely separation line are considered in the calculation while a high gamma means points close to the separation line are considered in the calculation. Install libraries below. However based off the confusion matrix the signs are only confused for each other a total of 3 times. They both make fists with the only difference being E tucking in the thumb and A not tucking. Filter data so it only has the symbol. Our optimal gamma value was fairly low which could mean our data was sparse and far from the decision boundary. add channel for RGB Model saving for easier local iterations HISTORY is only available if the model was run this time around which won t be the case when the model is read in from a file so we just skip it in that case. Consistent with the results of the confusion matrix we see from the classification report that the hand sign B has the lowest F1 score among all the symbols. We proceed to focus on tuning the number of estimators without limiting the size of the underlying decision tree. We can see that a few of our letters stand out as being easier to predict than others. There are two main hyperparameters to tune for a bagged trees classifier 1 the size of the underlying decision tree and 2 the number of estimators used for bagging. Next we looked at the gamma parameter. NaiveBayes seems to work better on the contoured processed images better. After the loop we then return that matrix back to its original shape and add it to a blurred_data_set that will end up being the transformed version of the original data parameter. We can see the the variations in gestures in sample plots below of 10 random images of each letter. When plotting out all the images we realized the images varied greatly ranging from what was in the background the brightness to the angles of the hand. Exploration Data AnalysisWe will explore the data to ensure that all labels are read in and also to visually examine the variations in the images. Out of these 3 models Bagged Trees performed the best with an accuracy of 87 with the number of estimators set to 80. These include C F G and M to name a few that have an f1 score falling between 0. As we have 3000 images of each letter named in the format of A1 A2. Each example in the dataset is a three dimensional array of 200 X 200 X 3 pixels. This lead to some interesting results such as the data set with the highest score was taking only the blue pixels from our image applying a PCA to it and then a gaussian blur lead to a 3. Since accuracy hovers around 85 for estimators equal to or above 50 we picked this over a larger number of estimators to run things more efficiently. pip install upgrade opencv python tqdm scikit image pandas numpy matplotlib keras tensorflow scikit learn seaborn Credits1. In this section we perform error analysis for the bagged tree classifier with number of estimators set to 50. 2 Gaussian blurWe create a Gaussian blur as a pre processing step to see if it can help improve training accuracy. com 2015 04 06 zero parameter automatic canny edge detection with python and opencv 4. In both cases the accuray rates are similar at around 61 62. C also known as regularization will choose a smaller margin hyperplane to make sure all the data is classified correctly for large values of C. Along with those we took our Red Green and Blue data sets and applied PCA and or a gaussian blur. Classification report and error analysis on blurred data base bagged trees classifier with dimensionality reduction base bagged trees classifier without dimensionality reduction Bagged trees tuning by varying size of underlying decision tree leaf_nodes and number of estimators for bagging. We use the train_test_split functionality to split the indices into two disjoint train and test indices. Other ClassifiersThis section includes other classifiers we explored but did not tune in depth for this project. The models we used first for our predictions were K Nearest Neighbors Bagged Trees and Support Vector Machines. This is also the label in our y data. We will run the RGB and blurred data through it along with transformations through PCA to determine which data set has the highest accuracy. Initialize a blank data set that is the same size as the data set parameter passed to our function We then iterate through the rows in our data set transforming them into a 50X50 matrix and performing the gaussian blur on them for each 50X50 matrix we have made we iterate through each pixel excluding the edges and take the average of that respective pixel and its 8 closest neighbors and make that the pixel s new value. We reduce the dimensions of the training dataset and development dataset by transforming them with the fitted PCA and store them separately to be used for training. Lastly we spent time looking at classifying the images with Naive Bayes and Multi layer Perceptron classifiers but eventually pulled the Multi layer Perceptron classifier because of how long it was taking to run. In the second code block we tune the bagged trees classifier by varying 1 the size of the underlying decision tree and 2 the number of estimators used for bagging. 2 Bagged TreesThis section covers the bagged trees classifier which is the bagging classifier with a decision tree as the underlying estimator. Based off the signs I would expect R U to be confused frequently as the only differnce between the two signs is R crosses the index and middle finger while U does not. After performing the gridsearch on the these two parameters we were able to increase our accuracy from 60. 2 which is likely insignificant. Based off the confusion matrix shown above two of the most confused signs are C D the model incorrectly predicts them a total of 7 times. compute the median of the single channel pixel intensities apply automatic Canny edge detection using the computed median return the edged image Create label Read original image Process image Apply Guassian blur Convert to HSV Apply median blur need to pick one of Guassian or median Resize resized resize imgray2 IMAGE_SIZE IMAGE_SIZE 3 Convert to gray THIS IS NOT WORKING WITH CANNY Get the edges tight Try changing this for better edge detection Get the edges auto Convert to gray THIS IS NOT WORKING WITH CANNY Binarize to be done https sourcedexter. A E also have a high count of incorrect predictions at 9 due to the signs being very similar. It is made up of 12 layers as is diagrammed below. This is expected as the feature space is very sparse even for the dataset with reduced dimensions. Edge detection can be tricky because there can be edges in the background as well and thus how tightly loosely to identify the edges can affect the quality of the output image and the prediction. We use GridSearchCV to find the optimal value of k for both datasets. 1 K Nearest NeighborsWe use KNN as a baseline model to compare against more sophisticated models including bagged trees SVM and neural networks. The least accurate model was SVM at around 60. We found that applying PCA to reduce the dimensionality and also performing a gaussian blur increased the accuracy over just using our original unfiltered data. For our classification task it seems we should focus on precision and f1 score as a few false positives would not cause a great deal of harm unlike if we were predicting bank fraud or sick patient detection. 1 Extracting R G and BSince each image has the color dimension that we saw above one of our pre processing steps is to extract each of these to create separate blue red and green training examples. 1 Model SpecificationThe model used here is taken from a Kaggle kernel called Running Kaggle Kernels with a GPU https www. 2 Validation Against Real World DataThe data provided in the ASL Alphabet data set is very much contrived. Our model found a C value somewhere in the middle to be optimal for our case. General libraries Deep Learning using Keras Visualizations Sci kit learn libraries Image Preprocessing Set random seeds so results are the same each time Define parameters and functions Change this to point to your data directory if the default relative path below does not work please provide complete path eg C Users subsh Documents 207 final_project asl alphabet asl_alphabet_train asl_alphabet_train Define train size this is the number of training samples for each letter Define the classes letters of the ASL alphabet that are being analyzed. For each example grab the Red Green Blue and Complete representation of the data and show it in the subplot. com grassknoted asl alphabet Libraries to InstallTo run this notebook you may have to run the following commands to install some prerequisites bashpip install upgrade opencv python tqdm scikit image pandas numpy matplotlib keras tensorflow scikit learn seaborn 1. 1 Data Processing Set UpIn the next snippet I make a generator for use by Keras. Define a hash table dict to store labels Image sizing Some visualization helpers Create label Read original image Append to data array Read in train and dev data Reshape the images from 3d to 2d arrays. 3 Support Vector MachinesNext we will take a look at the support vector machine algorithm to predict our data. Again the model building process is skipped if the model has already been saved to disk. Image processing credited to Adrian Rosebrock https www. The make_generator function is versatile enough to be used for setting up a generator for training validation prediction and testing. com danrasband asl alphabet test this data set is used to test against more realistic images. com grassknoted asl alphabet this data set is the basis for all models. Transform mini training data and development data using PCA fitted with mini training data. Below we evaluate the CNN model against a set of images made with various backgrounds and with a different person s hand to see how well the model works on a related but different set of images. I ve provided a helper function below to load the model from disk so that this part of the notebook can be run without rebuilding the model each time. It will then return that data set with a blur meaning a pixel will take on the average of its 8 closest neighbors plus itself. Print maximum number of incorrect predictions for each digit. Here we show the history of the fitting process which shows the loss and the accuracy of the fit. It s obvious that the images are made with one person s hand in basically one environment. As can be seen from the results below if we set the number of principal components to 110 we can reach 95 explained variance. As we move towards signing full sentences instead of just predicting images we can likely use our image classification along with some kind of bag of letters model to determine which letters are likely to come after each other. The best accuracy of 87 is achieved with 80 estimators. Interestingly we find that the accuracy worsens for the tree classifiers including random forests and bagged tress but improves for other classifers including KNN and SVM. We used a Bernoulli NB as the data is contoured and has only 2 levels of pixels. This function has been adapted from https www. It is worth noting that while the Blur_Blue_PCA dataset had the highest score our Blur_PCA original mini training data with a blur applied came in second place with only an accuracy decrease of 0. Subset data for each letter Pulls the index for the symbol. pruning does not improve accuracy. The outright winner would be the nothing sign with an f1 score of 0. As far as letters where our model struggled A U V and W all had low f1 scores which is interesting because the images for V and W seem fairly easy to distinguish compared to others. Images Pre processing 3. 3 Edge DetectionIn this segment we try various image processing functionalities available in Python to blur in the data ways other than Gaussian binarize and to extract the contour edges of images. In this next section the model is fitted against the data splitting the data into training and validation sets. This leads to a blurring of the original image. K Nearest Neighbors performed the second with an accuracy of around 70. The SVM s accuracy was also greatly helped by transformation through PCA. From the confusion matrix we can see that for this classifier the most often mis labeled pairs of hand signs include B with A and D with C. After performing a grid search we have found the optimal parameters for C and gamma. First we read and load the data into arrays. Code for loading images is credited to Paul Mooney https www. com paultimothymooney interpret sign language with deep learning2. This may be an artifact of where those particular images were taken though further analysis would have to be made to determine the exact cause. Originally we wanted to retain 99 of the variance but discovered that this requires the number of componenets to go up to thousands essentially defeating the purpose of PCA. com manipulating image pixels with python scikit image color schemes Pick which image to use for training THIS DOES NOT SEEM TO BE WORKING FIX SIZE Reshape train data Reshape dev data Set the number of components to be used below. The data sets we used included the original and the original with PCA applied. As seen from the results in both cases the optimal value of k is 1. In this part we build out the convolutional neural network. This blurred_data_set will then be returned. plot number of estimators vs accuracy without no limites on size of underlying decision tree output confusion matrix for bagged tree classifier with n_estimators 50 Print total number of incorrect predictions for each digit. Overall each time we applied a blur we saw an increase in the accuracy over the original data. I think much of the confusion boiled down to darker photos and not being able to distinguish the lines of the fingers. We set the mini training dataset to 2900 examples as there are 29 labels so there are 100 examples for each label. Convolutional Neural Network https www. TRAIN_DIR directory path where training dataset is saved Note that the current structure is set to how things would look if this notebook were to be run on Kaggle. cumulative explained variance as we increase the number of components. Below you can see a video compilation of all the A images. For future iterations we would like to explore random forests naive bayes and multilayer perceptrons more in depth. Break the data into red green and blue mini training sets to use in our later algorithms. ASL Alphabet Test https www. Blur our mini train data and dev data for use in our models Take the blurred red green and blue data pixels and stack them back together into an array of the original size and shape of the mini training data. Fit and score with the best parameter found pred gs. When this model was applied to similar images from a less contrived environment it still performed better than chance but had much lower accuracy than when run on the validation set. Model Development 5. Random forest Naive BayesHere we briefly look at performance of Naive Bayes on the contoured data. We were able to use Kaggle s GPU enabled kernels to train a model in less than 15 minutes. B3000 we create a random sample of indices and then read in only the sampled indiced. From there we will tune the parameters C and gamma. W207 Applied Machine Learning Summer 2018 Final Project Team Members Rachel Ho Dan Rasband Subha Vadakkumkoor Matt Vay Topic ASL Alphabet Kaggle Datasets ASL Alphabet https www. ", "id": "danrasband/w207-final-project", "size": "17591", "language": "python", "html_url": "https://www.kaggle.com/code/danrasband/w207-final-project", "git_url": "https://www.kaggle.com/code/danrasband/w207-final-project", "script": "keras.layers pathlib fit_and_tune_random_forest print_summary MLPClassifier Path blur build_model BaggingClassifier plot_confusion_matrix_with_default_options GaussianNB sklearn.neighbors pca_transform plot_confusion_matrix BernoulliNB fit_and_tune matplotlib.pyplot set_random_seed evaluate_validation_dataset skimage.transform keras.models make_decision_tree sklearn.svm fit_and_tune_svc auto_canny show_cnn_model_weights Dropout run_knn MultinomialNB run_bagged_trees2 show_class_counts sklearn.naive_bayes tensorflow getenv pandas plot_examples skimage.color plot_bagging GridSearchCV evaluate_test_dataset sklearn.ensemble load_model_from_disk reprocess_model run_bagged_trees os confusion_matrix make_generator preprocess_image keras.preprocessing.image numpy ImageDataGenerator make_generator_for sklearn.tree plot_symbol DecisionTreeClassifier evaluate_model resize Conv2D RandomForestClassifier reduce_dimensionality plot_bagging2 sklearn.metrics Flatten classification_report train_test_split plot_pca get_data2 rgb2gray seaborn Dense SVC bagging_cm tqdm sklearn.neural_network PCA Sequential sklearn.model_selection load_model fit_model run_naive_bayes run_svc KNeighborsClassifier keras.utils get_data fit_and_tune_knn sklearn.decomposition ", "entities": "(('we', 'data'), 'take') (('we', 'training separate blue red examples'), 'have') (('model', 'training sets'), 'fit') (('extremely well others', 'fact'), 's') (('6 accuracy', 'training original mini data'), 'increase') (('example', 'three dimensional 200 X 200 X 3 pixels'), 'be') (('run times', 'to 7 500'), 're') (('notebook', 'Kaggle'), 'path') (('plot', 'principal components'), 'show') (('again number', '80'), 'increase') (('it', 'validation when set'), 'apply') (('labels', 'images'), 'explore') (('that', 'ASL alphabet'), 'library') (('we', 'PCA'), 'include') (('k nearest neighbors', 'k optimal value'), 'lead') (('I', 'fingers'), 'think') (('training Blur_PCA original mini data', '0'), 'be') (('we', 'C.'), 'see') (('It', '12 layers'), 'make') (('com paultimothymooney', 'deep learning2'), 'interpret') (('dataset', 'space delete'), 'contain') (('data', 'decision boundary'), 'be') (('outright winner', '0'), 'be') (('make_generator function', 'validation prediction'), 'be') (('hand', 'image'), 'be') (('which', 'variance'), 'use') (('We', 'less than 15 minutes'), 'be') (('we', 'A1 A2'), 'have') (('B3000 we', 'then only sampled'), 'create') (('points', 'calculation'), 'point') (('K Nearest NeighborsWe', 'bagged trees'), '1') (('training exmmples', 'far other'), 'spread') (('function', 'https www'), 'adapt') (('it', 'letter'), 'ConclusionUsing') (('which', 'underlying estimator'), 'cover') (('We', '29 100 label'), 'set') (('First we', 'arrays'), 'read') (('It', 'Sobel method'), 'have') (('Fit', 'pred gs'), 'find') (('we', 'bank fraud'), 'seem') (('Edge detection', 'output image'), 'be') (('we', 'image edges'), 'provide') (('NaiveBayes', 'better contoured processed images'), 'seem') (('then gaussian blur', '3'), 'take') (('pixel', '8 closest neighbors'), 'return') (('which', 'fit'), 'show') (('WORKING FIX SIZE Reshape train data Reshape dev data', 'components'), 'pixel') (('we', 'data Blue PCA'), 'take') (('we', 'first predictions'), 'be') (('how well model', 'images'), 'evaluate') (('images', 'fairly others'), 'far') (('it', 'training accuracy'), 'create') (('even that', 'misclassifying points'), 'look') (('Therefore we', 'dimensionality reduction'), 'proceed') (('we', '60'), 'after') (('We', 'decision underlying tree'), 'proceed') (('we', 'parameters'), 'tune') (('middle U', 'index'), 'base') (('data set', 'models'), 'com') (('length', 'image'), 'vary') (('matplotlib keras tensorflow scikit', 'seaborn Credits1'), 'upgrade') (('up to thousands', 'PCA'), 'want') (('100 500', '30 10 20 50'), 'include') (('we', 'multilayer more depth'), 'like') (('tqdm scikit image pandas', 'seaborn'), 'run') (('we', 'red green pixels'), 'use') (('so we', 'case'), 'add') (('we', 'C'), 'after') (('We', 'disjoint two train'), 'use') (('images', 'basically one environment'), 's') (('Code', 'Paul Mooney https www'), 'credit') (('Below we', 'reduced dimensions'), 'fit') (('further us', 'model'), 'be') (('least accurate model', 'around 60'), 'be') (('optimal value', 'k'), 'be') (('few', 'others'), 'see') (('edges tight Try', 'https sourcedexter'), 'compute') (('letters', 'other'), 'move') (('accuracy', 'PCA'), 'help') (('accuracy rate', 'increases'), 'increase') (('hand sign B', 'symbols'), 'consistent') (('They', 'tucking'), 'make') (('accuracy', 'KNN'), 'find') (('we', 'respective pixel'), 'initialize') (('feature space', 'reduced dimensions'), 'expect') (('We', 'separately training'), 'reduce') (('it', 'when algorithms'), 'call') (('models', 'controlled environment'), 'because') (('best accuracy', '80 estimators'), 'achieve') (('function', 'data'), 'need') (('we', 'components'), 'explain') (('trees bagged classifer', 'dimensionality much reduction'), 'do') (('dimensionality reduction Bagged trees', 'bagging'), 'bag') (('Model SpecificationThe 1 model', 'Running Kaggle GPU https www'), 'take') (('further analysis', 'exact cause'), 'be') (('we', 'original data'), 'apply') (('we', '50'), 'tune') (('forest Naive Random BayesHere we', 'contoured data'), 'look') (('such maybe blue pixels', 'foreground'), 'do') (('we', 'methodology'), 'show') (('We', 'next convolutional neural network'), 'try') (('that', 'data transformed original parameter'), 'return') (('E', 'signs'), 'have') (('We', 'letter'), 'see') (('C value', 'case'), 'find') (('K Nearest Neighbors', 'around 70'), 'perform') (('we', 'things'), 'pick') (('greatly what', 'hand'), 'plot') (('f1 score', '0'), 'include') (('We', 'datasets'), 'use') (('data', 'C.'), 'choose') (('7 500 they', 'training'), 'split') (('This', 'original image'), 'lead') (('Perceptron how long it', 'Multi eventually layer'), 'spend') (('Subset data', 'symbol'), 'pull') (('Data Processing Set 1 next I', 'Keras'), 'UpIn') (('we', '95 explained variance'), 'reach') (('Transform mini training data data', 'training mini data'), 'fit') (('model', 'already disk'), 'skip') (('part', 'model'), 'provide') (('we', 'neural convolutional network'), 'build') (('we', 'bagging'), 'tune') (('C model', '7 times'), 'base') (('2 Validation', 'ASL Alphabet data set'), 'be') (('goal', 'variance'), 'be') (('we', 'only sample'), 'be') (('we', 'tree underlying i.'), 'conclude') (('2d arrays', 'other analyses'), 'use') (('data set', 'highest accuracy'), 'run') (('Bagged Trees', '80'), 'perform') (('com danrasband asl alphabet data set', 'more realistic images'), 'test') (('Edge 3 segment we', 'images'), 'detectionin') (('bagged trees', 'aside random state'), 'train') (('which', 'further report'), 'use') (('applying', 'just original unfiltered data'), 'find') (('Below you', 'A images'), 'see') (('we', 'project'), 'include') (('more efficiently we', 'classifiers'), 'Reduction') (('Gaussian blur', 'pixel new value'), 'take') (('predictions', 'pure chance'), 'perform') (('linear when simple line', 'data'), 'work') (('we', '50'), 'perform') (('total', '3 times'), 'base') (('accuray rates', 'around 61'), 'be') (('data', 'pixels'), 'use') "}
{"name": "analyzing the heart disease ", "full_name": " h3 HEART DISEASE ANALYSIS h3 CONTENT h2 If you like it please upvote h3 INTRODUCTION h3 DATASET COLUMNS FEATURE EXPLAIN h3 INVESTIGATING THE DATA and EXPLORATORY DATA ANALSIS h3 One Visualization to Rule Them All h3 Age Analysis h3 Sex Gender Analysis h3 Chest Pain Type Analysis h3 Age Range Analysis h3 Thalach Analysis h3 Thal Analysis h3 Target Analysis h3 MODEL TRAINING and TESTING h1 Logistic Regression h1 K Nearest Neighbors h1 Naive Baes h1 Gradient Boosting Machine h1 Random Forest h1 Decision Tree h1 Kernelized SVM h3 References h3 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "As is known most of our data are categorized and not categorized only among certain feature values. Our aim here is to obtain the average values of Thalach according to age ranges. As seen in this graph it is seen that the heart rate is less when the chest pain is low. This may change in some scaling operations. Now we are going to analyze both the sex and the heart health situation. com kralmachine python programming language for data scientistsOther kernels https www. But in cases where chest pain is 1 it is observed that the area is more. The goal field refers to the presence of heart disease in the patient. Hyperthermatic technique was used for this condition. Python Programming for Beginner https www. In this way comments about the properties can be madeAge AnalysisIn this section the best analysis can be divided into the elderly middle aged young people by looking at the age ranges. Therefore we need to use this method for SVM algorithm. Now I can constitute a DataFrame out of my reduced data with two dimensions Logistic RegressionFirst we need parameters to use our data more effectively. Now draw graph Target 0 so there has been a very nice graphic display. only two values are shown. As a result of this operation the data takes a value of 0. As a result of this listing it is aimed to ensure that these properties are used in different places by performing different operations. Likewise data points with greater values on the y axis represent the customers that are less likely to spend to Fresh and Frozen categories. \u03bc is the average value. The purpose of this value is to see the integration values between our data. The difference in value between our data is too big. com kralmachine data visualization of suicide rateshttps www. 0 status at least 1 condition slightly distressed 2 condition medium problem 3 condition too bad Show the results of a linear regression within each dataset First show 20 rows As shown in this graph this rate decreases as the heart rate is faster and in old age areas. This means that we need to integrate other values into this situation. MODEL TRAINING and TESTINGAs a result of our initial evaluations we have used a number of artificial learning algorithms. We re writing the following snippet to see the loaded data. com kanncaa1 seaborn tutorial for beginnershttps www. I install all the libraries in the first part because the algorithms I will use later and the analysis I will make more clearly will be done. com kralmachine seaborn tutorial for beginnersConclusionAs a result we have explained the seaborn library in a very detailed way and created a wide variety of graphs. Sex Gender AnalysisIn the above output I wish it would be good if there was an equal proportion of people. com kralmachine pandas tutorial for beginnerhttps www. If you want to get detailed information about python programming you can look at my account. We will list all the columns for all data. It is integer valued from 0 no presence to 4. All other data is normalized according to these values. Z score NormalizationIn a data set the data that are distant from each other are made to scale between each other by making a specific scaling. com kralmachine visual analysis of world happiness in 2015 Now our data is loaded. If you like UPVOTED I would be very happy if you do. In this process after determining the Class property as hypothesis the relations between all the other properties are checked. In this section we will use the groupby function. resim z score X is the incoming data. Thalach AnalysisThe analysis of the system we discussed in the case of maximum heart rate is shown. as seen only 50 was understood to be 50 target. The relationship between the features found in the training data is observed. It increases both the volume and the results are very bad. In the above analysis the gender of people who are female is more common. That doesn t mean much to us. If you like it I expect your support. Target 1 so Apparently there is a rate at Thal 2. At the bottom there are the kernel values that I have already done. If there s value in there we il do it there. To implement this algorithm model we need to separate dependent and independent variables within our data sets. But when it comes to advice and usage standard scaling comes out with a big difference. The value of \u03c3 is the standard deviation. In this section we have used our new feature values. It seems that old people have a very hard job because their values are very high. Thus the p value process determines a hypothesis and a hypothesis thesis is presented between each characteristic according to this hypothesis. This technique is used to express different features in the process. This is the evaluation for this. Chest Pain Type AnalysisA wide range of chest pain is present in cases of heart failure. all rows control for null values data age show value counts for age least 10 firstly find min and max ages Draw a categorical scatterplot to show each observation Plot the total crashes Sex 1 male 0 female Percentage ratios Male State target 1 0 Female State target 1 0 Plot miles per gallon against horsepower with other semantics As seen there are 4 types of chest pain. Furthurmore I have investigated the data presented some visualization and analysed features. But on the other hand there are problems in all cases of chest pain such as 1 2 3. A value of 1 is the value of patient 0. As a result of the above analyzes it can be seen that 0 cases with chest pain are less common with heart disease. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence values 1 2 3 4 from absence value 0. In order to better understand this distribution we need to take a look at the data set. We have shown the P value. Now we are uploading our data set to the data variable using the read_csv function in the pandas library. Describe function is a function that allows analysis between the numerical values contained in the data set. Because we re going to do chest pain. Using this function count mean std min max 25 50 75. Both the head and tail functions have a value of 5 by default. Is there any spelling mistake sample random rows in dataset New show columns And how many rows and columns are there for all data first one is rows other is columns Now I will check null on all data and If data has null I will sum of null data s. In addition we created a combination of features between different features to make different experiments. In order to better understand this we will make a more effective analysis in the following stages. This is the result of an analysis for us. I will import necessary Python modules and read the data. One Visualization to Rule Them AllWe will perform analysis on the training data. The first algorithm is logistic regression algorithm. We check all columns. Another issue I am curious about in this section is the situation in which the value of the target is 1 and it is the maximum value of Thal. determine the age ranges of patients with and without sickness and make analyzes about them now draw show on graph Target 1 0 show graph on scatter Let s see how the correlation values between them Normalization as the first process Normalize. There is a big change between the data obtained. All correlation values between the data are listed in the previous sections. The reason for this is that the parsing process between the data is better. At the moment it seems to be imbalance value but for this situation it applies to Gender. Finally machine learning algorithms are estimated. Target AnalysisWe will analyze this feature for people who are sick or not. As seen in this section most values are generally categorized. While creating these parameters the process of finding the best results was made by giving hyper parameter values. This results in a different number for each property. Now it is time to implement PCA to the data set. If you have any questions I am ready to answer your questions. different values should be given as parameters to change these values. com kralmachine kernelsDATASET COLUMNS FEATURE EXPLAIN Age age in years Sex 1 male 0 female CP chest pain type TRESTBPS resting blood pressure in mm Hg on admission to the hospital CHOL serum cholestoral in mg dl FPS fasting blood sugar 120 mg dl 1 true 0 false RESTECH resting electrocardiographic results THALACH maximum heart rate achieved EXANG exercise induced angina 1 yes 0 no OLDPEAK ST depression induced by exercise relative to rest SLOPE the slope of the peak exercise ST segment CA number of major vessels 0 3 colored by flourosopy THAL 3 normal 6 fixed defect 7 reversable defect TARGET 1 or 0 INVESTIGATING THE DATA and EXPLORATORY DATA ANALSISFirst I install all the libraries that I will use in our application. sigma resimTheoretically it is understood that there is no big difference between standard and normalization. INTRODUCTIONThis database contains 76 attributes but all published experiments refer to using a subset of 14 of them. 1 showed a distribution of 18. In the analysis system which will be carried out now an analysis shall be carried out for all persons or their status in the target process. But the minus value is a big problem for me but the value of the transactions are more valuable for us. In this way how many missing data is in the data. In particular the Cleveland database is the only one that has been used by ML researchers to this date. We will use a wide range of tools for this part. There are many scale operations for this. In this part taking the average of all transactions is performed. K Nearest NeighborsNaive BaesGradient Boosting Machine Random Forest Decision Tree Kernelized SVMReferenceshttps www. We will perform scale operations to eliminate these situations. Of these values 0 is only 2. The aim here is to normalize the smallest value to 0 and the maximum value to 1 and all other data is a value between 0 1. com spscientist students performance in examshttps seaborn. so a new feature value can be removed from these age ranges will not affect this impact will see in the future. These are logistic regression support vector machine SVM k close neighborhood kNN GradientBoostingClassifier and RandomForestClassifier algorithms. Because it will be more effective in future analysis. In addition we will analyze for this dataset. com biphili seaborn plot to visualize iris datahttps www. The transactions we perform in this section mean an average age. 1 will be obtained after using it. The diagonal values we see in these correlation values are always 1. These pains will be analyzed according to their problems and age ranges in the analysis system. This is the situation that best describes the situation. To reduce this situation we need to use the StandardScaler function. In the normalization system the largest and smallest values within a group of data are considered. But before that I will investigate the explained variance ratio and resulting principal components So I will apply PCA to the data with number of components 8. X normalization i\u015flemi resimOf course we need to remove the target property when doing this. The purpose here is to see the top five of the loaded data. 2019If you like it please upvote. HEART DISEASE ANALYSISCONTENT INTRODUCTION DATASET COLUMNS FEATURE EXPLAIN INVESTIGATING THE DATA and EXPLORATORY DATA ANALSIS One Visualization to Rule Them All Age Analysis Sex Gender Analysis Chest Pain Type Analysis Age Range Analysis Thalach Analysis Thal Analysis Target Analysis MODEL TRAINING and TESTING Logistic Regression K Nearest Neighbors Naive Bayes Decision Tree Random Forest Gradient Boosting Machine Kernelized SVM CONCLUSION REFERENCES http last updated 05. These are as follows. Standard and Normalization scale will be used for our operation. According to the principal components data points with greater values on the x axis represent the customers that are less likely to spend to Detergents_Paper category. Thal Analysis3 normal 6 fixed defect 7 reversable defectAccording to the analysis Thal values are observed. Age Range AnalysisIn this section age range analysis values are revealed. The reduced data can be seen on the plotting below. In this section the rate of disease is seen less when the gender value is male. com kralmachine football results from 1872 to 2018 datavisulationhttps www. 2 and 3 were found to be of the same degree. If the number is close to 1. com kralmachine gradient admission eda ml 0 92https www. The scale methods that we will do for this situation will increase this situation even higher. As you can see we are making a single clue of the columns that the data set contains. These age trestbps chol thalach. What is important here is that these numbers are not close to 1. ", "id": "kralmachine/analyzing-the-heart-disease", "size": "13442", "language": "python", "html_url": "https://www.kaggle.com/code/kralmachine/analyzing-the-heart-disease", "git_url": "https://www.kaggle.com/code/kralmachine/analyzing-the-heart-disease", "script": "classification_report train_test_split Imputer confusion_matrix sklearn.svm cross_val_score numpy accuracy_score seaborn SVC GaussianNB sklearn.neighbors sklearn.naive_bayes sklearn.tree GradientBoostingClassifier plot_feature_importances sklearn.linear_model auc PCA matplotlib.pyplot DecisionTreeClassifier sklearn.model_selection pandas plot_roc_ datetime RandomForestClassifier LogisticRegression roc_curve r2_score KNeighborsClassifier GridSearchCV sklearn.decomposition sklearn.metrics sklearn.ensemble StandardScaler sklearn.preprocessing ", "entities": "(('when it', 'usage big difference'), 'come') (('This', 'scaling operations'), 'change') (('here numbers', '1'), 'be') (('properties', 'different operations'), 'aim') (('I', 'application'), 'kralmachine') (('We', 'situations'), 'perform') (('it', 'Gender'), 'seem') (('it', 'more future analysis'), 'be') (('we', 'groupby function'), 'use') (('data', 'contains'), 'make') (('This', 'us'), 'be') (('removed', 'future'), 'affect') (('very you', 'UPVOTED'), 'be') (('that', 'less Fresh categories'), 'represent') (('best analysis', 'age'), 'be') (('I', 'questions'), 'have') (('values', 'very hard job'), 'seem') (('that', 'data set'), 'be') (('that', 'specific scaling'), 'score') (('other data', 'values'), 'normalized') (('One Visualization', 'training data'), 'perform') (('we', 'average age'), 'mean') (('how many missing data', 'data'), 'be') (('who', 'people'), 'be') (('http', 'last 05'), 'introduction') (('aim', 'age ranges'), 'be') (('later I', 'more'), 'install') (('X normalization resimOf course we', 'when this'), 'i\u015flemi') (('heart rate', 'age old areas'), 'distress') (('I', 'null data s.'), 'be') (('We', 'loaded data'), 'write') (('we', 'situation'), 'increase') (('difference', 'data'), 'be') (('we', 'StandardScaler function'), 'need') (('relationship', 'training data'), 'observe') (('com kralmachine football', 'datavisulationhttps www'), 'result') (('performance', 'examshttps'), 'seaborn') (('il', 'it'), 'do') (('values', 'first process'), 'determine') (('Now we', 'sex'), 'go') (('we', 'data sets'), 'implement') (('hypothesis thesis', 'hypothesis'), 'determine') (('largest values', 'data'), 'consider') (('that', 'best situation'), 'be') (('Now we', 'pandas library'), 'upload') (('most values', 'section'), 'categorize') (('Furthurmore I', 'visualization'), 'investigate') (('we', 'situation'), 'mean') (('Percentage ratios Male Sex 1 male 0 female State', 'chest 4 pain'), 'find') (('Thal values', 'normal 6 fixed 7 analysis'), 'reversable') (('value', '\u03c3'), 'be') (('it', 'maximum Thal'), 'be') (('Experiments', 'absence 1 2 3 4 value'), 'concentrate') (('we', 'following stages'), 'make') (('pains', 'analysis system'), 'analyze') (('different values', 'values'), 'give') (('other data', '0'), 'be') (('result we', 'graphs'), 'tutorial') (('Now it', 'data set'), 'be') (('Now data', '2015'), 'com') (('that', 'Detergents_Paper less category'), 'represent') (('you', 'account'), 'look') (('It', '4'), 'be') (('purpose', 'loaded data'), 'be') (('it', 'equal people'), 'AnalysisIn') (('Chest Pain Type AnalysisA wide range', 'heart failure'), 'be') (('Hyperthermatic technique', 'condition'), 'use') (('I', 'kernel that'), 'be') (('we', 'data set'), 'in') (('reduced data', 'plotting'), 'see') (('resimTheoretically it', 'big standard'), 'understand') (('only that', 'date'), 'be') (('who', 'people'), 'analyze') (('goal field', 'patient'), 'refer') (('I', 'data'), 'import') (('Therefore we', 'SVM algorithm'), 'need') (('relations', 'other properties'), 'check') (('0 cases', 'heart less disease'), 'see') (('we', 'correlation values'), 'be') (('So I', 'components'), 'investigate') (('we', 'dataset'), 'analyze') (('correlation values', 'previous sections'), 'list') (('Standard scale', 'operation'), 'use') (('Logistic we', 'data'), 'constitute') (('gender when value', 'disease'), 'see') (('best results', 'parameter hyper values'), 'create') (('head', 'default'), 'have') (('data', '0'), 'take') (('area', 'cases'), 'observe') (('now analysis', 'target process'), 'carry') (('most', 'feature only certain values'), 'categorized') (('parsing process', 'data'), 'be') (('we', 'learning artificial algorithms'), 'training') (('we', 'different experiments'), 'create') (('technique', 'process'), 'use') (('we', 'feature new values'), 'use') (('we', 'heart maximum rate'), 'show') (('published experiments', 'them'), 'contain') (('We', 'part'), 'use') (('We', 'data'), 'list') (('value', 'more us'), 'be') (('chest when pain', 'graph'), 'see') (('purpose', 'data'), 'be') (('2', 'same degree'), 'find') "}
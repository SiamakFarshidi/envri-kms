{"name": "hpa cellwise classification training ", "full_name": " h1 Human Protein Atlas Single Cell Classification h2 Categorical Classification At a Cellular Level TRAINING h1 TABLE OF CONTENTS h3 0 xa0 xa0 xa0 xa0IMPORTS h3 1 xa0 xa0 xa0 xa0BACKGROUND INFORMATION h3 2 xa0 xa0 xa0 xa0SETUP h3 3 xa0 xa0 xa0 xa0HELPER FUNCTIONS h3 4 xa0 xa0 xa0 xa0PREPARING THE DATASET TF DATA h3 5 xa0 xa0 xa0 xa0MODELLING h1 0 xa0 xa0IMPORTS xa0 xa0 xa0 xa0 h1 1 xa0 xa0BACKGROUND INFORMATION xa0 xa0 xa0 xa0 h3 1 1 APPROACH OVERVIEW h3 1 2 VISUAL HELPER h1 2 xa0 xa0NOTEBOOK SETUP xa0 xa0 xa0 xa0 h1 3 xa0 xa0HELPER FUNCTIONS xa0 xa0 xa0 xa0 h1 4 xa0 xa0PREPARING THE DATASET TF DATA xa0 xa0 xa0 xa0 h3 4 0 INITIALIZE DICTIONARIES MAPPING PATHS TO RELEVANT FILES h3 4 1 TRANSFORM THE PATH MAP INTO LISTS FOR INPUT INTO TF DATA h3 4 2 DETERMINE AN APPROPRIATE CLASS WEIGHTING h3 4 3 Define Model Dataset Parameters h3 4 4 CREATE THE TRAINING AND VALIDATION DATASETS h3 4 5 PREPROCESS THE DATASETS COMBINE RGBY AND ONE HOT ENCODE LABELS h1 5 xa0 xa0MODELLING xa0 xa0 xa0 xa0 h3 5 1 LOAD THE MODEL BACKBONE FOR TRAINING h3 5 2 FIT THE MODEL h3 5 3 VISUALIZE TRAINING ", "stargazers_count": 0, "forks_count": 0, "description": "count_nonzero y_pred y axis 0 tf. 1 APPROACH OVERVIEW TRAINING 1. float32 f1 2 tp 2 tp fn fp 1e 16 macro_f1 tf. Args y int32 Tensor targets array of shape BATCH_SIZE N_LABELS y_hat float32 Tensor probability matrix from forward propagation of shape BATCH_SIZE N_LABELS Returns cost scalar Tensor value of the cost function for the batch y tf. I will still calculate it here but I won t be adding it to the fit function. EfficientNetB1 include_top include_top weights weights pooling pooling input_shape input_shape elif b2 in efficientnet_name eb tf. EfficientNetB4 include_top include_top weights weights pooling pooling input_shape input_shape elif b5 in efficientnet_name eb tf. Identify slide level images containing only one label2. EfficientNetB5 include_top include_top weights weights pooling pooling input_shape input_shape elif b6 in efficientnet_name eb tf. Dense n_nodes activation relu x x tf. 05 head_layer_nodes 512 x tf. output x tf. VIEW SCHEDULE AUTO CALCULATED TRAIN DATASET VALIDATION DATASET Adjust class output expectation SEEDING KERNEL INIT Can t figure this out right now img_batch tf. Use probability values instead of binary predictions. 203 def macro_double_soft_f1 y y_hat Compute the macro soft F1 score as a cost average 1 soft F1 across all labels. reduce_mean cost average on all labels return macro_cost def macro_f1 y y_hat thresh 0. 2 FIT THE MODEL WIP5. Seperate the channels and store as seperate datasets8. list_files unfortunately either shuffles each list individually or forces the files into a sorted order. Args y int32 Tensor targets array of shape BATCH_SIZE N_LABELS y_hat float32 Tensor probability matrix of shape BATCH_SIZE N_LABELS Returns cost scalar Tensor value of the cost function for the batch y tf. Update the dataset greatly increase the number of negative class examples 9. EfficientNetB3 include_top include_top weights weights pooling pooling input_shape input_shape elif b4 in efficientnet_name eb tf. co y6YfBzN basic idea. Comparison Before and After Manual Heuristic Filtering Function. reduce_sum y_hat 1 y axis 0 fn tf. Dropout dropout x for n_nodes in head_layer_nodes x tf. n for i in range 19 print f CLS i 2 n ORIGINAL DISTRIBUTION ORIGINAL_DIST_MAP i n NEW DISTRIBUTION len RED_FILE_MAP i n red_inputs green_inputs blue_inputs yellow_inputs labels class_wts class_cnts get_class_wts RED_FILE_MAP return_counts True multiplier 23. Crop RGBY image around each cell4. float32 192 192 3 224 224 elems img_batch img_batch VISUALIZE EXAMPLES VISUALIZE EXAMPLES def get_backbone efficientnet_name efficientnet_b0 input_shape 224 224 3 include_top False weights imagenet pooling avg if b0 in efficientnet_name eb tf. 3 Define Model Dataset Parameters 4. 0 INITIALIZE DICTIONARIES MAPPING PATHS TO RELEVANT FILES 4. literal_eval x train_df. float32 fp tf. count_nonzero y_pred 1 y axis 0 tf. Segment slide level images get RLEs for all cells in all applicable slide level images 3. png 2 nbsp nbsp NOTEBOOK SETUP nbsp nbsp nbsp nbsp 10514 3 nbsp nbsp HELPER FUNCTIONS nbsp nbsp nbsp nbsp 10514 4 nbsp nbsp PREPARING THE DATASET TF. map_fn fn lambda img tf. Starting with a high LR would break the pre trained weights. DATA 5 nbsp nbsp nbsp nbsp MODELLING 0 nbsp nbsp IMPORTS nbsp nbsp nbsp nbsp 10514 1 nbsp nbsp BACKGROUND INFORMATION nbsp nbsp nbsp nbsp 10514 1. 3 VISUALIZE TRAINING WIP Try and get keras plot to work Machine Learning and Data Science Imports Built In Imports Visualization Imports PRESETS Define the path to the root data directory Define the path to the competition data directory Define path to the filtered TP IDs for each class Define the paths to the training tiles for the cell wise classification dataset Define the paths to the training and testing tfrecord and image folders respectively for the competition data Capture all the relevant full image paths for the competition dataset Capture all the relevant full tfrec paths Random Useful Info Define paths to the relevant csv files Create the relevant dataframe objects train_df. float32 fn tf. 4 CREATE THE TRAINING AND VALIDATION DATASETS WIP4. reduce_sum 1 y_hat y axis 0 tn tf. inputs outputs output eb get_backbone b2 eb add_head_to_bb eb n_classes dropout 0. compile optimizer OPTIMIZER loss LOSS_FN metrics acc tf. data to setup the input pipeline4. reduce_sum 1 y_hat 1 y axis 0 soft_f1_class1 2 tp 2 tp fn fp 1e 16 soft_f1_class0 2 tn 2 tn fn fp 1e 16 cost_class1 1 soft_f1_class1 reduce 1 soft f1_class1 in order to increase soft f1 on class 1 cost_class0 1 soft_f1_class0 reduce 1 soft f1_class0 in order to increase soft f1 on class 0 cost 0. Average 1 soft F1 across all labels. Dense n_classes activation sigmoid x return tf. EfficientNetB2 include_top include_top weights weights pooling pooling input_shape input_shape elif b3 in efficientnet_name eb tf. EfficientNetB7 include_top include_top weights weights pooling pooling input_shape input_shape else raise ValueError Invalid EfficientNet Name return eb def add_head_to_bb bb n_classes 19 dropout 0. 2 DETERMINE AN APPROPRIATE CLASS WEIGHTING I was using this previously. 2 VISUAL HELPER basic_idea_graph https i. 1 TRANSFORM THE PATH MAP INTO LISTS FOR INPUT INTO TF. 5 nbsp nbsp MODELLING nbsp nbsp nbsp nbsp 10514 This section will explore how to acquire augment and train the model5. Augment the dataset rotation flipping horizontal and vertical minor skew 10. count_nonzero 1 y_pred y axis 0 tf. Filter the images based on certain additional factors to obtain a better training dataset TBD 7. float32 tp tf. literal_eval x convert the compressed string to a 3D uint8 tensor resize the image to the desired size Get class stuff Get the relevant color directories Update map get the relevant full paths Capture all relevant paths REMOVE AFTER UPDATING CLASSBASED NOTEBOOK Initialize Get class counts Exclude mitotic spindle Calculate weights Manually adjust mitotic spindle to a more appropriate value TP_ID_MAP get_tp_id_map PKL_DIR Define the paths to the training files for the tile dataset as a map from class index to list of paths print n. We want the files shuffled but we want the shuffling to be identical across the various colour channels. 5 Compute the macro F1 score on a batch of observations average F1 across labels Args y int32 Tensor labels array of shape BATCH_SIZE N_LABELS y_hat float32 Tensor probability matrix from forward propagation of shape BATCH_SIZE N_LABELS thresh probability value above which we predict positive Returns macro_f1 scalar Tensor value of macro F1 for the batch y_pred tf. Resize each RGBY tile to be 256px by 256px 6. plot_model eb show_shapes True show_dtype True dpi 55. EfficientNetB0 include_top include_top weights weights pooling pooling input_shape input_shape elif b1 in efficientnet_name eb tf. Train a model to classify these tile level images accurately1. Human Protein Atlas Single Cell ClassificationCategorical Classification At a Cellular Level TRAINING CREATED BY DARIEN SCHETTLERTABLE OF CONTENTS 0 nbsp nbsp nbsp nbsp IMPORTS 1 nbsp nbsp nbsp nbsp BACKGROUND INFORMATION 2 nbsp nbsp nbsp nbsp SETUP 3 nbsp nbsp nbsp nbsp HELPER FUNCTIONS 4 nbsp nbsp nbsp nbsp PREPARING THE DATASET TF. AUC name auc multi_label True tf. reduce_sum 1 y_hat y axis 0 soft_f1 2 tp 2 tp fn fp 1e 16 cost 1 soft_f1 reduce 1 soft f1 in order to increase soft f1 macro_cost tf. DATA Using the command tf. reduce_sum y_hat y axis 0 fp tf. 1 LOAD THE MODEL BACKBONE FOR TRAINING WIP5. DATA nbsp nbsp nbsp nbsp 10514 This section will explore how to use tf. 5 cost_class1 cost_class0 take into account both class 1 and class 0 macro_cost tf. greater y_hat thresh tf. BatchNormalization bb. 5 PREPROCESS THE DATASETS COMBINE RGBY AND ONE HOT ENCODE LABELS We also augment visualize shuffle batch and prefetch. reduce_mean cost average on all labels return macro_cost def macro_soft_f1 y y_hat Compute the macro soft F1 score as a cost. mask_bboxes train_df. BatchNormalization x x tf. Pad each RGBY tile to be square5. This version uses the computation of soft F1 for both positive and negative class for each label. We also take this opportunity to identify the labels for each image and create an array as such. reduce_mean f1 return macro_f1 Using an LR ramp up because fine tuning a pre trained model. Dropout dropout 2 x output tf. EfficientNetB6 include_top include_top weights weights pooling pooling input_shape input_shape elif b7 in efficientnet_name eb tf. float32 y_hat tf. ", "id": "dschettler8845/hpa-cellwise-classification-training", "size": "8969", "language": "python", "html_url": "https://www.kaggle.com/code/dschettler8845/hpa-cellwise-classification-training", "git_url": "https://www.kaggle.com/code/dschettler8845/hpa-cellwise-classification-training", "script": "get_color_path_maps create_input_list Counter plotly.graph_objects preprocess_path_ds tensorflow_addons __load_with_tf plotly.express load_image_scaled augment macro_soft_f1 lrfn Image numpy get_tp_id_map seaborn get_backbone ListedColormap __load_with_pil decode_img glob get_class_wts plot_rgb tqdm convert_rgby_to_rgb matplotlib.patches tensorflow __load_with_cv2 matplotlib.pyplot plot_ex macro_f1 PIL matplotlib.colors pandas macro_double_soft_f1 datetime tqdm.notebook add_head_to_bb collections flatten_list_of_lists ", "entities": "(('APPROPRIATE CLASS 2 I', 'this'), 'DETERMINE') (('TRAIN DATASET', 'SEEDING this'), 'calculated') (('section', 'model5'), 'nbsp') (('fn 1 2 16 soft_f1', 'f1 soft macro_cost'), 'reduce_sum') (('here I', 'fit function'), 'calculate') (('NOTEBOOK Initialize Get class spindle Calculate CLASSBASED counts Exclude mitotic weights', 'print n.'), 'convert') (('section', 'how tf'), 'nbsp') (('reduce_mean cost average', 'cost'), 'return') (('reduce_mean cost average', 'macro_cost def'), 'return') (('n green_inputs blue_inputs', 'class_wts class_cnts'), 'n') (('input_shape input_shape elif pooling b5', 'efficientnet_name eb'), 'efficientnetb4') (('weights input_shape input_shape elif include_top pooling b6', 'efficientnet_name eb'), 'weight') (('Update', 'class negative examples'), 'increase') (('Segment slide level images', 'slide level applicable images'), 'get') (('include_top weights input_shape input_shape elif b1', 'efficientnet_name eb'), 'weight') (('b0', 'efficientnet_name eb'), 'float32') (('4', 'TRAINING'), 'CREATE') (('N_LABELS Returns', 'tf'), 'target') (('ValueError Invalid EfficientNet else Name', 'eb def'), 'EfficientNetB7') (('Data Science Imports Visualization PRESETS', 'dataframe relevant objects'), 'try') (('weights input_shape input_shape elif include_top pooling b3', 'efficientnet_name eb'), 'include_top') (('version', 'label'), 'use') (('input_shape input_shape elif pooling b4', 'efficientnet_name eb'), 'include_top') (('Starting', 'pre trained weights'), 'break') (('cost_class1 5 cost_class0', 'account'), 'take') (('shuffling', 'colour various channels'), 'want') (('list_files', 'sorted order'), 'shuffle') (('input_shape input_shape elif pooling b2', 'efficientnet_name eb'), 'include_top') (('dataset rotation', 'horizontal vertical skew'), 'augment') (('DICTIONARIES INITIALIZE MAPPING', 'RELEVANT FILES'), '0') (('scalar Tensor macro_f1 value', 'batch'), 'Compute') (('DATASETS ENCODE 5 PREPROCESS ONE HOT We', 'visualize shuffle also batch'), 'combine') (('We', 'array'), 'take') (('1 1e 16 cost_class1 soft_f1_class1', 'class 0 cost'), 'reduce_sum') "}
{"name": "exploratory analysis for online news popularity ", "full_name": " h1 Exploratory Analysis For Online News Popularity A deep insight analysis h2 Open Book Ideas to consider h2 Reading the data h1 Data Processing h2 Grading the Shares h3 Here we check the class balance h2 Data Visualization h3 Noise Removal h3 Evaluating Expectations h4 Weekdays Variable Effect h4 Data Channel Evaluation h3 Evaluating the Observerd Hypothesis h4 Data channels vs Num images vs popularity h1 Making Recommendations For Good Articles h1 Feature Extraction Selection h4 Feature Selection on the whole dataset h4 Feature selection based on best hypothesis observed h4 Feature Selection Based on Fisher Discrimating Analysis h4 Finding the normal distrubution of the dataset h4 Feature selection based on best hypothesis observed Normal distribution h4 Feature Selection Based on Fisher Discrimating Analysis Normal Distribution h4 Feature Selection on the whole dataset Normal Distribution h2 Visulazing the impact of normal distribution on the data h3 Variables of our features selection are listed below h1 Machine Learning Supervised Learning Classification h3 KNN Classifier h3 Random Forest Classifier h3 SVM Support Vector Machines h1 Summary and Conclusion h1 To Be Continued h2 Varaibles Summary Observation ", "stargazers_count": 0, "forks_count": 0, "description": "Is this also observed in the other data channels What about the effects of the Worst Best and Avg keywords Is their an influence on the min max or avg shares on each article referenced articles. Quantitative Analysis How correct is our intuition Here we carry our several analysis to accept or debunk our initial hypothesis Normal Distribuiton Observation on the dataset Feature Selection and Evaluation Machine Learning Classification Summary and Conclusion. For a more concrete channel The Business and Entertaiment channel are great for the best popularity. Random Forest ClassifierRandom Forest has the best result for this classification task reaching an accuracy of 51. 6 17 words is the ideal number of words to have for titles. The number of keywords in the metadata really influences the shares to a margin. Your chances are low Data Channel EvaluationHere it can be seen that the best articles with highest share popularity belongs to the Others channel. grouped both data together and create a pandas dataframe from it. Exploratory Analysis For Online News Popularity A deep insight analysis by Ayo Ayibiowu https www. So does it offers any uniques No it doesn t. com thehapyone online news popularity a classification problem. The Business and Entertainment channel are great for the best popularity. and label them with the respective list entries Rotate the tick labels and set their alignment. We evaluated the impact of this normaility on our modelsAlthough shares doesn t have a normal distrubition we can do a log transformation to give us a normal distrubition data Feature Extraction Selection Here we will be extracting some of the best features we observed out from the data. In the v2 of this project the knowledge gained so far is used to address a classification problem thus improving the prediction accuracy by large margin. From the plot below we can see that Business channels generally don t get influnece by the num_images in them. Evaluating Expectations Weekdays Variable EffectIt seems the best popular articles are usually posted on Mondays and Wednesday and a bit of tuesdays Sundays and Saturdays Weekends generally are the worsts days to publish an articles. To Be ContinuedThis project is continued here https www. Coming in third position will be the World and Tech. Summary and ConclusionIn this project we analyzed the given online news data set and was able to clearly observed some interesting patterns that good articles do have in common. Here it can be seen that the best articles with highest share popularity belongs to the Others channel. It belongs to world news or others. Those rare cases where the high visuals or low visuals doesn t change anything is in the Business channel. Does the number of shares in those referenced articles also influence the number of shares in the main article At what point in the weekend do people share articles the most Can that means people read those articles the most on those days What is the effect of LDA analysis on the article popularity Does article with more text sentiment influence the popularity what the is relationship between the text sentiment and the article publish day Are more sentiment on a particlar day How about the influence of postive negative words in the text sentiment and popularity. For example using all the features gave an accuracy less than 1 of the highest accuracy observed. 8 num_hrefs is between 1 and 40 referrence links num_imgs should between 1 40 images num_videos should be between 0 25 vidoes. Articles that talks about current trending are better for shares From the scatterplot below it can be seen than good articles will generally tend to have n_tokens_content less than 2000 and greater than 100 words From the scatterplot below it can be seen than good articles will generally tend to have n_tokens_title between 6 and 17 words similar to the above. Coming in third position will be the World and or Tech channels. Avoid the use of longer words in the articles. fetch the number of classes print grouped loop through all features the variance of the feature j mean for class k of feature j calculates the fisher score of the features plot the fisher analysis score feature selection based on fisher score Fisher Index Ratio Filter Remove features with low score indices of features to remove based on fisher ratios we mark for removal remove features with low fisher score use log transformation to transform each features to a normal distribution note log transformation can only be performed on data without zero value applying log transformation only apply to non zero features attempt to only transform the positive values alone only the best observed features are extracted here calculates the fisher score of the features plot the fisher analysis score feature selection based on fisher score Fisher Index Ratio Filter Remove features with low score indices of features to remove based on fisher ratios we mark for removal remove features with low fisher score ihave about 25 features left. Evaluating the Observerd Hypothesis Data channels vs Num_images vs popularityHere we compared data channels impact with num images in regards to article popularity Earlier we said good articles tend to have high visuals num_images in them but it is not always the case everytime. This is peculiar pattern. Sundays and Saturdays Weekends generally are the worsts days to publish an articles. Increase the amount of subjectivity in the title and content. Loop over data dimensions and create text annotations. Although this was the best accuracy discovered there wasn t much difference with the other models. Variables of our features selection are listed below Feature selection based on best hypothesis observed data_feature1 Feature Selection on the whole dataset data_feature2 Feature selection using fisher discriminal analysis data_feature_fisher Feature selection based on the best hypothesis observed but with a normal distribution log transformation data_feature1_normal Feature selection using fisher discriminate analysis on normal distribution dataset data_feature_fisher_normal Feature Selection on the whole dataset data_feature2_normal Machine Learning Supervised Learning Classification Here we are going to apply some machine learing models on our dataset for classifying an article popularity KNN ClassifierThe KNN model which gave the best accuracy of 49. Between 1 40 images is great. This record is classifed as a noise and will be remove. The lesser the better. The higher the value the better the shares chances. Best popular articles are usually posted on Mondays and Wednesday and a bit of tuesdays. defining the model predict the result predict the result predict the result Plot non normalized confusion matrix iterating through all the possible features commence training NOTE It takes hours to be complete predict the result iterating through all the possible features commence training NOTE It takes hours to be complete predict the result. Entertainment channels generally tend to have high visuals as their popularity increases with the only exception in Average popularity. n_unique_tokens should be between 0. Due to the nature of Random forest being able to set different number of decision trees features tree depth splitting criteria and others it tends to require a lot of parameter tuning. Articles that talks about current trending tends to have higher popularity. read_csv Here we drop the two non preditive url and timedelta attributes. running a pair plot for the kw__terms run a pairplot normalizaling the data with standard scaler we will normalized all the features selections scalled all the feature selections encoding the label set with a label encoder Splitting the data for Training and Testing train and test for a feature selections function for confusion matrix Compute confusion matrix Only use the labels that appear in the data We want to show all ticks. This is important because several statistic tests rely on this e. The below criteria will be considered Feature selection based on best hypothesis observed Feature Selection on the whole dataset Feature selection using fisher discriminal analysis Feature selection based on the best hypothesis observed but with a normal distribution log transformation Feature selection using fisher discriminate analysis on normal distribution dataset Feature Selection on the whole dataset Normal Distribution Feature Selection on the whole dataset Feature selection based on best hypothesis observed Feature Selection Based on Fisher Discrimating Analysis Finding the normal distrubution of the dataset Feature selection based on best hypothesis observed Normal distribution Feature Selection Based on Fisher Discrimating Analysis Normal Distribution Feature Selection on the whole dataset Normal Distribution Visulazing the impact of normal distribution on the data In the new transformation the features observation is more clear than before. 4 on the testing data set. SVM Support Vector MachinesThe maximum accuracy observed with SVM was 50 58. In order to be able to tune the models for better performances we consider different feature selection techniques but these feature selections technique didn t really made much influence to the performance of the machine learning models. com in ayoayibiowu In this project the goal is the explore the dataset given and be able to find critical insights that can be used to influence potential article popularity. From the insight analysis carried out on the data set the following are some of the things we recommend to improve the popularity of an article The number of words in the article should be less than 1500 words. Increase the number of popular unique words in the article to increase the chances of having better popularity. The higher the lower the odds. Articles should have good amount of images. One important observation is also that Entertaiment channel based articls seems to be persistent in all popularity types. The process followed is highlighted below Data Cleaning Noise detection and removal Subjective analysis Using our intuition to evaluate a data variable feature and decide whether a variable influences the popularity of the article or not. creating a grading criteria for the shares create label grades for the classes Update this class label into the dataframe Merging the weekdays columns channels as one single column Merging the data channels as one single column logic to merge data channel merge the the new data into the dataframe Now I drop the old data Evaluating features sensors contribution towards the label Fetch the counts for each class Visualizaing the low expectation hypothesis n_non_stop_words Comment Visualizing the n_non_stop_words data field shows that the present of a record with 1042 value futher observation of that data shows that it belongs to entertainment which is not actually. Making Recommendations For Good Articles n_tokens_content should be less than 1500 words. Although our main gain is to build important insight about how popularity of articles are defined we also went ahead in seeing how to predict the popularity of an article. this particluar also contains 0 on a lot of attributes. average_token_length should be between 4 6 The number of keywords in the metedata really influences the shares to a margin. Easy to read words helps to improve article popularity. They won t contribute anything describing the data from the data there will be need to normailze the data if their will be need for condersing any machine learning model. Here we will go ahead and drop the field of n_non_stop_words remove noise from n_tokens_content. We initially carried out a subjective analysis which was based on our own intuition and because we understand it is easily possible for human intuition to be biased or crowded from past experience and use a quantitative analysis to confirm our initial hypothesis by doing univariate analysis using scatter plot boxplot and barplot of each feature with the shares feature. Some of the reasons for this low accuracy score is as a result of the large variance in the data set and also the imbalance in the class distribution which drives the prediction models to be bias towards popularity classes with more articles. A value upward of 5 is recommend. those equals to 0 n_non_stop_unique_tokens a lot of unique words it is better to use a different plot from bar plots line plot box plot box plot of the dataset shows majority 75 of the data inrespective of their shares is in the range of 0. What is ratio of postive to negative word articles in the dataset Are the mutually balanced and can we make a judgment based on that alone What about the effect of subjectivity on the title and test in the popularity Reading the data Data Processing Grading the Shares Exceptional Top 95 Excellent Top 90 Very Good Top 80 Good Top 60 Average Top 50 Poor Top 35 Very Poor Rest Here we check the class balance Data Visualization Evaluating our hypothesis Noise Removal We observed some noise from the dataset coming from different features. Articles referencing popular articles have a higher chance of improving their own popularity. Best popular articles are usually posted on Mondays and Wednesday and a bit of Tuesdays. Varaibles Summary Observation image. 11 was based on using the all the data set feature and number of neighbor of 71. kw_min_min and related kw_ terms running a pair plot for the kw__terms run a pairplot Finding relationship between rate_positive_words rate_negative_words global_rate_positive_words global_rate_negative_words and shares running a pair plot for the these terms run a pairplot attempt polartiy attempt polartiy Finding relationship between rate_positive_words rate_negative_words global_rate_positive_words global_rate_negative_words and shares running a pair plot for the terms run a pairplot attempt title_subjectivity attempt title_subjectivity running a pair plot for the kw__terms run a pairplot attempt self_reference_min_shares running a pair plot for the kw__terms run a pairplot running a pair plot for the kw__terms run a pairplot extact the weekdays articles distrubution shows the days when articles are usually posted shows relationship with the number of shares and the weekdays shows relationship with the number of shares and the weekdays compare only the best three popularity running a pair plot for the kw__terms run a pairplot extact the weekdays articles distrubution Shows the distribution of the articles across the channels the ranking of the channels in regards to the shares popularity shows relationship with the number of shares and the ranking of the channels compare only the best three popularity histogram and normal probability plot applying log transformation transformed histogram and normal probability plot Check for missing data shares data is not needed for classification convert categorical variables into dummy it use one hot encoding extract the label data in this case popularity only the best observed features are extracted here helper function for evalating the fisher ndex create the fisher output variable A vector of all the features It s expected that the dim1_T and dim1_L be of the same size else this input parameters is nulled. png attachment image. png Libaries import linear algebra data processing CSV file I O e. They are generally low inrespective of the popularity. Normal Distribution analysis for Shares Normality what we mean is that the data should look like a normal distribution. Seven popularity classes was derived from the shares class and three machine learning model was built to be able to predict the popularity class of the model. Also machine learning models was built to be able to predict the popularity of a given article. Article title shouldn t be too long or too short. Tech channels performed generally okay. Meaning they mightnot always be the best channel to publish for. Do people favours postive worded article. Sundays and Saturdays Weekends generally are the worsts days to publish an article. n_tokens_title should be between 6 17 words. First extract out the number of features available. Open Book Ideas to considerSome ideas to consider What is the effect of number of images number of videos on the article popularity Is their a relationship between the number of words in the content and or number of words in the title in the article popularity Is their a concrete relationship between average length of words in the content to the popularity Create a grading rank for the popularity Excellent Good Okay Poor Very Poor How is the ranking of the channels in regards to the shares popularity What data channel has the most popularity and what feature in that particular data channel contributes towards that asserction. An observation with SVM is that training start becoming increasing as the number of polynomial degree increases training examples increases C value rises and also the number of features increase which basically makes the model become more complex to draw an hyper plane for separating the classes. The best machine learning model was the Random Forest which was able to attain an accuracy of 51. t statistics and some machine learning models. Also having a couple of videos is also nice for article popularity but not too much. ", "id": "thehapyone/exploratory-analysis-for-online-news-popularity", "size": "12792", "language": "python", "html_url": "https://www.kaggle.com/code/thehapyone/exploratory-analysis-for-online-news-popularity", "git_url": "https://www.kaggle.com/code/thehapyone/exploratory-analysis-for-online-news-popularity", "script": "sklearn.utils.multiclass train_test_split confusion_matrix accuracy_score numpy sklearn.svm seaborn SVC norm sklearn.neighbors plot_confusion_matrix unique_labels matplotlib.pyplot copy sklearn.model_selection pandas probplot RandomForestClassifier scipy.stats KNeighborsClassifier fisher_index_calc LabelEncoder GridSearchCV sklearn.metrics make_scorer sklearn.ensemble StandardScaler sklearn.preprocessing ", "entities": "(('it', 'uniques'), 'offer') (('best articles', 'Others channel'), 'be') (('We', 'ticks'), 'run') (('n_tokens_content', 'Good Articles'), 'be') (('Here we', 'Machine Learning Classification dataset Feature Selection Summary'), 'analysis') (('data', '71'), 'base') (('data', 'normal distribution'), 'be') (('Sundays Weekends', 'worsts generally articles'), 'be') (('It', 'result'), 'predict') (('referrence 1 between 1 between 40 images', '25 vidoes'), 'be') (('it', 'them'), 'evaluate') (('Also couple', 'article also popularity'), 'have') (('SVM Support Vector MachinesThe', 'maximum SVM'), 'be') (('which', 'entertainment'), 'create') (('features observation', 'new transformation'), 'consider') (('Avg keywords', 'article'), 'observe') (('Entertaiment also channel', 'popularity based types'), 'be') (('that', 'higher popularity'), 'tend') (('best articles', 'Others channel'), 'see') (('basically model', 'classes'), 'be') (('noise', 'different features'), 'be') (('don generally t', 'them'), 'see') (('Articles', 'own popularity'), 'have') (('low doesn', 'Business channel'), 'be') (('png Libaries import linear algebra data', 'CSV file'), 'process') (('good articles', 'similar above'), 'be') (('easily human intuition', 'shares feature'), 'carry') (('com thehapyone', 'news classification online problem'), 'popularity') (('KNN ClassifierThe KNN which', '49'), 'list') (('Here we', 'n_tokens_content'), 'go') (('feature', 'asserction'), 'be') (('that', 'article potential popularity'), 'com') (('majority', '0'), 'equal') (('their', 'machine learning model'), 'win') (('input else parameters', 'same size'), 'run') (('this', 'other models'), 'wasn') (('Sundays Weekends', 'worsts generally articles'), 'seem') (('is relationship', 'text sentiment'), 'influence') (('knowledge', 'large margin'), 'gain') (('They', 'generally low popularity'), 'be') (('6 17 words', 'titles'), 'be') (('variable', 'article'), 'highlight') (('people', 'postive worded article'), 'favours') (('read_csv Here we', 'two non preditive url attributes'), 'drop') (('Random which', '51'), 'be') (('respective list', 'alignment'), 'label') (('Best popular articles', 'tuesdays'), 'post') (('number', 'margin'), 'influence') (('good articles', 'that'), 'Summary') (('several statistic tests', 'e.'), 'be') (('Sundays Weekends', 'worsts generally article'), 'be') (('number', 'article'), 'be') (('popularity', 'Average popularity'), 'tend') (('we', 'data'), 'evaluate') (('we', 'article'), 'be') (('which', 'more articles'), 'be') (('we', 'about 25 features'), 'fetch') (('Best popular articles', 'Tuesdays'), 'post') (('popularity Seven classes', 'model'), 'derive') (('particluar', 'attributes'), 'contain') (('machine learning Also models', 'given article'), 'build') (('record', 'noise'), 'classife') (('Business channel', 'best popularity'), 'be') (('number', 'margin'), 'be') (('Easy', 'article popularity'), 'help') (('classification task', '51'), 'have') (('Coming', 'third position'), 'be') (('feature selections technique didn t', 'machine learning models'), 'make') (('Articles', 'images'), 'have') (('it', 'parameter'), 'feature') "}
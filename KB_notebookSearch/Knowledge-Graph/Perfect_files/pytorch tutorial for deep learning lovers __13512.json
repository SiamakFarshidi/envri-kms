{"name": "pytorch tutorial for deep learning lovers ", "full_name": " h2 INTRODUCTION h2 Basics of Pytorch h3 Matrices h3 Basic Math with Pytorch h3 Variables h3 Linear Regression h3 Logistic Regression h3 Artificial Neural Network ANN h3 Convolutional Neural Network CNN h3 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "Aim is fitting line with minimum error. Clean support for dynamic graphs Organizational backing from Facebook Blend of high level and low level APIs cons Much less mature than alternatives Limited references resources outside of the official documentation I accept you know neural network basics. com kanncaa1 deep learning tutorial for beginners Steps of Logistic Regression 1. While usign trained model lets predict car prices. INTRODUCTION It s a Python based scientific computing package targeted at two sets of audiences A replacement for NumPy to use the power of GPUs Deep learning research platform that provides maximum flexibility and speed pros Interactively debugging PyTorch. In order to split data we use train_test_split method from sklearn library Size of train data is 80 and size of test data is 20. Loss is almost zero that you can see from plot or loss in epoch number 1000. Therefore variable x should be have gradients Lets look at gradients with x. com kanncaa1 recurrent neural network with pytorch1. std Variables It accumulates gradients. However as you expect there should be logistic function in model right In pytorch logistic function is in the loss function where we will use at next parts. Instantiate Optimizer SGD Optimizer 1. Batch size is the group size. Therefore we need to handle gradients. You can try different values for hidden layer dimension and observe the results. com kanncaa1 convolutional neural network cnn tutorial Steps of CNN 1. create LinearRegression class 1. As you remember we need variable to accumulate gradients. Padding After applying filter dimensions of original image decreases. Backpropagation 1. Therefore usually convert result of neural network that is tensor to numpy array to visualize or examine. Fully Connected Layer Artificial Neural Network that we learnt at previous part. com kanncaa1 deep learning tutorial for beginners Difference between variables and tensor is variable accumulates gradients. This is the fact that we know and we have data set about this fact. Thanks to convolutional layer model learnt better and accuracy almost 98 is better than accuracy of ANN. import numpy library numpy array 2x3 array type shape import pytorch library pytorch array type shape numpy ones pytorch ones numpy random pytorch random random numpy array from numpy to tensor from tensor to numpy create tensor Resize Addition Subtraction Element wise multiplication Element wise division Mean Standart deviation std import variable from pytorch library define variable lets make basic backward propagation we have an equation that is y x 2 recap o equation o 1 2 sum y backward calculates gradients As I defined variables accumulates gradients. Instantiate Model Class input_dim 28 28 size of image px px output_dim 10 labels 0 1 2 3 4 5 6 7 8 9 Hidden layer dimension is 150. Prediction As a result as you can see from plot while loss decreasing accuracy almost 85 is increasing and our model is learning training. Deep learning tutorial https www. However we want to preserve as much as information about the original image. If the car price is high we sell less car. Prepare Dataset Totally same with previous part logistic regression. Instantiate Loss Cross entropy loss It calculates loss that is not surprise It also has softmax logistic function in it. You can learn CNN basics https www. In order to increase complexity of model we need to add more non linear functions as hidden layer. Import Libraries 1. I only choose it as 150 there is no reason. We train each groups 336 that have batch_size quota 100. shape shape of the array. com kanncaa1 long short term memory with pytorch Basics of Pytorch Matrices In pytorch matrix array is called tensors. If the car price is low we sell more car. numpy method Type type of the array. Concolutional Neural Network CNN 5 1. create feature and targets tensor for train set. Pooling layer Prepares a condensed feature map from output of convolutional layer feature map 2 pooling layer that we will use max pooling. Finally we train 33600 sample one time. linear regression logistic function softmax logistic regression Check my deep learning tutorial. create model 1. Convolutional Neural Network CNN CNN is well adapted to classify images. I am saying again that if you do not know what is artificial neural network check my deep learning tutorial because I will not explain neural network detailed here only explain pytorch. Prediction As a result as you can see from plot while loss decreasing accuracy is increasing and our model is learning training. Therefore lets learn how to make it with pytorch. Row x Column Allocation is one of the most used technique in coding. Recurrent Neural Network RNN https www. Data is trained 29 times. epoch 1 epoch means training all samples one time. Artificial Neural Network ANN Logistic regression is good at classification but when complexity non linearity increases the accuracy of model decreases. We use same batch size epoch and iteration numbers. If you do not know neural network check my deep learning tutorial first because I will not explain detailed the concepts like optimization loss function or backpropagation. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. Lets look at array example with numpy that we already know. In order to learn compare numpy and tensor np. I will not explain it in here detailed. Module and we can access everythink in nn. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. Recurrent neural network with pytorch https www. Artificial Neural Network tutorial https www. Now we have a trained model. We use logistic regression for classification. In this part there is only one variable x. We can apply padding to increase dimension of feature map after convolutional layer. read_csv Input data files are available in the. Steps of ANN 1. Logistic Regression 3 1. We create numpy array with np. Therefore we need to increase complexity of model. Thanks to hidden layers model learnt better and accuracy almost 95 is better than accuracy of logistic regression model. Number of feature map is out_channels 16 Filter kernel size is 5 5 1. There is detailed explanation of logistic regression. data type is long batch_size epoch and iteration Pytorch train and test sets data loader visualize one of the images in data set Create Logistic Regression Model Linear part There should be logistic function right However logistic function in pytorch is in loss function So actually we do not forget to put it it is only at next parts Instantiate Model Class size of image px px labels 0 1 2 3 4 5 6 7 8 9 create logistic regression model Cross Entropy Loss SGD Optimizer Traning the Model Define variables Clear gradients Forward propagation Calculate softmax and cross entropy loss Calculate gradients Update parameters Prediction Calculate Accuracy Predict test dataset Forward propagation Get predictions from the maximum value Total number of labels Total correct predictions store loss and iteration Print Loss visualization Import Libraries Create ANN Model Linear function 1 784 150 Non linearity 1 Linear function 2 150 150 Non linearity 2 Linear function 3 150 150 Non linearity 3 Linear function 4 readout 150 10 Linear function 1 Non linearity 1 Linear function 2 Non linearity 2 Linear function 2 Non linearity 2 Linear function 4 readout instantiate ANN hidden layer dim is one of the hyper parameter and it should be chosen and tuned. For now I only say 150 there is no reason. It also provides multi process iterators over the dataset. Lets look at conversion between tensor and numpy arrays. Many users who have used both frameworks would argue that makes pytorch significantly easier to debug and visualize. Now examine how we implement tensor pytorch array import pytorch library with import torch We create tensor with torch. grad As a car company we collect this data from previous selling lets define car prices lets define number of car sell lets visualize our data Linear Regression with Pytorch libraries create class super function. DataLoader It combines dataset and sample. Now this plot is our collected data We have a question that is what will be number of car sell if the car price is 100 In order to solve this question we need to use linear regression. Traning the Model 1. In our example we have 33600 sample to train and we decide our batch_size is 100. Linear Regression tutorial https www. Each sample is retrieved by indexing tensors along the first dimension. We use 2 convolutional layer. You can think that our fully connected layer is logistic regression. If you learn these parts very well implementing remaining parts like CNN or RNN will be very easy. If you do not know check my tutorial. Linear regression with pytorch1. Also we decide epoch is 29 accuracy achieves almost highest value when epoch is 29. Artificial neural network with with pytorch1. div a b a b Mean a. Artificial Neural Network ANN 4 1. Prediction Lets implement it with Pytorch Number of iteration is 1001. Linear Regression 2 1. In this example it is numpy np. com kanncaa1 long short term memory with pytorch If you have any question or suggest I will be happy to hear it This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. We can train 1000 sample in a same time or we can divide it 10 groups which include 100 sample and train 10 groups in order. As you remember we need to define variable for accumulation of gradients. A slope of curve B bias point that intersect y axis For example we have car company. Long Short Term Memory LSTM https www. In this example it is tensor shape shape of the array. from_numpy from numpy to tensor numpy from tensor to numpy Basic Math with Pytorch Resize view a and b are tensor. Basics of Pytorch 1 Matrices Math Variable1. com kanncaa1 deep learning tutorial for beginners The most important parts of this tutorial from matrices to ANN. batch_size batch size means is that for example we have data and it includes 1000 sample. Tensor method type type of the array. Create Logistic Regression Model Same with linear regression. Question is that how many iteration do I need Lets calculate training data 1 times training 33600 sample because data includes 33600 sample But we split our data 336 groups group_size batch_size 100 our data Therefore 1 epoch training data only once takes 336 iteration We have 29 epoch so total iterarion is 9744 that is almost 10000 which I used TensorDataset Data set wrapping tensors. define model input and output size are 1 MSE Optimization find parameters that minimize error how fast we reach best parameters train model optimization Forward to get output Calculate Loss backward propagation Updating parameters store loss print loss predict our car price predict if car price is 10 what will be the number of car sell Import Libraries Prepare Dataset load data split data into features pixels and labels numbers from 0 to 9 normalization train test split. Convolutional layer Create feature maps with filters kernels. Pooling size is 2 2 1. Convolutional neural network with pytorch1. Therefore first we create tensor then we will create variable data type is long create feature and targets tensor for test set. We use same dataset so we only need train_loader and test_loader. add a b a b Subtraction a. mul a b a b Element wise division torch. Module Linear function. We combine convolutional part and logistic regression to create our CNN model. Visualize one of the images in dataset 1. And as you know in neural network we have backpropagation where gradients are calculated. ConclusionIn this tutorial we learn 1. com kanncaa1 deep learning tutorial for beginners What we expect from artificial neural network is that when complexity increases we use more hidden layers and our model can adapt better. We use ReLU Tanh and ELU activation functions for diversity. Actually while tuning hyperparameters increase in iteration and expanding convolutional neural network can increase accuracy but it takes too much running time that we do not want at kaggle. We can make math operations with variables too. For example I choose batch_size 100 that means in order to train all data only once we have 336 groups. Instantiate Model input_dim 28 28 size of image px px output_dim 10 labels 0 1 2 3 4 5 6 7 8 9 create model 1. Row x Column We looked at numpy array. We will not use activation function in fully connected layer. Flattening Flats the features map 1. Prepare Dataset We use MNIST dataset. define model from this LinearRegression class 1. com kanncaa1 machine learning tutorial for beginners y Ax B. MSE Mean squared error 1. Create ANN Model We add 3 hidden layers. Optimization SGD stochastic gradient descent 1. Size of train data is 80 and size of test data is 20. We will use pytorch in neural network. As a result accuracy increase. rand Even if when I use pytorch for neural networks I feel better if I use numpy. Instantiate Loss Cross entropy loss It also has softmax logistic function in it. Instantiate Model Class create model 1. Logistic Regression Linear regression is not good at classification. sub b a b Element wise multiplication torch. Actually hidden layer dimension is hyperparameter and it should be chosen and tuned. Prepare Dataset Totally same with previous parts. The question is that what will be number of car sell if the car price is 100. We need to line fit into this data. mean Standart Deviation std a. In order to make backward propagation we need variables Assume we have equation y x 2 Define x 2 4 variable After calculation we find that y 4 16 y x 2 Recap o equation is that o 1 2 sum y 1 2 sum x 2 deriavative of o x Result is equal to x so gradients are 2 4 Lets implement Linear Regression Detailed linear regression tutorial is in my machine learning tutorial in part Regression. There are 28 28 images and 10 labels from 0 to 9 Data is not normalized so we divide each image to 255 that is basic normalization for images. Import Libraries In order to show you I import again but we actually imported them at previous parts. Or it can be only linear like logistic regression but at the end there is always softmax function. Create feature and target tensors. Logistic regression with pytorch1. Steps of Linear Regression 1. Because I will not explain neural network concepts detailed I only explain how to use pytorch for neural network Neural Network tutorial https www. At the next parts we create variable from these tensors. Create ANN Cross Entropy Loss SGD Optimizer ANN model training Clear gradients Forward propagation Calculate softmax and ross entropy loss Calculating gradients Update parameters Calculate Accuracy Predict test dataset Forward propagation Get predictions from the maximum value Total number of labels Total correct predictions store loss and iteration Print Loss visualization loss visualization accuracy Import Libraries Create CNN Model Convolution 1 Max pool 1 Convolution 2 Max pool 2 Fully connected 1 Convolution 1 Max pool 1 Convolution 2 Max pool 2 flatten Linear function readout batch_size epoch and iteration Pytorch train and test sets data loader Create CNN Cross Entropy Loss SGD Optimizer CNN model training Clear gradients Forward propagation Calculate softmax and ross entropy loss Calculating gradients Update parameters Calculate Accuracy Iterate through test dataset Forward propagation Get predictions from the maximum value Total number of labels store loss and iteration Print Loss visualization loss visualization accuracy. ", "id": "kanncaa1/pytorch-tutorial-for-deep-learning-lovers", "size": "13512", "language": "python", "html_url": "https://www.kaggle.com/code/kanncaa1/pytorch-tutorial-for-deep-learning-lovers", "git_url": "https://www.kaggle.com/code/kanncaa1/pytorch-tutorial-for-deep-learning-lovers", "script": "Variable DataLoader torch.nn torch.utils.data matplotlib.pyplot train_test_split LogisticRegressionModel(nn.Module) __init__ torch.autograd forward CNNModel(nn.Module) sklearn.model_selection pandas ANNModel(nn.Module) LinearRegression(nn.Module) numpy ", "entities": "(('I', 'only 150'), 'say') (('80', 'test data'), 'be') (('We', 'fully connected layer'), 'use') (('You', 'results'), 'try') (('model lets', 'car prices'), 'predict') (('I', 'variables accumulates gradients'), 'numpy') (('Therefore lets', 'pytorch'), 'learn') (('then we', 'test set'), 'create') (('we', 'car company'), 'slope') (('we', 'numpy'), 'look') (('we', 'max pooling'), 'prepare') (('we', 'linear regression'), 'be') (('we', 'tensors'), 'create') (('Row Column Allocation', 'coding'), 'be') (('epoch 1 epoch', 'samples'), 'mean') (('only we', '336 groups'), 'choose') (('when epoch', 'almost highest value'), 'achieve') (('Lets', 'x.'), 'have') (('pytorch', 'significantly debug'), 'argue') (('Prediction Lets', 'iteration'), 'implement') (('sample', 'first dimension'), 'retrieve') (('we', 'kaggle'), 'increase') (('it', '1000 sample'), 'be') (('I', '150'), 'choose') (('batch_size', '33600 sample'), 'have') (('which', 'order'), 'train') (('better almost 98', 'ANN'), 'thank') (('that', 'maximum flexibility'), 'introduction') (('we', 'more car'), 'sell') (('that', 'basic images'), 'be') (('we', 'only train_loader'), 'use') (('We', 'ELU activation diversity'), 'use') (('that', 'array'), 'convert') (('read_csv Input data files', 'the'), 'be') (('where we', 'next parts'), 'be') (('It', 'dataset'), 'DataLoader') (('Prepare load Dataset data', 'labels normalization train test 0 to 9 split'), 'be') (('more hidden layers', 'artificial neural network'), 'com') (('Lets', 'tensor'), 'look') (('com', 'variables'), 'be') (('again we', 'previous parts'), 'library') (('Logistic Regression Linear regression', 'classification'), 'be') (('we', 'less car'), 'sell') (('non when complexity linearity', 'model decreases'), 'be') (('from_numpy', 'a'), 'numpy') (('px px 8 layer 10 0 1 2 5 7 9 Hidden dimension', 'Instantiate Model Class 28 28 image'), 'input_dim') (('linear regression Detailed tutorial', 'part Regression'), 'need') (('model', 'training'), 'prediction') (('We', 'convolutional layer'), 'apply') (('we', 'nn'), 'everythink') (('it', 'hyper parameter'), 'be') (('where gradients', 'backpropagation'), 'have') (('I', 'network Neural Network tutorial https neural www'), 'explain') (('We', 'CNN logistic model'), 'combine') (('we', 'gradients'), 'need') (('Convolutional Neural CNN CNN', 'well images'), 'Network') (('almost you', 'epoch number'), 'be') (('We', 'batch same size epoch numbers'), 'use') (('you', 'output'), 'list') (('We', 'torch'), 'examine') (('almost 85 model', 'training'), 'prediction') (('It', 'python docker image https kaggle github'), 'com') (('Filter kernel out_channels 16 size', 'feature map'), 'be') (('Forward propagation', 'labels store Total loss'), 'train') (('first I', 'optimization loss function'), 'know') (('Therefore we', 'model'), 'need') (('I', 'wrapping tensors'), 'be') (('better almost 95', 'regression logistic model'), 'thank') (('neural network', 'here only pytorch'), 'say') (('parts', 'CNN'), 'be') (('it', 'tensor shape array'), 'be') (('It', 'dataset'), 'provide') (('336 that', 'quota'), 'train') (('pytorch matrix array', 'Pytorch Matrices'), 'com') (('Instantiate Loss Cross entropy It', 'it'), 'loss') (('We', 'variables'), 'make') (('Linear Pytorch libraries', 'class super function'), 'collect') (('we', 'previous part'), 'Network') (('80', 'test data'), 'use') (('we', 'fact'), 'be') (('I', 'numpy'), 'rand') (('car price', 'car'), 'be') (('it', 'end'), 'be') (('linear regression logistic function softmax logistic regression', 'learning deep tutorial'), 'check') (('It', 'it'), 'loss') (('we', 'hidden layer'), 'need') (('you', 'network neural basics'), 'con') (('However we', 'original image'), 'want') (('We', 'classification'), 'use') (('Convolutional layer', 'filters kernels'), 'create') "}
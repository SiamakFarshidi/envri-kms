{"name": "own build model ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "ReduceLROnPlateau to monitor learning rate3. Modelcheckpoint to save best weights of model and monitor the val_loss2. Display Few Samples with labels Set random seed we set the random seed for numpy and tansorflow to get reproducible result each time when we run Building Model for model construction we use keras with tensorfolw backend We use the vgg16 like architecture Two convolutional layers and one maxpooling 2x2 with strides of 2x2 to extract features We create 5 blocks of feature extraction and at last 2 pooling layer we change the strides to 3x3 We apply a flatten to make vector for dense layer After that we use 2 dense layers with 512 and 64 density respectively At final layer we use softmax activation with density of 2 to pridect Model compilation we use Adam optimizer with learning rate of 1e 4 and loss categorical_crossentropy list of callbacks 1. Earlystopping to stop training while model not learning furthure Training we use batch size of 32 and runs for 50 epochs Plot the model history to verify model Save best Model weights and load best wieghts Evaluating of Model Model Prediction Classification Reports ROC curve and ROC AUC Score This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. 0001 cooldown 5 min_lr 0. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. read_csv Input data files are available in the. after that we convert list to numpy array for fast processing. 0001 probably needs to be more patient but kaggle time is limited summarize history for accuracy summarize history for loss Original labels Get the confusion matrix Calculate Precision and Recall. config the session Set the seed for hash based operations in python Set the numpy seed Set the random seed in tensorflow at graph level block 2 block 3 block 4 reduceLROnPlat ReduceLROnPlateau monitor val_loss factor 0. we read the image using opencv labrary and then resize the image to 224x224 using inter_cubic interpolation. Also we use keras utils to convert labels into categorical labels. 8 patience 10 verbose 1 mode auto epsilon 0. Preprocessing Data The data are not well splite so we gather all data in one numpy array and then using sklearn library to split data in train and test 80 training data and 20 test data with equal distribution of each classes. For example running this by clicking run or pressing Shift Enter will list all files under the input directory Any results you write to the current directory are saved as output. ", "id": "uzairshahmdn/own-build-model", "size": "1691", "language": "python", "html_url": "https://www.kaggle.com/code/uzairshahmdn/own-build-model", "git_url": "https://www.kaggle.com/code/uzairshahmdn/own-build-model", "script": "mlxtend.plotting classification_report train_test_split keras seed model to_categorical LearningRateScheduler confusion_matrix numpy Adam glob layers keras.callbacks plot_confusion_matrix roc_auc_score keras.optimizers tensorflow ReduceLROnPlateau random matplotlib.pyplot ModelCheckpoint backend sklearn.model_selection pandas EarlyStopping roc_curve Model keras.utils sklearn.metrics ", "entities": "(('Also we', 'categorical labels'), 'use') (('we', 'inter_cubic interpolation'), 'read') (('we', 'fast processing'), 'convert') (('well so we', 'classes'), 'preprocesse') (('we', 'callbacks'), 'display') (('probably more patient limited history', 'confusion matrix Calculate Precision'), 'need') (('reduceLROnPlat 2 3 block 4 ReduceLROnPlateau', 'graph level block'), 'config') (('you', 'output'), 'list') (('It', 'python docker image https kaggle github'), 'earlystoppe') (('read_csv Input data files', 'the'), 'be') "}
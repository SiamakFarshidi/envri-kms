{"name": "rukshar skin cancer ", "full_name": " h1 Automated Classification of Skin Lesions h1 Making Dictionary of images and labels h1 Data Processing h1 Data Imputation h1 Data Visualization h1 Image Data Preparation for Training h1 Train Test Split h1 Normalization h1 Label Encoding h1 Creating a Validation Dataset h2 Data Augmentation h1 Model Building h2 CNN h2 Setting Optimizer and Annealer h2 Metrics of Performance h2 Callbacks Learning Rate Adapter Early Stopping Checkpointing h1 Model Training and Evaluation h3 Loading a Saved Model if any h3 Training from Scratch h2 Filter Visualization h2 Feature Map Visualization h1 Conclusion h2 Statement of Purpose h3 Acknowledgements ", "stargazers_count": 0, "forks_count": 0, "description": "Metrics of PerformanceIn order to measure how our model performs we use the following metrics Accuracy Validation Loss Precission Recall F1 ScoreTo learn more about multi class precision recall and f1 score the following article is a good read https towardsdatascience. e the area size pooled each time more the pooling dimension is high more the downsampling is important. Chosen methods of data augmentation Randomly rotate some training images by 10 degrees Randomly Zoom by 10 some training images Randomly shift images horizontally by 10 of the width Randomly shift images vertically by 10 of the height Once our model is ready we fit the augmented training dataset. Normalizing the data generally speeds up learning and leads to faster convergence. The higher the LR the bigger are the steps and the quicker is the convergence. This kernel includes Data imputation Exploratory Data Analysis Data Processing for training splitting data into training testing and validation sets normalization and augmentation Model building Model training and evaluation Visualization of filters Making Dictionary of images and labelsIn this step I have made the image path dictionary by joining the folder path from base directory base_skin_dir and merge the images in jpg format from both the folders HAM10000_images_part1. However high LR causes oscillations in loss reductions and the optimizer can fall into a local minima. Creating a Validation DatasetDuring training we want to observe how the model performs on unseen data. of filters and dropout rate dense_layer_no how many dense layers you want dense_layer_desc description of each dense layer namely no. The second important layer in CNN is the pooling MaxPool2D layer. The LR is the step by which the optimizer walks through the loss landscape. The rectifier activation function is used to add non linearity to the network. Basal cell carcinoma 5. So we create another dataset from the training data called validation data. As we go deeper into the network we get to explore more general features of image data. Plotting the distribution of localization field The most compromised regions of skin cancer are back 22 lower extremity 21 trunk 14 However no one part of the body dominates the chart. The Flatten layer is use to convert the final feature maps into a one single 1D vector. For multiclass classifications 2 classes this model uses categorical_crossentropy loss func. Here 75x100 is the image dimension and 1 is batch size. In the last layer Dense 10 activation softmax the net outputs distribution of probability of each class. zip and HAM10000_images_part2. The expectation would be that the feature maps close to the input detect small or fine grained detail whereas feature maps close to the output of the model capture more general features. The CNN can isolate features that are useful everywhere from these transformed images feature maps. layers for each conv. They applied the consensus label only if both authors independently gave the same unequivocal benign diagnosis. Now check the distribution of AgeFrom the given data people in below 30 are at lower risk of getting skin diseases as compared with people whose age is above 35. Follow up If nevi monitored by digital dermatoscopy did not show any changes during 3 follow up visits or 1. We have to choose the pooling size i. Some popular augmentations are grayscales horizontal flips vertical flips random crops color jitters translations rotations and much more. Model Training and Evaluation Loading a Saved Model if any Training from ScratchNow that our model class has been defined we can feed our data into the model for training and observe the performance through loss accuracy vs. By applying just a couple of these transformations we can create a very robust model. The optimizer iteratively improves parameters filters kernel values weights and bias of neurons to reduce loss. Setting Optimizer and AnnealerAfter adding layers to the model we need a score function a loss function and an optimisation algorithm. Dermatofibroma We detect 7 different classes of skin cancer using NN and analyse the result to see how the model can be useful in practical scenario. 3 meaning most samples are examined by dermatologists. The idea of visualizing a feature map for a specific input image would be to understand what features of the input are detected or preserved in the feature maps. layers save layer number for conv. It s suffice to say the skin diseases are spread throughout the body. Melanocytic nevi 2. callbacks the LR is halved if accuracy fails to improve after 3 epochs. Additionally we perform EDA visualize model metrics loss accuracy recall precision f1 score filters and feature maps for an input image. of neurons and dropout rate patience how many epochs should the model run if there is no improvement in the metrics example of format for conv_layer_desc and dense_layer_desc are given in the default initialization below how many epochs to run the model before stopping due to accuracy not improving define architecture of the model CNN architechture is In Conv2D relu 2 MaxPool2D Dropout 2 Flatten Dense Dropout Out first layer Define the optimizer Compile the model Set a learning rate annealer simple early stopping create the callback list for Keras model Fit the model summarize history for accuracy summarize history for loss Function to plot confusion matrix Predict the values from the validation dataset Convert predictions classes to one hot vectors Convert validation observations to one hot vectors compute the confusion matrix plot the confusion matrix i uploaded the pretrained model here loading the saved model the output is a dictionary whose format layer_name filter_shape filter_data adding this to conv. That would be a better representation of data. Choose colormap of your taste Add title and labels with custom font sizes Checking the image size distribution Perform one hot encoding on the labels Reshape image in 3 dimensions height 75px width 100px canal 3 With data augmentation to prevent overfitting set input mean to 0 over the dataset set each sample mean to 0 divide inputs by std of the dataset divide each input by its std apply ZCA whitening randomly rotate images in the range degrees 0 to 180 Randomly zoom image randomly shift images horizontally fraction of total width randomly shift images vertically fraction of total height randomly flip images randomly flip images explanation of some of the class arguments conv_layer_no how many conv. Let s see how many rows don t have age data. We plot 16 2 dimensional feature map images in a 4x4 setting. Benign keratosis like lesions 4. of filters of that conv. Root Mean Square Propagation RMSProp that also maintains per parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight e. Now lets visualize agewise distribution of skin cancer typesIt seems that skin cancer types 0 1 3 and 5 which are Melanocytic nevi dermatofibroma Basal cell carcinoma and Vascular lesions are not much prevalant below the age of 20 years Image Data Preparation for TrainingIn this step images will be loaded into the column named image using the image path and the image folder. Histopathology Histo Histopathologic diagnoses of excised lesions have beenperformed by specialized dermatopathologists. Checkpointing is used alongside early stopping to save the best model weights for later use. how quickly it is changing. For this purpose the training set is divided in two parts a small fraction 10 became the validation set on which the model is evaluated and the rest 90 is used to train the model. The original dimension of the images are 450 x 600 x3 which TensorFlow can t handle and so the images are resized to 100 x 75. epoch plots confusion matrix and other metric scoresNot only training stabilizes to a plateau after training for at least 80 epochs but also the oscillations of curves become less due to our adaptive learning rate mechanism that reduces LR after some epochs Filter VisualizationBefore visualizing the filters let s create a method to load and save filter names shapes filter dataRunning the example creates a figure with six rows of three images or 18 images one row for each filter and one column for each channelThe dark squares indicate small or inhibitory weights and the light squares represent large or excitatory weights. Adam optimizer a popular optimizer achieving satisfactory results fast combines advantages of 2 other extensions of stochastic gradient descent. This means it s better to fill the missing age values using median belonging to that datapoint s median value. Label EncodingFor multiclass classification the labels of 7 different classes of skin cancer types ranging from 0 to 6 need to be converted to one hot vectors. The next 2 largest numbers of cell types are Melanoma and Benign keratosis like lesions Plotting of Technical Validation field ground truth which is dx_type to see the distribution of its 4 categories which are listed below 1. This technique also improves generalization and reduces the overfitting. Using this intuition we can see that the filters detect gradients from light to dark. com sid321axn step wise approach cnn model 77 0344 accuracy used for converting labels to one hot encoding convert to one hot encoding. Actinic keratoses 6. Now lets check the presence of null values againOur data imputation step is complete. Data AugmentationIn order to avoid overfitting problem we artificially expand our HAM 10000 dataset by introducing transformations to produce the variations in the dataApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. It combines all the found local features of the previous convolutional layers. The first is the convolutional Conv2D layer a set of learnable filters. With the ReduceLROnPlateau function from Keras. Data VisualizationIn this we will explore different features of the dataset through visualizationsPlot to see distribution of 7 different classes of cell typeIts seems from the above plot that in this dataset more than 50 percent cells are of type Melanecytic nevi. It looks at the 2 neighboring pixels and picks the maximal value. Statement of Purpose The purpose of this notebook is to experiment with image datasets classification task visualizations and DNNs from existing literature and to showcase what I ve learned from other resources regarding the mentioned topics Acknowledgements https www. This means the algorithm does well on online and non stationary problems e. 5 years biologists accepted this as evidence of biologic benignity. Adaptive Gradient Algorithm AdaGrad maintains a per parameter learning rate that improves performance on problems with sparse gradients e. Model Building Before writing down the code for the class of neural network let s describe the features of our NN. natural language and computer vision problems. For example some highlight lines other focus on the background or the foreground. Dropout is a regularization method where a proportion of nodes in the layer are randomly ignored thus forcing the network to learn features in a distributed way. Confocal Reflectance confocal microscopy is an in vivo imaging technique with a resolution at near cellular level and some facial benign with a grey world assumption of all training set images in Lab color space beforeand after manual histogram changes. input skin cancer mnist ham10000 Merging images from both folders HAM10000_images_part1. This flattening step is needed so that you can make use of fully connected layers after some convolutional maxpool layers. Lets see the distribution of males and femalesBoth men and women seem to get affected by skin diseases nearly equally with men being infected somewhat more. layers you want conv_layer_desc descriptoion of each conv. So the age column has 57 null values. Only nevi but no other benign diagnoses were labeled with this type of ground truth because dermatologists usually do not monitor dermatofibromas seborrheic keratoses or vascular lesions. Automated Classification of Skin Lesions Automated classification of skin lesions using images is a challenging task owing to the fine grained variability in the appearance of skin lesions. Each filter transforms a part of the image defined by the kernel size using the kernel filter. To get the feature maps we input a processed image taken from x_train x_valid x_test in the newly defined sub model and the result will be a feature map with dimensions 1 75 100 no. We group the age values according to the skin disease type determine the median of each group and fill the null values with the median value corresponding to that data points skin disease type. These are used to reduce computational cost and to some extent also reduce overfitting. because this is needed when visualizing feature maps for an input image filter shape 3 3 channel filter_number 3x3 filter size normalize filter values to 0 1 so we can visualize them this method plots x number of filters with y number of channels in each row get the filter plot each channel separately specify subplot and turn of axis plot filter channel in grayscale show the figure shows layer info name filter shape of all layers of input model save conv. layer visualize some feature maps. Loss function is the error rate between the oberved labels and the predicted ones and measures how poorly a model performs on data with known labels. filter info in a dictionary format it also prints some info about the model layer name layer number used later for feature maps and filter shapes of the format kernel size channel filter no. Consensus For typical benign cases without histopathology or followup biologists provide an expert consensus rating of authors PT and HK. Lesions with this type of groundtruth were usually photographed for educational reasons and did not needfurther follow up or biopsy for confirmation. zip Data ProcessingIn this step we have read the csv by joining the path of image folder which is the base folder where all the images are placed named base_skin_dir. Feature Map VisualizationThe activation maps called feature maps capture the result of applying the filters to input such as the input image or another feature map. layer of a model and create feature map images for an input image layer number for conv. It consists of 10015 dermatoscopic images which are released as a training set for academic machine learning purposes It has 7 different classes of skin cancer which are listed below 1. Filters can be seen as a transformation of the image. Majority of technical validation is of the type Histopathology 53. At first we define a method to create a model from the previously trained model where the output is the layer output feature maps we wish to visualize. The kernel filter matrix is applied on the whole image. People in their 40s seem to be at the greatest risk. Additionally early stopping mechanism will allow the model to stop training if there s no improvement after certain number of epochs to save time and prevent overfitting. layer the img parameter representing input image must be of a preprocessed form with dimensions 75 100 3 the input shape to the original model specify subplot and turn of axis plot filter channel in grayscale show the figure this method traverses each conv. The next largest category is follow up 37 meaning Melanocytic Nevi being further checked upon to ensure its benignity. plot first few filters layer name you can find layer names model_filters model_filters dictionary containing filter weights x number of filters to plot y number of channels for each filter to plot layer output parameter output layer is the layer chosen for output method to visualize feature map from a particular conv. Combining convolutional and pooling layers CNN are able to combine local features and learn more global features of the image. CNNKeras Sequential API is used where we add one layer at a time starting from the input. To keep the advantage of the fast computation time with a high LR LR is dynamically reduced every X steps epochs if validation accuracy doesn t improve. We can see that the result of applying the filters in a convolutional layer is a lot of versions of the an image with different features highlighted. Classification of skin diseases here involves utilizing the HAM10000 Human Against Machine with 10000 training images dataset. So let s check out the median value of age per skin disease typeDifferent median ages for different skin diseases. com multi class metrics made simple part i precision and recall 9250280bddc2 Callbacks Learning Rate Adapter Early Stopping Checkpointingfor faster optimizer convergence and reaching global minimum of the loss function an annealing method of the learning rate LR is used. We create additional columns for later reference path to image file cell_type which contains the short name of lesion type categorical column cell_type_idx the lesion type is categorized from 0 to 6 Data ImputationIn this step we check for Missing values and impute the missing dataThere are some age data missing. Since there are above 10k images it ll take some time to process all of them into the dataframeWe can see image column has been added in its color format codeLet s check out a sample of 5 images from each cancer typeLet s separate the features from the target variable Train Test SplitThe data is into training and testing with a 80 20 ratio NormalizationThe x_train x_test data are normalized by substracting mean values and then dividing by standard deviations. So decreasing learning rate can help training to reach the global minimum of the loss function. relu is the rectifier activation function max 0 x. zip into one dictionary This dictionary is useful for displaying more human friendly labels later on Creating New Columns for better readability Now lets see the sample of tile_df to look on newly made columns it MUST be integer Good old loop. Vascular lesions 7. This layer simply acts as a downsampling filter. ConclusionIn this notebook we process skin disease dataset and feed it into a customizable neural network CNN with early stopping and checkpointing mechanism. ", "id": "mdruksharalam/rukshar-skin-cancer", "size": "15422", "language": "python", "html_url": "https://www.kaggle.com/code/mdruksharalam/rukshar-skin-cancer", "git_url": "https://www.kaggle.com/code/mdruksharalam/rukshar-skin-cancer", "script": "classification_report keras.layers keras.models train_test_split create_model plot_filter_w_channel plot_confusion_matrix_util keras confusion_matrix load_filters load_saved_model label_binarize keras.utils.np_utils Image numpy keras.preprocessing.image seaborn Adam Dropout tensorflow.keras.metrics visualize_all_conv_feature_maps ImageDataGenerator BatchNormalization Dense glob Custom_NN backend as K build_model keras.layers.normalization keras.callbacks MaxPool2D plot_confusion_matrix keras.optimizers ReduceLROnPlateau show_all_layer_info matplotlib.pyplot ModelCheckpoint Sequential backend PIL evaluate_model sklearn.model_selection pandas plot_model_history EarlyStopping Conv2D Model missingno to_categorical # convert to one-hot-encoding fit_model visualize_feature_map to_categorical # used for converting labels to one-hot-encoding __init__ sklearn.metrics Flatten sklearn.preprocessing ", "entities": "(('model', 'categorical_crossentropy loss func'), 'use') (('multiclass labels', 'one hot vectors'), 'need') (('It', 'maximal value'), 'look') (('notebook we', 'mechanism'), 'conclusionin') (('which', '1'), 'be') (('We', '4x4 setting'), 'plot') (('activation rectifier function', 'network'), 'use') (('optimizer', 'loss landscape'), 'be') (('Checkpointing', 'later use'), 'use') (('We', 'data points skin disease type'), 'group') (('accuracy', '3 epochs'), 'callback') (('technique', 'overfitting'), 'improve') (('format layer_name filter_shape filter_data', 'conv'), 'run') (('it', 'newly made columns'), 'zip') (('method', 'conv'), 'be') (('it', 'filter format kernel size channel filter'), 'print') (('light squares', 'large weights'), 'training') (('learning So decreasing rate', 'loss function'), 'help') (('Lesions', 'needfurther confirmation'), 'photograph') (('horizontal vertical flips', 'crops color jitters translations rotations'), 'be') (('s', 'NN'), 'Building') (('optimizer', 'local minima'), 'cause') (('figure', 'input model save conv'), 'need') (('optimizer', 'gradient stochastic descent'), 'combine') (('That', 'better data'), 'be') (('data', 'generally faster convergence'), 'speed') (('that', 'data augmentation techniques'), 'order') (('back 22 lower extremity 21 trunk However one part', 'chart'), 'plot') (('that', 'gradients sparse e.'), 'maintain') (('Flatten layer', '1D one single vector'), 'be') (('features', 'feature maps'), 'be') (('Majority', 'type'), 'be') (('filters', 'dark'), 'see') (('step images', 'image path'), 'seem') (('we', 'training augmented dataset'), 'rotate') (('you', 'maxpool convolutional layers'), 'need') (('layer names model_filters model_filters', 'particular conv'), 'plot') (('base where images', 'image folder'), 'ProcessingIn') (('image path', 'HAM10000_images_part1'), 'include') (('how model', 'practical scenario'), 'detect') (('vertically fraction', 'how many conv'), 'colormap') (('Consensus', 'authors'), 'provide') (('how model', 'unseen data'), 'create') (('only authors', 'independently same unequivocal benign diagnosis'), 'apply') (('dermatologists', 'dermatofibromas seborrheic usually keratoses'), 'label') (('filter', 'kernel filter'), 'transform') (('predicted how poorly model', 'known labels'), 'be') (('dropout how many dense you', 'dense layer'), 'dense_layer_no') (('don t', 'age data'), 'let') (('percent more than 50 cells', 'type Melanecytic nevi'), 'VisualizationIn') (('Combining', 'image'), 'be') (('X steps validation accuracy dynamically doesn', 'LR high LR'), 'reduce') (('NormalizationThe x_test data', 'then standard deviations'), 'be') (('result', 'feature dimensions'), 'no') (('that', 'images feature everywhere transformed maps'), 'isolate') (('kernel filter matrix', 'whole image'), 'apply') (('you', 'conv'), 'layer') (('second important layer', 'CNN'), 'be') (('f1 following article', 'class precision multi recall'), 'be') (('skin diseases', 'body'), 's') (('age', '35'), 'be') (('first', 'Conv2D convolutional learnable filters'), 'be') (('which', '1'), 'consist') (('feature maps', 'model capture'), 'be') (('we', 'image data'), 'get') (('nearly equally men', 'skin diseases'), 'see') (('Histopathology Histo Histopathologic diagnoses', 'specialized dermatopathologists'), 'beenperforme') (('where we', 'input'), 'use') (('Melanocytic 37 Nevi', 'further benignity'), 'follow') (('So we', 'training data'), 'create') (('So s', 'skin different diseases'), 'let') (('result', 'different features'), 'see') (('most samples', 'dermatologists'), 'mean') (('layer output feature we', 'previously trained model'), 'define') (('years 5 biologists', 'biologic benignity'), 'accept') (('optimizer', 'loss'), 'improve') (('I', 'topics Acknowledgements https mentioned www'), 'Statement') (('These', 'also overfitting'), 'use') (('we', 'very robust model'), 'create') (('model', 'overfitting'), 'allow') (('Additionally we', 'feature input image'), 'perform') (('it', 'median value'), 'mean') (('so images', '100 75'), 'be') (('we', 'loss function'), 'set') (('algorithm', 'problems well online stationary e.'), 'mean') (('Filters', 'image'), 'see') (('layer', 'downsampling simply filter'), 'act') (('that', 'weight e.'), 'rmsprop') (('regularization where proportion', 'distributed way'), 'be') (('90', 'model'), 'become') (('age data', 'missing dataThere'), 'create') (('classification', 'skin lesions'), 'be') (('nevi', 'visits'), 'follow') (('data imputation againOur step', 'null values'), 'check') (('It', 'previous convolutional layers'), 'combine') (('People', 'greatest risk'), 'seem') (('confocal microscopy', 'histogram manual changes'), 'be') (('training 10000 images', 'Machine'), 'involve') (('annealing method', 'learning rate LR'), 'make') (('we', 'loss accuracy'), 'Loading') "}
{"name": "mini project cancer detection ", "full_name": " h3 ROC curve and AUC h2 Remember AUC is the metric that is used for evaluating submissions We can calculate it here for ou validation set but it will most likely differ from the final score h1 Submit predictions h3 TTA h3 Submit the model for evaluation h2 We need to submit the tumor probability for each test sample in this competition The probability ranges from 0 to 1 h1 Deploy example ", "stargazers_count": 0, "forks_count": 0, "description": "Official documentation https docs. The augmentations used for this data random rotation random crop random flip horizontal and vertical both random lighting We use OpenCV with image operations original size of the images AUGMENTATION VARIABLES final size after crop range 0 180 180 allows all rotation variations 0 no change center crop shift in x and y axes 0 no change. csv and keep their original order List of tumor preds. The predictions are then averaged. We could deploy this for inference to another machine a web server for example. For this we need our saved model and then we need to export the DataBunch. Image file descriptors Description Format TIF Size 96 x 96 Channels 3 Bits per channel 8 Data type Unsigned label statistics Plot some images with and without cancer tissue for comparison OpenCV reads the image in bgr format by default We flip it to rgb for visualization purposes random sampling Negatives Create a Rectangle patch Positives Create a Rectangle patch label of the image is influenced only by the center region 32 x 32px crop data to that region only. Export to csv This is what the first 10 items of submission look like This will create an export. On a new machine We need to create an empty DataBunch and load it to a learner. We can calculate it here for ou validation set but it will most likely differ from the final score. Deploy example Now that we have a working model. Submit predictions TTATo evaluate the model we run inference on all test images. I haven t tried these so I cannot guarantee these will work straight away. 0 import all the models from torchvision specify model input size is the crop size this will extrat the model name as the model file name create test dataframe This ndarray image has to be converted to tensor before passing on as fastai Image we can use pil2tensor Create ImageDataBunch using fastai data block API Where to find the data How to split in train valid Where are the labels dataframe pointing to the test set We have our custom transformations implemented in the image loader but we could apply transformations also here Even though we don t apply transformations here we set two empty lists to tfms. These are means and std s of each three channel and we calculated these previously in the stats step. The probability ranges from 0 to 1. These are in the order of our test dataset and not necessarily in the same order as in sample_submission To know the id s we create a dict of id pred Now we can create a new list with the same order as in sample_submission Next a Pandas dataframe with id and label columns. Next we will transform class probabilities to just tumor class probabilities If we wanted to get the predicted class argmax would get the index of the max get test id s from the sample_submission. This function will convert image to the prediction format crop to center to the correct size and convert from 0 255 range to 0 1 range. This saves the internal information classes etc need for inference in a file named export. This cannot be more than ORIGINAL_SIZE CROP_SIZE 2 range 0 100 0 no change range 0 100 0 no change 0 or 1 random turn to left or right OpenCV reads the image in bgr We flip it to rgb for visualization purposes random rotation the center point is the rotation anchor random x y shift crop to center and normalize to 0 1 range Random flip Random brightness Random contrast clip values to 0 1 range Negatives Positives To see the effects of our augmentation we plot one image multiple times. As we have test time augmentation our results will probably improve if we do predictions multiple times per image and average out the results. Submit the model for evaluationWe need to submit the tumor probability for each test sample in this competition. pkl file that you ll need to copy with your model file if you want to deploy it on another device. Negatives Baseline model Fastai v1 min viable model the simplest accepted model Prepare the data and split train Split train data to 90 training and 10 validation parts. ROC curve and AUCRemember AUC is the metric that is used for evaluating submissions. This shows the activation maps of the predicted category so if the label is tumor the visualization shows all the places where the model thinks the tumor patterns are. Train and Validation augmentations convert to databunch Normalize with training set stats. reset learner Plot weight decays ax ranges may need some tuning with different model architectures predict the validation set with our model save the model at this stage Save the finetuned model get accuracy top losses will return all validation losses and indexes sorted by the largest first Random Most incorrect or top losses Most correct or least losses hook into forward pass we hook into the convolutional part m 0 of the model We can create a utility function for getting a validation image with an activation map this gets the model create a batch from the one image convert batch tensor image to grayscale image with opencv attach hooks get convolutional activations and average from channels Grad CAM Then modify our plotting func a bit top losses will return all validation losses and indexes sorted by the largest first Random Most incorrect or top losses Most correct or least losses probs from log preds Compute ROC curve Compute ROC area make sure we have the best performing model stage loaded Fastai has a function for this but we don t want the additional augmentations it does our image loader has augmentations so we just use the get_preds We do a fair number of iterations to cover different combinations of flips and rotations. You may need to do some debugging. ", "id": "smithstrivedi17it/mini-project-cancer-detection", "size": "1318", "language": "python", "html_url": "https://www.kaggle.com/code/smithstrivedi17it/mini-project-cancer-detection", "git_url": "https://www.kaggle.com/code/smithstrivedi17it/mini-project-cancer-detection", "script": "fastai.vision plot_heatmap_overview torchvision.models open train_test_split *=all the models from torchvision plot_overview sklearn.utils numpy getHeatmap getLearner fastai.callbacks.hooks randint tqdm_notebook tqdm fastai matplotlib.patches auc random matplotlib.pyplot hooked_backward shuffle sklearn.model_selection pandas roc_curve imageToTensorImage readImage MyImageItemList(ImageList) readCroppedImage sklearn.metrics * # fastai 1.0 ", "entities": "(('Negatives Baseline model', '90 training'), 'prepare') (('we', 'test images'), 'evaluate') (('we', 'one image'), 'be') (('probably we', 'results'), 'improve') (('Train augmentations', 'training stats'), 'convert') (('Now we', 'working model'), 'deploy') (('you', 'device'), 'file') (('We', 'example'), 'deploy') (('then we', 'DataBunch'), 'need') (('we', 'stats previously step'), 'be') (('i', 'sample_submission'), 'transform') (('function', '0 1 range'), 'convert') (('We', 'learner'), 'need') (('We', 'flips'), 'need') (('Rectangle patch label', 'crop 32 32px region'), 'plot') (('I', 'these'), 'try') (('it', 'most likely final score'), 'calculate') (('This', 'export'), 'be') (('AUCRemember that', 'submissions'), 'be') (('here we', 'two empty lists'), 'import') (('rotation variations', 'change center crop 0 x'), 'flip') (('etc', 'file'), 'save') (('Now we', 'i d columns'), 'be') (('tumor patterns', 'places'), 'show') "}
{"name": "mlops tutorial xgboost with w b ", "full_name": " h1 Setup and Imports h1 Load Dataset h4 Utils h1 Prepare Train Validation Split h1 Features h1 Train a naive XGBRegressor on one crypto data h1 So Far h2 Check out the W B Dashboard h1 XGBRegressor as Multi Output Regressor h1 WORK IN PROGRESS ", "stargazers_count": 0, "forks_count": 0, "description": "For a competition that runs for months a good data version control can make a huge difference. We will take the crypto data of Bitcoin fill the missing gaps in the series compute features for train and validation splits. High Highest price reached during time interval in USD. Since we have used the training and validation split and are going to train the model on a subset of the data we should log the subset as W B artifacts. We will use Sklearn s MultiOutputRegressor. Now finally let s train a simple regression and use W B s XGBoost Callback to log the metrics and configs. Open Opening price of the time interval in USD. Low Lowest price reached during time interval in USD. You might want to repeat this for different splits of the raw dataset. Train the regressor. Here we will log the raw dataset as W B Artifacts to build data lineage as we train models and validate on different split of the dataset. Upcoming Extend the regression for the entire dataset. This will act as reference for this split. If you have any questions feel free to comment or reach out. Asset_ID The asset ID corresponding to one of the crytocurrencies e. Use a quarter worth of data and forecast for one month ahead. Note the use of wandb_callback Get the booster Save the booster to disk Get the booster s config Notice the use of earlier artifact as reference for model artifact select training and test periods 86400 corresponds to one day 24 hrs in seconds. Setup and ImportsWeights and Biases comes preinstalled with Kaggle environment but it s recommended to get the latest version of the same. Volume Quantity of asset bought or sold displayed in base currency USD. Imagine you are training tons of models on different splits of the same dataset. This tutorial is based on Tutorial Time Series forecasting with XGBoost https www. This notebook can be considered a tutorial on how to use XGBoost for this competition and use Weights and Biases to make the most out of your XGBoost model. Taking the extra effor to build an MLOps pipeline around the same can be really useful in the long run. The step below might take some time since a large csv file is being written on the disk. We will then initalize a W B run and train an XGBRegressor with default parameters. The config below is for demonstration purposes. Get single crypto trading data Get the windowed data Fill missing value Get single crypto trading data Get the windowed data Fill missing value Create features define the direct multioutput model and fit it. Note however that this strategy doesn t use any dependence between different targets. Asset_ID 1 for Bitcoin. com cstein06 tutorial to the g research crypto competition. ai ayush thakur gresearch workspace user ayush thakur The image below shows the data and model lineage created so far. VWAP The average price of the asset over the time interval weighted by volume. Let s first start by initializing a W B run and use the split artifact reference that we logged previously. The mapping from Asset_ID to crypto asset is contained in asset_details. Later in this notebook we will try to find the best parameters. timestamp All timestamps are returned as second Unix timestamps the number of seconds elapsed since 1970 01 01 00 00 00. Again this is a one time process. Timestamps in this dataset are multiple of 60 indicating minute by minute data. VWAP is an aggregated form of trade data. This might be an additional step but can be really useful to have in your arsenal. We will again save the splits as W B Artifact and use the reference to the previously logged raw data to build the data lineage. Let s save the model along with model configuration. png XGBRegressor as Multi Output RegressorIn this section we will take in the trading data for one quarter 3 months and try to forecast the returns for the 4th month. Let s see how things go. Load DatasetIf you haven t already check out the Tutorial to the G Research Crypto Competition https www. First let s build our train and valid dataset for one quarter. Not sure how exactly Show how to use W B Sweeps for Hyperparameter Optimization. Here we will log the features dataframe for better sanity check in the future. Note This is a one time step. Close Closing price of the time interval in USD. The following are the columns available in the train. Plus if you think it can be improved further please let me know. Features Fill NaN values Fill Inf values Build features Concat all the features into one dataframe Rename feature columns Fill NaN and Inf Fill NaN and Inf Initialize a W B run Get single crypto trading data Fill missing value Create features Initialize a W B run Initialize an XGBRegressor with some parameters. I will be using this valid_df for evaluating all my models. png The image shown below is the logged metrics. So FarSo far we built a data and model lineage and used wandb_callback for XGBoost. Using wandb_callback is like using a single line of code to keep a tab of your experiments. Target Residual log returns for the asset over a 15 minute horizon. Once you have logged your raw_data you just need to log different splits of the same or preprocessed data. We will use the data from WORK IN PROGRESSI hope you will find it useful. if you encounter a year is out of range error the timestamp may be in milliseconds try ts 1000 in that case Notice the use of raw_artifact. Utils Prepare Train Validation SplitNote that I have used the data that s used for LB score computation as valid_df. Features Train a naive XGBRegressor on one crypto dataIn this section we will train an XGBRegressor which is an implementation of the scikit learn API for XGBoost regression. Check out the W B Dashboard https wandb. Let s prepare the features for just Bitcoin trading data. com robikscube tutorial time series forecasting with xgboost by Rob Mulla https www. Count Total number of trades in the time interval last minute. We will use the data lineage created so far and start building model lineage on top of it. ", "id": "ayuraj/mlops-tutorial-xgboost-with-w-b", "size": "5301", "language": "python", "html_url": "https://www.kaggle.com/code/ayuraj/mlops-tutorial-xgboost-with-w-b", "git_url": "https://www.kaggle.com/code/ayuraj/mlops-tutorial-xgboost-with-w-b", "script": "wandb_callback create_features plot_importance xgboost numpy timestamp_to_utc wandb.xgboost plot_tree fill_nan_inf mean_absolute_error tqdm log_return matplotlib.pyplot sklearn.multioutput pandas datetime MultiOutputRegressor utc_to_timestamp mean_squared_error upper_shadow sklearn.metrics lower_shadow ", "entities": "(('Taking', 'really long run'), 'be') (('So FarSo far we', 'XGBoost'), 'build') (('config', 'demonstration below purposes'), 'be') (('it', 'same'), 'preinstalle') (('s', 'model configuration'), 'let') (('we', 'that'), 'let') (('csv large file', 'disk'), 'take') (('Now finally s', 'metrics'), 'let') (('Fill Inf Fill Inf W B crypto trading Get single data', 'parameters'), 'value') (('Here we', 'future'), 'log') (('I', 'models'), 'use') (('Create features', 'it'), 'get') (('we', 'best parameters'), 'try') (('we', 'W B artifacts'), 'use') (('you', 'same data'), 'need') (('tutorial', 'Tutorial Time Series XGBoost https www'), 'base') (('mapping', 'asset_details'), 'contain') (('Target Residual', 'minute 15 horizon'), 'log') (('timestamp', 'raw_artifact'), 'be') (('asset ID', 'e.'), 'asset_id') (('Volume Quantity', 'base currency USD'), 'buy') (('Timestamps', 'minute minute data'), 'be') (('notebook', 'XGBoost model'), 'consider') (('High Highest price', 'USD'), 'reach') (('we', 'dataset'), 'log') (('This', 'split'), 'act') (('that', 'valid_df'), 'SplitNote') (('We', 'it'), 'use') (('strategy however doesn', 'different targets'), 'note') (('section we', '4th month'), 'XGBRegressor') (('We', 'train splits'), 'take') (('We', 'MultiOutputRegressor'), 'use') (('you', 'same dataset'), 'imagine') (('second Unix', '01 00 00 00'), 'timestamp') (('We', 'data lineage'), 'save') (('it', 'PROGRESSI'), 'use') (('image', 'below data lineage'), 'ai') (('s', 'Bitcoin trading just data'), 'let') (('This', 'additional really arsenal'), 'be') (('which', 'XGBoost regression'), 'train') (('You', 'raw dataset'), 'want') (('We', 'default parameters'), 'initalize') (('following', 'available train'), 'be') (('data version good control', 'huge difference'), 'make') (('Using', 'experiments'), 'be') (('t', 'G Research Crypto Competition https www'), 'DatasetIf') (('use', '24 seconds'), 'note') (('Low Lowest price', 'USD'), 'reach') (('VWAP', 'trade aggregated data'), 'be') (('First s', 'one quarter'), 'let') "}
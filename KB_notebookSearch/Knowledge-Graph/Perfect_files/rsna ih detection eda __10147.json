{"name": "rsna ih detection eda ", "full_name": " h1 What is intracranial hemorrhage h2 Our goal h2 Table of contents h1 Prepare to start h1 Exploratory analysis h2 Sample Submission h2 Evaluation metric h2 Target distribution h3 Insights h2 Number of samples h1 Preprocessing dicom files h2 What is given by a dicom file h2 Why can t we see something without windowing h2 What is covered by raw pixel values h3 Insights h2 What does pixel spacing mean h2 The doctors windows h3 Insights h2 My custom window h3 Insights h2 The image shape h2 Where to go next ", "stargazers_count": 0, "forks_count": 0, "description": "Consequently we would introduce a source of variation that is not given by original HU units per image. In my current case can change as listdir choses file order at random it s 195 mm meaning 19. Let s explore if we are better by focusing on our own window size My custom window Ok let s setup our own window width and center The majority of centers is located between 30 and 40 HUs. In the description it s given that the log loss is first taken for each subtype s given an image id n l_ n s t_ n s cdot ln y_ n s 1 t_ n s cdot ln 1 y_ n s Then they seem to be added whereas the any subtype obtains a higher weight than the others l_ n sum_ s w_ s cdot l_ n s And finally this loss is averaged over all samples Loss frac 1 N cdot sum_ n l_ n Hopefully I got this right Interestingly the competition host has not provided the weights or did they. What is intracranial hemorrhage Hmm let s watch a video Thank you Armando I have no medical background and this was really great to understand the topic better Our goalWe are asked to predict the occurence and the subtype of intracranial hemorrhage. What does that mean We need to find it out Nonetheless the mode is located at 0 for all example raw pixel value arrays. still don t know what this means. com gzuidhof full preprocessing tutorial. Let s understand it given our extreme examples. The first value is the row spacing in mm that is the spacing between the centers of adjacent rows or vertical spacing. Evaluation metric The weighted multilabel logarithmic loss is used to score our model performance. But I don t know if we can be sure about it. Preprocessing dicom files dicom What is given by a dicom file dicomfile Why can t we see something without windowing aboutwindows What is covered by raw pixel values pixelarray What does pixelspacing mean pixelspacing The doctors windows docwindows My custom window customwindow The image shape imageshape Prepare to start Exploratory analysis Sample Submission We can clearly see that we have to make several predictions for one image id epidural subdural subarachnoid intraparenchymal intraventricular any this one indicates that at least one subtype is present hence it tells us if the patient has IH or not. Is it possible that this can change from stage 1 to stage 2 What about the test data Ok for stage 1 this holds as well. After windowing to a center of 40 and width of 150 we can t see the same nice patterns as for the min and the median cases. By windowing to the same window we can t see differences between the median and the min case. Consequently it s related to the physical distance. Insights Uhh Very bad Do you see it There are extreme outliers in the window widths and centers. Hence this is going to be an LB probing hyperparameter to keep in mind. Reading in the docs https dicom. This way we can compare if a fixed custom window size is better suited that individual doctor window sizes. I would say it s worth to add zooming as image augmentation technique to our workflow later. The second value is the column spacing in mm that is the spacing between the centers of adjacent columns or horizontal spacing. that hounsfield units are a measurement to describe radiodensity. This does not make sense I would have expected the doctos to focus on the brain tissue and we have already learnt that HU values are roughly between 8 70 in these cases. This is likely to correspond to air. If we would simply put 256 shades of grey into one window this would differ from patient to patient as the given window ranges are different. Target distribution We need the same for our test data later Insights The first image already shows that we will have much more zero occurences than positive target values. Hence we can compute the overall distance covered by one image width or height This is the true length in mm covered by our image. Then we can see that mode is located at 1000 HU of air. rsplit of pandas we are lucky and can easily load images given the id column What is given by a dicom file Why can t we see something without windowing I haven t worked often with dicom images so far so I still get confused why we have someting like window center width and rescale parameters. The example of a hemorrhage in the brain shows relevant HUs in the range of 8 70. So I decided to watch a video about understanding CT images. Given 2000 HU of one image 1000 to 1000 this means that 1 greyscale covers 8 HUs. I m expected that the dataset holds patients with varying true head sizes ranging from childrens to adults. Then I would like to setup a fixed window level and width that covers the majority of all window properties. It could also be an adult but zoomed out. You can speed up a bit if you like by starting at 7min Ok I learnt. But pixel values differ The image shape Ok it seems that most images are of shape 512x512. com ciods ct image image plane 00280030 All pixel spacing related Attributes are encoded as the physical distance between the centers of each two dimensional pixel specified by two numeric values. In contrast the widths of windows vary between 70 to 150 HUs. Prepare to start prepare 2. 6 times more training images than the test data. But we can transform the image to HU units by scaling with the slope and intercept. Consequently there can happen a change of 120 HUs unit our eye is able to detect an intensity change in the image. What do you think The doctors windows Taking a look at the dicom dataset again we can see that there is already a window center and width given for us. And in the maximum case it s 500 mm consequently 50 cm. But the resolution might differ from scan to scan even if patients show same head sizes. Insights The first extreme case seems to be faulty. Nonetheless our model should still be able to detect the different types of hemorrhage. Consequently we can set these values to 1000 air in HU without worries. com allunia rsna ih detection baselineHappy kaggling. Jackpot This was the first time for me I m sorry that this happend. The pixel spacing yields the mm of physical distance of one pixel. We won t be able to see important changes in the intensity to detect the hemorrhage. For this type we only have a few 1 of positive occurrences. Preprocessing dicom files Ok the filename is given by the ID_alphanum column. Let s try to understand the 2000 and 3000 cases of rescaled images Yeah Great We can see that both cases 2000 and 3000 correspond to the outside region ot cylindrical CT scanners. What does this mean for us It means that small heads do not automatically mean that this is a child. This is the reason why we have to focus 256 shades of grey into a small range window of HU units. What is covered by raw pixel values No If we browse through the dicom files we can see that this is not true. Have to learn how to keep complex stuff simple more concise and light weighted. For this purpose we have to make 6 decisions per image 5 subtypes and if there is an occurence any. Ok in this stage 1 we have almost 8. Furthermore we have seen such combinations of width and center in our doc_windows dataframe. Exploratory analysis explore Sample submission sample_submission Evaluation metric evaluate Target distribution targets Number of samples num_samples 3. It will be difficult to train a model that is robust enough and does not tend to overfit. Going into details of each subtype we can see that we have to deal with high class imbalance. To understand this part the following tutorial was extremely helpful for me https www. Thank you a lot Guido Zuidhof. Now let s setup a window that is centered at 30 and has a width of 80. What to do instead I would like to collect window centers and width of 1000 images to see the varity of doctos favorite windows. Table of contents1. WINDOW The level means where this window is centered. This would be close to the median for both cases. Number of samples Let s check whether this matches the number of train images we have Ok as expected. If you like to continue with the modelling part you can find it here https www. I reached the end of the kaggle kernel world by exceeding the maximum kernel length that can be displayed. Our eye can only detect 6 change in greyscale 16 shades of grey. Consequently our raw pixel values are not given as HU units. Let s see how different dicom datasets differ in the distribution of pixel array values Insights Crazy that we observe cases with 1000 and 2000. Where to go next The kernel had been much longer in the past but. Epidural is the worst case. What does pixel spacing mean When browsing through the dicom files we can see that a value called pixel spacing changes as well I don t know what that means but perhaps we can understand it by looking at some extremes. But what does that mean Was this done by a doctor who set the range to visualise the hemorrhage Is this important for our algorithm We should be very careful now. different tissues have different HUs. ", "id": "allunia/rsna-ih-detection-eda", "size": "10147", "language": "python", "html_url": "https://www.kaggle.com/code/allunia/rsna-ih-detection-eda", "git_url": "https://www.kaggle.com/code/allunia/rsna-ih-detection-eda", "script": "skimage.transform get_window_value train_test_split os preprocess_input as preprocess_vgg_16 IPython.display set_manual_window listdir numpy seaborn augmenters ResNet50 rescale_pixelarray keras.applications preprocess_input Sequence imgaug keras.applications.vgg16 matplotlib.pyplot preprocess_input as preprocess_resnet_50 resize pandas sklearn.model_selection VGG16 keras.utils HTML augmenters as iaa keras.applications.resnet50 ", "entities": "(('Where go', 'much longer past'), 'be') (('most images', 'shape'), 'differ') (('that', 'adjacent rows'), 'be') (('why we', 'HU units'), 'be') (('This', 'cases'), 'be') (('HU already values', '8 roughly between cases'), 'make') (('still why we', 'window center width'), 'be') (('that', 'image'), 'introduce') (('dataset', 'adults'), 'expect') (('logarithmic loss', 'model performance'), 'metric') (('perhaps we', 'extremes'), 'mean') (('Insights we', '1000'), 'let') (('it', 'maximum case'), 's') (('Consequently we', 'worries'), 'set') (('patient', 'IH'), 'preprocesse') (('Furthermore we', 'doc_windows dataframe'), 'see') (('cases', 'CT cylindrical scanners'), 'let') (('majority', '30 HUs'), 'let') (('1 this', 'stage'), 'be') (('we', 'slope'), 'transform') (('we', 'Ok'), 'let') (('example', '8 70'), 'show') (('window given ranges', 'patient'), 'differ') (('instead I', 'doctos favorite windows'), 'like') (('Nonetheless model', 'hemorrhage'), 'be') (('mode', 'air'), 'see') (('Exploratory analysis', 'samples'), 'explore') (('Consequently it', 'physical distance'), 's') (('understand', 'me https extremely www'), 'be') (('Nonetheless mode', 'pixel value example raw arrays'), 'mean') (('related Attributes', 'two numeric values'), 'ciod') (('that', '80'), 'let') (('it', 'extreme examples'), 'let') (('widths', '70 to 150 HUs'), 'vary') (('eye', 'image'), 'happen') (('This', 'image'), 'compute') (('we', 'positive occurrences'), 'have') (('that', 'model'), 'be') (('1 greyscale', '8 HUs'), 'mean') (('competition Interestingly host', 'they'), 'give') (('it', 'random'), 'change') (('even patients', 'head same sizes'), 'differ') (('that', 'adjacent columns'), 'be') (('automatically this', 'us'), 'mean') (('this', 'dicom files'), 'cover') (('We', 'algorithm'), 'do') (('pixel spacing', 'one pixel'), 'yield') (('eye', 'grey'), 'detect') (('that', 'window properties'), 'like') (('don we', 'it'), 'know') (('you', 'it'), 'find') (('that', 'kernel maximum length'), 'reach') (('it', 'workflow'), 'say') (('I', 'first me'), 'Jackpot') (('pixel Consequently raw values', 'HU units'), 'give') (('filename', 'ID_alphanum column'), 'preprocesse') (('already we', 'target positive values'), 'distribution') (('we', 'median'), 'see') (('com gzuidhof', 'full tutorial'), 'preprocessing') (('hounsfield units', 'radiodensity'), 'be') (('Hence this', 'LB probing mind'), 'go') (('better goalWe', 'intracranial hemorrhage'), 'be') (('you', 'window extreme widths'), 'insight') (('again we', 'window already us'), 'think') (('We', 'hemorrhage'), 'win') (('we', 'class high imbalance'), 'go') (('com allunia rsna', 'detection'), 'kaggling') (('we', 'min'), 'see') (('6 decisions', 'image'), 'have') (('So I', 'CT images'), 'decide') "}
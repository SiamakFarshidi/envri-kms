{"name": "i shopee text prep fe image augmentation ", "full_name": " h1 Data Preprocessing h1 1 Introduction h3 Goal h3 Challenges h3 Libraries W B h1 2 Data Images h2 2 1 Duplicated Images h3 Clean Duplicates Function h2 2 2 Label Group h2 2 3 Image Augmentation h1 3 Data Texts h2 3 1 Text Preprocessing step by step h3 Text Preprocessing Function h2 3 2 Text Features Extraction h3 Explore the Features h2 3 3 Text Exploration h3 Wordcloud h2 3 4 Create Text Embeddings h1 4 Final Preprocessing Function h3 Training Submission Notebook here II Shopee Model Training with Pytorch x RAPIDS h1 Specs on how I prepped explored h3 on my local machine ", "stargazers_count": 0, "forks_count": 0, "description": "ai Input your personal key of the project mine will be secret as it is confidential You can find my project in the W B Dashboard by clicking here https wandb. Create Custom Plot for W B Let s also explore the pos Part of Speech column WRB wh adverb how WP wh pronoun who VBZ verb present tense with 3rd person singular bases VBP verb present tense not 3rd person singular wrap RP particle about You can find full list here https www. Clean Duplicates FunctionHence we ll clean these duplicates by selecting only the first appearence for each. com nalepae pandarallel. Challenges Finding near duplicates of the product and NOT the image Erasing the impact of the background the area surrounding the product Using the description of the image or the title Libraries W B Create an account on https wandb. To correct that you can use cv2. Note We ll end up with 26 705 columns instead of the 12 we are working with now or 5 in the original training dataset. But Maxim Vlah https www. Data Images train train_images the product photos 32 400 files train. Now the same function takes about 8 9 minutes. 1 Duplicated ImagesThere are 1 246 images that have 2 or more apparitions The title differs for most of them The label_group is usually the same but there are a few cases where it differs as well You can check the plot in the W B Project I also wanted to look at how these images with same image name look and what trully differentiates them The description usually reffers to the same object but the wording is different The Group ID can sometimes be different although the image is exactly the same this means that the text description is the one that is indicating the category in these instances. Remember We ll use an Unsupervised ML Technique to make our prediction for this competition. 2 Label Group Note If there are 2 or more images with the same label_group it means that these have been already mapped as being identical. You can find the albumentations documentation here https vfdev 5 albumentations. Note If you re using cv2 to visualize the images note that they will be displayed in the BGR colorspace blue green red order for some reason this is the default of this library. 3 Image AugmentationAnother aspect I wanted to explore was the different kinds of augmentation that might be performed on the images so that the model can better pick up unique patterns. Training Submission Notebook here II. Text Preprocessing Function Note This function takes 30 mins in the Kaggle environment. And this is the plot in the W B Project Let s also observe the images within some of the groups There is definitely a resemblance between products for the human eye For some groups however the overall structure of the images is very different 2. com andradaolteanu ii shopee model training with pytorch x rapids. csv the corresponding metadata each product is assigned a label_group that marks the images with identical products. You can check the GitHub repo here https github. Check out preprocessing methodology below 3. update yes Plot END of EXPERIMENT Vectorizer functions don t support NAs so we need to remove if any title vectorizer Create dataframe pos vectorizer Create dataframe Concatenate all data together Get title and pos embeddings Let s also save it to W B project Clean duplicates Preprocess title get POS Extract title features Get embeddings from title and pos Test the preprocess_df function. Data Preprocessing 1. Disclaimer I chose NOT to remove numbers as they might be very important when it comes to how many ml or how many pieces are in the package of a product. Hence all methodologies we ll apply for the CV score we ll also need to use for the submission notebook. com textfeatures library for extracting basic features from text data f98ba90e3932 for more about the textfeatures library. 2 Text Features ExtractionAnother method was to extract features from the title column in an attempt to feed into the final model more useful information. Note From my research the best performing augmentations for this type of problem were flips vertical flip horizontal flip etc. apply function in pandas. The extractions were word_count counts how many words are in a sentence char_count counts how many characters are in a sentence avg_word_length counts what s the average word length in a sentence stopwords_count counts how many stopwords are in a sentence numerics_count counts how many numbers are in a sentence Explore the Features Within out title variable the texts are usually 10 words long with 50 characters and containing 1 to 2 numerics. csv the corresponding metadata 2. test test_images the product photos to be predicted 70 000 hidden files only 3 showing test. com pos tagging chunking nltk. crops center crop random crop etc. com maximvlah came in the comments with the amazing library called pandarallel which enables parallelisation when applying. Create Custom Plot for W B Wordcloud 3. io en docs_pytorch_fix api augmentations. log the plot Get bag of words from pos column Plot Make a custom plot to save into W B Prepare data Create Table. I am thinking numbers might actually give a huge insight for our prediction. 3 Text ExplorationNow let s look at the newly created title_prep. com andradaolteanu ii shopee model training with pytorch x rapids Specs on how I prepped explored on my local machine Z8 G4 Workstation 2 CPUs 96GB Memory NVIDIA Quadro RTX 8000 RAPIDS version 0. ai andrada shopee kaggle workspace user andrada. html text POS 20Tagging 20in 20NLTK 20is each 20word 20of 20the 20sentence. Final Preprocessing FunctionWe ll need the functions we created in this notebook to preprocess the test dataframe as well before applying the ML model. log the plot Read in the image corresponding metadata Plot image Example 1 Example 2 Example 3 Clean duplicates Get count of values on each group Print info Make a custom plot to save into W B Prepare data Create Table. 17 Libraries Enable progress tracking Environment check Secrets Color scheme Read in data Log into W B Get the count of apparitions per image Make a custom plot to save into W B Prepare data Create Table. Introduction Goal Building a model that can identify which images contain the same product s. Below you can see an example of an image and 11 different applied augmentations. Shopee Model Training with Pytorch x RAPIDS https www. More on that in my next notebook https www. cvtColor to display them in the RGB colorspace. and rotations as they display the product in different positions without changing its color or texture attributes. 1 Text Preprocessing step by stepBefore analyzing the text we ll have to prepare it a little bit so the insights we ll gain afterwards will be as accurate as possible. Hence is best to create a preprocess_df function that contains the necessary metadata process pipeline. log the plot Retrieve a sample of 6 images from this group Plot Example 1 Example 2 Example 3 Read in original image Transformations Apply transformations Plot END of EXPERIMENT Original Convert to lower case Remove punctuation Remove whitespaces Tokenize words Remove stopwords Lemmatization Part of speech tagging ner_text ne_chunk pos_tag lemmatized_text print NER ner_text Lower Case Remove Punctuation Remove whitespaces Tokenize Remove stopwords Lemmatization Part of speech tagging Process preprocessed title Add part of speech Read in prepped data Save also as artifact Extract Features Plot Another W B Experiment Get bag of words from the title Plot Make a custom plot to save into W B Prepare data Create Table. 4 Create Text EmbeddingsLet s append now the TF IDF CountVectorizer embeddings explored above to our training dataframe. You can check out this article https towardsdatascience. log the plot Get all titles Wordcloud stopwords_wc. ", "id": "andradaolteanu/i-shopee-text-prep-fe-image-augmentation", "size": "6950", "language": "python", "html_url": "https://www.kaggle.com/code/andradaolteanu/i-shopee-text-prep-fe-image-augmentation", "git_url": "https://www.kaggle.com/code/andradaolteanu/i-shopee-text-prep-fe-image-augmentation", "script": "textblob get_image_info get_embeddings albumentations STOPWORDS as stopwords_wc display_augmentations pandarallel preprocess_title preprocess_df nltk.tokenize Image numpy CountVectorizer seaborn _show_on_single_plot TfidfVectorizer HueSaturationValue TextBlob STOPWORDS show_values_on_bars nltk.stem sklearn.feature_extraction.text get_POS HorizontalFlip extract_title_features matplotlib.pyplot ne_chunk kaggle_secrets nltk ImageColorGenerator PorterStemmer PIL clean_duplicates pandas get_group_info WordNetLemmatizer stopwords color nltk.corpus WordCloud UserSecretsClient pos_tag word_tokenize albumentations.augmentations.transforms RGBShift wordcloud ", "entities": "(('we', 'it'), 'step') (('s', 'newly created title_prep'), 'let') (('We', 'competition'), 'remember') (('we', 'submission also notebook'), 'need') (('images', 'same product'), 'build') (('however overall structure', 'images'), 'be') (('You', 'https here wandb'), 'be') (('numbers', 'prediction'), 'think') (('wrap', 'https here www'), 'Let') (('that', 'identical products'), 'csv') (('Clean FunctionHence we', 'each'), 'Duplicates') (('best performing augmentations', 'problem'), 'note') (('You', 'article https towardsdatascience'), 'check') (('that', 'process necessary metadata pipeline'), 'be') (('test product photos', '70 000 hidden files'), 'test_images') (('how many pieces', 'product'), 'choose') (('we', 'training original dataset'), 'note') (('that', 'instances'), '1') (('Data Images', 'product files 32 400 train'), 'train') (('this', 'library'), 'note') (('Below you', 'image'), 'see') (('they', 'color attributes'), 'rotation') (('Create Text TF IDF CountVectorizer 4 now embeddings', 'training above dataframe'), 'append') (('Read', 'W B Prepare data Create Table'), 'Enable') (('Text ExtractionAnother 2 method', 'more useful information'), 'Features') (('Text Preprocessing Function function', 'Kaggle environment'), 'Note') (('we', 'ML as well model'), 'need') (('Now same function', '8 about 9 minutes'), 'take') (('Plot', 'W B Prepare data Create Table'), 'log') (('count', 'W B Prepare data Create Table'), 'log') (('title texts', '1 to 2 numerics'), 'be') (('these', 'Label Group 2 2 same label_group'), 'Note') (('You', 'https here github'), 'check') (('model', 'better unique patterns'), 'be') (('POS Extract title features', 'title Test'), 'update') (('which', 'parallelisation'), 'come') (('here https', '5 albumentations'), 'find') (('G4 GB Memory NVIDIA Workstation 2 CPUs 96 Quadro', 'machine local Z8'), 'training') "}
{"name": "nuclei overview to submission ", "full_name": " h1 Overview h1 Read in the labels h1 Load in all Images h1 Create Training Data h1 Show a few images h1 Look at the intensity distribution h1 Check Dimensions h2 Making a simple CNN h1 Loss h1 Simple Training h1 Apply Model to Test h2 Show a few predictions h1 Check RLE h2 Calculate the RLEs for a Train Image h2 Take the RLEs from the CSV h2 Check h1 Calculate RLE for all the masks ", "stargazers_count": 0, "forks_count": 0, "description": "We cheat a bit with the padding to keep problems simple. read_csv use dilations to get a slightly larger field of view the final processing label regions. training a simple CNN1. For this we use a batch normalization to normalize the inputs. OverviewThe kernel goes through1. a quick visualization of the color space1. the preprocessing steps to load the data1. LossSince we are being evaulated with intersection over union we can use the inverse of the DICE score as the loss function to optimize Simple TrainingHere we run a simple training with each image being it s own batch not a very good idea but it keeps the code simple Apply Model to TestHere we apply the model to the test data Show a few predictions Check RLECheck that our approach for RLE encoding stolen from here https www. Show a few imagesHere we show a few images of the cells where we see there is a mixture of brightfield and fluorescence which will probably make using a single segmentation algorithm difficult Look at the intensity distributionHere we look briefly at the distribution of intensity and see a few groups forming they should probably be handled separately. We take a simplification here of grouping all the regions together rather than keeping them distinct. applying the model to the test data1. Check Dimensions Here we show the dimensions of the data to see the variety in the input images Making a simple CNNHere we make a very simple CNN just to get a quick idea of how well it works. creating the RLE test data Read in the labelsLoad the RLE encoded output for the training set Load in all ImagesHere we load in the images and process the paths so we have the appropriate information for each image Create Training DataHere we make training data and load all the images into the dataframe. com rakhlin fast run length encoding python works Calculate the RLEs for a Train Image Take the RLEs from the CSV CheckSince we made some simplifications we don t expect everything to be perfect but pretty close Calculate RLE for all the masksHere we generate the RLE for all the masks and output the the results to a table. T sets Fortran order down then right ensure at least one prediction per image. We use a few morphological operations to clean up the images before submission since they can be very messy remove single pixels connect nearby regions etc linear algebra data processing CSV file I O e. ", "id": "kmader/nuclei-overview-to-submission", "size": "2235", "language": "python", "html_url": "https://www.kaggle.com/code/kmader/nuclei-overview-to-submission", "git_url": "https://www.kaggle.com/code/kmader/nuclei-overview-to-submission", "script": "prob_to_rles clean_img keras.layers keras.models keras dice_coef dice_coef_loss Lambda numpy seaborn rle_encoding BatchNormalization glob backend as K imread skimage.io matplotlib.pyplot opening Sequential backend pandas closing Conv2D skimage.morphology disk UpSampling2D read_and_stack label # label regions simple_gen ", "entities": "(('they', 'very messy remove single nearby regions'), 'use') (('we', 'inputs'), 'use') (('they', 'a few groups'), 'show') (('how well it', 'just quick idea'), 'check') (('we', 'table'), 'run') (('T', 'image'), 'set') (('We', 'together rather them'), 'take') (('read_csv', 'processing label final regions'), 'use') (('a few predictions', 'https www'), 'evaulate') (('Create Training we', 'dataframe'), 'create') (('We', 'problems'), 'cheat') "}
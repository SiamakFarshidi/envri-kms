{"name": "a data science framework to achieve 99 accuracy ", "full_name": " h1 How a Data Scientist Beat the Odds h1 A Data Science Framework h1 Step 1 What is the problem h1 Step 2 Where is the dataset h1 Step 3 Prepare data for consumption h2 3 1 Import Libraries h2 3 11 Load Data Modelling Libraries h2 3 2 Meet and Great Data h2 3 21 Explore Data with Descriptive Statistics h2 3 22 Clean Data h2 3 23 Cleanup Formats h2 3 24 Da Double Check Cleaned Data h2 3 25 Split Training and Testing Data h1 Step 4 Perform Exploratory Analysis h1 Step 5 Model Data h2 5 1 Model Optimization h3 Data Science 101 Determine a Baseline Accuracy h3 Data Science 101 How to Create Your Own Model h1 Credits ", "stargazers_count": 0, "forks_count": 0, "description": "As a data scientist your strategy should be to outsource developer operations and application plumbing so you have more time to focus on recommendations and design. The Sex and embarked variables are a nominal datatype. Get to know your data by first name and learn a little bit about it. Accuracy with very simple data cleaning and logistic regression is 82. There are more complex methodologies however before deploying it should be compared to the base model to determine if complexity truly adds value. statistics linear algebra etc. qualitative vs quantitative. It s bad because a lower barrier to entry means more people will not know the tools they are using and can come to incorrect conclusions. When creating a decision tree you want to ask questions that gives you better information about your outcome by segregated the survived 1 from the dead 0. Our rule of thumb will be the majority rules. For example you won or did not win you passed the test or did not pass the test you were accepted or not accepted and you get the point. No new information to improve our model is gained. S the majority 63 died. 0 predict survived 1 predict died 0 score random guess of survival. Although there was some element of luck involved in surviving the sinking some groups of people were more likely to survive than others such as women children and the upper class. Adding another level does not seem to gain much more information. Most data scientist come from one of the three fields so they tend to lean towards that disciple. We can generalize that a continuous target variable requires a regression algorithm and a discrete target variable requires a classification algorithm. If this were a college course that would be a B grade. So with very little information we get to 82 accuracy. Our model accuracy increases to 81. What does it look like datatype and values what makes it tick independent feature variables s what s its goals in life dependent target variable s. 11 26 17 Skipped ahead to data model since this is a published notebook. Since are dead group is less than 9 we will stop going down this branch. com questions 33925494 seaborn produces separate figures in subplots more side by side comparisons how does family size factor with sex survival how does class factor with sex survival how does embark port factor with class sex and survival plot distributions of Age of passengers who survived or did not survive pair plots correlation heatmap Machine Learning Algorithm MLA Selection and initialization Ensemble Methods Gaussian Processes Navies Bayes Nearest Neighbor Discriminant Analysis create table to compare MLA index through MLA and save to table set name column get and set algorithm execution time and accuracy print and sort table https pandas. Guess and checking other features none seem to push us past 82. Once you re able to package your ideas this becomes your currency exchange rate. com questions 46327494 python pandas dataframe copydeep false vs copydeep true vs cleanup age with median preview data again cleanup embarked with mode preview data again delete the cabin feature column and others previously stated to exclude preview data again convert to explicit category data type Quantitative Descriptive Statistics Qualitative Descriptive Statistics define x and y variables for original features aka feature selection define x and y variables for dummy features aka feature selection split train and test data with function defaults Correlation by Survival excluding continuous variables of age and fare using group by https pandas. If you have a fair coin and you guessed heads or tail then you have a 50 50 chance of guessing right. html graph distribution of qualitative data Pclass we know class mattered in survival now let s compare class and a 2nd feature graph distribution of qualitative data Sex we know sex mattered in survival now let s compare sex and a 2nd feature graph individual features by survival close factor plot facetgrid we don t need https stackoverflow. 1 Model OptimizationLet s recap with some basic data cleaning analysis and machine learning algorithms MLA we are able to predict passenger survival with 85 accuracy. Question 4A going down the female class 3 branch with count 144 Did you embark from port C Q or S We gain a little information. html qcut vs cut https stackoverflow. html we will use matplotlib. For model optimization we have a couple options 1 find a better algorithm 2 tune our current algorithm parameters 3 feature engineer new variables to find new signals in the data or 4 we can go back to the beginning and determine if we asked the right questions got the right data and made the right decisions along the process. html Indexing and Selecting Data https pandas. computer science i. Data wrangling includes implementing data architectures for storage and processing developing data governance standards for quality and control data extraction i. At worst it makes completing the project impossible or even worst incorrect. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. org pandas docs stable visualization. However we want to use caution when we modify data from its original value because it may be necessary to create an accurate model. It is not recommended to delete the record especially a large percentage of records unless it truly represents an incomplete record. In addition we will explicitly convert Pclass to integer categorical variables so not to be confused with quantitative variables. org pandas docs stable categorical. html collection of functions for data processing and analysis modeled after R dataframes with SQL like features collection of functions for scientific and publication ready visualization foundational package for scientific computing collection of functions for scientific computing and advance mathematics pretty printing of dataframes in Jupyter notebook collection of machine learning algorithms measure execution of code snippets https docs. org stable modules generated sklearn. In the next step we will worry about transforming dirty data to clean data. We then hope to present it a new subset from the same dataset and have similar results in prediction accuracy. subplots graph distribution of quantitative data we will use seaborn graphics for multi variable comparison https seaborn. com blog_assets Scikit_Learn_Cheat_Sheet_Python. Another popular use case is healthcare s mortality rate or survival analysis. Thus it s important to fix before starting analysis. So keep that in mind. With that being said this step requires advanced knowledge in mathematics. Step 1 What is the problem For this project the problem statement is given to us on a golden plater develop an algorithm to predict the survival outcome of passengers on the Titanic. org pandas docs stable indexing. Common Model Algorithms Common Model Helpers Visualization Configure visualizations matplotlib inline show plots in Jupyter Notebook browser load as dataframe Note The test file is really validation data for competition submission because we do not know the survival status We will create real test data in a later section so we can evaluate our model before competition submission preview data https pandas. They will be converted to dummy variables for mathematical calculations. But we have information about the dataset so we should be able to do better. Nonetheless if we assumed everybody died our sample accuracy is 62. org stable user_guide. So we will use scikit function to split the training data in two datasets 75 25 split. Question 5A going down the female class 3 embarked S branch with count 88 So far it looks like we made good decisions. In this kernel I use Kaggle s Getting Started Competition Titanic Machine Learning from Disaster to walk the reader through how to use the data science framework to beat the odds. neighbors Support Vector Machines SVM http scikit learn. One I found was fare 0 8 majority survived. And reinforced learning is a hybrid of the previous two where the model is not given the correct target response immediately but later in a sequence of events to reinforce learning. So let s set 68 as a D grade because again if your model accuracy is any worst that that then why do I need you when I can just assume if you were on the Titanic that day you died and have a 68 accuracy. html to organize our graphics will use figure https matplotlib. Our categorical data imported as objects which makes it difficult for mathematical calculations. linear_model Naive Bayes http scikit learn. Both are dicrete quantitative datatypes. Surprisingly class or even embarked didn t matter title does and gets us to 82. Remember the name of the game is to create subsets using a decision tree model to get survived 1 in one bucket and dead 0 in another bucket. Data Science 101 How to Create Your Own Model Our accuracy is increasing but can we do better Are there any signals in our data To illustrate this we re going to build our own decision tree model because it is the easiest to conceptualize and requires simple addition and multiplication calculations. It may be external or internal structured or unstructured static or streamed objective or subjective etc. Too often we are quick to jump to the new shiny technology tool or algorithm before determining the actual problem we are trying to solve. Evaluate Data Model After you ve trained your model based on a subset of your data it s time to test your model. We can play with our features. and y dependent target outcome response etc. We will use scikit train_test_split function http scikit learn. Meaning the algorithm is so specific to a given subset it cannot accurately generalize another subset from the same dataset. communication subject matter knowledge etc. html Random float x 0. Below are common classes to load. Introduction to Machine Learning with Python A Guide for Data Scientists. Thus only data cleaning is in scope. In this stage you will find yourself doing one of three things completing missing information correcting outliers or creating new features for analysis. 5 to 1 for majority survived Score Decision Tree Model Accuracy Summary Report with http scikit learn. If you want to follow along on your own download the train dataset and import into Excel. com questions 30211923 what is the difference between pandas qcut and pandas cut Fare Bins Buckets using qcut Age Bins Buckets using cut simple frequency table of class and sex using crosstabs https pandas. If you work in research maybe the answer is yes but if you work in business mostly the answer is no. Reviewing the data there does not appear to be any aberrant or non acceptable data inputs. It s important to remember algorithms are tools and not magical wands. html random number generator https docs. 22 Clean DataNow that we know what to clean let s execute our code. Machine Learning Selection SciKit Estimator Overview http scikit learn. 11 25 17 Added enhancements of published notebook and started step 4. Therefore it is important to deploy descriptive and graphical statistics to look for potential problems patterns classifications correlations and comparisons in the dataset. This is part science and part art so let s just play the 21 question game to show you how it works. Also the dead subgroup is 9 or less so we will stop. Thanks 11 23 17 Cleaned up published notebook and updated through step 3. jpg A Data Science Framework1. org generated seaborn. pdf Now that we identified our solution as a supervised learning classification algorithm. The idea is why write ten lines of code when you can write one line. What happens when technology is too smart for its own good Funny Autocorrect http 15858 presscdn 0 65. Not bad for a few lines of code. html highlight matplotlib 20pyplot 20subplots matplotlib. There are two common methods either delete the record or populate the missing value using a reasonable input. We ll give that a grade of a C for average or our baseline. Thanks 12 2 17 Updated section 4 with exploratory statistics and section 5 with more classifiers. Problems before requirements requirements before solutions solutions before design and design before technology. DataFrame https pandas. pyplot https matplotlib. To do that we have to go back to the basics of data science 101. This is important so we don t overfit our model. Think of it like a first date before you jump in and start poking it in the bedroom. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. Use shortcut 1 Right Guess and 0 Wrong Guess the mean of the column will then equal the accuracy assume prediction wrong set to 1 for correct prediction we can also use scikit s accuracy_score function to save us a few lines of code http scikit learn. and business management i. In scikit algorithms are called Estimators and implemented in their own classes. fit train1_dummy_x train1_dummy_y barplot using https seaborn. get_dummies https pandas. recall_score And F1 score weighted average of precision and recall w 1 being best http scikit learn. Binary events create an interesting dynamic because we know statistically a random guess should achieve a 50 accuracy rate without creating one single algorithm or writing one single line of code. Machine Learning Classification Algorithms Ensemble Methods http scikit learn. In laymen terms this means it either occurred or did not occur. subplot and subplotS https matplotlib. For this dataset age will be imputed with the median the cabin attribute will be dropped and embark will be imputed with mode. ensemble Generalized Linear Models GLM http scikit learn. Continue to up vote and I will continue to develop this notebook. This subgroup 55 died and 33 survived since majority died we need to find a signal to identify the 33 or a subgroup to change them from dead to survived and improve our model accuracy. html Question 1 Were you on the Titanic majority died Question 2 Are you female majority survived Question 3A Female Class and Question 4 Embarked gain minimum information Question 5B Female FareBin set anything less than. Therefore If I just guessed that 100 of people died then I would be right 67. Therefore normal processes in data wrangling such as data architecture governance and extraction are out of scope. Project Summary The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. However data science is like a three legged stool with no one leg being more important than the other. For this dataset we will convert object datatypes to categorical dummy variables. For data visualization we will use the matplotlib and seaborn library. It can be used during subsequent iterations to evaluate if more complexity improves the base model accuracy. However just like autocorrect spellcheck technology sometimes we humans can be too smart for our own good and actually underperform a coin flip. We know that 1 502 2 224 or 67. Instead it s best to impute missing values. C and Q the majority still survived so no change. Prepare data for consumption. So problems that once required graduate mathematic degrees now only take a few lines of code. We can narrow our list of choices. 25 Split Training and Testing DataAs mentioned previously the test file provided is really for the competition submission data and does not provide the outcome target variable for us to validate our model. Create a pivot table with survival in the columns count and of row count in the values and the features described below in the rows. So we ll stop here for now. Improved model to 85 accuracy. com 2013 09 08 basic feature engineering with the titanic data to derive the gender from title family size from surname and SES from titles like doctor or master however these variables already exist. Before we do let s code what we just wrote above. In particular we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. qualitative vs quantitative in order to select the correct hypothesis test or data model. The Name variable is a nominal datatype. So think of it like a coin flip. html prettify using pyplot https matplotlib. Question 3A going down the female branch with count 344 Are you in class 1 2 or 3 Class 1 majority 97 survived and Class 2 majority 92 survived. Your dataset and expected results will determine the algorithms available for use. But can we do better By making a better decision tree new features etc. f1_score Credit http scikit learn. It is a binary nominal datatype of 1 for survived and 0 for did not survive. faster than it was before. At worst it makes completing the project impossible. At best it shows a complete lack of understanding. On April 15 1912 during her maiden voyage the Titanic sank after colliding with an iceberg killing 1502 out of 2224 passengers and crew. Libraries provide pre written functionality to perform necessary tasks. The Age and fare variable are continuous quantitative datatypes. In this stage you will find yourself classifying features and trying to determine their relationship with the target variable and each other. 21 Explore Data with Descriptive StatisticsDescriptive statistics is a quick and dirty way to identify aberrant missing or outlier data. Source Documentation Categorical Encoding http pbpython. This is both good and bad. My goal is to add to the Data Science Community 1 a framework that teaches how to think like a data scientist vs what to think code and 2 concise code and clear documentation because simple is better than complex. So now that I ve hammered no pun intended my point I ll show you what to do and most importantly WHY you do it. Unsupervised learning is where you train the model using a training dataset that does not include the correct target response. There are many machine learning algorithms however they can be reduced to four categories classification regression clustering or dimensionality reduction depending on your target variable and data modeling goals. Implement Optimize and Strategize This is the bionic man step where you iterate back through the process to make it better. It s a small sample size 11 9 but one often used in statistics. All other variables are potential predictor or independent variables. Since our problem is predicting if a passenger survived or did not survive this is a discrete target variable. This step is often referred to as data wrangling a required process to turn wild data into manageable data. There are multiple ways to encode categorical variables we will use the pandas method scikit also has LabelEncoder and OneHotEncoder. We will use a classification algorithm from the scikit library to begin our analysis. Class 3 is even at a 50 50 split. org stable auto_examples model_selection plot_confusion_matrix. However since there are many null values it does not add value and thus is excluded from analysis. It s good because these algorithms are now accessible to more people that can solve more problems in the world. svm Decision Trees http scikit learn. Note our sample survival is different than our population of 68. fillna https pandas. html Compute confusion matrix Plot non normalized confusion matrix Plot normalized confusion matrix. At this stage we see we may have potential outliers in age and fare. A basic methodology for quantitative data is impute using mean median or mean standard deviation. Machine learning can be categorized as supervised learning unsupervised learning and reinforced learning. The PassengerID and Ticket variables are assumed to be random unique identifiers that have no impact on the outcome variable. There are no date or currency formats but datatype formats. To begin this tasks we first import our data. In this step we will also define our x independent features explanatory predictor etc. com c titanic data Step 3 Prepare data for consumption. html Choosing Estimator Mind Map http scikit learn. html Quantitative Descriptive Statistics Qualitative Descriptive Statistics create a copy of data remember python assignment or equal passes by reference vs values so we use the copy function https stackoverflow. Perform exploratory analysis. programming languages computer systems etc. Practice Skills Binary classification Python and R basics Step 2 Where is the dataset The dataset is also given to us on a golden plater with test and train data at Kaggle s Titanic Machine Learning from Disaster https www. It could be used for feature engineering https triangleinequality. That s why I focus on teaching you not just what to do but why you re doing it. Previously I used the analogy of asking someone to hand you a Philip screwdriver and they hand you a flathead screwdriver or worst a hammer. However since they are reasonable values we will wait until after we complete our graphical statistics to determine if we should include or exclude from analysis. 1 Import LibrariesThe following code is written in Python 3. Anybody who has ever worked with data knows garbage in garbage out GIGO. figure subplot https matplotlib. variables for data modeling. Giving us an accuracy of 79. How a Data Scientist Beat the Odds It s the classical problem predict the outcome of a binary event. 2 Meet and Great DataThis is the meet and great step. We know this is a binary problem because there are only two possible outcomes passengers survived or died. We slightly improve our accuracy but not much to move us past 82. A common business application is churn or customer retention. The same is true in data modelling. html optional plotting w pandas https pandas. Subsequent model iterations will modify this decision to determine if it improves the model s accuracy. 12 3 17 Update section 4 with improved graphical statistics. Source Documentation pandas. com categorical encoding. Question 3B going down the male branch with count 577 Going back to question 2 we know the majority of males died. Missing values can be bad because it skews our data model. So we are looking for a feature that identifies a subgroup that majority survived. This sensational tragedy shocked the international community and led to better safety regulations for ships. accuracy_score group by or pivot table https pandas. Since step 2 was provided to us on a golden plater so is step 3. So chances are the dataset s already exist somewhere in some format. There are null values or missing data in the age cabin and embarked field. So let s set 50 as an F grade because if your model accuracy is any worse than that then why do I need you when I can just flip a coin Okay so with no information about the dataset we can always get 50 with a binary problem. ETL and web scraping and data cleaning to identify aberrant missing or outlier data points. Step 5 Model DataData Science is a multi disciplinary field between mathematics i. CreditsProgramming is all about borrowing code because knife sharpens knife. describe https pandas. classification_report Where recall score true positives true positive false negative w 1 being best http scikit learn. Nonetheless I want to give credit where credit is due. A basic methodology for qualitative data is impute using mode. classification_report. 5 in female node decision tree back to 0 Question 3B Male Title set anything greater than. html cut or value bins https pandas. com wp content uploads 2016 03 hilarious autocorrect fails 20x. org api _as_gen matplotlib. An intermediate methodology is to use the basic methodology based on specific criteria like the average age by class or embark port by fare and SES. Thus they will be excluded from analysis. html create a 2nd copy of our data Feature Engineering Note we will not do any imputing missing data at this time coin flip model with random 1 survived 0 died Iterate over DataFrame rows as index Series pairs https pandas. html SciKit Estimator Detail http scikit learn. So use caution when selecting your tool because at the end of the day you are still the master craft wo man. It s important our algorithm has not seen the subset we will use to test so it doesn t cheat by memorizing the answers. In this challenge we ask you to complete the analysis of what sorts of people were likely to survive. Before we move on to the next step let s deal with formatting. The Pclass variable is an ordinal datatype for the ticket class a proxy for socio economic status SES representing 1 upper class 2 middle class and 3 lower class. But thanks to computer science a lot of the heavy lifting is done for you. First you must understand that the purpose of machine learning is to solve human problems. Also we will stop if the subgroup is 10 of our total dataset or 9 cases and or our model accuracy plateaus or decreases. Next we use the info and sample function to get a quick and dirty overview of variable datatypes i. The cabin variable is a nominal datatype that can be used in feature engineering for approximate position on ship when the incident occurred and SES from deck levels. Question 2 Are you male or female Male majority 81 died. html Pandas Categorical dtype https pandas. Supervised learning is where you train the model by presenting it a training dataset that includes the correct target response. html Ignore warnings Input data files are available in the. value_counts https pandas. 11 Load Data Modelling LibrariesWe will use the popular scikit learn library to develop our machine learning algorithms. This helps ensure you haven t overfit your model or made it so specific to the selected subset it does not accurately fit another subset from the same dataset. Statistical classification is also important to understand the overall datatype structure i. com kaggle docker python For example here s several helpful packages to load in access to system parameters https docs. The Survived variable is our outcome or dependent variable. The SibSp represents number of siblings spouse aboard and Parch represents number of parents or children aboard. org stable tutorial machine_learning_map index. naive_bayes Nearest Neighbors http scikit learn. 23 Cleanup FormatsWe will convert Sex and Embarked from objects to dummy variables for mathematical analysis. For the first model iteration this variable will be excluded from analysis. 12 7 17 Updated section 5 with Data Science 101 Le Hello this is my debut project on Kaggle using the popular Getting Started Competition. Where is the dataset John Naisbitt wrote in his 1984 book Megatrends we are drowning in data yet staving for knowledge. It s important to note more predictor variables do not make a better model but the right variables. It should be noted that if they were unreasonable values for example age 800 instead of 80 then it s probably a safe decision to fix now. 24 Da Double Check Cleaned DataNow that we ve cleaned our data let s do a discount da double check 3. Step 4 Perform Exploratory AnalysisNow that our data is cleaned let s use descriptive and graphical statistics to describe and summarize our data. html Family Size create a new feature and initialize to yes 1 is alone now update to no 0 if family size is greater than 1 qcut or frequency bins https pandas. html timeit logreg. Got it Let s go Question 1 Were you on the Titanic If Yes then majority 62 died. Update 11 22 17 Please note this kernel is currently in progress but open to feedback. Data Science 101 Determine a Baseline Accuracy Before we decide how to make our model better let s determine if 85 is good enough. org stable modules classes. But the question we always ask is can we do better and more importantly get an ROI return on investment for our time invested For example if we re only going to increase our accuracy by 1 10th of a percent is it really worth 3 months of model optimization. This can be used for feature engineering to create a family size or is alone variable. Meaning if the majority or 50 or more survived then everybody in our subgroup survived 1 but if 50 or less survived then if everybody in our subgroup died 0. What is the problem If data science big data machine learning predictive analytics business intelligence or any other buzzword is the solution then what is the problem As the saying goes don t put the cart before the horse. One side note logistic regression while it has regression in the name is really a classification algorithm. Female majority 74 survived. As the saying goes you don t have to reinvent the wheel you just have to know where to find it. Click here for the Source Data Dictionary https www. Model Data Like descriptive and inferential statistics data modeling can either summarize the data or predict future outcomes. org pandas docs stable generated pandas. isnull https pandas. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. We are doing supervised machine learning because we are training our algorithm by presenting it with a set of features and their corresponding target. In two lines of code we can quickly determine we have a little bit of data cleaning ahead of us. html Choosing Estimator Cheat Sheet https s3. An analogy would be asking someone to hand you a Philip screwdriver and they hand you a flathead screwdriver or worst a hammer. So we will change females class 3 embarked S from assuming they survived to assuming they died. ", "id": "ldfreeman3/a-data-science-framework-to-achieve-99-accuracy", "size": "26317", "language": "python", "html_url": "https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy", "git_url": "https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy", "script": "RFECV OneHotEncoder linear_model sklearn.feature_selection train_test_split Imputer IPython.display matplotlib.pylab correlation_heatmap Image ensemble numpy seaborn Normalizer subprocess tree IPython plot_confusion_matrix gaussian_process scipy sklearn neighbors StratifiedKFold StratifiedShuffleSplit matplotlib.pyplot plot_distribution metrics svm sklearn.model_selection pandas timeit scatter_matrix scale naive_bayes time pandas.tools.plotting RandomizedSearchCV matplotlib display #pretty printing of dataframes in Jupyter notebook check_output discriminant_analysis LabelEncoder GridSearchCV sklearn.preprocessing ", "entities": "(('Cleanup 23 FormatsWe', 'mathematical analysis'), 'convert') (('dataset results', 'available use'), 'determine') (('This', 'family size'), 'use') (('sometimes we humans', 'coin actually flip'), 'be') (('more complexity', 'base model accuracy'), 'use') (('most importantly WHY you', 'it'), 'intend') (('Model DataData Step 5 Science', 'mathematics multi disciplinary i.'), 'be') (('it', 'simple addition calculations'), 'Science') (('complexity', 'truly value'), 'be') (('less than we', 'branch'), 'be') (('everybody', 'sample accuracy'), 'be') (('knife', 'knife'), 'be') (('Project sinking', 'history'), 'Summary') (('yourself', 'target variable'), 'find') (('we', 'analysis'), 'wait') (('Statistical classification', 'datatype structure also overall i.'), 'be') (('it', 't answers'), 's') (('many machine learning however they', 'dimensionality data target variable goals'), 'be') (('don t', 'horse'), 'be') (('status socio economic SES', '1 upper class 2 middle class'), 'be') (('mostly answer', 'business'), 'be') (('many null it', 'thus analysis'), 'however') (('we', 'matplotlib library'), 'use') (('sample small 11 9 one', 'often statistics'), 's') (('Data wrangling', 'data extraction quality i.'), 'include') (('we', 'learning classification supervised algorithm'), 'pdf') (('information Question 5B Female minimum FareBin', 'anything'), 'die') (('it', 'model really 3 months optimization'), 'be') (('often data', 'manageable data'), 'refer') (('however variables', 'doctor'), 'com') (('rule', 'thumb'), 'be') (('passengers', 'tragedy'), 'ask') (('us', 'model'), 'mention') (('we', 'yet knowledge'), 'be') (('Thanks', 'step'), 'clean') (('sorts', 'people'), 'ask') (('da', 'double 3'), 'clean') (('it', 's.'), 'look') (('this', 'data ahead model'), 'skip') (('variable', 'analysis'), 'exclude') (('we', 'model dead accuracy'), 'die') (('you', 'point'), 'win') (('we', 'competition submission preview data https pandas'), 'show') (('majority', 'that'), 'look') (('they', 'flathead screwdriver'), 'ask') (('set name column', 'algorithm execution time'), 'produce') (('Score Decision Tree Model Accuracy Summary Report', 'http scikit'), 'survive') (('that', 'world'), 's') (('I', 'odds'), 'use') (('basic methodology', 'standard deviation'), 'be') (('when incident', 'deck levels'), 'be') (('we', 'quantitative variables'), 'convert') (('when you', 'one line'), 'be') (('html collection', 'code snippets https docs'), 'model') (('you', 'bedroom'), 'think') (('s', 'code'), 'DataNow') (('it', 'accuracy'), 'modify') (('Explore 21 Data', 'missing outlier data'), 'be') (('we', 'predictor explanatory etc'), 'define') (('we', 'categorical dummy variables'), 'convert') (('classical problem', 'binary event'), 'beat') (('sensational tragedy', 'ships'), 'shock') (('family size', 'now 0'), 'create') (('they', 'conclusions'), 's') (('so we', 'copy function https stackoverflow'), 'create') (('subgroup', 'total dataset'), 'stop') (('We', '82'), 'improve') (('that', 'target correct response'), 'be') (('Import 1 LibrariesThe following code', 'Python'), 'write') (('sample survival', '68'), 'note') (('majority', 'males'), '3b') (('we', 'what'), 'let') (('we', 'index Series pairs https pandas'), 'create') (('so we', 'model'), 'be') (('then I', 'people'), 'be') (('it', 'same dataset'), 'help') (('2016 03 hilarious autocorrect', '20x'), 'upload') (('we', 'comparison https multi variable seaborn'), 'use') (('5', 'anything'), 'set') (('we', 'clean data'), 'worry') (('predictor more variables', 'better model'), 's') (('step', 'mathematics'), 'require') (('We', 'little information'), 'go') (('C majority', 'still so change'), 'survive') (('they', 'flathead screwdriver'), 'use') (('Instead it', 'missing values'), 's') (('this', 'ideas'), 'become') (('we', 'dataset'), 'have') (('It', 'survived'), 'be') (('qualitative', 'hypothesis correct test'), 'quantitative') (('quickly we', 'ahead us'), 'determine') (('you', 'train Excel'), 'want') (('who', 'out GIGO'), 'know') (('At best it', 'understanding'), 'show') (('we', 'good decisions'), '5a') (('Reviewing', 'data'), 'appear') (('it', 'truly incomplete record'), 'recommend') (('s', 'data'), 'AnalysisNow') (('feature aka selection', 'https pandas'), 'question') (('when technology', 'Funny too own good Autocorrect'), 'happen') (('At worst it', 'project'), 'make') (('we', '82 accuracy'), 'get') (('It', 'feature engineering https triangleinequality'), 'use') (('step', 'golden plater'), 'provide') (('we', 'features'), 'do') (('85', 'Baseline Data 101 Accuracy'), 'Science') (('then you', '50 50 chance'), 'have') (('Therefore it', 'dataset'), 'be') (('Therefore normal processes', 'scope'), 'be') (('dataset', 'Disaster https www'), 'classification') (('they', '3 S'), 'change') (('I', 'notebook'), 'continue') (('where model', 'learning'), 'be') (('com difference', 'crosstabs https pandas'), 'question') (('fit train1_dummy_y barplot', 'https seaborn'), 'train1_dummy_x') (('1 predict', 'survival'), 'die') (('html', 'figure https matplotlib'), 'use') (('you', 'day'), 'use') (('1 2 3 Class 1 97 Class 2 majority', '344 class'), 'be') (('we', 'data science'), 'have') (('we', '85 accuracy'), '1') (('intermediate methodology', 'fare'), 'be') (('we', 'code http scikit'), 'assume') (('it', 'name'), 'be') (('we', 'process'), 'have') (('So we', '75 25 split'), 'use') (('It', 'python docker image https kaggle github'), 'come') (('we', 'actual problem'), 'be') (('you', 'output'), 'list') (('why you', 'it'), 's') (('Thus they', 'analysis'), 'exclude') (('Next we', 'variable datatypes'), 'use') (('shipwreck', 'enough passengers'), 'be') (('it', 'same dataset'), 'be') (('Load Data Modelling 11 LibrariesWe', 'machine learning algorithms'), 'use') (('embark', 'mode'), 'impute') (('you', 'just where it'), 'have') (('then majority', 'Titanic'), 'let') (('new information', 'model'), 'gain') (('we', 'age'), 'see') (('yourself', 'analysis'), 'find') (('We', 'average'), 'give') (('that', 'code'), 'take') (('where credit', 'credit'), 'want') (('we', 'first data'), 'import') (('Guess', '82'), 'seem') (('it', 'data model'), 'be') (('aboard Parch', 'parents'), 'represent') (('we', 'https stackoverflow'), 'distribution') (('concise 2 clear simple', 'code'), 'be') (('data However science', 'more other'), 'be') (('we', 'also LabelEncoder'), 'be') (('application so you', 'recommendations'), 'be') (('didn t matter even title', '82'), 'do') (('Le 101 this', 'Getting Competition'), 'section') (('so they', 'disciple'), 'come') (('it', 'accurate model'), 'want') (('lot', 'you'), 'do') (('name', '0 bucket'), 'remember') (('We', 'analysis'), 'use') (('11 22 17 kernel', 'currently progress'), 'update') (('age 800 instead 80 then it', 'unreasonable example'), 'note') (('http best scikit', 'true positive false negative w'), 'learn') (('algorithms', 'own classes'), 'call') (('it', 'terms'), 'mean') (('that', 'dead 0'), 'create') (('Machine learning', 'supervised learning unsupervised learning'), 'categorize') (('Accuracy', 'data very simple cleaning'), 'be') (('how it', 'you'), 'be') (('statistically random guess', 'code'), 'create') (('Thus it', 'analysis'), 's') (('day you', '68 accuracy'), 'let') (('s', 'formatting'), 'let') (('it', 'model'), 'Model') (('html Ignore warnings Input data files', 'the'), 'be') (('http best scikit', '1'), 'learn') (('purpose', 'human problems'), 'understand') (('it', 'mathematical calculations'), 'datum') (('problem statement', 'Titanic'), 'step') (('random unique that', 'outcome variable'), 'assume') (('then everybody', 'subgroup'), 'mean') (('dataset', 'already somewhere format'), 'be') (('Adding', 'much more information'), 'seem') (('regression algorithm', 'target classification discrete algorithm'), 'generalize') (('basic methodology', 'mode'), 'be') (('We', 'prediction accuracy'), 'hope') (('we', 'binary problem'), 'let') (('Libraries', 'necessary tasks'), 'provide') (('They', 'mathematical calculations'), 'convert') (('it', 'back process'), 'Optimize') "}
{"name": "heart disease prediction w knn naivebayes trees ", "full_name": " h2 Problem Statement and Objective h2 Dataset h2 Data Preprocessing h2 Handling Duplicates and Outliers Data Cleaning h2 Feature Selection Data Reduction h2 Dummy Variables Data Transformation h2 Exploratory Data Analysis EDA h2 Dimension and Variables or Attributes of Dataset h2 Frequency Distribution Table h2 Measure of Central Tendency and Dispersion h2 Skewness of Dataset h2 Correlation Matrix h2 Visualization of Attributes h2 Realibility Fitting Probability Distribution h1 Model Development h2 K Nearest Neighbours KNN Modelling h2 Decision Tree Classification h2 Naive Bayes Classifier h2 Performance Evaluation of K Nearest Neighbour Decion Tree and Naive Bayes Classification Model h2 Interpretation of Model h2 References ", "stargazers_count": 0, "forks_count": 0, "description": "fbs fasting blood sugar 120 mg dl 1 true 0 false 7. In this case study the worst case scenario is the False Negatives FN which is located in the top right of the confusion matrix. As the dataset used in this case study has little to no multicollinearity hence Naive Bayes Classifier is suitable for this case study. skew fbs and ca are highly skewed. exang exercise induced angina 1 yes 0 no 10. Weibull 2P best fits for the all quantitative attributes as Weibull 2P has low AIC and BIC compared to other distribution fitted for the quantitative attributes. 5 hence no multicollinearity. 05 mV Value 2 showing probable or definite left ventricular hypertrophy by Estes criteria 8. The Weibull distribution is widely used in reliability and life data analysis due to its versatility. AIC and BIC are both calculated using the maximum likelihood which maximizes the conditional probability of observing the data X given a specific probability distribution and its parameters theta Brownlee 2019. The above scatter density plot matrix is associated with Kernel Density Estimation KDE plots which estimates the probability density of a variable and also the probability distribution JournalDev n. Scatter plot matrix is a matrix of scatter plots where each scatter plot in the grid is created between different combinations of variables. From the bar chart female tends to have higher risk to suffer from heart disease. From the KNN model prediction a male which is 55 years old with trestbps of 140 chol of 250 thalach of 160 oldpeak of 2. Prediction of heart disease can be achieved by implementing machine learning algorithms on data provided by healthcare institutions. Data preprocessing transforms raw data to useful and efficient format for human and machine learning process. Whenver a new unknown record is added it will be classified based on its 10 nearest neighbours votes. However all the scatter plot are dispersed with correlation of absolute value less than 0. These categorical attributes are then transformed to dummy variables in data transformation resulting in 31 columns in total. Naive Bayes Classifier Naive Bayes Classifier the most straightforward and fast classification algorithm suitable for use in high dimensionality dataset. What do you consider a good standard deviation. It can be measured using range standard deviation and variance and also coefficient of variation Kaufmann 2014. According to research there are no optimal K number of neighbours which suits all kind of dataset as each dataset has different requirements. online Available at Accessed 4th December 2020 CK 12. Problem Statement and Objective Heart disease describes a range of conditions that affects a person s heart functioning performance. The histogram and scatter plot for quantitative variales is also able to show the dispersion and central tendancy of the data points. online Available at Accessed 4th December 2020 Whitworth G. Skewness of Dataset Skewness measures a dataset s symmetry or lack of symmetry. ca is considered as qualitative categorical attributes as it only consists of 4 type of unique values. Weibull distribution is commonly used assess product reliability analyze life data and model failure times from biology industry to economic industry Stephanie 2017. Machine learning algorithms such as Naive Bayes Classification K Nearest Neighbour Logistic Regression Decision Tree Classification and others which helps to classifies the presence of heart disease with the given symptoms. A CV value of lesser than 1 indicates a low variance. There are many ways to evalute the model performance depending on the model. online Available at Accessed 4th December 2020 loading packages and libraries directory of dataset detect missing values print min and max of acceptable range since thalach is integer attribute rounded to integer rounded to integer cap outliers with min and max of acceptable range correlation matrix categorical variables to convert to dummy variables convert to dummy variables data frame with dummy variables combine dummy variables with dataset drop categorical variabes as they are converted to dummy variables scatter plot of radius and compactness scatter plot of radius and texture scatter plot of radius and smoothness scatter plot of radius and concavity scatter plot of radius and compactness scatter plot of radius and texture scatter plot of radius and smoothness scatter plot of radius and concavity correlation matrix split dataset to train and test split train and test for decision tree model 80 20 split suggested number of neighbours to determine optimum number of neighbours n_neighbors means k 1 as index starts from 0 in array modeling KNN to determine optimum number of maximum leaf nodes n_neighbors means k 1 as index starts from 0 in array since max leaf node of 6 to 9 has the same scores thus 9 is used for better accuracy. In layman terms AIC indicates the overfitting issues and BIC indicates the underfitting issues as they both penalize free parameters Ash3323 and Taylor 2018. online Available at Accessed 4th December 2020 Brownlee J. It considers K number of neighbours nearest the unknown and newly added point which classifies the unknown point based on the neighbours votes for instance if 5 out of 6 neighbours has a target of presence of heart disease then the newly added unknown point will be classified as presence of heart disease. 5 IQR where Q1 and Q3 represents the first and third quartile respectively and IQR represents the interquartile range. Thus in this assessment AIC and BIC are both taken into consideration in choosing the best probability distribution model. As shown in the plot the distribution of heart disease and no heart disease is considered evenly distribute as there are no big difference in count. The dataset is loaded from the downloaded directory and the first five rows of dataset is shown above. This is to reduce overfitting and multicollinearity which will cause misleading prediction. Heart disease describes a range of conditions that affects a person s heart. 5 with each other and also with target thus no attributes are removed from the dataset. The dataset originally consists of 14 attributes where 5 of them are quantitative attributes including integers and float and 9 of them are qualitative categorical attributes which were encoded to integers in the raw dataset. sex cp exang oldpeak are moderately skewed. It will not only reduce the cost of diagnosis but also improves the efficiency in diagnosis and treatment as patients are diagnosed efficiently and early treatment can be given for better recovery. From the scatter density plot matrix all variables are moderately related to target. online Available at Accessed 4th December 2020 Dernoncourt F. Dummy variables uses 0 or 1 to indicate absence or presence of the categorical value sorting them to mutually exclusive categories. thal 3 normal 6 fixed defect 7 reversable defect14. sex 1 male 0 female 3. Diagonally from top left to right the plots represent univariate distribution of data for the variable in that column for instance distribution of age distribution of sex and others. What When and How of Scatterplot Matrix in Python Data Analytics. Is there any reason to prefer the AIC or BIC over the other. 5 to 1 is moderately skewed and highly skewed if more than 1. mode the mean median 2nd Quartile or 50 and mode for the quantitative attributes are approximately the same thus they are approximately normal. However oldpeak has CV value of 1. In other words scatter plot matrix represents bi variate or pairwise relationship between different combinations of variables in grid form Kumar 2020. Decision trees are not affected by monotonic transformation such as normalization hence normalization is not needed Rapaio 2015. K Nearest Neighbours KNN Modelling K Nearest Neighbours KNN is a supervised learning algorithm which is also a classification algorithm. 077 thus it is considered as high variance thus oldpeak is spread out Kaufmann 2014. AIC attempt to select an unknown model which has high dimensional reality whereas BIC finds only True models. UCI Machine Learning Repository n. This is because different countries has different culture and lifestyle and different ethnics has different genetic which also contributes to the causes of heart disease thus the KNN model developed in this case study is more biased for United States citizens. Part of the EDA has already performed in data preprocessing for outlier detection using Quartile method with boxplot and for data reduction using correlation matrix plot. Correlation Matrix Correlation Matrix heatmap is shown in Feature Selection or Data Reduction in Data Preprocessing. Like Decision Tree Classifier Naive Bayes Classifier is not affected by monotonic transformation hence normalization is not required Dernoncourt 2016. online Available at Accessed 4th December 2020 Kedarps. With the Naive Bayes classifier why do we have to normalize the probabilities after calculating the probabilities of each hypothesis. Decision Tree Classification Decision Tree Classification is a supervised machine learning algorithm which has a tree like structure consisting of nodes leaves and branches. A perfectly symmetrical data set will have a skewness of 0. However the KNN model will perform better if it was trained with a larger dataset with more instances it will help improve the KNN model s capability to predict unknown data. Available at Accessed 4th December 2020 Rapaio. Heart disease is the leading cause of death in the United States with about 655 000 Americans die from heart disease each year and that is about 1 in every 4 deaths CDC n. As accuracy sometimes may be misleading thus F1 score is also used to evaluate model performance. Accoding to rule of thumb skewness of 0. The lower score of AIC and BIC indicates a better probability distribution model. The dataset is now free from duplicates and outliers. This high accuracy model can be used as reference for healthcare instituitions for prediction of presence of heart disease in United States citizens. The optimal number of maximum leaf nodes is calculated using the loop to determine the best model score with maximum leaf node ranged from 2 to 20. Since K Nearest is dependent on the major votes of the neighbours it is easily affected by attributes with large range as these attributes tends to dominate the other attributes which in turn affects the model performance. There are various algorithms to build decision tree such as ID3 CART C4. The mathematical symbol in skewness value indicates whether the variables is postiviely or negatively skewed. 5 with other predictors is chosen. Decision Tree Classifier Naive Bayes Classifier and K Nearest Neighbours will be modelled and evaluated to choose the best model with high performance metrics. Data are partitioned recursively from the root node to leaf node. Since dummy varialbes is created hence there is no need to perform concept hierarchy or relevelling to reduce the factor levels of the attributes. As the KNN model in this case study is built using a United States based dataset the model tends to overfit which implies that the model is only capable to predict heart disease of United States citizen but not citizens from other country. Seaborn Kdeplot A Comprehensive Guide. online Available at Accessed 4th December 2020 CDC. The outliers are handled by capping them with the acceptable range of minimum and maximum value with the Winsorization method. Feature Selection Data Reduction Feature selection is done by using the filter method as various machine learning algorithms will be applied to build various models. Life data analysis refers to data analysis involving prediction of lifetime. Data reduction involves numerosity reduction and dimensionality reduction GeeksforGeeks 2019. Exploratory Data Analysis EDA Exploratory Data Analysis EDA analyses the dataset gives insight about dataset with visuals to discover patterns and abnormalies. Statistical approaches to estimating how well a given model fits a dataset and how complex the model is calculating using the Akaike Information Criterion AIC which is derived from frequentist probability and Bayesian Information Criterion BIC which is derived from Bayesian probability. Decision trees has the capability of handling high dimensionality data with good accuracy. Hence this dataset will produce a good model as it is not biased. The distance of the newly added point with the neighbours can be calculated using Euclidean distance formula and the distance is then sorted to find the nearest neighbours. It may not be true since it is comparing in a univariate or bivariate way. As shown in the correlation matrix all attributes has absolute correlation of less than 0. However Decision Tree is easily affected by imbalanced or biased dataset. Naive Bayes Classifier is a collection of classification algorithm based on Bayes Theorem which take likelihood prior probability and posterior probability of an event into account. However the above conclusions are induced from the basic visualization of the attributes. It is suggested to have sqrt number of instances of neighbours however this is just as a guideline to decided the number of neighbours Navlani 2018. Heart Disease Prediction. Frequency Distribution Table Frequency Distribution Table for Categorical Variables are shown below which measures if the dataset is biased or having imbalance class or not. slope the slope of the peak exercise ST segment Value 1 upsloping Value 2 flat Value 3 downsloping 12. This can be seen from the boxplot plotted in data cleaning too as the boxes are approximately evenly separated. Accuracy measures how correct the predictions are precision measures how often the model is correct when predicting the positive class and recall measures how many actual positives are predicted correctly Algorithmia 2020. 5 is fairly symmetrical. Realibility Fitting Probability Distribution Probability distribution is fitted to the quantitative variables to select the best probability model. Naive Bayes Classifier assumes that each predictors are independent from each other which implies that it requires minimal multicollinearity. From the plot shown above the optimal K value is 10 with a model performance score of 88. Performance Evaluation of K Nearest Neighbour Decion Tree and Naive Bayes Classification Model Model performance of KNN Decition Tree and Naive Bayes Classifier is calculated and evaluated using accuracy F1 score and confusion matrix. 9 Measures of Central Tendency and Dispersion. 5 with target thus a bar form correlation of features with target is plotted to have better insights of the correlation. Probabilistic Model Selection with AIC BIC and MDL. Measure of Central Tendency and Dispersion Measures of central tendency of the dataset measures the center or middle of the dataset which can be measured using the mean median and mode CK 12 2020. Medical Center Long Beach and Cleveland Clinic Foundation Robert Detrano M. The KNN model devolped for this case study is considered performing well with accuracy of 88. 5 with asymptomatic chest pain with fasting blood sugar of greater than 120mg dl resting electrocardiographic showing proabable or definite left ventricular hypertropy by Estes criteria with exercise induced angina with upsloping slope of the peak exercise ST segment 0 number of major vessels colored by flourosopy and normal thal is predicted to suffer from heart disease. From the bar form correlation matrix chol and fbs has the least correlation with the target. Scatter plot matrix is useful in investigating the feature correlation and multicollinearity. Skewness with absolute value of 0. Available at Accessed 4th December 2020 Rawat S. online Available at Accessed 4th December 2020 Singh D. 5 with each other hence there will be no multicollinearity. As decision tree mimic the way human makes decision thus it is easy to understand and interpret by humans. Do you have to normalize data when building decision trees using R. It is also suggested to train the model with dataset from different locations and countries such as dataset from Asia. What is Predictive Model Performance Evaluation. 5 and F1 score of 87. As all attributes has a absolute correlation coefficient of less than 0. The Weibull 2p or 2 parameters distribution consists parameters of shape and scale where Weibull 3p or 3 parameters distribution consists paramters of shape scale and location Weibull n. Data cleaning includes handling missing values and noises data transformation includes data discretization concept hierarchy normalization and standardization. 5 with the target and absolute correlation coefficient of less than 0. Since the dataset used in this case study is not biased hence it is suitable to use Decision Tree for modeling Navlani 2018. online Available at Accesse 4th December 2020 GeeksforGeeks. online Available at Accessed 4th December 2020 Khurana S. validate model by using test set to predict decision tree. From the bar chart of Age versus frequency age of 41 to 45 and 51 to 54 are having a high amount of heart disease impling that they are highly risked people to have heart disease. Hence the maximum leaf node is set to 9 to provide a better accuracy results. Model Development dataset2 is used for model development which consists of dummy variables created from categorical variables as shown in Data Preprocessing while doing Data Transformation. online Available at Accessed 4th December 2020 Kumar A. In this assessment various classification models will be developed and evaluated to determine the best model for prediction of heart disease in United States citizens. F1 score is a harmonic balance between precision and recall which is commonly used for biased dataset. The higher density of KDE plots implies the high probability of occurence. oldpeak ST depression induced by exercise relative to rest 11. online Available at Accessed 4th December 2020 Ash3323 Taylor J. cp 4 values chest pain type Value 1 typical angina Value 2 atypical angina Value 3 non anginal pain Value 4 asymptomatic 4. EDA process involves exploring the dimension of dataset central tendency and dispersion of dataset summary statistics and others which will be demonstrated below. As each type of heart diseases has different kind of symptoms and all symptoms are complicated thus it is difficult to identify the presence of heart disease. Thus K value for this case study is set to 10. From the scatter plot person with high heart rate and low blood pressure will have higher chance to suffer from heart disease. Suggestions mentioned above can be implemented for a better prediction model that will be used not only in United States but also all over the world with high accuracy and precise prediction. Dummy Variables Data Transformation Data transformation is done by converting categorical attributes to dummy variables for the ease of model construction using the. Naive Bayes Classifiers. From the scatter plot a higher heart rate implies a higher chance of having heart disease. Hence prediction of heart disease is one of the most important focus in the section of clinical data analysis Rawat 2019. Why do you need to scale data in KNN. From the confusion matrix KNN model has the lowest FN among the other models hence KNN is more preferable. online Available at Accessed 4th December 2020 McNeese B. The model with the best performance will then be used identify if a person with the given conditions is suffering from heart disease or not. thalach maximum heart rate achieved 9. ca number of major vessels 0 3 colored by flourosopy 13. online Available at Accessed 4th December 2020 Kaufmann J. Everything You Need To Know About Heart Disease. From the plot above the optimal maximum number of leaf nodes is 6 to 9 with model score of 77. The Coefficient of Variation CV is calculated by dividing standard deviation by mean. This is to determine the best model that best fit this case study of prediction of presence of heart disease. Data Preprocessing Data preprocessing is the one of the major step in building a machine learning algorithms as only quality and clean dataset produces quality model that gives quality results. However all predictors or independent variable has a absolute correlation coefficient of less than 0. In conclusion the KNN model best fits the case study to predict if a United States citizens suffers from heart disease or not. This would help to reduce the mortality rate caused by heart disease. Hence to determine the optimal K number of neighbours for this case study the model performance scorse is calculated and assessed for K of 1 to 20 using looping. The dataset description are as below UCI Machine Learning Repository n. The original dataset consists of 76 attributes but published experiments refer the dataset using a subset of 14 attributes with 303 instances. Since the model built in this case study is classification model thus confusion matrix is used. Hence normalization is done to have a good KNN model performance. The accuracy and F1 score of KNN is also higher compared with Decision Tree and Naive Bayes Classifier with accuracy of 88. Thus KNN is chosen to be the model to predict presence of heart disease in this case study. Are the Skewness and Kurtosis Useful Statistics. online Available at Accessed 4th December 2020 UCI Machine Learning Repository. Decision Tree Classification in Python. Dimension and Variables or Attributes of Dataset The dataset is a dataframe with dimension consists of 31 features including the dummy variables and 301 instances as shown using the. Data Preprocessing in Data Mining. Visualization of Attributes Attributes are visualized to discover general patterns in the attributes and have a rough conclusion about the attributes. A precise conclusion or rules should be extracted from the classification model. Naive Bayes Classifier also assumes that each predictors contributes equally to the outcome which implies that they all have the same probability to contribute to the outcome Khurana 2020. References Algorithmia. Heart Disease Data Set. trestbps resting blood pressure in mm Hg on admission to the hospital 5. Measures of dispersion of the dataset measures how disprese or spread out the data in the dataset are. age sex thalach slope thal and target is negatively skewed and other attributes are positively skewed. Heart disease includes Arrythymia Atherosclerosis Cardioyopathy Congenital heart defects Coronary artery disease CAD and heart infections which is caused by various factors including heart defects anxiety diabetes excessive use of alcohol and caffeine and others Whitworth 2020. online Available at Accessed 4th December 2020 Navlani A. The dataset does not consist any missing values as shown in the code segment. online Available at Accessed 4th December 2020 JornalDev. As shown in the histograms and scatter plots all the attributes are considered less disperse. online Available at Accessed 4th December 2020 Weibull. Features with absolute correlation coefficient of greater than 0. As Cleveland is one of the major city in United States the dataset used is relevant for use in prediction of heart disease in United States citizen. Handling Duplicates and Outliers Data Cleaning Missing values are detected using the isnull syntax. The normal distribution has a skewness of 0 McNeese 2016. chol serum cholestoral in mg dl6. Filter method is chosen as wrapper method such as Reduce Feature Elimination RFE function in scikit learn is limited to certain machine learning algorithms such as linear regression and decision tree. Weibull Distribution and Weibull Analysis. The boxplot for quantitative attributes which are age trestbps chol thalach and oldpeak is plotted and outliers is detected for the mentioned attributes except age using IQR outlier detection method. KNN Classification using Scikit learn. The DecisionTreeClassifier from Sckit learn is using CART algorithm to build decision tree. In FN patients with heart disease is classified as no heart disease this might cause delay in treatment for the patient due to misdiagnosis and wrong prediction by the model causing death in serious cases. target 1 presence 0 absence The dataset consisting 5 quantitative attributes which are age trestbps chol thalach and oldpeak 9 qualitative categorical attributes which are sex cp fbs restecg exang slope ca thal and target. In filter method only relevant features are taken. AIC and BIC works in a similar way but they focus on different situation. Dataset The dataset used is the Heart Disease Data Set from the Cleveland database created in 1988 by V. For classification model confusion matrix is used for regression model methods such as root mean square error RMSE mean absolute error MAE relative absolute error RAE and others are used Singh 2019. The model developed will reduce the burden for healthcare instituition as it is able to identify and predict the presence of heart disease efficiently. Interpretation of Model The KNN model is interpreted by giving an unknown new data for prediction as shown below. Evaluating machine learning models with a confusion matrix. Normalization is done after Train and Test dataset split using the MinMaxScaler Kedarps 2017. Characteristics of the Weibull Distribution. restecg resting electrocardiographic results values 0 1 2 Value 0 normal Value 1 having ST T wave abnormality T wave inversions and or ST elevation or depression of 0. Data preprocessing involves data cleaning data transformation and data reduction. online Available at Accessed 5th November 2020 Stephanie. The IQR outlier detection method accepts range of values from Q1 1. get_dummies syntax. Available at Accessed 4th December 2020 Navlani A. ", "id": "janrauhl/heart-disease-prediction-w-knn-naivebayes-trees", "size": "27902", "language": "python", "html_url": "https://www.kaggle.com/code/janrauhl/heart-disease-prediction-w-knn-naivebayes-trees", "git_url": "https://www.kaggle.com/code/janrauhl/heart-disease-prediction-w-knn-naivebayes-trees", "script": "train_test_split IPython.display confusion_matrix get_dummies accuracy_score numpy seaborn plot_tree f1_score GaussianNB sklearn.neighbors sklearn.naive_bayes sklearn.tree Fit_Everything matplotlib.pyplot DecisionTreeClassifier MinMaxScaler sklearn.model_selection pandas KNeighborsClassifier display sklearn.metrics reliability.Fitters sklearn.preprocessing ", "entities": "(('CV value', 'low variance'), 'indicate') (('Weibull where 3p', 'shape scale'), 'consist') (('Hence normalization', 'KNN model good performance'), 'do') (('they', 'free parameters'), 'indicate') (('dataset', 'patterns'), 'Analysis') (('however this', 'neighbours'), 'suggest') (('it', 'good model'), 'produce') (('learning supervised machine which', 'nodes'), 'be') (('chart female', 'heart disease'), 'tend') (('original dataset', '303 instances'), 'consist') (('hence normalization', 'such normalization'), 'affect') (('Normalization', 'MinMaxScaler Kedarps'), 'do') (('mV 2 showing', 'Estes'), '05') (('AIC', 'probability distribution best model'), 'take') (('thus it', 'humans'), 'be') (('Data Missing values', 'isnull syntax'), 'handle') (('normal distribution', '0 McNeese 2016'), 'have') (('Filter method', 'such linear regression'), 'choose') (('Weibull 2P', 'quantitative attributes'), 'fit') (('hence normalization', 'Dernoncourt'), 'affect') (('hence KNN', 'other models'), 'be') (('which', 'commonly biased dataset'), 'be') (('distance', 'then nearest neighbours'), 'calculate') (('You', 'Heart Disease'), 'everything') (('F1 sometimes thus score', 'model also performance'), 'use') (('variables', 'moderately target'), 'be') (('optimal number', '20'), 'calculate') (('exang exercise', 'angina'), 'induce') (('which', 'given symptoms'), 'learning') (('bar form thus correlation', 'correlation'), 'plot') (('then newly added unknown point', 'heart disease'), 'consider') (('It', 'Asia'), 'suggest') (('they', 'outcome'), 'assume') (('why we', 'hypothesis'), 'have') (('age trestbps chol outliers', 'detection IQR outlier method'), 'plot') (('error MAE error absolute relative absolute RAE', 'regression model methods'), 'use') (('thus it', 'heart disease'), 'have') (('Data cleaning', 'data discretization concept hierarchy normalization'), 'include') (('that', 'functioning performance'), 'describe') (('you', 'good standard deviation'), 'consider') (('Coronary artery disease heart which', 'alcohol'), 'include') (('Prediction', 'healthcare institutions'), 'achieve') (('categorical attributes', 'total'), 'transform') (('model', 'other country'), 'dataset') (('scatter However plot', 'absolute value'), 'disperse') (('classification various models', 'United States citizens'), 'develop') (('dataset', 'imbalance class'), 'show') (('Decision trees', 'good accuracy'), 'have') (('dataset', 'first five dataset'), 'load') (('which', 'Data Transformation'), 'use') (('Bayesian Information Criterion which', 'Bayesian probability'), 'approach') (('Correlation Matrix Correlation Matrix heatmap', 'Data Data Preprocessing'), 'show') (('heart higher rate', 'heart disease'), 'imply') (('then person', 'heart disease'), 'use') (('Naive Bayes hence Classifier', 'case study'), 'be') (('scatter where plot', 'variables'), 'be') (('only relevant features', 'filter method'), 'take') (('KNN model', 'prediction'), 'interpretation') (('qualitative categorical which', 'raw dataset'), 'consist') (('which', 'summary dataset statistics'), 'involve') (('which', 'misleading prediction'), 'be') (('This', 'heart disease'), 'help') (('Skewness', 'symmetry'), 'measure') (('dataset', 'United States citizen'), 'be') (('DecisionTreeClassifier', 'decision tree'), 'use') (('Scatter plot matrix', 'feature correlation'), 'be') (('BIC', 'only True models'), 'attempt') (('However predictors', 'less than 0'), 'have') (('variables', 'skewness value'), 'indicate') (('they', 'heart highly risked disease'), 'have') (('that', 'quality results'), 'be') (('thus attributes', 'dataset'), 'remove') (('Visualization', 'attributes'), 'visualize') (('dataset', '301 the'), 'dimension') (('data perfectly symmetrical set', '0'), 'have') (('United States citizens', 'heart disease'), 'fit') (('thus 9', 'better accuracy'), 'available') (('Thus KNN', 'case study'), 'choose') (('precise conclusion', 'classification model'), 'extract') (('T', 'ST 0'), 'value') (('scatter attributes', 'histograms'), 'consider') (('plots', 'sex'), 'left') (('Negatives False which', 'confusion matrix'), 'study') (('hence it', 'Navlani'), 'be') (('it', 'minimal multicollinearity'), 'assume') (('accuracy', '88'), 'be') (('K Thus value', '10'), 'set') (('it', 'heart disease'), 'reduce') (('male which', '2'), 'from') (('it', 'unique values'), 'consider') (('respectively IQR', 'interquartile range'), 'IQR') (('Coefficient', 'mean'), 'calculate') (('efficiently early treatment', 'better recovery'), 'reduce') (('dataset description', 'UCI Machine Learning Repository as n.'), 'be') (('it', 'univariate way'), 'be') (('attributes', 'less than 0'), 'have') (('Dummy variables', 'mutually exclusive categories'), 'use') (('various machine learning algorithms', 'various models'), 'do') (('outliers', 'Winsorization method'), 'handle') (('you', 'R.'), 'have') (('Decision However Tree', 'easily imbalanced biased dataset'), 'affect') (('heart disease', 'evenly big count'), 'consider') (('dataset', 'now duplicates'), 'be') (('Performance Evaluation', 'Naive Bayes accuracy F1 score'), 'calculate') (('dataset', 'different requirements'), 'be') (('this', 'serious cases'), 'classify') (('which', 'sex cp fbs restecg exang thal'), 'target') (('which', 'account'), 'be') (('that', 'heart'), 'describe') (('which', 'model performance'), 'be') (('Life data analysis', 'lifetime'), 'refer') (('Data', 'learning human process'), 'transform') (('5 to 1', 'moderately highly more than 1'), 'be') (('histogram plot', 'data central points'), 'be') (('Part', 'correlation matrix plot'), 'perform') (('how many actual positives', 'when positive class measures'), 'measure') (('IQR', 'Q1'), 'accept') (('it', 'unknown data'), 'help') (('KNN thus model', 'United States more citizens'), 'be') (('higher density', 'occurence'), 'imply') (('It', 'variation also Kaufmann'), 'measure') (('model performance scorse', 'looping'), 'study') (('Weibull distribution', 'life data versatility'), 'use') (('probability also JournalDev', 'variable'), 'associate') (('classification confusion thus matrix', 'case study'), 'be') (('leaf Hence maximum node', 'accuracy better results'), 'set') (('scatter plot matrix', 'grid form Kumar'), 'represent') (('However above conclusions', 'attributes'), 'induce') (('Dummy Variables Data Transformation Data transformation', 'the'), 'do') (('year that', 'CDC n.'), 'be') (('which', 'mean median'), 'measure') (('exercise ST segment 0 number', 'heart disease'), 'rest') (('dummy varialbes', 'attributes'), 'be') (('dataset', 'V.'), 'Dataset') (('dataset', 'code segment'), 'consist') (('that', 'high accuracy'), 'implement') (('they', 'different situation'), 'work') (('devolped', '88'), 'consider') (('Decision Tree Classifier Naive Bayes Classifier', 'performance high metrics'), 'model') (('accuracy high model', 'United States citizens'), 'use') (('Data reduction', 'numerosity reduction'), 'involve') (('approximately thus they', 'quantitative attributes'), 'be') (('lower score', 'probability distribution better model'), 'indicate') (('product commonly assess reliability', 'industry economic Stephanie'), 'use') (('X', 'probability specific distribution'), 'calculate') (('too boxes', 'data cleaning'), 'see') (('Realibility Fitting Probability Distribution Probability distribution', 'probability best model'), 'fit') (('Hence prediction', 'data analysis clinical Rawat'), 'be') (('Data', 'node'), 'partition') (('Data preprocessing', 'data transformation reduction'), 'involve') (('that', 'heart disease'), 'be') (('it', 'neighbours 10 nearest votes'), 'add') "}
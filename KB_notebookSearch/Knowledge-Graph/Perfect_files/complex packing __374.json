{"name": "complex packing ", "full_name": " h3 general jupyter and cv2 utility helpers h3 cv2 contour bounding rect extraction h3 write bounding rects to a cache h3 rectangle cropping and scaling helpers h3 rectangle and image packing helpers h3 get image packer for defining packers ", "stargazers_count": 0, "forks_count": 0, "description": "index show_image_row pack_images chunks_of i 1 0 for i in df. general jupyter and cv2 utility helpers cv2 contour bounding rect extraction write bounding rects to a cache rectangle cropping and scaling helpers rectangle and image packing helpers get_image_packer for defining packersbusiness are connecting 1 to another a37b456a2bc920630c60c2ff0c7d6325 I could have gotten them smaller if I had just munged outliers level 0 is shape 13312 15360 level 1 is shape 3328 3840 4 level 2 is shape 832 960 16 center float float size float float theta float am fairly salty about this https www. level_2_packed pack_run. index i show_image_row chunks_of 00928370e2dfeb8a507667ef1d4efcbb 0 i. json recontouring_pack_run. resize print datetime. resize int 15360 16 int 13312 16 resample Image. index print datetime. index try show_image_row pack_images chunks_of sample 2 0 figsize 50 20 except Exception as e print sample raise e result metrics get_image_packer 128 6 128 6 retry_halved 4 retry_eager_splits 12 chunks_of 1836f6539ccc9e37d426603cc4526f8b result whats_up_with 1836f6539ccc9e37d426603cc4526f8b slender denny and lenny big bertha 10000 128 20 128 6 3 8 bytes to gigabytes is 7. now Get center size and angle from rect convert to rad chunk_source_shape is height width rgb generic rect packer if tuple contains two elements assume they are width and height and origin is 0 0 empty PackNode PIL crop boxes areas are left upper right lower PIL crop boxes areas are left upper right lower PIL crop boxes areas are left upper right lower Crop empty space Remove by row Remove by column crop box is left upper right lower crop box is left upper right lower skip all white chunks abstracted out halve_image into split_strategy so we can retry with recontouring todo this exception handling error checking is bad ugly pack_images get_image_packer 128 20 128 6 retry_halved 4 get_image_packer 128 8 128 8 retry_halved 4 pack_images_hi get_image_packer 4 128 30 4 128 10 s a10eb69fb260132fde150bd76bd7b15c a6a7146bd23b394f54a5950d2dbefa7b 1836f6539ccc9e37d426603cc4526f8b pack_images get_image_packer 128 20 128 6 retry_halved 4 packed for i in range 0 3 for i in df. now print datetime. index d datetime. index figsize 50 20 p get_image_packer 128 8 128 8 retry_halved 4 retry_eager_splits 6 4 bigboys pack_images chunks_of i for i in failures print b 1 for b in bigboys show_image_row b 0 for b in bigboys figsize 50 20 show_image_row chunks_of 000920ad0b612851f8e01bcc880d9b3d pack_images get_image_packer 128 8 128 8 retry_halved 4 recontour_at 1. 0 pack_hi get_image_packer 4 128 8 4 128 8 retry_halved 4 datetime. now show_image_row _flatten pack_images chunks_of i 0 pack_hi chunks_of i 1 0 for i in df. MAX_IMAGE_PIXELS 268435456 1 metrics pack_images chunks_of sample 2 sample 1 for sample in df. append p print metrics show_image_row packed chunks packed image_id info list chunk_window_cache. index try metrics. append pack chunks_of sample 2 sample 1 except Exception as e print f sample failed s sample failures. This is ok for now but won t be for level 1 output_dimensions 128 20 128 6 128 13 128 5 saved under run_1664x640 128 12 128 4 under run_1536x512 whats_up_with 01571191abf6e8e209111e819823759b or df. now pack_hi get_image_packer 16 128 8 16 128 8 retry_halved 4 recontour_at 1 16 s pack_hi chunks_of i 0 for i in df. index chunks chunks_of i level 2 p metrics pack_images chunks i packed. append sample return metrics failures metrics failures consider_packer whats_up_with failures metrics failures consider_packer get_image_packer 128 8 128 8 retry_halved 4 retry_eager_splits 6 4 len metrics get_image_packer 128 8 128 8 retry_halved 4 retry_eager_splits 6 4 chunks_of failures 0 whats_up_with failures show_image_row get_image_packer 128 10 128 10 retry_halved 8 retry_eager_splits 6 4 chunks_of s s 0 for s in a10eb69fb260132fde150bd76bd7b15c 1836f6539ccc9e37d426603cc4526f8b 1f368e9829e850bd6b6de7a521376720 000920ad0b612851f8e01bcc880d9b3d 031f5ef5b254fbacd6fbd279ebfe5cc0 004391d48d58b18156f811087cd38abf metrics consider_packer show_slides s show_image_row chunks_of s i pack_images chunks_of s 2 0 i show_image_row pack_images chunks_of s 2 0 for s in 1836f6539ccc9e37d426603cc4526f8b 1f368e9829e850bd6b6de7a521376720 000920ad0b612851f8e01bcc880d9b3d 031f5ef5b254fbacd6fbd279ebfe5cc0 004391d48d58b18156f811087cd38abf show_slides s show_image_row chunks_of s show_image_row print np. 3728 gigabytes tarred will be 3. now h Image. rotate 90 expand True i metrics pack_images chunks_of 1836f6539ccc9e37d426603cc4526f8b 2 i 0 s 1f368e9829e850bd6b6de7a521376720 def whats_up_with image_ids for image_id in image_ids show_slides image_id show_image_row chunks_of image_id def consider_packer pack pack_images n None metrics global s failures for index sample in enumerate df. now h m pack_hi chunks_of a10eb69fb260132fde150bd76bd7b15c 1 cv2. __version__ print datetime. BILINEAR print datetime. array c or c for c in chunks_of s for sample in samples df. index loosen retry_halved for our special case mv. com product feedback 99742 show_image_row chunks_of 000920ad0b612851f8e01bcc880d9b3d 0 645x137 wsi pil_tiff_frame str TRAIN 000920ad0b612851f8e01bcc880d9b3d. items 0 samples 000920ad0b612851f8e01bcc880d9b3d 031f5ef5b254fbacd6fbd279ebfe5cc0 004391d48d58b18156f811087cd38abf get_image_packer 128 10 128 8 chunks_of 031f5ef5b254fbacd6fbd279ebfe5cc0 031f5ef5b254fbacd6fbd279ebfe5cc0 0 s pack_images chunks_of i 1 for i in df. ", "id": "micimize/complex-packing", "size": "374", "language": "python", "html_url": "https://www.kaggle.com/code/micimize/complex-packing", "git_url": "https://www.kaggle.com/code/micimize/complex-packing", "script": "pathlib pyplot reject_outliers pack_images whats_up_with eager_splits cropped_contours_of Path _pack height skimage.io matplotlib.pyplot scale_factor PIL meaningful_pixels cv2_threshold recontour_parts cv2_image reject_outlying_deltas matplotlib.image sum_values write_json show_image_row where_not_none scaled_rect imread count_where pil_image scaled_chunks_of consider_packer pandas area_below _longest_side_ascending _reduce_bounding_boxes matplotlib filled_bounding_box cv2_tiff_frame center_bounds pil_to_cv2 to_timedelta get_image_packer insert numpy Image __repr__ _max_bounds cv2_to_pil halve_image tissue_chunk_windows_of interleave typing try_inplace_center pil_tiff_frame _can_contain cut_empty_space imshow PackNode(object) pyplot as plt crop_tilted_rect get_chunk_loader write_packed_images area_from_upper_left read_json Timedelta area_to_right_of show_slides contours_of MultiImage chunks_of halve_and_recontour figure datetime axis _tilted_rect_area __init__ width write_chunk_windows summarize_metrics ", "entities": "(('i', '0 i.'), 'show_image_row') (('a10eb69fb260132fde150bd76bd7b15c 128 4 10 1836f6539ccc9e37d426603cc4526f8b pack_images', 'df'), 'be') (('slender 3 128 6 128 6 4 retry_eager_splits 12 1836f6539ccc9e37d426603cc4526f8b whats_up_with 1836f6539ccc9e37d426603cc4526f8b denny big 10000 128 20 128 6 8 bytes', 'gigabytes'), 'try') (('packed chunks', 'info list chunk_window_cache'), 'show_image_row') (('items 0 004391d48d58b18156f811087cd38abf', 'df'), 'sample') (('2 0 i', '1836f6539ccc9e37d426603cc4526f8b 1f368e9829e850bd6b6de7a521376720'), 'failure') (('268435456 1 metrics', 'df'), 'pack_image') (('def consider_packer pack_images None', 'enumerate df'), 'rotate') (('This', 'whats_up_with 128 12 128 4 01571191abf6e8e209111e819823759b'), 'be') (('index show_image_row', 'df'), 'pack_images') (('pack_images', '128 8 128 8'), 'figsize') (('center float float size float float theta 1 3328 3840 4 level 2 832 960 16 float', 'https fairly www'), 'write') (('i', 'chunks'), 'chunk') "}
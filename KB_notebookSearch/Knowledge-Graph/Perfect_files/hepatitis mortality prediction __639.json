{"name": "hepatitis mortality prediction ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "Univariate and Multivariate analysisFeature selection and importance strong realtion with output Model deployment linear algebra data processing CSV file I O e. The Notebook uses different Machine Learning algorithms to predict whether the person will die or survive based on characteristics w. It uses Logistic Regression Decision tree calssifier and KNN. read_csv load datasets ignoring albumin and bilirubin as they are float values plotting 1 male 2 female plot gender pie chart plot of frequency Methods boxplt scatterplot Zscore InterQuartile range Boxplot Univariate scatterplot multivariate using IQR H spread Mid_spread measure the statistical dispersion IQR quantile 3 75 1 25 True Outliers removing all values that are outliers i. The notebook has EDA and Prediction. Here Columns Are assigned names Column names are lowered for better understanding Convert all columns to numeric i. int or floatUsing matplotlib graphs with diferrent dimensions are plotted for simple EDA. The dataset is taken from UCI repositry. e True values plot of distribution of data SelectKbest features and labels transform mapping to features and values concat those 2 df higher the number the more importatnt feature get 10 high values Recurssive Feature Elimination selection selection eliminate lower values ranking or True Extra tree classifier heat map for correlation Feature and Labels train test split Logistic Regression KNN DCT Initial features Selected Features original dataset best features of dataset Logistic Regression 1 Die 2 Live. Checking for outliers i. ", "id": "sm261998/hepatitis-mortality-prediction", "size": "639", "language": "python", "html_url": "https://www.kaggle.com/code/sm261998/hepatitis-mortality-prediction", "git_url": "https://www.kaggle.com/code/sm261998/hepatitis-mortality-prediction", "script": "sklearn.feature_selection train_test_split RFE accuracy_score numpy seaborn ExtraTreesClassifier chi2 sklearn.neighbors sklearn.tree sklearn.linear_model matplotlib.pyplot DecisionTreeClassifier sklearn.model_selection pandas SelectKBest RandomForestClassifier LogisticRegression KNeighborsClassifier sklearn.metrics sklearn.ensemble ", "entities": "(('True tree classifier heat correlation train test Logistic Regression KNN DCT Extra Feature Initial', 'Logistic dataset Regression'), 'concat') (('It', 'Logistic Regression Decision tree calssifier'), 'use') (('Column names', 'numeric i.'), 'assign') (('that', 'dispersion IQR True Mid_spread statistical 3 1 25 values'), 'dataset') (('matplotlib int graphs', 'simple EDA'), 'plot') (('person', 'characteristics w.'), 'use') "}
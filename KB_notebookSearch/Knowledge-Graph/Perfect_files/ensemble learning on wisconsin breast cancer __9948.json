{"name": "ensemble learning on wisconsin breast cancer ", "full_name": " h1 Table of Contents h1 1 Installing Importing Libraries h3 1 1 Installing Libraries h3 1 2 Upgrading Libraries h3 1 3 Importing Libraries h1 2 Data Acquisition Description h3 2 1 Data Description h3 2 2 Data Information h1 3 Data Pre Processing h3 3 1 Pre Profiling Report h2 Similarly we can explore information for rest of features from the report h4 Question 1 h4 Question 2 h2 h4 Question 6 h1 4 Exploratory Data Analysis h2 h4 Question 3 h2 We will resolve this issue in our further analysis h4 Question 4 h1 5 Post Data Processing Feature Selection h4 Question 5 h4 Question 6 h1 6 Model Development Evaluation h2 Remember that we want generalize results i e same results or error on testing data as that of training data h4 Question 7 h4 Question 8 h4 Question 9 h4 Question 10 h2 We can use different model like LogisticRegression DecisionTreeClassifier SVC to create a voting classifier h4 Question 11 h4 Question 12 h2 We can see that all models generalize well on the test set without overfitting h4 Question 13 h1 7 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "09 Mitosis Cancer is essentially a disease of uncontrolled mitosis. Question 1 Create a function that drops the redundant rows and displays the frequency of final rows. We approached this problem using build different ensemble methods where the voting classifer and random forest gave us the highest accuracy scores. Question 12 Create a function to create a dataframe to compare the scores of different models. You have to use the hyperparameters setting of the model as following n_neghbors 70 and random_state 42 Question 10 Create a function to create an ensemble model using Voting Classifier. 2 Upgrading Libraries Section12 1. 1 Data Description Section21 3. 75 of the cancer cell have Bland Chromatin less than equal to 5. Records Features Dataset Size 699 11 88. Observations We can see that the value in the Bare nuclei is replaced with 0. Split the data into 80 20 inside train_test_split. Create a list with different models and use for loop to predict on train and test set. Uniformity of Cell Shape is highly correlated with Uniformity of Cell Size Similarly we can explore information for rest of features from the report. Make sure not to execute the cell above 3. Those are typically seen in benign tumors. Similarly we can understand the statistical inference for other features. Observation We can observe that their is a unique feature that uniquely identifies each data point. 1 Installing Libraries 1. Observation We can see that Mitosis column is negatively correlated with clump Thickness and Bland Chromatin columns. 3 Importing Libraries Section13 2. 2 Upgrading Libraries After upgrading the libraries you need to restart the runtime to make the libraries in sync. Observation We can see that the data is quite imbalanced. 1 Pre Profiling Report Observation The report shows that there are 11 features out of which 2 is categorical and 9 is numerical. Remember that we want generalize results i. Installing Importing Libraries 1. 50 of the cancer cell have Clump Thickness less than equal to 4. Observation We can see that stacking classifier gives us pretty good accuracy scores the other models. 05 Marginal Adhesion Normal cells tend to stick together. Data Pre Processing 3. Installing Importing Libraries Section1 1. 10 Class Benign non cancerous or malignant cancerous lump in a breast. Then we will analyze the results obtained and make our observation. 2 B Id Feature Description 01 Sample code number Unique code for each sample. There exists 0 missing values and 8 redundant data points. You have to use the hyperparameters setting of the model as following base_estimator Logistic Regression n_neghbors 500 and random_state 42 Question 8 Create a function to instantiate RandomForest Classifier. Make sure to set the random_state 42. In cancer cells the chromatin tends to be more coarse. Use transpose method to make the data frame more readable. Their are plethora of other ensemble techniques you can try on to build a better model with better accuracy score. We will resolve this issue in our further analysis. Using the StandardScaler function transform scale the data in suitable format for the model. Conclusion Section7 1. same results or error on testing data as that of training data. Print accuracy for different models with the model name. corr function to find the correlation between the features in the data. You can also add proportions onto your plot. 2 again after restarting the runtime. 04 Uniformity of Cell Shape Cancer cells tend to vary in size and shape. 25 of the cancer cell have Bland Chromatin less than equal to 2. Question 6 Create a function to replace in Bare Nuclei with 0 Print the unique values in Bare Nuclei after the opreation is performed. Use StackingClassifier from mlxtend to create the model. Using pandas DataFrame method create a data frame to compare accuracy score of different models. Use cross validation score to predict on the entire dataset with following parameters estimator clf stacked models X X y y cv 3 scoring accuracy Note that use the whole dataset. Post Data Processing Feature Selection Question 5 Prepare the data according to the model requirements. 06 Single Epithelial Cell Size Epithelial cells that are significantly enlarged may be a malignant cell. Question 7 Create a function to instantiate Bagging classifer. Table of Contents 1. Question 13 Create a function to stack different models to create a stacking classifier. 08 Bland Chromatin Describes a uniform texture of the nucleus seen in benign cells. Observation We can see that there is 1 features with object datatype and 10 features as int datatype. Model Development Evaluation Section6 7. Question 11 Create a function to predict accuracy score in both train and test dataset using different models. 07 Bare Nuclei This is a term used for nuclei not surrounded by cytoplasm the rest of the cell. Observations 25 of the cancer cell have Clump Thickness less than equal to 2. 50 of the cancer cell have Bland Chromatin less than equal to 3. Use 500 logistic regression classifiers to create a bagging method. 02 Clump Thickness Benign cells tend to be grouped in monolayers while cancerous cells are often grouped in multilayers. 03 Uniformity of Cell Size Cancer cells tend to vary in size and shape. 3 Importing Libraries 2. We can use different model like LogisticRegression DecisionTreeClassifier SVC to create a voting classifier. For evaluation purpose we will focus on accuracy score. Observation We can see that RandomForest model has the best accuracy scores among the models. We can see that all models generalize well on the test set without overfitting. Question 2 Create a function that drops Sample code number feature from the dataset. Data Pre processing Section3 3. 75 of the cancer cell have Clump Thickness less than equal to 6. Model Development Evaluation In this section we will develope different ensemble methods. So the loss of adhesion is a sign of malignancy. We can also see that uniformity of Cell Shape is higly correlated with uniformity of Cell Size. 2 Data Information In this section we will get information about the data and see some observations. Post Data Processing Feature Selection Section5 6. 08 Normal Nucleoli In cancer cells the nucleoli become more prominent and sometimes there are more of them. Data Acquisition Description Section2 2. We can drop this feature because it won t provide any necessary infomation. Question 6 Create a function to normalize the data. 1 Installing Libraries Section11 1. Exploratory Data Analysis Question 3 Create a function that displays the frequency of Malignant and Benign tumors in the class column You can plot the frequency distribution using seaborn countplot function. 1 Pre Profiling Report Section31 4. Store the result of train and test scores in different list. Conclusion We analyzed and understood different factors to classify if the tumor is benign or malignant. You can plot the frequency distribution and proportion using seaborn countplot function. Use seaborn heatmap function to plot the following. Cancer cells tend to lose this ability. Build stacking classifier using KNN RadomForest and Naive Bayes use LogisticRegression as meta_classifier. Write a function plot_corr function to create a heatmap of size 10 7. 1 Data Description In this section we will get description and statistics about the data. Exploratory Data Analysis Section4 5. You have to use the hyperparameters setting of the model as following n_neghbors 100 and random_state 42 Question 9 Create a function to instantiate AdaBoost Classifier. Write a function data_prep to structure the data according to model requirement. Data Acquisition Description This corpus has been collected from free research sources on the Internet and it can be retrieved from the attached link. We can also try experimenting with various hyperparameter to improve model accuracy. Question 4 Create a function that displays the correlation between different features. ", "id": "ashishlepcha/ensemble-learning-on-wisconsin-breast-cancer", "size": "9948", "language": "python", "html_url": "https://www.kaggle.com/code/ashishlepcha/ensemble-learning-on-wisconsin-breast-cancer", "git_url": "https://www.kaggle.com/code/ashishlepcha/ensemble-learning-on-wisconsin-breast-cancer", "script": "plot_class random_forest data_prep accuracy_score                 # For precision and recall metric estimation Counter                                                   # For estimating frequency classification_report                                 # To generate complete report of evaluation metrics scale_data StandardScaler                                  # Importing Standard Scaler library from preprocessing. mlxtend.classifier files                   # Use only if you are using Google Colab precision_recall_curve sklearn.svm numpy seaborn stacking_clf train_test_split                              # To split the data in training and testing part pandas_profiling ProfileReport                                        # Import Pandas Profiling (To generate Univariate Analysis) BaggingClassifier                 # Loading differernt ensemble models cross_val_score                               # Importing cross validation score from model selection GaussianNB sklearn.neighbors sklearn.naive_bayes sklearn.tree plot_confusion_matrix replace_unwanted drop_duplicate_data predict_scores otherwise remove it sklearn.linear_model sklearn create_frame drop_features google.colab matplotlib.pyplot LogisticRegression                               # Loading Logistic regression from linear model sklearn.model_selection pandas VotingClassifier             # Loading differernt ensemble models RandomForestClassifier votingClass adaBoost model_selection SVC                                                       # Loading SVM from  Sklearn DecisionTreeClassifier                                   # Loading decision tree classifier from tree plot_corr KNeighborsClassifier AdaBoostClassifier StackingClassifier collections ensemble_log sklearn.metrics sklearn.ensemble roc_auc_score                   # To plot confusion matrix sklearn.preprocessing ", "entities": "(('chromatin', 'cancer cells'), 'tend') (('Mitosis column', 'Bland negatively clump Thickness columns'), 'see') (('opreation', 'Bare Nuclei'), 'create') (('Bland Chromatin', 'benign cells'), 'describe') (('50', 'less equal 3'), 'have') (('Bare This', 'cell'), '07') (('tumor', 'different factors'), 'analyze') (('Question', 'different models'), 'create') (('we', 'results generalize i.'), 'remember') (('models', 'overfitting'), 'see') (('25', 'less equal 2'), 'have') (('Question', 'test different models'), 'create') (('Mitosis 09 Cancer', 'essentially uncontrolled mitosis'), 'be') (('75', 'less equal 6'), 'Clump') (('Uniformity', 'size'), 'tend') (('Those', 'typically benign tumors'), 'see') (('we', 'different ensemble methods'), 'Evaluation') (('also uniformity', 'Cell Size'), 'see') (('you', 'accuracy better score'), 'be') (('DataFrame method', 'different models'), 'create') (('we', 'observations'), 'Information') (('that', 'final rows'), 'create') (('9', '11 which'), 'Observation') (('it', 'attached link'), 'Description') (('you', 'sync'), 'Libraries') (('voting where classifer', 'accuracy random highest scores'), 'approach') (('We', 'further analysis'), 'resolve') (('cancerous cells', 'often multilayers'), 'tend') (('stacking classifier', 'other models'), 'see') (('We', 'model accuracy'), 'try') (('Build', 'meta_classifier'), 'use') (('You', 'RandomForest Classifier'), 'have') (('Similarly we', 'report'), 'explore') (('Then we', 'observation'), 'analyze') (('Observations', 'less equal 2'), 'Clump') (('we', 'data'), 'description') (('Similarly we', 'other features'), 'understand') (('unique that', 'data uniquely point'), 'observe') (('You', 'countplot seaborn function'), 'create') (('value', '0'), 'see') (('nucleoli', 'more sometimes them'), 'Nucleoli') (('75', 'less equal 5'), 'have') (('we', 'accuracy score'), 'focus') (('RandomForest model', 'models'), 'see') (('Question', 'data'), 'create') (('We', 'voting classifier'), 'use') (('You', 'plot'), 'add') (('Post Data Processing Feature Selection Question', 'model requirements'), 'prepare') (('You', 'countplot seaborn function'), 'plot') (('50', 'less equal 4'), 'Clump') (('that', 'dataset'), 'create') (('So loss', 'malignancy'), 'be') (('You', 'Voting Classifier'), 'have') (('frame', 'transpose method'), 'use') (('Question', 'stacking classifier'), 'create') (('it', 'necessary infomation'), 'drop') (('Question', 'Bagging classifer'), 'create') (('100 random_state', 'AdaBoost Classifier'), 'have') (('Using', 'model'), 'scale') (('Observation We', 'int 10 datatype'), 'see') (('that', 'whole dataset'), 'Use') (('that', 'different features'), 'create') "}
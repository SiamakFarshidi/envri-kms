{"name": "titanic a newcomer s tale ", "full_name": " h1 1 Introduction h1 2 Exploratory Data Analysis h3 2a Determining the missing data h3 2b Encoding and Categorizing Data h3 2c Data Visualization h1 3 Modelling h2 3a Logistic Regression h2 3b Gaussian Naive Bayes h2 3c K Neighbors Classifier h2 3d Support Vector Machine h2 3e Decision Tree ", "stargazers_count": 0, "forks_count": 0, "description": "Beside the Gaussian Naive Bayes there are also existing the Multinomial naive Bayes and the Bernoulli naive Bayes. Test underlying assumptions6. Supervised learning is when a model learns from data that is already labeled. It involves the creation and study of the visual representation of data. In this algorithm we plot each data item as a point in n dimensional space where n is number of features you have with the value of each feature being the value of a particular coordinate. Gaussian Naive BayesA Gaussian Naive Bayes algorithm is a special type of NB algorithm. predict x_test print accuracy_score y_pred y_test select_model. It s specifically used when the features have continuous values. The term ML model refers to the model artifact that is created by the training process. EDA is not identical to statistical graphics although the two terms are used almost interchangeably. score x_test y_test print AdaBoost_estimator. Statistical graphics is a collection of techniques all graphically based and all focusing on one data characterization aspect. There are couple of algorithms there to build a decision tree we only talk about a few which are 1. Next I needed to figure out if the supervised problem is a regression task or a classification task. In reality it was even worst 68 people on board died. png This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. You would provide ML with training data that contains emails for which you know the target that is a label that tells whether an email is spam or not spam. Logistic RegressionLogistic regression produces a logistic curve which is limited to values between 0 and 1. I use two highly effective libraries herea. append AdaBoost_estimator. extract values do not drop passenger id dependent variable replace nan with most frequent replace nan with median replace nan with most frequent replace nan with median encoding and categorizng data plot how many survive Title PClass vs Survived Fitting the models LR. Uncover underlying structure3. fit x_train y_train y_pred grid_KNNsearch. predict x_test extraTree_accy round accuracy_score y_pred y_test 3 select_model. Modelling The process of training an ML model involves providing an ML algorithm that is the learning algorithm with training data to learn from. fit x_train y_train print SVC_grid. Remember this is just for training data. The learning algorithm finds patterns in the training data that map the input data attributes to the target the answer that you want to predict and it outputs an ML model that captures these patterns. ID3 Iterative Dichotomiser 3 uses Entropy function and Information gain as metrics. Determine optimal factor settings. A supervised learning model takes in a set of input objects and output values. Logistic regression is similar to a linear regression but the curve is constructed using the natural logarithm of the odds of the target variable rather than the probability. append extraTree_accy print extraTree_accy print rf_grid. score x_test y_test y_pred GaussianProcessClassifier. com handle missing data python https www. predict x_test print grid_KNNsearch. You can use the ML model to get predictions on new data for which you do not know the target. Decision TreeA decision tree is a tree where each node represents a feature attribute each link branch represents a decision rule and each leaf represents an outcome categorical or continues value. predict x_test confusion_matrix y_test y_pred print LR. The logistic function also called the sigmoid function was developed by statisticians to describe properties of population growth in ecology rising quickly and maxing out at the carrying capacity of the environment. So I clubbed most of the ML algorithms. MatplotlibMy focus now is to see for myself what kind of relationship the data has with other data that may belong to the same or different category. Remember that P C is not calculated for our data. EDA encompasses a larger venue EDA is an approach to data analysis that postpones the usual assumptions about what kind of model the data follow with the more direct approach of allowing the data itself to reveal its underlying structure and model. So how many made the cut Turns out very few lived 61 Died. Exploratory Data Analysis Exploratory Data Analysis Exploratory Data Analysis EDA is an approach philosophy for data analysis that employs a variety of techniques mostly graphical to1. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. So first we need to find the missing data and fill or replace the missing data with value. Embedding and Exploring https i. P A B is the probability A under the condition B. append voting_accy. In all fairness even experts in the field are divided on this question so I used a mixture of both. read_csv Input data files are available in the. predict x_test voting_accy accuracy_score y_pred y_test print voting_accy select_model. For this as of now I use the median to fill the values or the most frequent to fill NA values. Bayes Thorem https i. CART Classification and Regression Trees uses Gini Index Classification as metric. Sigmoidal https i. append grid_KNNsearch. It s an S shaped curve that can take any real valued number and map it into a value between 0 and 1 but never exactly at those limits. Hyper plane will be a point in case of 1 dimensional data line in case of 2 dimensional data plane in case of 3 dimensional data and so on. I picked the Gaussian Naive Bayes because it is the simplest and the most popular one. SVMs are more commonly used in classification problems and as such this is what we will focus on in this post. jpg KERNEL Making In progress 1. Develop parsimonious models7. score x_test y_test y_pred voting_classifier. EDA is not a mere collection of techniques EDA is a philosophy as to how we dissect a data set what we look for how we look and how we interpret. Gaussian Naive BayesThe Gaussian Naive Bayes is one classifier model. Encoding and Categorizing DataOnce we have gathered data we might wish to classify it. Roughly speaking data can be classified as categorical data or quantitative data. Decidion Tree https i. The whole idea is to create a tree like this for the entire data and process a single outcome at every leaf or minimize the error in every leaf. append accuracy_score y_pred y_test y_pred ExtraTreesClassifier. We use sklearn s GaussianNB module but first lets recap to what Bayes theorem doesLet s break the equation below down 1. Data VisualizationData visualization is viewed by many disciplines as a modern equivalent of visual communication. k NN models work by taking a data point and looking at the k closest labeled data points. It s also assumed that all the features are following a gaussian distribution i. score x_test y_test print GBayes_clf. org wiki Missing_datahttps machinelearningmastery. For example let s say that you want to train an ML model to predict if an email is spam or not spam. Some good references https en. Support Vector MachineA Support Vector Machine SVM is a supervised machine learning algorithm that can be employed for both classification and regression purposes. com python example 93356 sklearn. The model then trains on that data to learn how to map the inputs to the desired output so it can learn to make predictions on unseen data. However I wanted this to be a good introduction to all beginners. But first I had to decide whether this task was going to be a done by a supervised ML Algorithm or unsupervised ML algorithm. Now that I have decided what kind of problems I need to boil this down to let s look at our dataset. Maximize insight into a data set2. fit x_train y_train y_pred LR. score x_test y_test confusion_matrix y_pred y_test grid_KNNsearch. ML would train an ML model by using this data resulting in a model that attempts to predict whether new email will be spam or not spam. Extract important variables4. K Neighbors Classifier k Nearest Neighbors k NN is a supervised machine learning model. P A and P B P B not 0 are the probabilities of the event independent from each other. Equivalent with P B A it is the probability of observing event B given that event A is true. score x_test y_test confusion_matrix y_pred y_test grid_search. Determining the missing dataMissing data can occur because of nonresponse no information is provided for one or more items or for a whole unit. For example running this by clicking run or pressing Shift Enter will list the files in the input directory supress warnings Any results you write to the current directory are saved as output. Quantitative data are responses that are numerical in nature and with which we can perform meaningful arithmetic calculations. In this case the dataframe called Title has been recategorized to 4 values Mr Mrs Miss Master. score x_test y_test select_model. The data point is then assigned the label of the majority of the k closest points. e normal distribution. Moreover the predictors do not have to be normally distributed or have equal variance in each group. Titanic https i. We assume that P C A is Guassian following normal distribution. Then we perform classification by finding the optimal hyper plane that differentiate the two classes very well. The model in this case is a Binary Classification problem meaning the output of this model is either a class 0 or a class 1. Detect outliers and anomalies5. The training data must contain the correct answer which is known as a target or target attribute. or incase of an unsupervised problem is it a clustering task or an association task. For example if k 5 and 3 of points are green and 2 are red then the data point in question would be labeled green since green is the majority. Introduction The aim of the competition is to correctly predict the survival rate of Titanic Survivors. It is true that EDA heavily uses the collection of techniques that we call statistical graphics but it is not identical to statistical graphics per se. Categorical qualitative data are pieces of information that allow us to classify the objects under investigation into various categories. ", "id": "akhileshrai/titanic-a-newcomer-s-tale", "size": "9196", "language": "python", "html_url": "https://www.kaggle.com/code/akhileshrai/titanic-a-newcomer-s-tale", "git_url": "https://www.kaggle.com/code/akhileshrai/titanic-a-newcomer-s-tale", "script": "math Counter train_test_split confusion_matrix sklearn.ensemble xgboost accuracy_score numpy cross_val_score sklearn.svm seaborn XGBClassifier ExtraTreesClassifier SVC BaggingClassifier GaussianNB sklearn.neighbors sklearn.naive_bayes sklearn.tree GradientBoostingRegressor sklearn.linear_model GaussianProcessClassifier StratifiedShuffleSplit matplotlib.pyplot DecisionTreeClassifier sklearn.model_selection pandas replace_titles xgboost.sklearn RandomForestClassifier LogisticRegression pi VotingClassifier KNeighborsClassifier AdaBoostClassifier LabelEncoder GridSearchCV sklearn.gaussian_process sklearn.metrics collections sklearn.preprocessing ", "entities": "(('s', 'dataset'), 'decide') (('two terms', 'statistical graphics'), 'be') (('I', 'two highly effective libraries'), 'use') (('It', 'data'), 'involve') (('Moreover predictors', 'group'), 'have') (('we', 'post'), 'use') (('A', 'event'), 'equivalent') (('which', '0'), 'produce') (('BayesA Gaussian Naive Bayes Gaussian Naive algorithm', 'NB special algorithm'), 'be') (('I', 'both'), 'divide') (('ID3 Iterative Dichotomiser', 'metrics'), 'use') (('value', 'particular coordinate'), 'plot') (('logistic function', 'environment'), 'call') (('now I', 'NA most values'), 'for') (('also features', 'gaussian distribution'), 'assume') (('email', 'ML model'), 'let') (('we', 'meaningful arithmetic calculations'), 'be') (('k NN models', 'data k closest labeled points'), 'work') (('P A B', 'condition'), 'be') (('P C A', 'normal distribution'), 'assume') (('machine learning supervised that', 'classification purposes'), 'be') (('Hyper plane', '3 dimensional data'), 'be') (('Roughly speaking data', 'categorical data'), 'classify') (('new email', 'model'), 'train') (('that', 'two classes'), 'perform') (('learning supervised model', 'input objects'), 'take') (('specifically when features', 'continuous values'), 'use') (('even worst 68 people', 'board'), 'be') (('which', 'target'), 'contain') (('CART Classification', 'Gini Index Classification'), 'use') (('whole idea', 'leaf'), 'be') (('that', 'same category'), 'be') (('data', 'underlying structure'), 'encompass') (('read_csv Input data files', 'the'), 'be') (('it', 'Naive Gaussian Bayes'), 'pick') (('you', 'target'), 'use') (('we', 'it'), 'gather') (('model', 'model'), 'be') (('it', 'unsupervised problem'), 'be') (('doesLet', '1'), 'use') (('us', 'various categories'), 'be') (('data then point', 'green'), 'label') (('curve', 'rather probability'), 'be') (('So first we', 'value'), 'need') (('com', 'data python https www'), 'handle') (('aim', 'Titanic Survivors'), 'introduction') (('It', 'python docker image https kaggle github'), 'come') (('it', 'se'), 'be') (('Data VisualizationData visualization', 'visual communication'), 'view') (('you', 'output'), 'list') (('dataframe', '4 values'), 'recategorize') (('that', 'training process'), 'refer') (('which', 'only about a few'), 'talk') (('how we', 'what'), 'be') (('that', 'patterns'), 'find') (('information', 'whole unit'), 'occur') (('P C', 'data'), 'remember') (('that', 'data'), 'be') (('task', 'ML algorithm'), 'have') (('P P B P 0', 'independent other'), 'a') (('that', 'training learning data'), 'involve') (('email', 'target'), 'provide') (('it', 'unseen data'), 'train') (('this', 'good beginners'), 'want') (('how many', 'models'), 'drop') (('that', 'techniques'), 'be') (('leaf', 'categorical value'), 'be') (('S shaped that', 'exactly limits'), 's') (('data point', 'k closest points'), 'assign') (('all graphically all', 'data characterization one aspect'), 'be') "}
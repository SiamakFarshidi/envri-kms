{"name": "qa integrated biomedical ner classifier for pico ", "full_name": " h1 Intro h2 My previous work as basis for this notebook h2 Contribution to CORD 19 h3 TL DR Merge existing NER biomedical and reading comprehension general topic data Get a high performing specialised population health condition and outcome classifier with general reading comprehension ability Also aim is to present data interactively and in a meaningful way h1 Teaser Results h2 Example for an interactive plot on diseases and symptoms connected with COVID 19 h2 Example 2 for an interactive plot on medical care h1 Methods h1 The training data h1 Aim h1 Creating the training testing and prediction data h3 Step 1 Familiarise myself with the SQuAD data format json file and adapt the corpus h1 Fine tune a Question answering model on the newly created training data h1 Convert the CORD 19 data into a format that we can feed to the network h1 Predict on CORD data ", "stargazers_count": 0, "forks_count": 0, "description": "After fine tuning all tuned weights will be saved in the outputs folder. Integrated existing corpora of annotated biomedical entities 5000 abstracts annotated with data of interest to many CORD 19 challenges 2. PNG eg asking for study population I compiled these options quests Who was treated What were the criteria for enrollment What were the inclusion criteria Who was enrolled in the study What were participants diagnosed with Which participants took part in the study Fine tune a Question answering model on the newly created training dataThen I use the Transformers library mentioned above and to fine tune my own Frankenstein NER QA modelsWith a bit of work on my own fork of Transformers I can display evaluation results as needed e. Above we can see that the raw results from the data mining are not a bad starting point. png Teaser Results Example for an interactive plot on diseases and symptoms connected with COVID 19 Question for each epidemiological study Patients with which medical conditions were included This is a small teaser showing mined medical conditions and probable corona related diseases in the dataset. Methods The training data 1 5000 entity annotated abstracts of medical clinical trials 1. NB of course I don t use any additional SQuAD domains in the evaluation data because I want my results to be comparable with other architectures trained on the basis of the same data. When sorted by frequency count pneumonia comes up as the top health condition which is sadly also true in the real world. io SQuAD explorer 3 https huggingface. ipynbAs this is a bit resource intensive all fine tuned weights are aviailable here TODO upload to kaggle Convert the CORD 19 data into a format that we can feed to the network Predict on CORD dataThis is essentially a repetition ofthe fine tuning step just that one now removes the do train parameter in the colab file and selects a previous trained model as input to compute the predictions There are cells in the COLAB file that do and explain this and I hope to acutally include the colab script in this Kaggle notebook once I figure out how to do this Each CORD task will have its own notebook where I will go more into detail and show more data and more visualisations. Processing the results deriving interactive plots trends between different versions of the dataset word clouds. This will be explained in more detail in my task specific submissions. Transformed the baseline task of extracting entities into a Question Answering task in order to utilise further general reading comprehension data from the SQuAD corpus I did evaluated published these models early February. png attachment image. The Colab script can be found here https github. co ultimately it d be great to use any other NER dataset in the following architecture Aim We will harness BERTs or XL Net or ANY transformers power of domain adaptation and transfer learning to extract entities from any epidemiological study on COVID. png Intro Population Intervention Comparator and Outcomes PICO are key parts of medical systematic or rapid reviews of literature. The plot is interactive and on hover shows some more detailled information about the mined procedure as well as the cluster it was assigned to More detailed explanation of the code will be added in each task submission. PNG attachment SquadArchi. per class recall scores in order to adjust undersampling rate of my training dataFor fine tuning itself I use Googe Colab whith the GPU option enabled. com annotations 2 https rajpurkar. Applying the aforementioned models to abstracts in the CORD dataset2. Example 2 for an interactive plot on medical care Question for each epidemiological study What was the intervention given to the participants This is another small teaser showing my mined medical interventions in the dataset. Get a high performing specialised population health condition and outcome classifier with general reading comprehension ability. Below I am doing some post processing and clustering on the data. NB I will use my own fork of this repo but I still download the pretrained models from them. N amount of Original SQuAD domains eg 200 are randomly selected and shuffeled in between my adapted ebm nlp training data. 2 data for general reading comprehension in question answering we will use random parts of the corpus at most 200 domains 2. The resulting top 5 health conditions show for example that cancer and lung cancer have been grouped All in all this step reduces 566 unique descriptions of health conditions to 291 clusters and in the resulting data frame we see that for example pneumonia ncp and severe covid 19 pneumonia get grouped and that type 2 diabetes is now part of the diabetes cluster. Creating the training testing and prediction data Step 1 Familiarise myself with the SQuAD data format json file and adapt the corpus SQuAD consists of domains namely a whole Wikipedia article as one domain PURPLE in the picture below Each domain has some question contexts something like a paragraph of text YELLOW Questions about the text potentially multiple questions about the same paragraph BLUE Span annotations of where the labelled answer is OR if there is no answer a boolean to indicate that GREENWhen I adapt the ebm nlp corpus abstracts become domains purple sentences become question contexts yellow entity types become questions I created a list of questions that aim to comprehensively ask for entity types examples below sentences with labelled entities become proper span answers and sentences without entity become impossible answers NB depending on entity type it is worth considering under sampling some of the impossible answers in order to boost recall I am a systematic reviewer turned data scientist so I really care about recall most ie retrieving ALL entities and F1 second. My previous work as basis for this notebook 1. I did not even train models on most tasks But it is possible with the code in this notebook my GIT The corpus has age group samle size pharma vs non pharma and outcome types such as mortality or different adverse events annotated https ebm nlp. When doing this one simply needs to upload their training and evaluation files created in the previous step save them in a google drive and point the script to the right folder. Following is a short overview and some code on how to merge the datasets and what the final architecture looks like on a super high level. Since 2005 a significant amount of research already focused on mining this type of information. Also aim is to present data interactively and in a meaningful way. Trying to provide a framework that allows to integrate all available training data over time TL DR Merge existing NER biomedical and reading comprehension general topic data. Using some pre Covid 19 training data and fine tuned neural networks I will show how my system can be used now in order to support evidence synthesis. And even more obvious I use the ebm nlp expert annotated held out abstracts for evaluation. Described a process of enriching NER data through the Squad corpus and to describe how this boosts the results Contribution to CORD 19 1. This is how systematic reviewing works and what medical researchers are going to expect if they ever use a tool like this one. com annotations About merging it with SquAD I did not even use the whole SQuAD data because its just too much training data and my GPU access is limited image. The plot is interactive and on hover shows some more detailled information about the mined health problem as well as the cluster it was assigned to More detailed explanation of the code will be added in each single task submission. But there are a lot of duplicates here. com L ENA CORD19scripts blob master CORD_mining. 3 Jumping on the Transformer train we can use basically any pre trained architecture capable of performing the SQuAD task implemented by Huggingface s Transformers 3. ", "id": "lenaschmidt0493/qa-integrated-biomedical-ner-classifier-for-pico", "size": "8466", "language": "python", "html_url": "https://www.kaggle.com/code/lenaschmidt0493/qa-integrated-biomedical-ner-classifier-for-pico", "git_url": "https://www.kaggle.com/code/lenaschmidt0493/qa-integrated-biomedical-ner-classifier-for-pico", "script": "interactive_plots Counter sent_tokenize glob display HTML IPython.display CORD19scripts defaultdict pandas make_train_test collections covid_input tqdm nltk.tokenize numpy ", "entities": "(('we', 'Huggingface Transformers'), 'use') (('that', 'time'), 'try') (('which', 'sadly also real world'), 'come') (('it', 'task submission'), 'be') (('fine tuned weights', 'outputs folder'), 'save') (('corpus', 'outcome such mortality'), 'train') (('results', 'same data'), 'use') (('GPU option', 'Googe Colab'), 'per') (('raw results', 'data mining'), 'see') (('I', 'them'), 'use') (('even more I', 'evaluation'), 'use') (('I', 'models'), 'publish') (('significant amount', 'information'), 'focus') (('amount', 'nlp training 200 randomly adapted ebm data'), 'select') (('This', 'dataset'), 'example') (('This', 'probable corona related dataset'), 'result') (('Below I', 'data'), 'do') (('data systematic so I', 'most ie entities'), 'consist') (('how system', 'evidence synthesis'), 'use') (('they', 'one'), 'be') (('Also aim', 'interactively meaningful way'), 'be') (('training data', 'medical clinical trials'), 'method') (('I', 'needed e.'), 'ask') (('training just too much data', 'SQuAD even whole data'), 'com') (('type 2 diabetes', 'diabetes now cluster'), 'reduce') (('how this', 'CORD'), 'describe') (('where I', 'more data'), 'ipynbas') (('png Intro Population Intervention Comparator', 'literature'), 'be') (('This', 'task specific submissions'), 'explain') (('final architecture', 'super high level'), 'be') (('it', 'task single submission'), 'be') (('Colab script', 'https here github'), 'find') (('we', 'most 200 domains'), 'use') (('Aim We', 'COVID'), 'be') "}
{"name": "a cluster of colors principal component analysis ", "full_name": " h1 A CLUSTER OF COLORS h4 PCA APPROACH h1 1 Introduction h1 2 Extracting only the color features h3 Encoding categorical values h1 3 Correlation of color features h1 4 Principal Component Analysis with KMeans Clustering h1 CLOSING REMARKS ", "stargazers_count": 0, "forks_count": 0, "description": "Since the color s categorical value correspond to one another across columns I want to ensure that the encoding provides the same output across all columns. Inspecting the data we see that there are 6 columns features that allude to colors 1. Therefore as a rough heuristic let s look at PCA ing the features into 3 components. Check out the official sklearn link for a more detailed explanation http scikit learn. With this 2D plot of the PCA projections let s try to apply a simple KMeans and see if we can identify any clusters from the projections. htmlWe also import the KMeans method so that we can use KMeans clustering to extract our PCA components. stalk color above ring 4. From the code below since I am going to look at PCA with 3 components therefore I assign the PCA parameter n_components to be equal to 3. Therefore this notebook is organized as follows Label encoding the categorical values Pearson Correlation to investigate any linear dependence on the color features PCA and KMeans clustering for visualization 2. Extracting only the color features The first step is to extract all the features in the dataset that point to the colors of the mushroom. IntroductionThis notebook is not meant to be an exhaustive EDA nor will it attempt to run fancy stuff like XGBoosting or Ensembling methods. Simple visualisation of the 3 clusters with a pre defined color map CLOSING REMARKSSince I m only starting out and am still very green behind the ears around data science I will stop my notebook at this juncture. However this PCA decomposition coupled with KMeans clustering or other clustering methods can be quite powerful especially when you imagine that your dataset features contain 100s or 1000s of columns you are able to scale it down by an order of magnitude via this method. Importing the usual libraries Read in the mushroom data into a dataframe called data what a creative name I use a list color_features to store the color column names. Let s plot some hexplots for visualisationJust some pretty visuals but let s delve deeper into the meat of the data by looking at Pearson Correlation. org stable modules generated sklearn. The chief focus of this script will simply be to try out sklearn s PCA Principal Decomposition Analysis method on a small dataset hence the choice to only look at mushroom colors. Therefore we need to encode. stalk color below ring 5. Correlation of color featuresNow let s look at the Pearson correlation of the color features as a sort of first attempt to identify how linearly related they are to one another. Seems that from this heatmap we identify about 2 or 3 features that have some weakly to medium positive linear correlation with one another. spore print colorTherefore let s extract these 6 color columns into its own dataframe data_color Encoding categorical valuesWe see that the colors are all categorical values. A CLUSTER OF COLORS PCA APPROACH 1. The method of fit_transform fits the model with X mushroom color values and then reduces the dimensions of X to our stated 3 dimensions. Please feel free to leave comments and thoughts on how I could improve this notebook from a data science point of view or plotting point of view or organisational point of view or views from any other point. Do let me know if there is create our color dataframe and inspect first 5 rows with head List to store all unique categories Use sklearn Labelencoder for transformation Define a dictionary encodedict to store our encoding Finally use dictionary to generate encoded dataframe correlation matrix using the corr method used the astype or else I get empty results Set up the matplotlib figure Draw the heatmap using seaborn import the relevant modules calling sklearn PCA fit X and apply the reduction to X Let s see how it looks like in 2D could do a 3D plot as well Set a 3 KMeans clustering Compute cluster centers and predict cluster indices. Therefore my idea was to create a dictionary that contains the encoding for the unique values across the dataframe. Not really sure if there is an easier way to do this. Principal Component Analysis with KMeans ClusteringThankfully the immense power of the sklearn module can be utilized to implement Principal Component Analysis conveniently. To take this further from a qualitative point of view one would then extract the KMeans clusters and use those as new features in training the Machine Learning model should the effect of this dimensionality reduction clustering prove helpful. And to visualize this with a more swanky heatmap that everyone is using these days. ", "id": "arthurtok/a-cluster-of-colors-principal-component-analysis", "size": "3863", "language": "python", "html_url": "https://www.kaggle.com/code/arthurtok/a-cluster-of-colors-principal-component-analysis", "git_url": "https://www.kaggle.com/code/arthurtok/a-cluster-of-colors-principal-component-analysis", "script": "sklearn.cluster seaborn numpy PCA matplotlib.pyplot LabelEncoder sklearn.decomposition pandas KMeans sklearn.preprocessing ", "entities": "(('s', '3 components'), 'therefore') (('I', 'juncture'), 'stop') (('we', 'projections'), 'let') (('therefore I', '3'), 'assign') (('we', 'PCA components'), 'import') (('that', 'one'), 'seem') (('exhaustive it', 'XGBoosting methods'), 'mean') (('immense power', 'Principal Component Analysis'), 'utilize') (('you', 'method'), 'be') (('PCA', 'visualization'), 'organize') (('s', 'Pearson Correlation'), 'let') (('everyone', 'days'), 'visualize') (('effect', 'dimensionality reduction clustering'), 'prove') (('colors', 'Encoding categorical own dataframe data_color valuesWe'), 'let') (('explanation http more detailed scikit', 'sklearn official link'), 'check') (('first step', 'mushroom'), 'feature') (('creative I', 'color column names'), 'import') (('that', 'dataframe'), 'be') (('looks', 'cluster indices'), 'let') (('encoding', 'columns'), 'correspond') (('choice', 'mushroom only colors'), 'be') (('how I', 'other point'), 'feel') (('columns 6 that', 'colors'), 'inspect') (('how linearly they', 'one'), 'let') (('method', 'stated 3 dimensions'), 'fit') "}
{"name": "image segmentation using unet tfrecords ", "full_name": " h1 Image segmentation using Unet architecture and TFrecords h3 Authors Muhammad Valiallah and Martin Page h2 Abstract h3 In this document we show h2 Introduction h2 Data h3 Encoding h3 Images h2 Evaluation Metric Dice Coefficient h2 Libraries to import h1 We tackle this problem into two general steps h2 Data Processing TF Records h2 Generating a TFRecord h2 Using TPU from Kaggle h2 U Net Model h2 Acknowlegements ", "stargazers_count": 0, "forks_count": 0, "description": "7080Epoch 4 30119 119 ETA 0s dice_coeff 0. The task is to take the image files as well as the pixel location of the glomeruli referred to as masks and train a machine learning model to find the pixel locations of glomeruli on an unlabelled data set of kidney images. How to read a TFrecord5. The contracting path is a typical convolutional network with repeated application of convolutions with ReLU and max pooling activations downsampling operations. 7080Epoch 26 30119 119 ETA 0s dice_coeff 0. Here the pixel locations label of an object are represented by two numbers. 7080Epoch 00014 saving model to kaggle working unet tpu. connected consecutively. Preparing the images for processinng Normalising Tiling Serialising 2. Print out the image shapes to see if there is consistency. The first number refers to the starting pixel in 1D and the second number is the number of successive pixels that object is present on. 7080Epoch 11 30119 119 ETA 0s dice_coeff 0. 7080Epoch 19 30119 119 ETA 0s dice_coeff 0. 7080Epoch 3 30119 119 ETA 0s dice_coeff 0. 7080Epoch 00015 saving model to kaggle working unet tpu. Here is the formula Large frac 2 X Y X Y And here is its visualisation Dice https miro. 7080Epoch 00025 saving model to kaggle working unet tpu. h5119 119 106s 888ms step dice_coeff 0. Create a tfrecord file and write the messages image and its associated features to it Serialisation function and its helpers Creating the TF record The code below is used to package all steps into a single function which will generate a separate TFrecord file for. 7080Epoch 24 30119 119 ETA 0s dice_coeff 0. scope block to ensure the TPU is used. The differences being that a few normalisation layers were added to the downsampling block and we used strides of 1 for the convolution layers and different size input images. The expansive pathway combines the feature and spatial information through a sequence of up convolutions down sampling that halves the number of feature channels and concatenations with the high resolution features from the contracting pathway see more https www. h5119 119 106s 887ms step dice_coeff 0. 7080Epoch 17 30119 119 ETA 0s dice_coeff 0. 7080Epoch 00024 saving model to kaggle working unet tpu. Image segmentation using Unet architecture and TFrecords Authors Muhammad Valiallah and Martin Page AbstractWe are presented with images of kidney tissue. 7080Epoch 00018 saving model to kaggle working unet tpu. 7080Epoch 00011 saving model to kaggle working unet tpu. The image formatsSteps 1. The image_feature_description dictionary must be loaded the keys ultimtaley refer to the image_feature_description dictionary needs to be 4 dimensional for the model the model cannot take in bool so must cast to float image_distribution0. So the strategy is to first sub sample the large images into smaller images before passing them on to a CNN. In order to use a TPU the datasets need to be stored on Google Cloud Storage Google Colab also has TPUs but TFrecords are not supported. This is how we associate the image to the mask4. com prvnkmr unet architecture breakdown. We now call the above function which will generate tfrecord files. 7275Epoch 00001 saving model to kaggle working unet tpu. Uncompress the TFrecord and pass it to the decode function Reading the TF record We now have a function that reads a TFrecord and can be used to generate images and masks that can be passed to a CNN U Net ModelThe UNet architecture was proposed in 2015. 7080Epoch 10 30119 119 ETA 0s dice_coeff 0. 7080Epoch 00030 saving model to kaggle working unet tpu. png We now need to read in the TF records. 7080Epoch 25 30119 119 ETA 0s dice_coeff 0. How to sub sample a large image into smaller images a process referred to as tiling. 7080Epoch 13 30119 119 ETA 0s dice_coeff 0. 7080Epoch 20 30119 119 ETA 0s dice_coeff 0. 7080Epoch 7 30119 119 ETA 0s dice_coeff 0. Normalise Standardise the images so that they are in the same format. 7080Epoch 00013 saving model to kaggle working unet tpu. 7080Epoch 22 30119 119 ETA 0s dice_coeff 0. h5119 119 169s 1s step dice_coeff 0. THe run length encoding would be 789 3 900 2 904 1 906 1. Login to your GCS account image. You will then be provided with the code snippet belowYou can now add a TPU by setting the accelerator to TPU v image. A major advantage of this format is the datasets that are too large to be stored fully in memory can be loaded in batches from the disk and processed see more https towardsdatascience. Pixels are labelled if they share a certain shared characteristic. How to construct a class of encoder decoder models UNet type model 6. These records can be accessed by referring to the global storage pathWe now split the training data into a training set and validation set. Creat a function to decode the messages into images and masks3. For this problem there is only 1 object for detection so glomeruli pixels so binary classification is used where 1 represents the presence of a glomeruli and 0 not a glomeruli. 7080Epoch 00002 saving model to kaggle working unet tpu. This problem is an image segmentation type problem and can be solved using an encoder decoder architecture where a CNN is first downsampled to extract features and then subsequently symmetrically upsampled to reproduce the image and identify the pixels containing glomeruli. In this document we show 1. 7080Epoch 00003 saving model to kaggle working unet tpu. 7080Epoch 00020 saving model to kaggle working unet tpu. 0s to 1s For the mask BytesList won t unpack a string from an EagerTensor. How to train a UNet type model Introduction Image segmentation is the process of separating a digital image into specific partitions by creating a pixel wise mask for an object s of interest. com c hubmap kidney segmentation data contains 8 training and 5 test images as TIFF files. 7080Epoch 00004 saving model to kaggle working unet tpu. Additional information is also available for each image such as demographic information. Read the images into arrays using the tifffile library. 7080Epoch 9 30119 119 ETA 0s dice_coeff 0. 7080Epoch 28 30119 119 ETA 0s dice_coeff 0. com marcosnovaes hubmap unet keras model fit with tpu this formula adds epsilon to the numerator and denomincator to avoid a divide by 0 error in case a slice has no pixels set the relative values are important so this addition does not effect the coefficient defined as 1 minues the dice coefficient Convert strings to integers and subtract 1 because of python s 0 indexing add 0 to start and end so that first change will be 1s This gives us all changes in sequence we add 1 to get index of 1s we want every second change i. EncodingRun Length Encoding RLE is a lossless compression format. 7080Epoch 6 30119 119 ETA 0s dice_coeff 0. Convert the image masks into image arrays 0s and 1s of the same size as their associated images. Num_tile_cols Parse the input tf. 7080Epoch 00019 saving model to kaggle working unet tpu. Building a CNN and reading the serialized images Model Definition Model Compilation Model Fitting Model Tuning Data Processing TF RecordsThe Tensorflow record is a format to store a sequence of binary record from large datasets. Pick an image size to subsample the image The image tile chosen must have equal dimensions and be a multiple of the number of filters in the convolutional kernals. The images are stained with Periodic acid Schiff stain histology tissue sections of the kidney. 7080Epoch 16 30119 119 ETA 0s dice_coeff 0. In order to use the TPU functionality on Kaggle the Tfrecords need to be uploaded to Google Cloud Storage. Problem example An example of a image segmentation task is a recent Kaggle challenge https www. Create a bucket on Google Cloud Storage GCS 2. com c hubmap kidney segmentation where a structure in the kidney called the glomeruli cells and capillaries that facilitate the filtration of waste products 100 350 \u03bcm in diameter spherical shape needed to be identified in unlablled images on a pixel level. 7080Epoch 00010 saving model to kaggle working unet tpu. 7080Epoch 00026 saving model to kaggle working unet tpu. Convert the images into a TFrecord steps outlined later This code is used to read all the tiff image file paths in the training set and put it in a list Normalisation function We noticed that the colour channel sometimes occurred in the first column and sometimes in the third. The basic architecture is UNet https www. 7080Epoch 00017 saving model to kaggle working unet tpu. The below information summarises this Epoch 1 30 119 Unknown 167s 1s step dice_coeff 0. 7080This plots a graph comparing training to validation AcknowlegementsThis workflow is based on the below sources mainly by reading other Kaggle Kernals in particular the Notebooks of the Hacking the Kidney coach Marcos Novaes notebook series. png Libraries to import We tackle this problem into two general steps 1. Use the Secret Keys5. How to convert images into TensorFlow record files TFrecord to save on storage space as well as faster processing4. We run the garbage collector to free up memory space after calling the function RLE decoder function This function is used to encode an image into its run length Generating a TFRecord A Tensorflow record file consists of serialised messages which is a dictionary of a feature label and its associated value. We did not use all the images as we the number of files was quite large and we wanted to first generate a training model and see what the performance is like before loading all the images. We define a pandas DataFrame to store the image names along with the number of tiles this is helpful in getting an idea of how many images can be trained on. As can be seen from the above example the RLE will only be smaller than the original image if the object of interest is dense i. png To summarize the architecture 1. The first step is to have a look at the image arrays to get an idea of 1. 7080Epoch 21 30119 119 ETA 0s dice_coeff 0. 23 Convolution operations2. Last Level Conv 1x1 2D softmax function which is the sigmoid function 5. We now compile the modelWe then fit the model to the data set using a batch size of 128 and 30 epochs. 7080Epoch 00005 saving model to kaggle working unet tpu. 7080Epoch 00008 saving model to kaggle working unet tpu. The functional tissue unit FTU that needs to be identified is a block of cells around a capillary a 3D sphere. How to use a TPU for faster machine learning7. 7080Epoch 12 30119 119 ETA 0s dice_coeff 0. 7080Epoch 00028 saving model to kaggle working unet tpu. 7080Epoch 00006 saving model to kaggle working unet tpu. 7080Epoch 27 30119 119 ETA 0s dice_coeff 0. 7080Epoch 00009 saving model to kaggle working unet tpu. DataThe data set https www. com max 858 1 yUd5ckecHjWZf6hGrdlwzA. 7080Epoch 5 30119 119 ETA 0s dice_coeff 0. 7080Epoch 14 30119 119 ETA 0s dice_coeff 0. 7080Epoch 15 30119 119 ETA 0s dice_coeff 0. 7080Epoch 00021 saving model to kaggle working unet tpu. 7080Epoch 00029 saving model to kaggle working unet tpu. pdf using Python with tensorflow and keras. Convert the features into to bytes a process called serialization5. net profile Alan_Jackson9 publication 323597886 figure fig2 AS 601386504957959 1520393124691 Convolutional neural network CNN architecture based on UNET Ronneberger et al. The model designed is very similar to the one in the paper https arxiv. The authors of the paper recommended initailising the kernal weights to have a Gaussian Normal Distribution due to the repeated Convultions and Pooling layers6. 7080Epoch 29 30119 119 ETA 0s dice_coeff 0. 7080Epoch 00012 saving model to kaggle working unet tpu. 7080Epoch 23 30119 119 ETA 0s dice_coeff 0. Parse the input tf. It was based off a similar architecture called FCN but it has no dense layer. 7080Epoch 00027 saving model to kaggle working unet tpu. 7080Epoch 00007 saving model to kaggle working unet tpu. These images are supplemented with a CSV file where for each image the pixel location of glomeruli cells spherical capsules are indicated. We first ran the training model without a validation dataset to get an idea of the training times. Create a Features message using tf. Add the features to a message6. Look for all the tiff files in the training set. h5119 119 105s 886ms step dice_coeff 0. Using TPU from KaggleA TPU is a Tensor Processing Unit it it has a built in distribution strategy with 8 cores. 7080Epoch 30 30119 119 ETA 0s dice_coeff 0. Reference the GCS bucket1. 7080Epoch 00022 saving model to kaggle working unet tpu. Downsampling operations Conv 3x3 Relu Conv 3x3 Relu MaxPooling3. h5119 119 105s 885ms step dice_coeff 0. 7080Epoch 18 30119 119 ETA 0s dice_coeff 0. png attachment image. ImagesThe image files are large 1 2GB and difficult to train computationally intensive. com metrics to evaluate your semantic segmentation model 6bcb99639aa2. com marcosnovaes hubmap 3 unet models with keras cpu gpu https www. How to associate pixel lables masks to the image3. Set the Accelarator to TPU on the Notebook4. To convert images into TFrecord files we utilize the protocol tensorflow. Here pixels are numbered in 1D first from top to bottom row wise then from left to right. Objective of Notebook This notebook will walk you through a pipeline using TF records and the convolutional neural network U Net architecture for biomedical image segmentation also see this academic article https arxiv. 7080Epoch 00023 saving model to kaggle working unet tpu. No padding in the layersWe now define the model within a with strategy. Create helper functions to cast datatypes into 1 of the type lists integer float and bytes 3. Some images allso had leading dimensions of size 1 which we remove using the squeeze function. Create a dictionary mapping the features of the messages in the TFrecord to a label and specifying the data type2. png Run the code below to see ther tensorflow version as well as if the TPU is infact runningWe created tfrecords for all of the training image files. Link Notebook to GCS image. Evaluation Metric Dice CoefficientThe dice coefficient is used to compare the pixel wise agreement between a predicted segmentation and the true value ground truth and is defined as 2 times the area of overlap between the predicted and actual value divided by the total number of pixels in both images see more https towardsdatascience. Example proto using the dictionary above. 7080Epoch 8 30119 119 ETA 0s dice_coeff 0. The U Net architecture uses a contracting path and an expansive path encoder decoder which thus give the U shape. Break down the image into smaller images tiling 2. 7275Epoch 2 30119 119 ETA 0s dice_coeff 0. Create a feature dictionary which will be the contents of message. So for example if an image has an object with pixels labelled at 789 790 791 900 901 904 906. As a general rule of thumb many smaller images are faster to train and process than one large image of the same disk size. Upsampling operations Upsampling Conv 2x2 Concatenation Conv 3x3 Relu Conv 3x3 Relu 4. Link GCS drive to Kaggle Notebook Add ons Google Cloud SDK 3. Segmentation creates a representation of an image that is easier and more meaningful to analyse. The training images come with an associated mask that identifies the areas of interest that can be accessed as in both an unencoded JSON form and as a run length encoded RLE form from a CSV file which stores a sequence of data in a single value. 7080Epoch 00016 saving model to kaggle working unet tpu. The contracting pathways reduce the spatial information while increasing feature information thus the resolution of the output is increased at each step the number of features is doubled. ", "id": "muhammadvaliallah/image-segmentation-using-unet-tfrecords", "size": "19759", "language": "python", "html_url": "https://www.kaggle.com/code/muhammadvaliallah/image-segmentation-using-unet-tfrecords", "git_url": "https://www.kaggle.com/code/muhammadvaliallah/image-segmentation-using-unet-tfrecords", "script": "skimage.transform generate_tf_records unet_model imread_collection tensorflow.keras.layers compute_output_shape Lambda serialiaze_images tensorflow.keras.models numpy MaxPooling2D seaborn Adam Dropout RLE_ENCODER create_tf_record _int64_feature LayerNormalization(Layer) backend as K chain layers keras.engine.topology imread convert_rle_to_image concatenate_images LayerNormalization tqdm Layer tensorflow _parse_image_function2 skimage.io matplotlib.pyplot tensorflow.keras.callbacks ModelCheckpoint kaggle_secrets backend resize pandas EarlyStopping skimage.morphology load_model Conv2D call Model Conv2DTranspose dice_coeff concatenate UpSampling2D Input get_custom_objects tensorflow.keras UserSecretsClient keras.layers.core keras.utils.generic_utils imshow label dice_loss tensorflow.keras.optimizers normalize _float_feature _bytes_feature read_tf_dataset2 itertools ", "entities": "(('number', 'features'), 'reduce') (('path encoder expansive which', 'thus shape'), 'use') (('Tensor Processing it it', '8 cores'), 'use') (('task', 'kidney images'), 'be') (('ModelThe UNet architecture', '2015'), 'have') (('that', 'image'), 'create') (('contracting path', 'operations'), 'be') (('pixel locations Here label', 'two numbers'), 'represent') (('we', 'convolution layers'), 'be') (('it', 'dense layer'), 'base') (('7275Epoch', 'unet kaggle working tpu'), 'save') (('that', 'pixel level'), 'segmentation') (('We', 'training times'), 'run') (('notebook', 'article https also academic arxiv'), 'Objective') (('Model Definition Model Compilation Model Fitting Tuning Processing RecordsThe Tensorflow Data record', 'large datasets'), 'be') (('So strategy', 'CNN'), 'be') (('image', '904 789 790 791 900 901 906'), 'have') (('how many images', 'idea'), 'be') (('image tile', 'convolutional kernals'), 'pick') (('below information', 'Epoch'), 'summarise') (('png We', 'TF now records'), 'need') (('7080Epoch', 'unet kaggle working tpu'), 'saving') (('that', 'capillary'), 'be') (('they', 'same format'), 'Standardise') (('that', 'https more towardsdatascience'), 'be') (('graph', 'Kidney Marcos Novaes notebook Hacking series'), 'base') (('code snippet then belowYou', 'v image'), 'provide') (('performance', 'images'), 'use') (('how we', 'mask4'), 'be') (('now modelWe', '128 epochs'), 'compile') (('example', 'image segmentation task'), 'example') (('padding', 'strategy'), 'define') (('which', 'TFrecord separate file'), 'create') (('mask BytesList', 'EagerTensor'), '0s') (('many smaller images', 'disk same size'), 'be') (('How train', 'interest'), 'be') (('validation', 'training set'), 'access') (('they', 'certain shared characteristic'), 'label') (('where 1', 'glomeruli'), 'be') (('where CNN', 'glomeruli'), 'be') (('test 5 TIFF', '8 training'), 'contain') (('which', 'feature label'), 'run') (('object', 'interest'), 'be') (('spherical capsules', 'glomeruli cells'), 'supplement') (('we', 'squeeze function'), 'have') (('value ground true 2 times area', 'https more towardsdatascience'), 'use') (('authors', 'repeated Convultions'), 'recommend') (('object', 'successive pixels'), 'refer') (('Image segmentation', 'kidney tissue'), 'present') (('we', 'second change'), 'fit') (('Tfrecords', 'Google Cloud Storage'), 'need') (('which', 'message'), 'create') (('Link GCS', 'Kaggle Notebook Add ons'), 'drive') (('number', 'https more www'), 'combine') (('images', 'kidney'), 'stain') (('model', 'so image_distribution0'), 'load') (('Additional information', 'such demographic information'), 'be') (('first step', '1'), 'be') (('model', 'paper https arxiv'), 'be') (('7080Epoch', 'unet kaggle working tpu'), 'save') (('colour channel', 'sometimes third'), 'use') (('png We', 'two general steps'), 'Libraries') (('Here pixels', 'then right'), 'number') (('net publication', 'UNET Ronneberger et al'), 'profile') (('which', 'tfrecord files'), 'call') (('runningWe', 'training image files'), 'create') (('which', 'single value'), 'come') (('we', 'protocol tensorflow'), 'utilize') (('TFrecords', 'also TPUs'), 'need') "}
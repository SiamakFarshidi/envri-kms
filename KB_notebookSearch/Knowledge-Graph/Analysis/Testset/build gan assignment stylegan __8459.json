{"name": "build gan assignment stylegan ", "full_name": " h1 Components of StyleGAN h3 Goals h3 Learning Objectives h2 Getting Started h2 Truncation Trick h2 Mapping z w h2 Random Noise Injection h2 Adaptive Instance Normalization AdaIN h1 text AdaIN boldsymbol mathrm x i boldsymbol mathrm y boldsymbol mathrm y s i frac boldsymbol mathrm x i mu boldsymbol mathrm x i sigma boldsymbol mathrm x i boldsymbol mathrm y b i h2 Progressive Growing in StyleGAN h2 Running StyleGAN ", "stargazers_count": 0, "forks_count": 0, "description": "However to reiterate in practice StyleGAN will slowly phase out the upsampled image by increasing the alpha parameter over many training steps doing this process repeatedly with larger and larger alpha values until it is 1 at this point the combined image is solely comprised of the image from the generator block. It takes the noise vector z and maps it to an intermediate noise vector w. This micro model you will implement will visualize what the model outputs at a particular stage of training for a specific value of alpha. Upsample to the starting_size bilinearly https pytorch. Given an image x_i and the intermediate vector w AdaIN takes the instance normalization of the image and multiplies it by the style scale y_s and adds the style bias y_b. Create a LeakyReLU activation with slope 0. Truncation TrickThe first component you will implement is the truncation trick. Transform it into an image and then upsample it to be 16 x 16. Replace the Nones with the correct dimensions keep in mind that both linear maps transform a w vector into style weights corresponding to the number of image channels. This is comprised of an upsampling layer a convolutional layer random noise injection an AdaIN layer and an activation. The output is some noise that can then be transformed into a blurry 4 x 4 image. The truncation value is at least 0 where 1 means there is little truncation high diversity and 0 means the distribution is all truncated except for the mean high quality fidelity. Adaptive Instance Normalization AdaIN The next component you will implement is AdaIN. StyleGAN starts with a constant 4 x 4 x 512 channel tensor which is put through an iteration of the generator without upsampling. The key here is that the alpha term is gradually increased until eventually only the image from 1 the generator is used. Components of StyleGAN GoalsIn this notebook you re going to implement various components of StyleGAN including the truncation trick the mapping layer noise injection adaptive instance normalization AdaIN and progressive growing. By mixing an upsampled 8 x 8 image which is 16 x 16 with increasingly more of the 16 x 16 generator output the generator is more stable as it progressively trains. Implement the components of StyleGAN. The instance normalized image style scale and style shift have already been calculated for you. Progressive Growing in StyleGANThe final StyleGAN component that you will create is progressive growing. Create an object to inject noise 4. For example imagine an image has 512 channels and its height and width are 4 x 4. Parameter so that these weights can be optimized Initiate the weights for the channels from a random normal distribution Set the appropriate shape for the noise Creates the random noise Applies to image after multiplying by the weight for each channel UNIT TEST COMMENT Required for grading UNIT TEST COMMENT Required for grading UNIT TEST Check that something changed Check that the change is per channel Check that the per channel change is roughly normal Make sure that the weights are being used at all UNQ_C4 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL AdaIN Normalize the input per dimension You want to map w to a set of style weights per channel. Random Noise InjectionNext you will implement the random noise injection that occurs before every AdaIN block. Your linear layers should be input hidden_dim hidden_dim output. The mapping network in StyleGAN is composed of 8 layers but for your implementation you will use a neural network with 3 layers. Next you multiply the 4 x 4 matrix by each one of these values. You would then pass this into the discriminator and use the feedback to update the weights of your generator. This creates a random tensor of 512 channels and 4 x 4 pixels the same dimensions as the image. Pass it into the next generator block to create an output noise that you will then transform to an image. Optional hint for InjectNoise1. 512 channels into 3 channels Note that this is simplified with clipping used in the real StyleGAN First generator run output Second generator run output Upsample first generator run output to be same size as second generator run output Interpolate between the upsampled image and the image from the generator using alpha UNIT TEST COMMENT Required for grading Check if the block works Check that the interpolation is correct The noise is exaggerated for visual effect. Optional hints for MappingLayers1. Now you can implement progressive growing. Running StyleGANFinally you can put all the components together to run an iteration of your micro StyleGAN You can also visualize what this randomly initiated generator can produce. UNQ_C1 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL get_truncated_noise Test the truncation sample UNQ_C2 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL MappingLayers Please write a neural network which takes in tensors of shape n_samples z_dim and outputs n_samples w_dim with a hidden layer with hidden_dim neurons UNIT TEST COMMENT Required for grading Test the mapping function UNQ_C3 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL InjectNoise You use nn. You may find torch. Finally you add this noise tensor to the image. Within a layer every following time the noise injection is called you take another step with the optimizer and the weights that you use for each channel are optimized i. lerp https pytorch. You would first create a random 4 x 4 noise matrix with one channel. Calculate the transformed image UNIT TEST COMMENT Required for grading UNIT TEST COMMENT Required for grading UNIT TEST COMMENT Required for grading UNQ_C5 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL MicroStyleGANGeneratorBlock Replace the Nones in order to 1. The weight should have the shape 1 channels 1 1. The truncation trick resamples the noise vector z from a truncated normal distribution which allows you to tune the generator s fidelity diversity. 2 Padding is used to maintain the image size UNIT TEST COMMENT Required for grading UNQ_C6 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED CELL MicroStyleGANGenerator Typically this constant is initiated to all ones but you will initiate to a Gaussian to better visualize the network s effect You need to have a way of mapping from the output noise to an image so you learn a 1x1 convolution to transform the e. In fact you may recall playing with it in an earlier GAN notebook. org docs stable generated torch. This code should be five lines. To increase control over the image you inject w the intermediate noise vector multiple times throughout StyleGAN. The noise tensor is not entirely random it is initialized as one random channel that is then multiplied by learned weights for each channel in the image. org docs master generated torch. Mapping z w The next component you need to implement is the mapping network. This makes it so z can be represented in a more disentangled space which makes the features easier to control later. To do this you need to create a noise tensor that is the same size as the current feature map image. This is done by transforming it into a set of style parameters and introducing the style to the image through AdaIN. Getting StartedYou will begin by importing some packages from PyTorch and defining a visualization function which will be useful later. Understand the components of StyleGAN that differ from the traditional GAN. You will start by creating a block for the StyleGAN generator. Optional hint for forward1. Create an AdaIN object 5. In the generated image the samples start from low alpha values and go to high alpha values. text AdaIN boldsymbol mathrm x _i boldsymbol mathrm y boldsymbol mathrm y _ s i frac boldsymbol mathrm x _i mu boldsymbol mathrm x _i sigma boldsymbol mathrm x _i boldsymbol mathrm y _ b i Optional hints for forward1. You will now have two images that are both double the resolution of the 8 x 8 noise. The code will automatically interpolate between different values of alpha so that you can intuitively see what it means to mix the low resolution and high resolution images using different values of alpha. This method of gradually training the generator increases the stability and fidelity of the model. Remember the equation for AdaIN. Remember that this is done after the model is trained and when you are sampling beautiful outputs. As such you will do two separate operations with the 8 x 8 noise 1. You will simulate progressive growing from an 8 x 8 image to a 16 x 16 image. This trick is not exclusive to StyleGAN. This is to save time training later. This is where the progressive growing process begins. This helps StyleGAN to create high resolution images by gradually doubling the image s size until the desired size. Then your model would create 512 values one for each channel. New starting weights are generated for every new layer or generator where this class is used. That is your final image or you could continue this process to make a 32 x 32 image or 64 x 64 128 x 128 etc. This introduces uncorrelated noise and is meant to increase the diversity in the image. However this will be done gradually. You need 3 linear layers and should use ReLU activations. Instead of simply passing it to the generator block with upsampling StyleGAN gradually trains the generator to the new size by mixing in an image that was only upsampled. The 4 x 4 noise can be further passed through a generator block with upsampling to produce an 8 x 8 output. Then using an alpha alpha term you combine the higher resolution images obtained from 1 and 2. Remember that you only make the noise for one channel it is then multiplied by random values to create ones for the other channels. Create a kernel_size convolution which takes in an image with in_chan and outputs one with out_chan https pytorch. You need to calculate the learnable style scale and bias by using linear mappings from w. Learning Objectives1. ", "id": "amoghjrules/build-gan-assignment-stylegan", "size": "8459", "language": "python", "html_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-stylegan", "git_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-stylegan", "script": "__init__ InjectNoise(nn.Module) make_grid show_tensor_images truncnorm get_mapping forward torch.nn numpy MicroStyleGANGeneratorBlock(nn.Module) upsample_to_match_size scipy.stats AdaIN(nn.Module) get_style_scale_transform get_truncated_noise get_self matplotlib.pyplot get_weight torch.nn.functional get_style_shift_transform torchvision.utils MicroStyleGANGenerator(nn.Module) MappingLayers(nn.Module) ", "entities": "(('features', 'more disentangled space'), 'make') (('that', 'both 8 8 noise'), 'have') (('such you', '8 8 noise'), 'do') (('You', 'ReLU activations'), 'need') (('where class', 'new layer'), 'generate') (('This', 'AdaIN'), 'do') (('it', 'alpha'), 'interpolate') (('You', 'channel'), 'parameter') (('Next you', 'values'), 'multiply') (('distribution', 'quality mean high fidelity'), 'be') (('This', 'upsampling layer'), 'comprise') (('Now you', 'progressive growing'), 'implement') (('model', 'alpha'), 'visualize') (('image style scale', 'style already you'), 'normalized') (('which', 'visualization function'), 'get') (('so you', 'e.'), 'use') (('You', '16 16 image'), 'simulate') (('introduces', 'image'), 'uncorrelate') (('you', 'then image'), 'pass') (('you', '3 layers'), 'compose') (('method', 'model'), 'increase') (('that', 'then blurry 4 4 image'), 'be') (('This', 'desired size'), 'help') (('you', '1'), 'combine') (('that', 'AdaIN block'), 'InjectionNext') (('Finally you', 'image'), 'add') (('You', 'w.'), 'need') (('you', 'GAN earlier notebook'), 'recall') (('which', 'upsampling'), 'start') (('when you', 'beautiful outputs'), 'remember') (('randomly initiated generator', 'also what'), 'put') (('samples', 'alpha high values'), 'in') (('you', 'multiple times StyleGAN'), 'increase') (('Then model', 'channel'), 'create') (('that', 'image'), 'train') (('It', 'noise vector intermediate w.'), 'take') (('final you', '32 32 image'), 'be') (('intermediate vector', 'style scale'), 'take') (('you', 'that'), 'grow') (('it', 'other channels'), 'remember') (('combined image', 'generator block'), 'phase') (('noise', 'visual effect'), 'note') (('512 channels', 'example'), 'imagine') (('generator', '1'), 'be') (('4 4 noise', '8 8 output'), 'pass') (('You', 'nn'), 'IDENTIFIER') (('you', 'fidelity diversity'), 'resample') (('linear maps', 'image channels'), 'replace') (('that', 'traditional GAN'), 'understand') (('that', 'image'), 'be') (('more it', 'generator 16 16 output'), 'be') (('i', 'Optional forward1'), 'mathrm') (('that', 'feature map same current image'), 'need') (('weight', '1 1'), 'have') (('This', 'image'), 'create') (('you', 'channel'), 'take') (('You', 'one channel'), 'create') (('mapping layer', 'instance normalization adaptive AdaIN'), 'component') (('You', 'StyleGAN generator'), 'start') (('You', 'generator'), 'pass') (('which', 'out_chan https pytorch'), 'create') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["block", "calculate", "channel", "code", "combine", "combined", "control", "convolution", "convolutional", "correct", "could", "create", "current", "dimension", "distribution", "diversity", "double", "effect", "equation", "every", "fact", "feature", "feedback", "final", "find", "following", "frac", "function", "generated", "generator", "grading", "height", "high", "https pytorch", "image", "implement", "implementation", "including", "increase", "input", "instance", "interpolate", "interpolation", "iteration", "key", "layer", "learn", "least", "linear", "little", "map", "mapping", "matrix", "mean", "method", "mind", "mixing", "model", "mu", "multiple", "need", "network", "neural", "new", "next", "noise", "normal", "normalization", "normalized", "not", "notebook", "number", "object", "optimizer", "order", "out", "output", "parameter", "per", "point", "practice", "random", "re", "recall", "resolution", "run", "sample", "sampling", "save", "scale", "second", "separate", "set", "shape", "shift", "size", "something", "space", "stage", "start", "step", "style", "tensor", "term", "text", "through", "time", "training", "transform", "truncated", "truncation", "tune", "until", "update", "upsampling", "value", "vector", "visualization", "visualize", "weight", "width", "write"], "potential_description_queries_len": 122, "potential_script_queries": ["forward", "nn", "numpy", "truncnorm"], "potential_script_queries_len": 4, "potential_entities_queries": ["high", "mean", "style"], "potential_entities_queries_len": 3, "potential_extra_queries": ["test"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 127}
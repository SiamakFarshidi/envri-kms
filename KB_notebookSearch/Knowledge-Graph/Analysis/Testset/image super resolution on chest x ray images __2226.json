{"name": "image super resolution on chest x ray images ", "full_name": " h3 Define image data generators to load and preprocess the images h3 Normalize the pixels for training and validation images h3 Here we have prepared a dataset of test image paths that we will use for visual evaluation at the end of this example h3 Here we define functions to process the input images h3 Visualize input images after processing them And we will also look into target images h3 Define Our CNN Model Architecture h3 Here we have defined some utility functions to monitor our results h3 Here we have defined callbacks to monitor training h3 Now we run the model prediction and plot the results ", "stargazers_count": 0, "forks_count": 0, "description": "Here authors have proposed sub pixel convolution layer which learns an array of upscaling filters to upscale the final Low Resolution feature maps into the High Resolution output. We take input data low resolution images we crop the image retrieve the y channel luninance and resize it. Restore the image in RGB color space. The model weights that are considered the best are loaded into the model. get_lowres_image to convert an image to its low resolution version. Store PSNR value in each epoch. Here I am trying to implement the Real Time Single Image and Video Super Resolution Using an Efficient Sub Pixel Convolutional Neural Network http https arxiv. We only consider the luminance channel in the YUV color space because humans are more sensitive to luminance change. Now we run the model prediction and plot the results Import all the necessary libraries Scale from 0 255 to 0 1 Use TF Ops to process. upscale_image to turn a low resolution image to a high resolution version reconstructed by the model. Create a new figure with a default 111 subplot. This is the main metric we use to evaluate super resolution performance. This effectively helps to eliminate bicubic filter in the Super Resolution pipeline with more complex upscaling filters specifically trained for each feature map whilst also reducing the computational complexity of the overall Super Resolution operation. pdf paper on medical chest X ray images. For the target data high resolution images we just crop the image and retrieve the y channel. The ESPCNCallback object will compute and display the PSNR metric. Here we define functions to process the input images. Here we have defined callbacks to monitor training1. plot_results to plot an save an image. First we convert our images from the RGB color space to the YUV colour space. Define image data generators to load and preprocess the images Normalize the pixels for training and validation images Here we have prepared a dataset of test image paths that we will use for visual evaluation at the end of this example. In this function we use the y channel from the YUV color space as input to the model and then combine the output with the other channels to obtain an RGB image. And we will also look into target images Define Our CNN Model Architecture Here we have defined some utility functions to monitor our results1. Visualize input images after processing them. ", "id": "mayank1101sharma/image-super-resolution-on-chest-x-ray-images", "size": "2226", "language": "python", "html_url": "https://www.kaggle.com/code/mayank1101sharma/image-super-resolution-on-chest-x-ray-images", "git_url": "https://www.kaggle.com/code/mayank1101sharma/image-super-resolution-on-chest-x-ray-images", "script": "get_model __init__ display on_test_batch_end process_target tensorflow.keras.preprocessing.image mpl_toolkits.axes_grid1.inset_locator mark_inset image_dataset_from_directory upscale_image on_epoch_end zoomed_inset_axes numpy process_input array_to_img plot_results img_to_array on_epoch_begin ESPCNCallback(keras.callbacks.Callback) load_img matplotlib.pyplot tensorflow scaling tensorflow.keras get_lowres_image layers tensorflow.keras.preprocessing keras IPython.display ", "entities": "(('Now we', 'Use TF 0 255 to 0 1 Ops'), 'run') (('This', 'Super Resolution overall operation'), 'help') (('we', 'example'), 'load') (('we', 'RGB image'), 'use') (('Here we', 'training1'), 'define') (('best', 'model'), 'load') (('Here I', 'https arxiv'), 'try') (('Here we', 'input images'), 'define') (('which', 'High Resolution output'), 'propose') (('humans', 'YUV color space'), 'consider') (('we', 'it'), 'take') (('we', 'y channel'), 'crop') (('First we', 'YUV colour space'), 'convert') (('Here we', 'results1'), 'look') (('main we', 'resolution super performance'), 'be') (('ESPCNCallback object', 'PSNR metric'), 'compute') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["array", "best", "channel", "chest", "color", "combine", "compute", "consider", "convert", "convolution", "crop", "data", "dataset", "default", "define", "display", "end", "evaluate", "evaluation", "feature", "figure", "filter", "final", "function", "high", "http", "image", "implement", "input", "layer", "load", "look", "main", "map", "medical", "metric", "model", "new", "object", "output", "overall", "pdf", "pipeline", "pixel", "plot", "prediction", "processing", "resize", "resolution", "run", "save", "space", "sub", "target", "test", "training", "turn", "validation", "value", "version"], "potential_description_queries_len": 60, "potential_script_queries": ["numpy", "preprocessing", "scaling", "tensorflow"], "potential_script_queries_len": 4, "potential_entities_queries": ["overall"], "potential_entities_queries_len": 1, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 63}
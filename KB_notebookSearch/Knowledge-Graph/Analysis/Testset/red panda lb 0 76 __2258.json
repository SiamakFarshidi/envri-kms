{"name": "red panda lb 0 76 ", "full_name": " h1 Loading the Important Libraries h1 Fixing Config h1 Create Folds h1 Building Dataset h1 Plotting some Images h1 Processing The Images h1 Building Model h1 Defining Training and Validation epochs h1 Defining Training Loop h1 Training with 5 Fold CV h1 Plotting the Losses and the Metric h1 Making submission to leaderboard ", "stargazers_count": 0, "forks_count": 0, "description": "Plotting some ImagesAs you see a lot of white space still remains but that is necessary in order not to miss out actual data. to device optimizer optim. EffecientNet Implementation2. These tissue samples are examined by a pathologist and scored according to the Gleason grading system. reshape 1 return pd. Diagnosis of PCa is based on the grading of prostate tissue biopsies. parameters print f The model has count_parameters model trainable parameters preds preds. With more than 1 million new diagnoses reported every year prostate cancer PCa is the second most common cancer among males worldwide that results in more than 350 000 deaths annually. com kaggle media competitions PANDA Screen 20Shot 202020 04 08 20at 202. The images are normalized using the Mean and Standard Deviation calculated on them previously. Learning Rate Scheduler Loading the Important Libraries Fixing Config Create Folds Building DatasetBecause a majority of the image is white space passing the image directly to the network may result in the model not working upto its full potential as it tries to find patterns in the white space where there are none. Tiled Regularization4. Tiling of the Images3. Another point to notice is that to the human eye the images are extremely indistinguishable and a very eduacted and experienced eye is required to actually grade the images. DataFrame f model_name _Training_Loss train_losses f model_name _Training_Acc train_accs f model_name _Validation_Loss valid_losses f model_name _Validation_Acc valid_accs Make Train and Valid DataFrame from fold Build and load Dataset Initialize model loss and optimizer opt4 optim. 5 each and then the entire concatenated image is flipped with 0. 99 temp_tr_loss temp_val_loss temp_val_metric fit_model model efficientnet b2 train_iterator valid_iterator opt4 loss_criterion device epochs 2 tr_loss temp_tr_loss val_loss temp_val_loss val_metric temp_val_metric test_data Build_Dataset test_df resize 256 256 mode test augmentations test_transforms test_iterator DataLoader test_data batch_size 2 num_workers 4 y_pred get_predictions model test_iterator device test_df isup_grade y_pred test_df. So the image has been greedily tiled into 16 smaller images of regions where non white pixels were more concentrated. To add a pre model regularizing effect each individual tile is flipped horizontally and vertically with a probability of 0. The key to decreasing mortality is developing more precise diagnostics. 225 Defining train and test transforms model enetv2 efficientnet b0 5. One can imagine that mistakes are very plausible in such scenarios and hence perfecting automation of the detecting becomes not only a helping hand software but a necessity in the medical sector Processing The Images Building Model Defining Training and Validation epochs Defining Training Loop Training with 5 Fold CV Plotting the Losses and the Metric Making submission to leaderboard image cv2. png The following kernel uses a dataset of Prostate Tissue images and predicts the ISUP Grade of the PCa. COLOR_BGR2RGB Image net standard mean and std mean 0. to device loss_criterion nn. reshape 1 targets targets. To sum it up the clever ideas to look out for in the implementation 1. ", "id": "sicmunduscreatusest/red-panda-lb-0-76", "size": "2258", "language": "python", "html_url": "https://www.kaggle.com/code/sicmunduscreatusest/red-panda-lb-0-76", "git_url": "https://www.kaggle.com/code/sicmunduscreatusest/red-panda-lb-0-76", "script": "torch.optim torch.utils.data __init__ count_parameters display torch albumentations.pytorch optim tqdm_notebook model as enet train model DataLoader forward ToTensorV2 fit_model extract seaborn numpy tqdm_notebook as tqdm models __getitem__ epoch_time efficientnet_pytorch evaluate get_predictions PIL torchvision Build_Dataset(Dataset) sklearn metrics sklearn.model_selection nn lr_scheduler seed_everything Image matplotlib.pyplot pandas Dataset __len__ enetv2(nn.Module) submit tqdm transforms StratifiedKFold IPython.display ", "entities": "(('tissue samples', 'Gleason grading system'), 'examine') (('count_parameters model trainable parameters', 'preds'), 'f') (('png following kernel', 'PCa'), 'use') (('images', 'them'), 'normalized') (('y_pred 2 4 get_predictions', 'test_iterator device'), '99') (('it', 'white space'), 'Loading') (('worldwide that', '350 more than 000 deaths'), 'report') (('still that', 'actual data'), 'plot') (('extremely very eduacted eye', 'actually images'), 'be') (('key', 'more precise diagnostics'), 'develop') (('mistakes', 'Metric Making image cv2'), 'imagine') (('Diagnosis', 'tissue prostate biopsies'), 'base') (('individual tile', '0'), 'add') (('each then entire concatenated image', '0'), '5') (('where non white pixels', 'regions'), 'tile') ", "extra": "['biopsy of the greater curvature', 'test', 'diagnosis']", "label": "Perfect_files", "potential_description_queries": ["batch_size", "cancer", "dataset", "device", "directly", "effect", "efficientnet", "every", "eye", "find", "fold", "following", "grade", "grading", "hand", "human", "image", "implementation", "individual", "isup_grade", "kaggle", "kernel", "key", "leaderboard", "load", "look", "lot", "majority", "mean", "medical", "mode", "model", "mortality", "most", "network", "new", "non", "normalized", "not", "optimizer", "order", "out", "pathologist", "png", "point", "potential", "pre", "print", "probability", "prostate", "reshape", "resize", "result", "return", "second", "space", "standard", "std", "submission", "sum", "test", "tile", "tissue", "train", "up", "year"], "potential_description_queries_len": 66, "potential_script_queries": ["display", "enet", "evaluate", "extract", "forward", "nn", "numpy", "optim", "seaborn", "sklearn", "torch", "torchvision", "tqdm"], "potential_script_queries_len": 13, "potential_entities_queries": ["grading", "model", "prostate"], "potential_entities_queries_len": 3, "potential_extra_queries": ["biopsy", "diagnosis"], "potential_extra_queries_len": 2, "all_components_potential_queries_len": 80}
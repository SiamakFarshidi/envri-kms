{"name": "introduction to decision trees titanic dataset ", "full_name": " h2 Abstract h2 Preparing the Titanic dataset h2 Visualising processed data h2 Gini Impurity h2 Finding best tree depth with the help of Cross Validation h2 Final Tree ", "stargazers_count": 0, "forks_count": 0, "description": "org wiki Decision_tree_learningIntroduction When applying Machine Learning algorithms it s critical to always keep in mind the problem we re trying to solve. Group all non common titles into one single grouping Rare Mapping Sex Mapping titles Mapping Embarked Mapping Fare Mapping Age Feature selection remove variables no longer containing relevant information Since Survived is a binary class 0 or 1 these metrics grouped by the Title feature represent MEAN survival rate COUNT total observations SUM people survived title_mapping Mr 1 Miss 2 Mrs 3 Master 4 Rare 5 Since Survived is a binary feature this metrics grouped by the Sex feature represent MEAN survival rate COUNT total observations SUM people survived sex_mapping female 0 male 1 Let s use our original_train dataframe to check the sex distribution for each title. font_manager matplotlib. In addition Title may be more valuable to our task by capturing other characteristics of the individuals like age social class personality. Therefore the feature Title is capturing all the information present in Sex. A good example is the traditional problem of classifying Iris flowers included in the sklearn documentation 5 were we can learn about the characteristics of each flower type in the resulting tree. Each split uses different data for training and testing purposes allowing the model to be trained and tested with different data each time. If it doesn t include Mr Title FamilySize is more than 4 and Pclass is more than 2 then we classify it as not survived. png to allow display in web notebook Annotating chart with PIL Drawing offset position Text to draw RGB desired color ImageFont object with desired font Code to check available fonts and respective paths import matplotlib. It s true that by regrouping rare titles into a single category we are losing some information regarding Sex. Misters seem to have honoured their title and sacrificed themselves in favour on women and men with more exotic titles like Master or Dr. First we re going to prepare the dataset and discuss the most relevant features. The code below does exactly this in one line and explains the meaning of each metric when working with a binary class. com arthurtok titanic introduction to ensembling stacking in pythonThis heatmap is very useful as an initial observation because you can easily get an idea of the predictive value of each feature. 6 23 out of 891 samples. After this short introduction to Decision Trees and their place in Machine Learning let s see how to apply them for the Titanic challenge. This is a critical point for every Data Science project since too much train data can easily result in bad model generalisation accuracy on test real unseen observations. Title VS Sex You can easily compare features and their relationship with the class by grouping them and calculating some basic statistics for each group. We use copy again to prevent modifications in out original_train dataset Create Title feature Map Sex as binary feature Table with Sex distribution grouped by Title Since Sex is a binary feature this metrics grouped by the Title feature represent MEAN percentage of men COUNT total observations SUM number of men Define function to calculate Gini Impurity Gini Impurity of starting node Gini Impurity decrease of node for male observations Gini Impurity decrease if node splited for female observations Gini Impurity decrease if node splited by Sex Gini Impurity decrease of node for observations with Title 1 Mr Gini Impurity decrease if node splited for observations with Title 1 Mr Gini Impurity decrease if node splited for observations with Title 1 Mr Desired number of Cross Validation folds Testing max_depths from 1 to max attributes Uncomment prints for details about each Cross Validation pass print Current max depth depth n Extract train data with cv indices Extract valid data with cv indices We fit the model with the fold train data We calculate accuracy with the fold validation data print Accuracy per fold fold_accuracy n print Average accuracy avg print n Just to show results conveniently Create Numpy arrays of train test and target Survived dataframes to feed into our models Create Decision Tree with max_depth 3 Predicting results for test dataset Export our trained model as a. It is calculated as the probability of mislabelling an element assuming that the element is randomly labelled according the the distribution of all the classes in the set. Let s load the data and get an overview. Lastly class correspond to the predominant class of each node and this is how our model will classify an observation. org wiki Information_gain_in_decision_trees 2 https en. Gini Impurity measures the disorder of a set of elements. Thanks to these rules we can infer some insights about the shipwreck. 89 Title seems therefore to be more useful than Sex for our purpose. Next we find the Gini Impurity of the node already explained in this kernel. Given their transparency and relatively low computational cost Decision Trees are also very useful for exploring your data before applying other algorithms. Thanks to this in depth analysis of the Sex and Title features we ve seen that even if the correlation of the feature Sex with the class Survived was higher Title is a richer feature because it carries the Sex information but also adds other characteristics. We ll then find the best tree depth to avoid over fitting generate the final model and explain how to visualise the resulting tree. In other cases too much data can also hide meaningful relationships either because they evolve with time or because highly correlated features prevent the model from capturing properly the value of each single one. Samples is simply the number of observations contained in the node. High chances are one of them will be used for the first node in our final decision tree so let s first explore further these features and compare them. Anisotropic Kernel 3 are commonly used for complex tasks. We re now going to simulate both splits calculate the impurity of resulting nodes and then obtain the weighted Gini Impurity after the split to measure how much each split has actually reduced impurity. html 6 https en. This allows the algorithm to be trained and tested with all available data across all folds avoiding any splitting bias and giving a good idea of the generalisation of the chosen model. The goal of their learning algorithms is always to find the best split for each node of the tree. Of course a complex classification algorithm will do better at identifying the customers who bought a tie by taking into account more features but is that really useful for the supermarket Decision Trees can also help a lot when we need to understanding the data. Decision Trees will try to find the split which decreases Gini Impurity the most across the two resulting nodes. The data shows that less Mr survived 15 67 than men in general 18. org wiki Apriori_algorithm 5 http scikit learn. org wiki Ensemble_learning 3 https www. A good way to find the best value for this parameter is just iterating through all the possible depths and measure the accuracy with a robust method such as Cross Validation 1. The class Survived is already in binary format so no additional formatting is necessary but features like Name Ticket or Cabin need to be adapted for the problem we re trying to solve and we can also engineer some new features by merging or regrouping existing ones. org wiki Cross validation_ statistics The best max_depth parameter seems therefore to be 3 82. Let s now explore the relationship between our variables by plotting the Pearson Correlation between all the attributes in our dataset credit to Anisotropic 1 for this beautiful plot 1 https www. Using them in a Random Forest 6 helps mitigate some of this issues. Let s take the case of a supermarket looking to better understand customer behaviour the straightforward Apriori 4 algorithm can quickly offer relevant insights like 80 of customers who bought a suit also bought a tie so they may try to increase tie sales by offering a discount to clients buying a suit. Thanks to this overview we can see that our dataset needs some treatment. com mrisdal titanic exploring survival on the titanic Visualising processed data Our dataset is now much cleaner than before with only numerical values and potentially meaningful features. We can also note that smaller families had better chances to survive maybe because bigger families tried to stick together or look for missing members and therefore didn t had places left in the lifeboats. That s why advanced techniques such as Deep Learning 1 or Ensemble Learning 2 cf. Finally we can observe that 3rd class passengers had also less chances to survive so probably passengers belonging to upper social social classes were privileged or simply 3rd class cabins may have been further away of the lifeboats. One commonly used metric is Information Gain 1. com c titanic discussion 10169 Finding best tree depth with the help of Cross Validation After exploring the data we re going to find of much of it can be relevant for our decision tree. It s not intended to be the most accurate Titanic survival model out there but to explain how to create visualise and understand Classification Trees. This result only accounts for part of the submission dataset and is indicative while the competition is running. Over fitting a model excessively adapted to the train data is a common reason. There s already extended work on this so we re just using one the best approches out there credit to Sina 1 Anisotropic 2 and also Megan Risdal 3 for the suggestion of the Title feature. findSystemFonts fontpaths None fontext ttf. 86 the highest in our dataset so they are probably carrying the same information and using the two as inputs for the same model wouldn t be a good idea. We ll therefore use 3 as the max_depth parameter for our final model. Abstract In this Kernel we re going to take a look at Decision Trees 1 using Python and the Titanic dataset. This confirms our previous analysis and we re now sure that Title will be used for the first split. The colour also represents the class the opacity increasing with the actual distribution of samples. org wiki Deep_learning 2 https en. com sinakhorami titanic titanic best working classifier 2 https www. The sklearn library we re gonna use implements Gini Impurity 2 another common measure so let s explain it. Value shows the class distribution of the samples count non_survived count survived. But the absolute correlation between both is also very high 0. But measuring the goodness of a given split is a subjective question so in practice different metrics are used for evaluating splits. But for our current purpose let s also find out what can the data tell us about the shipwreck with the help of a Classification Tree. For the titanic example it can be calculated as follows code should be explicit enough 1 https en. If it doesn t include Mr Title FamilySize is more than 4 and Pclass is 2 or less then we classify it as survived. org wiki Random_forest Preparing the Titanic dataset For the Titanic challenge we need to guess wheter the individuals from the test dataset had survived or not. In the case of decision trees the max_depth parameter determines the maximum number of attributes the model is going to use for each prediction up to the number of available features in the dataset. The main downside is that Cross Validation requires the model to be trained for each fold so the computational cost can be very high for complex models or huge datasets. In this case Sex and Title show the highest correlations in absolute terms with the class Survived 0. But remember the KISS principle Keep It Simple Stupid Always consider the complexity accuracy trade off complex techniques should only be used if they offer significant improvements. com arthurtok titanic introduction to ensembling stacking in python 3 https www. Gini Impurity Before start working with Decision Trees let s briefly explain how they work. Our submission to the Titanic competition results in scoring 2234 out of 5672 competition entries. org wiki Decision_tree_learning Gini_impurityLet s use our Sex and Title features as an example and calculate how much each split will decrease the overall weighted Gini Impurity. Let s begin explaining how to read the graph. Therefore is very likely that Title is going to be the first feature in our final decision tree making Sex useless after this initial split. 38 across the training dataset. Our model can therefore be summarised with 4 simple rules If our observation includes de Mr Title then we classify it as not survived all the branches in the left side of the tree lead to an orange node If it doesn t include Mr Title and FamilySize is 4 or less then we classify it as survived. We find that excepting for a single observation a female with Dr title all the observations for a given Title share the same Sex. com arthurtok titanic introduction to ensembling stacking in python 4 https en. In most cases the most accurate and robust model might be what you re looking for. This may be because Title implicitly includes information about Sex in most cases. To verify this we can use the copy we made of the original training data without mappings and check the distribution of Sex grouped by Title. But if we re using Machine Learning to actually get insights from the data blackbox models are almost useless and it s best to stick with simpler transparent techniques. The main aspects covered are Learning from the data with Decision Trees Dataset exploration and processing Relevant features for Decision Trees Gini Impurity Finding best tree depth with the help of cross validation Generating and visualising the final modelThis is my first Kernel so please feel free to include any suggestions comments or critics 1 https en. But sometimes we need to actually get insights from the available data and in these cases transparent easy to understand models like Decision Trees will greatly simplify our task. We could create two categories Rare Male and Rare Female but the separation will be almost meaningless due to the low occurrence of Rare Titles 2. If you want to learn more about how Decision Trees work I recommend you to follow the links in this Kaggle discussion 3. org stable modules tree. Not bad for a simple Decision Tree And remember any suggestions comments or critics are welcome Thanks for reading Diego Imports needed for the script Loading the data Store our test passenger IDs for easy access Showing overview of the train dataset Copy original dataset in case we need it later when digging into interesting features WARNING Beware of actually copying the dataframe instead of just referencing it original_train train will create a reference to the train variable changes in train will apply to original_train Using copy allows to clone the dataset creating a different object with the same values Feature engineering steps taken from Sina and Anisotropic with minor changes to avoid warnings Feature that tells whether a passenger had a cabin on the Titanic Create new feature FamilySize as a combination of SibSp and Parch Create new feature IsAlone from FamilySize Remove all NULLS in the Embarked column Remove all NULLS in the Fare column Remove all NULLS in the Age column Next line has been improved to avoid warning Define function to extract titles from passenger names If the title exists extract and return it. Sex will therefore be neglected since the information is already included in the Title feature. Cross Validation is a model validation technique that splits the training dataset in a given number of folds. If we need to build a model that will be directly used for some task and only show it s end results then we don t really care about building some kind of blackbox if it s accurate enough image or speech recognition for example. Final Tree Finally here we have our Decision Tree It achieves an accuracy of 82. The main downsides of Decision Trees are their tendency to over fit their inability to grasp relationships between features and the use of greedy learning algorithms not guaranteed to find the global optimal model. They re helpful for checking the quality of engineered features and identifying the most relevant ones by visualising the resulting tree. First we need to calculate the Gini Impurity of the starting node including all 891 observations in our train dataset. Since only 342 observations survived the survival probability is around 38 38 342 891. 8 average accuracy across the 10 folds and feeding the model with more data results in worst results probably due to over fitting. The first line of each node except those of the final row shows the splitting condition in the form feature value. Simpler models are also less prone to over fitting and tend to generalise better. If we split by Sex we ll have the two following nodes Node with men 577 observations with only 109 survived Node with women 314 observations with 233 survivedIf we split by Title 1 Mr we ll have the two following nodes Node with only Mr 517 observations with only 81 survived Node with other titles 374 observations with 261 survivedWe find that the Title feature is slightly better at reducing the Gini Impurity than Sex. ", "id": "dmilla/introduction-to-decision-trees-titanic-dataset", "size": "14834", "language": "python", "html_url": "https://www.kaggle.com/code/dmilla/introduction-to-decision-trees-titanic-dataset", "git_url": "https://www.kaggle.com/code/dmilla/introduction-to-decision-trees-titanic-dataset", "script": "sklearn.metrics cross_val_score plotly.offline these metrics grouped by the Title feature represent check_call Image as PImage seaborn numpy ImageFont plotly.graph_objs PIL (0 or 1) get_gini_impurity sklearn sklearn.model_selection KFold plotly.tools Image matplotlib.pyplot pandas subprocess ImageDraw accuracy_score get_title tree xgboost IPython.display ", "entities": "(('We', 'final model'), 'use') (('png', 'available fonts'), 'offset') (('model validation that', 'folds'), 'be') (('that', 'same Sex'), 'find') (('Title', 'most cases'), 'be') (('model', 'train excessively data'), 'be') (('then we', 'it'), 'include') (('you', 'feature'), 'be') (('sometimes we', 'greatly task'), 'need') (('Gini Impurity', 'already kernel'), 'find') (('you', 'what'), 'be') (('That', 'Deep why advanced such Learning'), 's') (('dataset', 'treatment'), 'see') (('Title feature', 'Sex'), 'have') (('sex_mapping female 0 1 s', 'title'), 'group') (('algorithm', 'chosen model'), 'allow') (('how much split', 'Gini overall weighted Impurity'), 'use') (('Using', 'issues'), 'help') (('almost it', 'simpler transparent techniques'), 'be') (('s', '1 beautiful plot'), 'let') (('title', 'it'), 'bad') (('briefly how they', 'Gini Decision Trees'), 'Impurity') (('we', 'problem'), 'decision_tree_learningintroduction') (('s', 'Titanic challenge'), 'let') (('Relevant', 'suggestions first so comments'), 'learn') (('good way', 'Cross such Validation'), 'iterate') (('model', 'dataset'), 'determine') (('when we', 'data'), 'do') (('first line', 'form feature value'), 'show') (('We', 'a.'), 'use') (('less Mr', 'general'), 'show') (('calculated', 'follows code'), 'be') (('We', 'how resulting tree'), 'find') (('they', 'suit'), 'let') (('8 average accuracy', 'probably fitting'), 'due') (('It', 'Classification Trees'), 'intend') (('cost Decision relatively computational Trees', 'other algorithms'), 'be') (('it', 'speech accurate enough example'), 'need') (('Misters', 'Master'), 'seem') (('train too much data', 'unseen test real observations'), 'be') (('which', 'most two resulting nodes'), 'try') (('didn therefore t', 'lifeboats'), 'note') (('opacity', 'samples'), 'represent') (('It', '82'), 'Tree') (('we', 'Title'), 'use') (('5 we', 'resulting tree'), 'be') (('non_survived count', 'samples count'), 'show') (('competition', 'submission dataset'), 'result') (('code', 'when binary class'), 'do') (('Sex', 'class'), 'show') (('we', 'existing ones'), 'be') (('then we', 'it'), 'summarise') (('only they', 'significant improvements'), 'remember') (('They', 'resulting tree'), 're') (('wouldn t', 'same model'), '86') (('now Title', 'first split'), 'confirm') (('we', 'decision tree'), 'be') (('main downsides', 'global optimal model'), 'be') (('absolute correlation', 'both'), 'be') (('First we', 'train dataset'), 'need') (('Gini 2 common so s', 'it'), 'library') (('89 Title', 'purpose'), 'seem') (('Title VS Sex You', 'group'), 'compare') (('higher richer it', 'also other characteristics'), 'see') (('computational cost', 'very complex models'), 'be') (('Sex', 'initial split'), 'be') (('Gini Impurity', 'elements'), 'measure') (('Samples', 'node'), 'be') (('goal', 'tree'), 'be') (('class simply cabins', 'further away lifeboats'), 'observe') (('different metrics', 'splits'), 'be') (('Simpler models', 'also less fitting'), 'be') (('feature Therefore Title', 'present Sex'), 'capture') (('how much split', 'actually impurity'), 'go') (('Rare Rare separation', 'Rare Titles'), 'create') (('so s', 'them'), 'be') (('more than then we', 'it'), 'include') (('s', 'how graph'), 'let') (('also data', 'Classification Tree'), 'let') (('highly correlated features', 'single one'), 'hide') (('dataset', 'now much only numerical values'), 'survival') (('model', 'different data'), 'use') (('individuals', 'test dataset'), 'Random_forest') (('how model', 'observation'), 'correspond') (('we', 'Sex'), 's') (('element', 'set'), 'calculate') (('Anisotropic Kernel', '3 commonly complex tasks'), 'use') (('we', 'shipwreck'), 'infer') (('we', '1 Python'), 'go') (('therefore information', 'Title already feature'), 'neglect') (('First we', 'most relevant features'), 'go') (('I', 'Kaggle discussion'), 'want') (('so we', 'Title feature'), 's') (('Title', 'age class social personality'), 'be') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["absolute", "account", "accuracy", "advanced", "age", "algorithm", "apply", "average", "avg", "avoiding", "basic", "best", "binary", "build", "cabin", "calculate", "care", "case", "category", "challenge", "chart", "check", "checking", "classification", "classifier", "classify", "clone", "code", "color", "column", "compare", "competition", "condition", "consider", "copy", "correlation", "correlations", "cost", "could", "count", "course", "create", "credit", "current", "customer", "cv", "data", "dataframe", "dataset", "decision", "depth", "directly", "display", "distribution", "draw", "end", "engineering", "ensembling", "even", "every", "explained", "explore", "extract", "feature", "feed", "final", "find", "fit", "fitting", "flower", "fold", "following", "form", "format", "formatting", "function", "general", "generate", "grouped", "heatmap", "help", "high", "http", "idea", "image", "import", "include", "including", "increase", "labelled", "lead", "learn", "learning", "left", "let", "library", "line", "load", "look", "looking", "lot", "main", "male", "max", "max_depth", "maximum", "meaning", "measure", "men", "method", "metric", "might", "mind", "missing", "model", "most", "my", "need", "new", "no", "node", "non", "not", "notebook", "number", "numerical", "object", "observation", "offset", "opacity", "out", "overall", "overview", "parameter", "part", "passenger", "people", "per", "percentage", "place", "plot", "plotting", "png", "point", "position", "practice", "prediction", "prepare", "present", "prevent", "print", "probability", "problem", "processing", "project", "purpose", "python", "question", "rare", "re", "read", "reading", "recommend", "reference", "relationship", "remove", "result", "return", "robust", "row", "scikit", "scoring", "script", "selection", "separation", "set", "sex", "short", "side", "single", "sklearn", "split", "splitting", "start", "submission", "survival", "survived", "target", "task", "technique", "test", "testing", "those", "through", "time", "titanic", "title", "total", "train", "training", "tree", "try", "type", "understanding", "up", "upper", "valid", "validation", "value", "variable", "verify", "visualise", "warning", "web", "while", "who", "work", "worst"], "potential_description_queries_len": 218, "potential_script_queries": ["feature", "numpy", "seaborn", "tree", "xgboost"], "potential_script_queries_len": 5, "potential_entities_queries": ["average", "feature", "overall", "validation"], "potential_entities_queries_len": 4, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 220}
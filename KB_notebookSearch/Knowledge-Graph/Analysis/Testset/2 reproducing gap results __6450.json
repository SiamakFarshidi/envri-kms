{"name": "2 reproducing gap results ", "full_name": " h1 Reproducing GAP results Code repository https github com sattree gpr pub h2 Executive Summary h2 Generate predictions for submission ", "stargazers_count": 0, "forks_count": 0, "description": "The paper uses a different evaluation strategy than the one being used in kaggle. The numbers are quite close other than for Random Model explained below. heuristics Contains all the heuristic models the code repository contains models in addition to the ones being presented here. 25 normalizing column names. The evaluation metric in the paper assumes predictions for mention A and B to be conditionally independent while in reality they are mutually exclusive. Hope you will find the code structure easily navigable. This may also be handled by the same confidence model as mentioned above. Hope you find the kernel and models presented useful Don t forget to check out Coref visualization https www. You may have noticed in the code below an adjustment of 0. pronoun_resolution Resolves pronoun mentions from the clusters predicted by the coref models gpr_pub. Reproducing GAP results 1. The model codes are available at https github. Log loss will induce a non linear penalty and will penalize the predictions exponentially as they drift away from ground truth. Results were reproduced for gold two mention task alone since it is directly applicable to this competition. As a consequence of this any model performing better than a random guess would enjoy an upward drift in measured performance. Table Results produced by Parallelism URL heuristic with appropriate fallbacks and evaluated according to multi class kaggle formulation 0. Kaggle multi class evaluation the discrepancy in evaluation is evident from figures 2 and 3 72 vs 65 and illustrates the argument made above about the difference in the two evaluation strategies. Log loss evaluation of the proposed heuristics measured by kaggle s metric of choice the observed performance indicates that the heuristics models serve as a pretty strong baseline for this competition. 25 to the predictions before the calculation of log loss. Fortunately this has been fixed in the kaggle multi class formulation of the problem and models will not be able to leverage such unfair rewards during evaluation. com sattree 1 coref visualization jupyter allenlp stanford1. Looking at the first two figures it appears that all the models have been reproduced well. The stack of models is applied in the order of decreasing precision from top to bottom or left to right if seen as arguments to the sieve model Leads to increasing recall in the same directionEvaluate the predictions as per kaggle fromulation for comparison Generate predictions for submission This concludes the second installment. Reproducing GAP results Code repository https github. Executive Summary First an important note about the results presented in the paper. pdf This kernel is the second in a tri series of self contained installments to introduce the GPR problem. Further Improvements There can be two straighforward extensions to further improve the performance of the heuristic models 1. 8393752431386904 Log loss of the predictions generated by Parallelism URL heuristic with appropriate fallbacks Heuristic Models Reproduced Surface cues Random Token Distance Structural cues Syntactical Distance Parallelism Wikipedia cues URL Results Discussion 1. multi_pass_sieve Implements Backoff mechanism The functionality is similar to the multi pass sieve algorithm proposed for coref resolution by manning et al. com sattree gpr_pub A best effort attempt to reproduce the results presented in the research paper Mind the GAP A Balanced Corpus of Gendered Ambiguous Pronouns https arxiv. com sattree 1 coref visualization jupyter allenlp stanford Stay tuned for the last and final episode A better baseline Download and install all dependencies gpr_pub contains the heuristics models and supplementary code gap_scorer_ext has minor fixes for py3 and to take pandas df as input instead of filepaths Heuristic models implement coref resolution based on heuristics described in the paper Pronoun resolution is a simple wrapper to convert coref predictions into class specific labels Multi pass sieve model implements backoff mechanism Instantiate stanford corenlp server Instantiate base models Load data normalizing column names Instantiate heuristic models Creates sieve pipeline of heuristic models applying each new heuristic with appropriate backoff models Multi pass sieve order of models provided as input is important left to right recall increases right to left precision increases shift the predictions by 0. This should lead to the same results as Token Distance heuristic with a small variance. Only heuristics based results showcased by the authors as best performing in their study were reproduced. To avoid extreme penalties I use a crude lower bound guesstimate to bound the predictions away from zero. A better baseline without any trainingThe notebook only presents results and demonstrates model usage to avoid flooding it with code statements. Replace token distance model as backoff the token distance model enforces a decision for NEITHER category as A or B which actually constitutes a significant portion 10 of the samples and necessarily accepts mispredictions on a subset of these 10 those filtering down to this level in the stack of models. A confidence model to map the the predicted labels to probabilities. py script provided by the GAP authors in their code repository. Moving on below is a summary of the results and findings Table Results reproduced by this kernel predictions scored by gap_scorer. The results from pre trained models will be presented in the upcoming kernel A better baseline. Coref visualization https www. Topical Entity results were not reproduced for gold two mentions the frequency of each token will almost always be 1. Random Model it is suprising that the author s random model generated a performance close to 50 given that 10 of the samples actually belong to NEITHER category. This should provide a significant bump to log loss evaluation. Log loss is applied to the probabilities of predictions whereas we only have access to hard labels. ", "id": "sattree/2-reproducing-gap-results", "size": "6450", "language": "python", "html_url": "https://www.kaggle.com/code/sattree/2-reproducing-gap-results", "git_url": "https://www.kaggle.com/code/sattree/2-reproducing-gap-results", "script": "gpr_pub.models.heuristics.syntactic_distance sklearn.metrics CoreNLPServer gpr_pub.models.pronoun_resolution add_to_score_view attrdict StanfordSyntacticDistanceModel MultiPassSieveModel gpr_pub.gap.gap_scorer_ext gpr_pub.models.heuristics.url_title RandomModel StanfordURLTitleModel PronounResolutionModel gpr_pub.models.multi_pass_sieve read_annotations gpr_pub.models.heuristics.parallelism StanfordURLTitleModel as URLModel CoreNLPDependencyParser allennlp.predictors.predictor pandas classification_report CoreNLPParser load_archive gpr_pub.utils AllenNLPParallelismModel as ParallelismModel TokenDistanceModel log_loss Predictor nltk.parse.corenlp calculate_scores AllenNLPParallelismModel gpr_pub.models.heuristics.token_distance AttrDict gpr_pub.models.heuristics.random_distance allennlp.models.archival ", "entities": "(('exponentially they', 'ground away truth'), 'induce') (('You', '0'), 'notice') (('Fortunately this', 'evaluation'), 'fix') (('This', 'log loss evaluation'), 'provide') (('This', 'confidence also same model'), 'handle') (('models', 'first two figures'), 'appear') (('model', 'measured performance'), 'enjoy') (('I', 'away zero'), 'avoid') (('kernel', 'GPR problem'), 'pdf') (('This', 'second installment'), 'apply') (('10', 'actually category'), 'suprise') (('paper', 'kaggle'), 'use') (('better baseline', 'code statements'), 'present') (('com best effort', 'Gendered Ambiguous Pronouns https arxiv'), 'sattree') (('results', 'upcoming kernel'), 'present') (('Only heuristics based results', 'best study'), 'reproduce') (('pronoun_resolution', 'coref models'), 'resolve') (('pass', 'et al'), 'mechanism') (('discrepancy', 'evaluation two strategies'), 'be') (('they', 'conditionally reality'), 'assume') (('which', 'models'), 'enforce') (('we', 'hard labels'), 'apply') (('code repository', 'ones'), 'contain') (('Moving', 'gap_scorer'), 'be') (('alone it', 'directly competition'), 'reproduce') (('This', 'small variance'), 'lead') (('model codes', 'https github'), 'be') (('kernel', 'visualization https Coref www'), 'hope') (('numbers', 'Random quite close Model'), 'be') (('Multi', '0'), 'com') (('heuristics models', 'competition'), 'indicate') (('frequency', 'token'), 'reproduce') ", "extra": "['biopsy of the greater curvature', 'gender']", "label": "Perfect_files", "potential_description_queries": ["algorithm", "argument", "author", "baseline", "best", "bottom", "calculation", "category", "check", "choice", "close", "code", "column", "comparison", "confidence", "convert", "data", "decision", "df", "difference", "directly", "distance", "effort", "evaluation", "explained", "final", "find", "fixed", "frequency", "generated", "ground", "implement", "improve", "input", "kaggle", "kernel", "lead", "left", "level", "linear", "log", "lower", "map", "mention", "metric", "model", "new", "non", "not", "notebook", "order", "out", "pdf", "per", "performance", "performing", "pipeline", "pre", "precision", "problem", "provide", "py", "random", "recall", "repository", "research", "resolution", "right", "script", "second", "shift", "similar", "stack", "strategy", "structure", "submission", "subset", "summary", "task", "those", "token", "usage", "visualization", "while", "wrapper"], "potential_description_queries_len": 85, "potential_script_queries": ["gap", "parse"], "potential_script_queries_len": 2, "potential_entities_queries": ["close"], "potential_entities_queries_len": 1, "potential_extra_queries": ["biopsy of the greater curvature", "biopsy", "gender"], "potential_extra_queries_len": 3, "all_components_potential_queries_len": 90}
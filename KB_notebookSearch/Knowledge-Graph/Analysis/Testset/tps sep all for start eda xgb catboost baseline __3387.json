{"name": "tps sep all for start eda xgb catboost baseline ", "full_name": " h1 TPS Sep all for start EDA XGB CatBoost Baseline h3 See also my previous TPS works h2 Required functions h2 EDA h2 XGB Baseline h2 Test prediction h2 WORK IN PROGRESS ", "stargazers_count": 0, "forks_count": 0, "description": "The features in this dataset have been anonymized and may contain missing values. The ground truth claim is binary valued but a prediction may be any number from 0. Looks like this new feature can be used for prediction. Although the features are anonymized they have properties relating to real world features. EDA Back to the start section start We have training and test observations. The original dataset deals with calculating the loss associated with a loan defaults. See also my previous TPS works TPS Jun starting point EDA Baseline CV https www. TPS Sep all for start EDA XGB CatBoost Baseline https storage. The feature we created is really very important Let s try a slightly more complex model. Before we continue let s pull the target feature into the separate variable. There are missing values in our data. We encourage you to avoid saturating the leaderboard. Let s create a variable with the sum of missing features and then look at the claim rate for each group of this new feature. Also let s try a CatBoostClassifier. Back to the start section start for feature importance study ML Reproducability Custom theme Show our custom palette Concatenate train and test datasets columns with missing values Create data sets for training 80 and validation 20 The basic model The basic model. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. We should also look at the correlations between features. 0 representing the probability of a claim. All our data is in float32 format. Let s fill them with an average. All features are weakly correlated. com kaggle competitions kaggle 26480 logos header. com maksymshkliarevskyi tps july eda baseline analysis xgbregressor TPS Aug EDA Baselines XGB Keras NN https www. XGB Baseline Back to the start section start In this step we ll train our simple baseline XGBClassifier model. The dataset is used for this competition is synthetic but based on a real dataset and generated using a CTGAN. Wow some groups have a low claim rate. Target feature has int format. com maksymshkliarevskyi tps aug eda baselines xgb keras nn Required functions Back to the start section start First let s load the data and take a look at basic statistics. If you re an established competitions master or grandmaster these probably won t be much of a challenge for you. Now let s look at the feature distributions. For this competition you will predict whether a customer made a claim upon an insurance policy. Test prediction Back to the table of contents section start Let s make 5 folds cv prediction for XGBClassifier and CatBoostClassifier. png t 2021 04 09 00 57 05 The goal of these competitions is to provide a fun and approachable for anyone tabular dataset. com maksymshkliarevskyi tps jun starting point eda baseline cv TPS July EDA Baseline Analysis XGBRegressor https www. It s important to see if our data has missing values. ", "id": "maksymshkliarevskyi/tps-sep-all-for-start-eda-xgb-catboost-baseline", "size": "3387", "language": "python", "html_url": "https://www.kaggle.com/code/maksymshkliarevskyi/tps-sep-all-for-start-eda-xgb-catboost-baseline", "git_url": "https://www.kaggle.com/code/maksymshkliarevskyi/tps-sep-all-for-start-eda-xgb-catboost-baseline", "script": "pdp PermutationImportance seaborn numpy SimpleImputer CatBoostClassifier scipy.stats XGBClassifier sklearn.impute sklearn.model_selection sklearn metrics KFold matplotlib.pyplot pandas eli5.sklearn set_seed StandardScaler RobustScaler model_imp_viz GridSearchCV sklearn.preprocessing catboost xgboost train_test_split pdpbox ", "entities": "(('We', 'training observations'), 'EDA') (('competitions', 'Titanic Getting competition'), 'be') (('s', 'new feature'), 'let') (('new feature', 'prediction'), 'look') (('customer', 'insurance policy'), 'predict') (('features', 'missing values'), 'anonymize') (('png 2021 09 00 57 goal', 'tabular dataset'), 't') (('com kaggle competitions', 'logos 26480 header'), 'kaggle') (('data', 'values'), 's') (('5 folds', 'XGBClassifier'), 'prediction') (('they', 'world real features'), 'have') (('First s', 'basic statistics'), 'baselines') (('ML Reproducability Custom theme custom palette Concatenate train', '20'), 'start') (('Now s', 'feature distributions'), 'let') (('s', 'separate variable'), 'continue') (('dataset', 'CTGAN'), 'use') (('We', 'leaderboard'), 'encourage') (('really very s', 'slightly more complex model'), 'be') (('probably won', 'you'), 'be') (('binary prediction', '0'), 'be') (('we', 'baseline XGBClassifier simple model'), 'Baseline') (('We', 'features'), 'look') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["associated", "aug", "baseline", "basic", "binary", "challenge", "competition", "contain", "correlations", "create", "custom", "customer", "cv", "data", "dataset", "eda", "feature", "fill", "float32", "fun", "generated", "ground", "group", "importance", "int", "kaggle", "let", "load", "loan", "look", "looking", "missing", "model", "my", "new", "nn", "number", "people", "png", "point", "predict", "prediction", "probability", "provide", "re", "section", "separate", "something", "start", "step", "sum", "table", "tabular", "target", "test", "train", "training", "try", "validation", "variable", "world", "xgb"], "potential_description_queries_len": 62, "potential_script_queries": ["catboost", "numpy", "pdp", "pdpbox", "seaborn", "sklearn", "xgboost"], "potential_script_queries_len": 7, "potential_entities_queries": ["kaggle"], "potential_entities_queries_len": 1, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 69}
{"name": "end to end object detection with transformers detr ", "full_name": " h1 About this Notebook h1 Update Log h3 V2 h1 DETR Detection Transformer h1 Using DETR without Fine Tuning h1 Wheat Detection Competition With DETR h1 Utils h1 Configuration h1 Seed Everything h1 Preparing the Data h1 Augmentations h1 Creating Dataset h1 Model h1 Comp Metric h1 Matcher and Bipartite Matching Loss h1 Training Function h1 Eval Function h1 Engine h1 Sample h1 End Notes ", "stargazers_count": 0, "forks_count": 0, "description": "About this NotebookObject Detection is a problem which is not only a bit complex but also computationally expensive due to the number of components to it. com shonenkov training efficientdet The data can be split into any number of folds as you want split is stratified based on number of boxes and source Augmentations As suggested by aleksendra in her kernel augentations will play a major role and hence took her up advice and use awesome augmentations cut mix and other will be included in future versions Creating Dataset I hope you have the video by now DETR accepts data in coco format which is x y w h for those who do not know there are two formats coco and pascal smin ymin xmax ymax which are widely used. Note that for now this is just a baseline to demonstrate the architecture and its working it does not aim at getting very good results on lb this will be a work in progress and I will soon update with full training and a separate Update Log V2 As I was made aware that I was printing the target boxes instead of predicted boxes I have corrected it I am really sorry It was an honest mistake Thanks to PRVI and his valuable suggestions I have incorporated the following changes Normalizing bounding boxes Using label 0 for main classThe code for the changes has been taken from here https www. com facebookresearch detr blob master engine. com facebookresearch detr is link to their github repo for code and model zoo They recently added a wrapper to use DETR from Detectron2 API Wheat Detection Competition With DETRSo I wanted to try DETR and what could be greater oppurtunity than a kaggle competition to test a model s potential. com wp content uploads 2020 05 Screenshot from 2020 05 27 17 48 38. A big Thanks to prvi for his help Utils AverageMeter class for averaging loss metric etc over epochs ConfigurationBasic configuration for this model Seed EverythingSeeding everything for reproducible results Preparing the Data For preparation of data I use code from Alex s awesome kernel here https www. Detection Transformer leverages the transformer network both encoder and the decoder for Detecting Objects in Images. In this notebook I explore this new architecture its working and fine tune it for Wheat Detection competition Dataset. 8562 6 101177000_245125840263462_1160672288488554496_n. Here are the conclusions derived from that kernel Images are taken at different zoom levels. DETR calcuates three individual losses Classification Loss for labels its weight can be set by loss_ce Bbox Loss its weight can be set by loss_bbox Loss for Background class Training FunctionTraining of DETR is unique and different from FasteRRcnn and EfficientDET as we train the criterion as well the training function can be viewed here https github. Transformer acrhitecture is very very powerful and is something which is very close to my part this is the reason I am motivated to explore anything that uses transformers be it google s recently released Tabnet or OpenAI s ImageGPT. 5 A. 0 p 1. It s still quite new but the resuts are astonishing and the model itself is very fast. 5 ToTensorV2 p 1. I just joined two days ago and from what I have analyzed these are by far the best practices for this competition Use Stratified Kfold because of different sources of Images Use Cut mix for better model generalization Use WBF ensemble for unifying predictions of Kfold modelBesides these I found gem of an EDA kernel It gives very valuable insigts you can have a look here https www. The main motive behind DETR is effectively removing the need for many hand designed components like a non maximum suppression procedure or anchor generation that explicitly encode prior knowledge about the task and makes the process complex and computationally expensive The main ingredients of the new framework called DEtection TRansformer or DETR are a set based global loss that forces unique predictions via bipartite matching and a transformer encoder decoder architecture. Special filters should be used to address that. This is the reason for forking the github repo So I did not know that we can add the path to environment variables using sys hence I was changine directories but now I have made changes so I do not have to change directories and import detr easily. Crop and resize data augmentations to be used for model training. HueSaturationValue hue_shift_limit 0. Bounding boxes are messy There are some Giant bounding boxes and some micro bounding boxes removal of which have reported bad lb so I assume the noise is present in the test setas well hence keeping them would be more benificial Keeping all this in find we start with coding DETR Note that this code can be used and easily modified to other object detection tasks Now if you have seen the video you know that DETR uses a special loss called Bipartite Matching loss where it assigns one ground truth bbox to a predicted box using a matcher thus when fine tuning we need the matcher hungarian matcher as used in paper and also the fucntion SetCriterion which gives Bipartite matching loss for backpropogation. 01 A. com watch v LfUsGv ESbc Here https scontent. 0 bbox_params A. BboxParams format coco min_area 0 min_visibility 0 label_fields labels DETR takes in data in coco format Area of bb AS pointed out by PRVI It works better if the main class is labelled as zero Normalizing BBOXES for de normalizing images if p 0. I hope you liked my effort trying hands with this new model If this kernel receives love I plan to fine tune DETR run all five folds and publish an inference kernel using WBF for this competition I belive this can score above 0. Facebook s researchers argue that for object detection one part of the image should be in contact with the other part of the image for greater result especially with ocluded objects and partially visible objects and what s better than to use transformer for it. png Interesting Right Want to learn more please bare with me as always I will try to explain everythingFor Fully understanding DETR I recommend read this https ai. com aleksandradeis globalwheatdetection eda by aleksandra. While I was learning all the different concepts in Object Detection I came across Facebook s Detection tranformer DETR launched in April 2020. com watch v T35ba_VXkMY Using DETR without Fine Tuning Before learning how to fine tune DETR if you want to use and play with DETR directly on some sample images please refer the video here https www. Though mainly developed for NLP the latest research around it focuses on how to leverage it across different verticals of deep learning. com blog end to end object detection with transformers blogHowever if you want in depth knowledge and are a video person like please see the video in the cell belowYou can find the video in youtube here https www. Images are taken at various lighting conditions. pdf _nc_cat 104 _nc_sid ae5e01 _nc_ohc KwU3i7_izOgAX9bxMVv _nc_ht scontent. com prokaj end to end object detection with transformers detr Creating Dataset DETR Detection Transformer Attention is all you need paper for Transformers changed the state of NLP and has achieved great hieghts. 74 without any pseudo labelling tricks I also plan to include visualization of attentionn weights in the next version along with first fold fully trained on 30 35 epochs with a good lr scdeduler I tried to write a genric code so that this can be used with any general object detection dataset and tasksPlease consider upvoting if my efforts helped you or made you excited about DETR cloning github repo of detr to import its unique loss AS PER COMPETITION METRIC Creating Folds def get_train_transforms return A. 2 sat_shift_limit 0. 9 A. Resize height 512 width 512 p 1 A. py Eval Function Engine Sample I know we might be naive to visualize the model ouput just after one epoch but lets do that and see what are the results like End NotesI will further add information about various losses that DETR uses how is criterion declared what are its parameters exactly what is hungarian matcher a little intuition We trained one epoch that too for a single fold but Detr seems to work fairly well. So now we need to prepare data in that format Model Initial DETR model is trained on coco dataset which has 91 classes 1 background class hence we need to modify it to take our own number of classes Also DETR model takes in 100 queries ie it outputs total of 100 bboxes for every image we can very well change that too Comp Metric Matcher and Bipartite Matching LossNow we make use of the unique loss that the model uses and for that we need to define the matcher. I always wanted to learn it and I got really excited when I saw a Kaggle competition on it although I was not able to fully concentrate on it due to other competitions up untill now. Cutout num_holes 8 max_h_size 64 max_w_size 64 fill_value 0 p 0. fna oh 64dad6ce7a7b4807bb3941690beaee69 oe 5F1E8347 is the link to the paper Here https github. RandomBrightnessContrast brightness_limit 0. ", "id": "tanulsingh077/end-to-end-object-detection-with-transformers-detr", "size": "8843", "language": "python", "html_url": "https://www.kaggle.com/code/tanulsingh077/end-to-end-object-detection-with-transformers-detr", "git_url": "https://www.kaggle.com/code/tanulsingh077/end-to-end-object-detection-with-transformers-detr", "script": "torch.utils.data albumentations glob __init__ DETRModel(nn.Module) reset IFrame view_sample SequentialSampler detr.models.detr DataLoader YouTubeVideo forward torch.nn ToTensorV2 collate_fn numpy train_fn __getitem__ RandomSampler get_valid_transforms WheatDataset(Dataset) sklearn.model_selection seed_everything run matplotlib.pyplot HungarianMatcher AverageMeter(object) detr.models.matcher pandas albumentations.pytorch.transforms Dataset __len__ calculate_final_score tqdm eval_fn tqdm.autonotebook StratifiedKFold update torch.utils.data.sampler get_train_transforms SetCriterion IPython.display datetime ", "entities": "(('I', 'directories'), 'be') (('I', 'other competitions'), 'want') (('belowYou', 'https youtube here www'), 'end') (('partially visible what', 'it'), 'argue') (('Here conclusions', 'zoom different levels'), 'take') (('fucntion also which', 'backpropogation'), 'be') (('classThe 0 main code', 'https www'), 'note') (('I', 'April'), 'come') (('you', 'Folds def'), 'plan') (('oe 5F1E8347', 'paper'), 'fna') (('Special filters', 'that'), 'use') (('you', 'https here www'), 'v') (('you', 'look'), 'join') (('better main class', 'normalizing de images'), 'coco') (('I', 'https ai'), 'want') (('Detection Transformer', 'Images'), 'leverage') (('training as well function', 'https here github'), 'calcuate') (('Images', 'lighting various conditions'), 'take') (('this', '0'), 'hope') (('latest research', 'deep learning'), 'focus') (('I', 'Alex awesome kernel'), 'thank') (('DEtection set based global that', 'bipartite matching'), 'remove') (('Detr', 'too single fold'), 'py') (('it', 'recently Tabnet'), 'be') (('you', 'great hieghts'), 'com') (('we', 'matcher'), 'need') (('which', 'it'), 'be') (('formats smin xmax two pascal which', 'y w those'), 'efficientdet') (('I', 'Wheat Detection competition Dataset'), 'explore') (('what', 'potential'), 'be') ", "extra": "['test', 'procedure']", "label": "Perfect_files", "potential_description_queries": ["architecture", "background", "baseline", "bb", "bbox", "best", "bit", "blob", "blog", "bounding", "box", "cell", "close", "coco", "code", "coding", "competition", "consider", "contact", "content", "could", "criterion", "cut", "data", "dataset", "decoder", "def", "define", "depth", "detection", "detr", "directly", "eda", "efficientdet", "effort", "encode", "encoder", "end", "ensemble", "environment", "epoch", "every", "everything", "explore", "find", "fold", "following", "format", "found", "framework", "function", "future", "general", "generalization", "generation", "google", "ground", "hand", "height", "help", "hope", "image", "import", "include", "individual", "inference", "intuition", "itself", "kaggle", "kernel", "knowledge", "label", "labelled", "learn", "learning", "link", "little", "look", "lr", "main", "major", "matching", "maximum", "metric", "might", "mistake", "model", "my", "naive", "need", "network", "new", "next", "noise", "non", "not", "notebook", "number", "object", "out", "part", "path", "pdf", "person", "png", "prepare", "present", "printing", "problem", "procedure", "py", "read", "reason", "recommend", "research", "resize", "result", "return", "role", "run", "sample", "score", "separate", "set", "single", "something", "source", "special", "split", "start", "state", "suppression", "target", "task", "test", "those", "total", "train", "training", "transformer", "try", "tune", "tuning", "understanding", "unique", "up", "update", "version", "video", "visualization", "visualize", "weight", "who", "width", "work", "wrapper", "write", "zoo", "zoom"], "potential_description_queries_len": 159, "potential_script_queries": ["datetime", "forward", "glob", "numpy", "pytorch", "reset", "torch", "tqdm"], "potential_script_queries_len": 8, "potential_entities_queries": ["main", "single"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 165}
{"name": "g2net searching the sky pytorch effnet w meta ", "full_name": " h1 Searching the Sky Explore Understand h1 1 Introduction h3 Libraries h3 Custom Functions h1 2 The Data h2 2 1 The Target is there a black hole h2 2 2 The npy files h1 3 u200d Explore h2 3 1 The Gravitational Waves h3 GW when there is NO signal present h3 GW when there IS a signal present h2 3 2 Signals in time h2 3 3 The MEL Spectrogram h3 Sample h3 GW Signals Spectrogram With Target vs No Target h2 3 4 nnAudio h1 4 Basic Feature Engineering Site Comparisons h2 4 1 In depth analysis h3 Overall Means h3 Overall Minim and Maxim h1 PyTorch EffNet Model Feature Metadata h3 Competition Metric h3 More Libraries Functions h1 5 u200d PyTorch Dataset h3 Test the Dataset function h1 6 PyTorch EfficientNet h3 How it works h1 7 Training h2 7 1 Training Function h3 Full Training Function below h2 7 2 Experiments h3 W B Dashboard h1 8 Submission h3 Submission h1 My Specs ", "stargazers_count": 0, "forks_count": 0, "description": "Competition Goal detect GW Gravitational Wave signals from the mergers of binary black holes from simulated GW time series data created from a network of Earth based detectors. 1 Training FunctionUsually this part can get quite long and weird this is why I usually choose to visualize it with a schema so I can better know at a later date what I did here. It will ask for the API key to login which you can get from your W B profile https wandb. Steps to submission Retrieve the pretrained model s Create a new Dataset Dataloader careful here you don t have the target anymore Predict using the trained models Blend the predictions if you want into a final output Submit Have a snack you re done Submission Note For the purpose of this notebook running faster I ll make the prediction on only the first 20 observations within the test data. GW when there is NO signal present The 3 sites have fairly similar distribution with the third one having fewer outliers than the rest. head 20 line to get the full prediction which is save within my G2net dataset as well. 1 The Gravitational WavesLet s take a look at the Gravitational Waves and see what insights we can find about them before starting creating an actual model. PyTorch DatasetFirst we must create the PyTorch Dataset which will be a class that will take the paths and targets compute the numpy arrays spectrograms and return the result. ROC is a probability curve and AUC represents the degree or measure of separability. ai andrada g2net workspace user andrada Custom Functions 2. What is a Mel Spectrogram A mel spectrogram is a spectrogram where the frequencies are converted to the mel scale. SampleFirst let s look at how the function above works on a simple sample from the data. Higher the AUC the better the model is at predicting the classes. IntroductionUiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii I was hoping to have some fun with a notebook. 1 In depth analysis Overall Means Note We can now explore the means of all observations per site and the differences between them. Why should we use it In sound processing the mel frequency cepstrum MFC is a representation of the short term power spectrum of a sound based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. Convert a power spectrogram amplitude squared to decibel dB units Get the spectrogram Plot it Samples per category Sample 6 paths with target and no target available Plot Enumerate plot Save to W B This function is to calculate the CQT of the input signal. eval Compute a roc_auc score and if better than the last one we save the model Repeat Full Training Function below 7. or CQT kernels can be trained more info on this pachage here https github. factor LOOP TRAIN EVAL UPDATES class VAR name 60k_samples splits 3 epochs 2 batch_size 64 no_neurons 250 lr 0. Note Keep in mind this data is becoming pretty big. 2 Experiments W B DashboardYou can check the evolution of the experiments here https wandb. However these diferences are very tiny. ai site click on Profile Settings scroll to API keys. By doing so spectrograms can be generated from audio on the fly during neural network training and the Fourier kernels e. As a summary First we initiate a new W B experiment where we store all the hyperparameters we ll be using this way we know how to reproduce everything afterwards. How it works Goooood Let s see how it works Below is a schema to help you better grasp how the model works 7. The DataThe training_labels. My Specs Z8 G4 Workstation 2 CPUs 96GB Memory NVIDIA Quadro RTX 8000 Zbook Studio G7 on the go CSS STYLE Libraries Librosa Environment check Secrets Custom colors Set Style Read in the training data Print some useful information Save data to W B Dashboard Create W B Plot Add info about total number of observations Get the full paths to the files and create a df Append the full path as a new column Get a sample data with TARGET 0 Plot Get a sample data with TARGET 1 Plot Target Sample No Target Sample size 6. You can find my W B Dashboard here https wandb. Note There are indeed some differences that can be seen a bit more clear than by looking only at histograms. This is how they look 6. However as the description tells us signals of black holes are very rare. Bonus I added the features from the 3 sites too on a later iteration now we can use the additional information for better serults. This frequency warping can allow for better representation of sound. 4 nnAudio nnAudio is an audio processing toolbox using PyTorch CNN as its backend. This is because the data itself is simulated so there s the benefit that you can purposely simulate a black hole as many times as you want. Searching the Sky Explore Understand 1. List of all metrics we want to compute for each site Create empty columns of the metrics Compute for each ID these metrics First extract the cronological info For each site compute the metrics Add it to the dataframe Process the entire data This took a while and cannot be done in the Kaggle Environment So I made it locally processed get_site_metrics df train_df processed. to_csv training_labels_features. More Libraries Functions 5. Besides the bigger values between Site1 Site2 vs Site3 the distributions look very similar and uniform. Nakama and his notebook here from where I took my inspiration to use this library. com headsortails did in his notebook right here https www. lr weight_decay VAR. Note This function will be used to quickly and efficiently convert the signals from the 3 sites to spectrograms. Overall Minim and Maxim PyTorch EffNet Model Feature Metadata Competition Metric AUC ROC curve is a performance measurement for the classification problems at various threshold settings. 3e20 Plot Images Get the waves from the 3 sites Loop and make spectrogram Compute a mel scaled spectrogram. csv index False Import the data with basic features Save data to W B Dashboard Plot Separate minim maxim values Plot Images End this experiment Libraries Generate Sample Dataset no skill prediction Fit Ensemble Predict probabilities Comparison Plot Set FUNCTIONS Create an image with 3 channels for the 3 sites Load the numpy file Create the spectrograms Select the features Return the images target if available Sample Initiate the Dataset Initiate the Dataloader Output of the Dataloader NN for the spectrogram out layer 2560 NN for the features Final NN for classification Combination of spectrogram features Spectrogram Features Combine Layers Create an example model Effnet We ll use previous datasets dataloader example for 1 batch Outputs Criterion Unsqueeze 1 from shape 3 shape 3 1 W B Experiment CV Split To go quicker through validation Datasets Dataloader Model Optimizer Criterion Scheduler scheduler ReduceLROnPlateau optimizer optimizer mode max verbose True patience VAR. Basic Feature Engineering Site ComparisonsNow let s see some differences similarities between our 3 main sites LIGO Hanford LIGO Livingston and VIRGO. The length of 4096 spans for 2 seconds and it is sampled at 2 048 Hz. We start the training loop epochs train on the training data model. Let s get started Libraries Note If this line throws an error try using wandb. batch_size no_neurons VAR. Test the Dataset function Good Now that we ve created our Dataset class we can test it by using a simple sample of 4 observations 4 distinct paths pointing to the numpy arrays split in 2 batches of size 2 4 distinct targets which are the labels of these paths Note I am also lotting here the 3 channel spectrogram that is created from the 3 sites hence we re making 1 image with 3 channels instead of 3 images with only 1 channel. Special thanks to Y. train we compute the loss and then optimize evaluate how the model did model. ai andrada g2net workspace user andrada Below is a sneak peak of the dashboard 8. GW when there IS a signal present The distributions look similar however there is some more fluctuation at the peak of density and and the extremes especially for Site 2. To do that we are going to take some basic metrics and compute them for each observation and site mean std var min mode max 4. Then we split the data into folds For each fold We initiate a G2Dataset the model loss criterion optimizer etc. com headsortails when stars collide g2net eda. This class is also helpful within the Dataloader tool so we can iterate through multiple files at once. Haven t done some proper artistic EDA in a while and the theme of this competition is absolute perfection. SubmissionWe re at the end of the line folks I ve put here a simple submission code for this notebook. 01 sample 60000 train_effnet name VAR. Below is a sample example the goal is tu have the Area Under the Curve AUC be as big as possible meaning that the line should aim to be as closer to the X and Y axis as possible. csv file contains the file id and the target meaning a flag that is 0 if there is no signal 1 is there is any signal 2. 1 The Target is there a black hole Note The targets are splitted almost 50 50. npy files Note The simulated GW Gravitational Waves are coming from 3 different Observatories LIGO Hanford below in purple LIGO Livingston below in yellow VIRGO below in greenOK Each file has a shape of 3 4096 meaning 3 different GW coming from the 3 sites around the globe of a length of 4096. 0001 weight_decay 0. PyTorch EfficientNetNow we need to create a Module class which will help us take the output from the Dataset class and train it to predict out target variable. weight_decay sample VAR. sample TEST CELL runs faster Sample submission containing extracted features Retrieve all pretrained models Test Dataset Dataloader Loop Disable gradients Predict with each of the 3 models Blend the predictions TODO make KFold Validation DONE TODO Change graph representation DONE TODO create train function DONE TODO create schema for train function DONE TODO preprocess submission data DONE TODO train on more data submit with model DONE TODO dataset add spectrogram augmentation. splits batch_size VAR. 000001 patience 1 factor 0. Note You can notice that it is very hard to observe any kind of difference between the images as the fluctuation is so unperceptable by the naked eye. 2 Signals in timeOk now we can look at how these waves look in time comparing the 3 sites we already know and are familiar with LIGO Hanford LIGO Livingston and VIRGO. 3 The MEL Spectrogram What is a Spectrogram A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. We have 560 000 observation x 3 sites x 4 096 time series length 6 881 280 000 that s 6 billion datapoints. The signals with no target have bigger fluctuations while the other ones have smaller more consistent ones. with a B Hence I will rename these 3 as Site1 Site2 and Site3 like the one and only Heads or Tails https www. com KinWaiCheuk nnAudio. GW Signals Spectrogram With Target vs No TargetGood Looks nice Now we can do a proper comparison between a few samples that contain the Target Signal vs samples that don t. ", "id": "andradaolteanu/g2net-searching-the-sky-pytorch-effnet-w-meta", "size": "9865", "language": "python", "html_url": "https://www.kaggle.com/code/andradaolteanu/g2net-searching-the-sky-pytorch-effnet-w-meta", "git_url": "https://www.kaggle.com/code/andradaolteanu/g2net-searching-the-sky-pytorch-effnet-w-meta", "script": "show_values_on_bars sklearn.metrics torch.utils.data AnnotationBbox torch.optim autocast __init__ matplotlib.gridspec torch __transform__ VAR torch.autograd create_wandb_hist UserSecretsClient create_nnAudio_graph GradScaler make_classification G2Dataset(Dataset) css_styling DataLoader Adam make_spectrogram matplotlib.patches model_selection as sk_model_selection forward train_effnet _show_on_single_plot seaborn numpy librosa.feature torch.cuda.amp torch.optim.lr_scheduler EfficientNet __getitem__ efficientnet_pytorch color ReduceLROnPlateau G2EffNet(nn.Module) offset_png matplotlib.offsetbox melspectrogram get_auc_score pylab CQT1992v2 sklearn.ensemble save_dataset_artifact IPython.core.display nnAudio.Spectrogram sklearn.model_selection RandomForestClassifier nn sklearn matplotlib.pyplot text kaggle_secrets get_site_metrics pandas set_seed Dataset __len__ sklearn.datasets OffsetImage tqdm Variable torch.nn.functional model_selection roc_auc_score matplotlib roc_curve StratifiedKFold plot_loss_graph create_wandb_plot get_npy_df train_test_split matplotlib.image HTML ", "entities": "(('fluctuation', 'so naked eye'), 'note') (('frequency warping', 'sound'), 'allow') (('which', 'G2net dataset'), 'head') (('You', 'W B Dashboard'), 'find') (('distributions', 'bigger values'), 'look') (('we', 'how everything'), 'know') (('indeed that', 'bit more only histograms'), 'note') (('that', 'samples'), 'Spectrogram') (('targets', 'result'), 'create') (('factor LOOP TRAIN EVAL UPDATES class VAR 60k_samples', '3 epochs'), 'name') (('Hanford', 'Livingston'), 'signal') (('We', 'training data model'), 'start') (('signals', 'black holes'), 'tell') (('Overall We', 'them'), '1') (('hence we', 'instead 3 only 1 channel'), 'test') (('W B Experiment CV validation Datasets Dataloader Model Optimizer Criterion scheduler ReduceLROnPlateau optimizer optimizer mode 3 3 1 quicker Scheduler max', 'patience True VAR'), 'Import') (('we', 'multiple files'), 'be') (('here where I', 'library'), 'Nakama') (('GW when signal distributions', 'especially Site'), 'look') (('we', 'Repeat Full Training 7'), 'Compute') (('Hence I', 'Site1 Site2'), 'rename') (('com headsortails', 'https right here www'), 'do') (('now we', 'better serults'), 'add') (('you', 'W B profile https wandb'), 'ask') (('ai workspace user g2net Below', 'sneak dashboard'), 'andrada') (('other ones', 'smaller more consistent ones'), 'have') (('Overall EffNet Feature Metadata Competition Metric AUC ROC curve', 'threshold various settings'), 'Minim') (('when 3 sites', 'rest'), 'gw') (('so spectrograms', 'network neural training'), 'generate') (('better how model', '7'), 'work') (('how function', 'data'), 'let') (('as many times you', 'purposely black hole'), 'be') (('line', 'wandb'), 'let') (('model', 'classes'), 'high') (('Competition Goal', 'Earth'), 'detect') (('3 different GW', '4096'), 'file') (('ROC', 'separability'), 'be') (('Experiments W B 2 DashboardYou', 'experiments'), 'check') (('we', 'actual model'), '1') (('it', 'time'), '3') (('IntroductionUiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii I', 'notebook'), 'hope') (('optimize then how model', 'model'), 'compute') (('CQT kernels', 'https here github'), 'train') (('mel frequency cepstrum MFC', 'frequency'), 'use') (('function', 'spectrograms'), 'note') (('spectrogram Compute', 'sites 3 Loop'), 'get') (('it', '2 048 Hz'), 'sample') (('us', 'target variable'), 'EfficientNetNow') (('function', 'input signal'), 'get') (('df train_df', 'locally get_site_metrics'), 'create') (('line', 'as X'), 'be') (('TODO', 'spectrogram augmentation'), 'run') (('faster I', 'test data'), 'step') (('we', 'std var'), 'go') (('that', 'file'), 'contain') (('0 Plot', 'TARGET'), 'NVIDIA') (('theme', 'competition'), 'do') (('280 6 881 000 that', '560 000 observation'), 'have') (('model loss criterion optimizer', 'G2Dataset'), 'split') (('Hanford', 'Livingston'), 'let') (('com when stars', 'g2net eda'), 'headsortail') (('I', 'what'), '1') (('I', 'notebook'), 're') (('where frequencies', 'mel scale'), 'be') (('nnAudio 4 nnAudio', 'backend'), 'be') (('data', 'Note mind'), 'keep') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["absolute", "audio", "basic", "batch", "batch_size", "binary", "bit", "calculate", "category", "channel", "check", "choose", "classification", "clear", "code", "column", "comparison", "competition", "compute", "contain", "convert", "cosine", "create", "criterion", "csv", "curve", "data", "dataframe", "dataset", "date", "degree", "depth", "description", "detect", "df", "difference", "distribution", "empty", "end", "error", "eval", "evaluate", "everything", "experiment", "explore", "extract", "factor", "faster", "file", "final", "find", "fly", "fold", "frequency", "fun", "function", "generated", "globe", "graph", "head", "help", "id", "image", "index", "info", "input", "iteration", "itself", "key", "layer", "length", "let", "line", "linear", "log", "look", "looking", "loop", "lr", "main", "max", "mean", "meaning", "measure", "measurement", "mel", "min", "mind", "mode", "model", "multiple", "my", "name", "need", "network", "neural", "new", "no", "notebook", "number", "numpy", "observation", "optimize", "optimizer", "out", "output", "part", "path", "peak", "per", "performance", "plot", "power", "predict", "prediction", "present", "pretrained", "probability", "processing", "profile", "purpose", "re", "representation", "return", "right", "running", "sample", "save", "scale", "scaled", "scheduler", "score", "shape", "short", "signal", "similar", "site", "size", "sound", "spectrum", "split", "squared", "start", "std", "store", "submission", "summary", "target", "term", "test", "threshold", "through", "time", "tool", "total", "train", "training", "transform", "try", "user", "validation", "var", "visualize", "while"], "potential_description_queries_len": 164, "potential_script_queries": ["color", "core", "cuda", "forward", "matplotlib", "melspectrogram", "nn", "optim", "pylab", "seaborn", "sklearn", "text", "torch", "tqdm"], "potential_script_queries_len": 14, "potential_entities_queries": ["data", "mode", "optimizer", "right", "signal", "validation"], "potential_entities_queries_len": 6, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 177}
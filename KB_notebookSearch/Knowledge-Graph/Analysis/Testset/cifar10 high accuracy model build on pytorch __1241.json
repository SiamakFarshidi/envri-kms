{"name": "cifar10 high accuracy model build on pytorch ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "input to device as our model is running in mentioned device. setting the initial gradient to 0 backpropagating the loss updating the weights and bias values for every single step. FLips the image w. We iter the batch of images to display converting our train_dataloader to iterable so that we can iter through it. going from 1st batch of 100 images to the next batch We plot 20 images from our train_dataset converting to numpy array as plt needs it. Set the color params comvert the image to tensor so that it can work with torch Normalize all the images Data augmentation is only done on training images Batch size of 100 i. input is color image hence 3 i p channels. Max pooling layer with kernal of 2 and stride of 2 flatten our images to 1D to input it to the fully connected layers Applying dropout b t layers which exchange highest parameters. every batch of 100 images are put as an input. calculating te accuracy by taking the sum of all the correct predictions in a batch. loss per epoch accuracy per epoch appending for displaying applying the transformations on new image as our model has been trained on these transformations convert to numpy array for plt put inputs in device as our model is running there. I p image size is 32 32 after 3 MaxPooling layers it reduces to 4 4 and 64 because our last conv layer has 64 outputs. Displaying the progress. t horizontal axis Rotates the image to a specified angel Performs actions like zooms change shear angles. Maybe by running more epochs I can get better accuracy or some more hyper parameter tuning will help. As seen I got 71 accuracy for this model and te model performed well on images it had never seen before. Different classes in CIPHAR 10 dataset. resises the image so it can be perfect for our model. Calc loss after each batch i p by comparing it to actual labels. This process will happen in normal cpu. We double the feature maps for every conv layer as in pratice it is really good. taking the highest value of prediction. It correctly classified a random image from the internet. Output nodes is 500 output nodes are 10 because our dataset have 10 different categories Apply relu to each output of conv layer. In this notebook I am using the Cifar10 dataset to classify various images. Let me know the suggestions for hyper parameter tunning for the same model. I have build this on PyTorch but personally I like Tensorflow Keras more. we do not need gradient for validation. This is a good practice run our model on cuda GPU for faster results same as categorical_crossentropy loss used in Keras models which runs on Tensorflow fine tuned the lr training our model put input according to every batch. Even though LeNet is a old it is still a very good model to start with. Additionally I am sure that Transfer learning will yield much better accuracy if I use Vgg16 for suppose. I have coded the traditional LeNet model with some hyper parameter tuning for this purpose. Input new image from web to check our model s accuracyUse the images from our validation dataset to check the precdictions As seen the predictions on new images are really good. e to work with 100 images at a time We need to convert the images to numpy arrays as tensors are not compatible with matplotlib. 16 filters kernal size is tuned to 3 to avoid overfitting stride is 1 padding is 1 extract all edge features. Please find the code belowInitializing GPU UsageTransformations and Data AugmentationConverting the Input images to plot using pltDefining our ModelFitting our model with the inputs to generate output. But for this case I wanted to code my own model. ", "id": "vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch", "size": "1241", "language": "python", "html_url": "https://www.kaggle.com/code/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch", "git_url": "https://www.kaggle.com/code/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch", "script": "torch.nn.functional __init__ nn forward transforms torch LeNet(nn.Module) numpy matplotlib.pyplot Image datasets im_convert PIL torchvision ", "entities": "(('t horizontal axis', 'shear angles'), 'rotate') (('I', 'various images'), 'use') (('which', 'highest parameters'), 'layer') (('it', 'model'), 'resise') (('code', 'output'), 'find') (('input', 'mentioned device'), 'run') (('I', 'purpose'), 'code') (('I', 'own model'), 'want') (('model', 'batch'), 'be') (('predictions', 'new images'), 's') (('it', 'te well images'), 'get') (('plt', 'it'), 'plot') (('I', 'suppose'), 'be') (('model', 'device'), 'loss') (('I', 'better accuracy'), 'get') (('batch', 'input'), 'put') (('it', 'pratice'), 'be') (('It', 'internet'), 'classify') (('10 different categories', 'conv layer'), 'be') (('me', 'same model'), 'let') (('conv last layer', '64 outputs'), 'be') (('Data augmentation', '100 i.'), 'comvert') (('personally I', 'Tensorflow Keras'), 'build') (('we', 'it'), 'iter') (('tensors', 'matplotlib'), 'e') (('stride 1 padding', 'edge 1 features'), 'tune') (('i', 'actual labels'), 'loss') ", "extra": "", "label": "No_extra_files", "potential_description_queries": ["accuracy", "array", "augmentation", "batch", "build", "case", "check", "classify", "code", "color", "conv", "convert", "correct", "cuda", "dataset", "device", "display", "double", "edge", "epoch", "every", "extract", "faster", "feature", "find", "generate", "gradient", "image", "input", "iter", "layer", "learning", "lr", "model", "my", "need", "new", "next", "normal", "not", "notebook", "numpy", "output", "overfitting", "padding", "parameter", "per", "plot", "plt", "pooling", "practice", "random", "run", "running", "shear", "single", "size", "start", "stride", "sum", "tensor", "through", "time", "torch", "training", "tuning", "validation", "value", "web", "work"], "potential_description_queries_len": 70, "potential_script_queries": ["forward", "nn", "torch", "torchvision"], "potential_script_queries_len": 4, "potential_entities_queries": [], "potential_entities_queries_len": 0, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 73}
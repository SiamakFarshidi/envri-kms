{"name": "transfer learning densenet xception pneumonia ", "full_name": " h1 Pneumonia Detection Using Chest Xrays h2 CNN DenseNet201 Xception h3 xa0 xa0 xa0 xa01 Problem Statement h3 xa0 xa0 xa0 xa02 EDA and Image Augmentation h3 xa0 xa0 xa0 xa03 Model Building h3 xa0 xa0 xa0 xa04 Conclusion and Results h1 Import Libraries xa0 xa0 xa0 xa0 h1 Read the Dataset xa0 xa0 xa0 xa0 h1 Get the class labels in Train Test and Val xa0 xa0 xa0 xa0 h1 Distribution plots xa0 xa0 xa0 xa0 h1 Bluring xa0 xa0 xa0 xa0 h3 Greyscale h3 Gaussian Blur h3 Median h3 Averaging h3 X rays with Gaussian Bluring Median Bluring Average Bluring h1 Transformations xa0 xa0 xa0 xa0 h1 Simple CNN model xa0 xa0 xa0 xa0 h3 Prepare Image Data Generator h3 Add Model Layers h3 Visualize the model h3 Plot the model h3 Fit the model h3 Plot the loss curve h3 Trying more epcohs may give better results on validation set h3 Get prediction for all xrays in Val h3 Get actual classes h1 DenseNet201 xa0 xa0 xa0 xa0 h3 Add DenseNet201 layer h3 Model Building xa0 xa0 xa0 xa0 h3 Plot the loss h3 Accuracy plot h3 Quite a few fluctuation in the loss of the Test set are observed h3 Evaluate the model on test set h3 Predict on Val set h3 Evaluate the model on Val set h3 Get actual classes h4 1 XceptionNet h4 2 Separable Layers h4 3 Why is separable convolution better than normal convolution h1 Xception xa0 xa0 xa0 xa0 h3 Model Building xa0 xa0 xa0 xa0 h3 Plot the loss h3 Plot the accuracy h3 Cut off at epoch 5 post that the val accuracy decreases h3 Evaluate the model on Test set h3 Predict on Val set h3 Evaluate on Val set h3 Predict on Val set h3 Get Actual Classes ", "stargazers_count": 0, "forks_count": 0, "description": "It also helps in zooming in images. Similarly for the Middle flow and the Exit flow this diagram clearly explains the image size the various layers the number of filters the shape of filters the type of pooling the number of repetitions and the option of adding a fully connected layer in the end. There are also Max Pooling layers. Also all Convolutional and Separable Convolutional layers are followed by batch normalization. If we make H_l to produce k feature maps every time then we can generalize for the l th layer kl k0 k l 1 This hyperparameter k is the growth rate. There are 5 863 X Ray images JPEG and 2 categories Pneumonia Normal. We want to keep them in inference mode when we unfreeze the base model for fine tuning so we make sure that the base_model is running in inference mode here. This operation processes the edges while removing the noise. Many times we need to resize the image i. Each layer is then adding a new information to this collective knowledge in concrete k feature maps of information. Freeze the base_model The base model contains batchnorm layers. Conclusion and Results Problem Statement and Introduction to Dataset The dataset is organized into 3 folders train test val and contains subfolders for each image category Pneumonia Normal. Model Building nbsp nbsp nbsp nbsp 4. figure figsize 16 9 plt. The difference lies in the dimensionality of the filters. history loss label Train Loss plt. Furthermore some variations of ResNets have proven that many layers are barely contributing and can be dropped. MedianThe Median blur operation is similar to the other averaging methods. The growth rate regulates how much information is added to the network each layer. Another problem with very deep networks was the problems to train because of the mentioned flow of information and gradients. Since we are concatenating feature maps this channel dimension is increasing at every layer. DenseNets simplify the connectivity pattern between layers introduced in other architectures 1. It also shows the shape of the input tensor in each flow. To do it they simply connect every layer directly with each other. DenseNets do not sum the output feature maps of the layer with the incoming feature maps but concatenate them. Evaluate the model on test set Predict on Val set Evaluate the model on Val set Get actual classes Xception Architechture 1. Color MapsApplying different types of color maps. This exam will also help determine if you have any complications related to pneumonia such as abscesses or pleural effusions fluid surrounding the lungs. The next version of notebook will deal with the pretrained models like Resnet50. Problem Statement nbsp nbsp nbsp nbsp 2. Fractal Networks The authors solve the problem ensuring maximum information and gradient flow. Using the Xception reached a accuracy of 74. ylabel Accuracy plt. Motivation The problems arise with CNNs when they go deeper. Reference https towardsdatascience. XceptionNet Convolutional Neural Networks CNN have come a long way from the LeNet style AlexNet VGG models which used simple stacks of convolutional layers for feature extraction and max pooling layers for spatial sub sampling stacked one after the other to Inception and ResNet networks which use skip connections and multiple convolutional and max pooling blocks in each layer. In the separable convolution we only transform the image once in the depthwise convolution. xl 1 ResNets DenseNets are divided into DenseBlocks where the dimensions of the feature maps remains constant within a block but the number of filters changes between them. rotate method is used to rotate a 2D array in multiples of 90 degrees. As we see in figure above the Xception module has 3 main parts. Scaling comes in handy in many image processing as well as machine learning applications. Model BuildingSimple CNN model nbsp nbsp nbsp nbsp Prepare Image Data Generator Add Model Layers Visualize the model Plot the model Fit the model Plot the loss curve Trying more epcohs may give better results on validation set Get prediction for all xrays in Val Get actual classes DenseNet Architechture BackgroundDensely Connected Convolutional Networks DenseNets are the next step on the way to keep increasing the depth of deep convolutional networks. ylabel Loss plt. Consequently the equation reshapes again into xl Hl x0 x1 x2. Regularize with dropout plt. How Pneumonia is detected Chest x ray An x ray exam will allow your doctor to see your lungs heart and blood vessels to help determine if you have pneumonia. Affine TransformationIn Affine transformation all parallel lines in the original image will still be parallel in the output image. When the strides are different than one the strides are also mentioned. history accuracy label Train Accuracy plt. Then we take the transformed image and simply elongate it to 64 channels. add_shape type rect x0 9. 5 arrowhead 2 fig. Do not include the ImageNet classifier at the top. Xception nbsp nbsp nbsp nbsp Model Building nbsp nbsp nbsp nbsp Plot the loss Plot the accuracy Cut off at epoch 5 post that the val accuracy decreases. Structure Traditional feed forward neural networks connect the output of the layer to the next layer after applying a composite of operations. Evaluate the model on Test set Predict on Val set Evaluate on Val set Predict on Val set Get Actual Classes Conclusion and Results Using the simple version of CNN with multiple layers of Con2d with Maxpooling2d reached a accuracy of 82 on the test set. Separable Layers Separable convolutions consist of first performing a depthwise spatial convolution which acts on each input channel separately followed by a pointwise convolution which mixes the resulting output channels. The diagram also mentions in detail the number of filters the filter size kernel size and the strides. When interpreting the x ray the radiologist will look for white spots in the lungs called infiltrates that identify an infection. What problem DenseNets solve Counter intuitively by connecting this way DenseNets require fewer parameters than an equivalent traditional CNN as there is no need to learn redundant feature maps. Scaling ResizingImage resizing refers to the scaling of images. The entry flow has two blocks of convolutional layer followed by a ReLU activation. xlabel Epochs plt. getAffineTransform will create a 2 3 matrix which is to be passed to cv2. Without having to transform the image over and over again we can save up on computational power. And every transformation uses up 3x3x3x64 1 728 multiplications. DenseNets solve this issue since each layer has direct access to the gradients from the loss function and the original input image. 15 line dict color yellow width 1 dash dash Evaluate the model Define Training and Validation Data Generator with Augmentations Flow the data into the Data Generator Rebuild top plt. Import Libraries nbsp nbsp nbsp nbsp Read the Dataset nbsp nbsp nbsp nbsp Get the class labels in Train Test and Val nbsp nbsp nbsp nbsp EDA and Image Augmentation Distribution plots nbsp nbsp nbsp nbsp Bluring nbsp nbsp nbsp nbsp Greyscale Gaussian BlurIn Gaussian Blur operation the image is convolved with a Gaussian filter instead of the box filter. The Gaussian filter is a low pass filter that removes the high frequency components are reduced. There are also Skip connections where we use ADD to merge the two tensors. And the total number of filters we want is 64. Preprocessing the data Look at the training testing and validation data numbers Create a 1x2 subplot create empty figure trace Get the Express fig broken down as traces and add the traces to the proper plot within in the subplot Define Training and Validation Data Generator with Augmentations Flow the data into the Data Generator Compile the model and see it s structure and parameters display using your system viewer write and show Save the model plt. 12 filters and they just add a small set of new feature maps. Instead of drawing representational power from extremely deep or wide architectures DenseNets exploit the potential of the network through feature reuse. In this process the central element of the image is replaced by the average of all the pixels in the kernel area. Chest X ray images anterior posterior were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children s Medical Center Guangzhou. It helps in reducing the number of pixels from an image and that has several advantages e. In fact the number of parameters of ResNets are big because every layer has its weights to learn. Every layer has access to its preceding feature maps and therefore to the collective knowledge. X rays with Gaussian Bluring Median Bluring Average BluringTransformations nbsp nbsp nbsp nbsp 1. This is because the path for information from the input layer until the output layer and for the gradient in the opposite direction becomes so big that they can get vanished before reaching the other side. Instead DenseNets layers are very narrow e. 7 font dict color yellow size 12 arrowcolor yellow arrowsize 5 arrowwidth 0. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. title Accuracy over the Epochs plt. Pneumonia Detection Using Chest XraysCNN DenseNet201 Xception Contents nbsp nbsp nbsp nbsp 1. From Keras Documentation 3. These layers between them are called Transition Layers and take care of the downsampling applying a batch normalization a 1x1 convolution and a 2x2 pooling layers. 15 line dict color yellow width 1 dash dash Evaluate the model Evaluate the model Define Training and Validation Data Generator with Augmentations Flow the data into the Data Generator Load weights pre trained on ImageNet. 15 line dict color yellow width 1 dash dash plt. either shrink it or scale up to meet the size requirements. The equation for this would be xl Hl xl 1 ResNets extended this behavior including the skip connection reformulating this equation into xl Hl xl 1 xl 1 DenseNets make the first difference with ResNets right here. AveragingDuring this operation the image is convolved with a box filter normalized. There are also various Separable convolutional layers. 16 ax 0 ay 40 text MobileNet Model stopped Overfitting Zone xanchor center xshift 10 opacity 0. How so We could see the feature maps as the information of the network. Extra metallic objects such as jewelry are removed from the chest and neck areas for a chest X ray to avoid interference with X ray penetration and improve the accuracy of the interpretation. The Entry flow the Middle flow which is repeated 8 times and the Exit flow. 15 line dict color yellow width 1 dash dash Evaluate the model Evaluate the model. It can reduce the time of training of a neural network as more is the number of pixels in an image more is the number of input nodes that in turn increases the complexity of the model. For example we begin with an image size of 299x299x3 and after the entry flow we get an image size of 19x19x728. To find the transformation matrix we need three points from input image and their corresponding locations in the output image. Since its introduction one of the best networks in computer vision has been the Inception network. The main difference is that in the normal convolution we are transforming the image multiple times. OpenCV provides us several interpolation methods for resizing an image. Here the central element of the image is replaced by the median of all the pixels in the kernel area. We have already seen that normally this composite includes a convolution operation or pooling layers a batch normalization and an activation function. Now we are ready to talk about the growth rate. Why is separable convolution better than normal convolution If we were to use a normal convolution on the input tensor and we use a filter kernel size of 3x3x3 kernel size 3 3 and 3 feature maps. All chest X ray imaging was performed as part of patients routine clinical care. history val_accuracy label Valid Accuracy plt. history val_loss label Valid Loss plt. In order to account for any grading errors the evaluation set was also checked by a third expert. What Does a Chest X Ray Show A chest X ray is most commonly used to detect abnormalities in the lungs but can also detect abnormalities in the heart aorta and the bones of the thoracic area. So a total of 3x3x3x64. title Loss over the Epochs plt. Traditional Convolutional layer 3x3x3x64 1 728Separable Convolutional layer 3x3x1x3 1x1x3x64 27 192 219As we see separable convolution layers are way more advantageous than traditional convolutional layers both in terms of computation cost as well as memory. com understanding and visualizing densenets 7f688092391aDenseNet201 nbsp nbsp nbsp nbsp Add DenseNet201 layerModel Building nbsp nbsp nbsp nbsp Plot the loss Accuracy plot Quite a few fluctuation in the loss of the Test set are observed. The Inception model uses a stack of modules each module containing a bunch of feature extractors which allow them to learn richer representations with fewer parameters. Instead in separable convolution we first use 3x3x1x3 in depthwise convolution and 1x1x3x64 in pointwise convolution. show summarize history for metric annotations dict showarrow True x 10 y 1. EDA and Image Augmentation nbsp nbsp nbsp nbsp 3. For the analysis of chest x ray images all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. Using the DenseNet201 reached a accuracy of 85. ", "id": "ankitp013/transfer-learning-densenet-xception-pneumonia", "size": "19462", "language": "python", "html_url": "https://www.kaggle.com/code/ankitp013/transfer-learning-densenet-xception-pneumonia", "git_url": "https://www.kaggle.com/code/ankitp013/transfer-learning-densenet-xception-pneumonia", "script": "Flatten tensorflow.keras.optimizers tensorflow.keras.layers tensorflow.keras.preprocessing.image Dropout rotation colormaps SGD Adam Conv2D numpy plotly.graph_objs make_subplots affine_tf subtract_gaussian_bg_image plotly.express ImageDataGenerator subtract_average_bg_image load_img image matplotlib.pyplot tqdm.notebook tensorflow ResNet50 pandas Dense tensorflow.keras.layers.experimental keras.utils plotly.subplots subtract_median_bg_image tqdm resize plot_model preprocess_input load_model Model MaxPooling2D tensorflow.keras.preprocessing backend backend as K keras tensorflow.keras.applications.resnet50 keras.models preprocessing ", "entities": "(('we', 'kernel 3x3x3 size'), 'be') (('image', 'Gaussian filter'), 'nbsp') (('DenseNet Architechture BackgroundDensely Connected Convolutional Networks DenseNets', 'deep convolutional networks'), 'model') (('central element', 'kernel area'), 'replace') (('Structure Traditional', 'operations'), 'feed') (('image', 'box filter normalized'), 'averagingduring') (('we', '19x19x728'), 'begin') (('chest X ray imaging', 'clinical care'), 'perform') (('Overfitting Zone xanchor center', '10 opacity'), 'ax') (('diagram', 'filters'), 'mention') (('as number', 'model'), 'be') (('OpenCV', 'image'), 'provide') (('Convolutional Also Convolutional layers', 'batch normalization'), 'follow') (('strides', 'one'), 'be') (('history val_accuracy', 'Valid Accuracy plt'), 'label') (('Consequently equation', 'xl Hl x0 x1 again x2'), 'reshape') (('DenseNets', 'them'), 'sum') (('layers', '1x1 convolution'), 'call') (('It', 'flow'), 'show') (('Now we', 'growth rate'), 'be') (('difference', 'filters'), 'lie') (('Define Data Training Generator', 'ImageNet'), 'Evaluate') (('we', 'image'), 'be') (('next version', 'Resnet50'), 'deal') (('val accuracy', 'that'), 'nbsp') (('dash dash 1 model', 'Data Generator Rebuild top plt'), 'Evaluate') (('ResNet which', 'max multiple convolutional layer'), 'come') (('that', 'infection'), 'look') (('layer', 'information'), 'add') (('them', 'fewer parameters'), 'use') (('Many times we', 'image i.'), 'need') (('entry flow', 'ReLU activation'), 'have') (('when they', 'CNNs'), 'Motivation') (('color 7 font dict yellow size', '12 arrowcolor yellow 5 arrowwidth'), 'arrowsize') (('operation', 'noise'), 'process') (('parallel lines', 'output still image'), 'be') (('already normally composite', 'pooling batch normalization'), 'see') (('we', 'pointwise convolution'), 'use') (('layer', 'therefore collective knowledge'), 'have') (('Chest X Ray chest X ray', 'thoracic area'), 'what') (('dataset', 'image category'), 'conclusion') (('channel dimension', 'layer'), 'concatenate') (('problem', 'information'), 'be') (('Scaling ResizingImage resizing', 'images'), 'refer') (('intuitively way DenseNets', 'feature redundant maps'), 'solve') (('number', 'them'), 'divide') (('layer', 'weights'), 'be') (('DenseNets', 'feature reuse'), 'of') (('one', 'computer vision'), 'be') (('show', 'annotations dict metric showarrow'), 'summarize') (('diagnoses', 'AI system'), 'grade') (('Exit diagram', 'end'), 'explain') (('model', 'actual classes'), 'evaluate') (('Using', '74'), 'reach') (('a few fluctuation', 'Test set'), 'com') (('Extra metallic objects', 'interpretation'), 'remove') (('blood you', 'pneumonia'), 'detect') (('DenseNets', 'other architectures'), 'simplify') (('xl Hl 1 ResNets', 'ResNets'), 'be') (('layer', 'loss function'), 'solve') (('which', 'Middle flow'), 'flow') (('Fractal authors', 'maximum information'), 'Networks') (('many layers', 'ResNets'), 'prove') (('Using', 'test set'), 'evaluate') (('they', 'directly other'), 'connect') (('Skip also where we', 'two tensors'), 'be') (('Scaling', 'image many processing'), 'come') (('we', 'filters'), 'be') (('which', 'output resulting channels'), 'consist') (('how much information', 'network'), 'regulate') (('which', 'cv2'), 'create') (('convolution separable layers', 'computation cost'), 'layer') (('we', '3 main parts'), 'have') (('that', 'advantages several e.'), 'help') (('we', 'depthwise once convolution'), 'transform') (('base_model', 'inference mode'), 'make') (('1 hyperparameter k', 'l th layer'), 'make') (('Using', '85'), 'reach') (('DenseNet201 Xception Contents', 'Pneumonia Chest'), 'detection') (('Here central element', 'kernel area'), 'replace') (('Chest X ray images anterior posterior', 'Guangzhou one to five years old Women'), 'select') (('Then we', '64 channels'), 'take') (('How so We', 'network'), 'see') (('MedianThe blur Median operation', 'averaging other methods'), 'be') (('also you', 'pleural effusions lungs'), 'help') (('transformation', '1 3x3x3x64 728 multiplications'), 'use') (('rotate method', '90 degrees'), 'use') (('chest radiographs', 'low quality'), 'screen') (('over we', 'computational power'), 'save') (('they', 'feature new maps'), 'add') (('we', 'output corresponding image'), 'need') (('so they', 'other side'), 'be') (('evaluation set', 'also third expert'), 'in') (('viewer', 'model plt'), 'look') (('base model', 'batchnorm layers'), 'freeze') ", "extra": "['annotation', 'biopsy of the greater curvature', 'patient', 'test', 'lung', 'pleura']", "label": "Perfect_files", "potential_description_queries": ["account", "accuracy", "array", "average", "batch", "behavior", "best", "block", "blood", "box", "care", "category", "center", "channel", "chest", "classifier", "color", "computation", "computer", "concatenate", "connection", "control", "convolution", "convolutional", "cost", "could", "create", "curve", "data", "dataset", "depth", "detail", "detect", "detected", "dict", "difference", "dimension", "dimensionality", "direction", "directly", "display", "doctor", "empty", "epoch", "equation", "evaluation", "every", "extraction", "fact", "feature", "feed", "fig", "figure", "filter", "find", "flow", "forward", "frequency", "function", "gradient", "grading", "growth", "heart", "help", "high", "history", "https towardsdatascience", "hyperparameter", "image", "improve", "include", "including", "inference", "initially", "input", "interpolation", "issue", "kernel", "knowledge", "label", "layer", "learn", "learning", "line", "look", "main", "matrix", "max", "maximum", "median", "merge", "method", "metric", "mode", "model", "module", "most", "multiple", "neck", "need", "network", "neural", "new", "next", "no", "normal", "normalization", "not", "notebook", "number", "opacity", "operation", "option", "order", "output", "parallel", "part", "path", "pattern", "performing", "plot", "pneumonia", "pooling", "post", "potential", "power", "pre", "prediction", "pretrained", "problem", "processing", "reduce", "resize", "right", "rotate", "routine", "running", "sampling", "save", "scale", "scaling", "selected", "set", "several", "shape", "similar", "size", "spatial", "stack", "step", "structure", "style", "sub", "subplot", "sum", "summarize", "system", "tensor", "test", "testing", "text", "through", "time", "title", "total", "train", "training", "transform", "transformation", "tuning", "turn", "type", "understanding", "until", "up", "val", "validation", "version", "vision", "while", "width", "write"], "potential_description_queries_len": 182, "potential_script_queries": ["backend", "numpy", "preprocessing", "tensorflow", "tqdm"], "potential_script_queries_len": 5, "potential_entities_queries": ["chest", "dict", "hyperparameter", "metric", "new"], "potential_entities_queries_len": 5, "potential_extra_queries": ["biopsy", "pleura"], "potential_extra_queries_len": 2, "all_components_potential_queries_len": 187}
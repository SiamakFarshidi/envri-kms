{"name": "online retail superstore cohort and rfm analysis ", "full_name": " h1 Retail Capstone Project h2 Problem Statement h2 Dataset Description h3 Variables Description h4 Import Libraries h4 Set relative path of input files h4 Import Input Datasets h4 Import Bonus Country Country Code Mapping Dataset for Tableau Visualization h2 Data Cleaning n h2 Data Pre processing n h4 Check Shape of Input Train Dataset h4 Validate First Few Records of Input train dataframe h4 Check the shape of Test Dataframe h4 Validate First Few Records of Input Test Dataframe h4 Concatenate train and test Dataframes into Single Merged dataframe data h4 Validate First Few Records of data Dataframe h4 Identify Missing Values and Type of Data using data info h4 Identify statistics of numeric data using describe h4 Identify Duplicates h4 Drop Identified Duplicates h4 Identify count of CustomerID which have Valid Data h4 Validate percentage of missing customer IDs h4 Retain only records where CustomerID is populated and drop the remaining 25 h4 Recheck the missing values information on data dataframe h4 Change the case of column Description from Upper to Title Proper for better readability h4 Change the DType of CustomerID to Integer h4 Change the DType of CustomerID to String h4 Purchase Transactions Split By Country h4 Plot Bar Plot Transaction Count of Purchases by Country h4 Summarize Top 3 Countries Transactions Count as Percentage h4 Create Feature Total Cost as Quantity UnitPrice h4 Overall Purchase by Country h4 Average Purchase Per Transaction by Country h4 Transaction Spread by Year h4 Transaction Spread by Month for Year 2011 h4 Top 20 Purchase Split By Item Description h4 Top 20 Purchases by Invoices h4 Plot Bar Plot Top 20 Purchases by Invoice Number h4 Bottom 20 Purchases by Invoices h4 Plot Bar Plot Bottom 20 Purchases by Invoice Number h4 Top 20 Customers by Spending h3 Handling Inappropriate Data h4 Boxplot on Quantity to Identify Outliers in Data Distribution h4 InterQuartile Range IQR 1 5 IQR Rule on Quantity to Identify Outliers in Data Distribution h4 Records with Quantity 0 and records with Quantity 20000 which are cancelled are removed h4 Validate Quantity Distribution after removing inappropriate data h4 Perform Boxplot Test for Outliers on UnitPrice h4 Perform IQR Test for Outliers on UnitPrice h4 Visualise the UnitPrice Distribution h4 Records with UnitPrice Less than 0 are removed n h4 Boxplot Validation on UnitPrice after removing inappropriate data h4 Check Input Data Spread until and after December 2011 h4 Remove Partial Month Data of December 2011 h4 Post EDA Validation of Top 20 Customers by Spend h4 EDA on Countries Dataframe h4 Create Dataframe dataTableau merging EDA completed dataframe data and EDA completed dataframe countries on Country using left join n h4 Add Region column based on Country value to classify as UK and Others for Visualization n h4 Add MonthYear column based on InvoiceDate to filter for Visualization Tableau gives MonthYear in long format and take space hence export in short form from Python n h4 Check Info of dataTableau dataframe to validate DType and Missing Values n h4 Compute Number of Refunded Invoices for Tableau Visualization KPI n h4 Create Dataframe refundedInvoices to compute count of Distinct Refunded Invoices for Tableau Visualization KPI h3 Data Cleaning Completed h3 Data Transformation h4 Copy cleaned EDA dataframe data into cohortdata dataframe for cohort analysis n h4 Perform head operation on cohortdata to check data integrity n h3 Cohort Analysis n h4 Types of cohorts n h4 For cohort analysis there are a few labels that we have to create h4 Elements of cohort analysis h3 Create month cohorts and analyze active customers for each cohort h4 Monthly Cohort Assignment h4 Compute time offset in months for InvoiceMonth and CohortMonth to obtain Year and Month n h4 Compute Cohort Index using the year and month parts of cohort and invoice dates h4 Compute Ordered Month List for usage on HeatMaps on CohortMonth n h4 Sum Total of Items Purchased Spread by CohortMonth n h4 Cohort Monthly Customer Count Heatmap n h4 Sum Total of Gift Items Purchased Spread by CohortMonth h4 Plot Bar Graph on dataframe TotalPurchase n h4 Create Heatmap on Total Items Purchased Spread by Cohort Month n h4 Cohort Mean Quantity of Gift Items Purchased Spread by CohortMonth h3 Analyse the retention rate of customers h4 Create summarization cohortGroup on CohortMonth and CohortIndex h4 Compute Retention Rate h4 Create Heatmap Customer Retention Rate Spread by Cohort Month in Percentage h3 Data Transformation Completed h3 Data Modeling h3 Build a RFM Recency Frequency Monetary model h3 RFM Analysis h4 Benefits of RFM analysis h4 Copy EDA completed Data dataframe into RFMData for RFM Analysis h4 Perform head operation on RFMData to check data integrity h3 Recency h4 Create a hypothetical snapshot currentDate data as if we re doing analysis recently h4 Compute Recent Purchase Date column to have Date part alone of Invoice date h4 Compute Recency by Grouping RFMData on CustomerID and Maximum of RecentPurchaseDate h4 Add column CurrentDate column to Recency Dataframe n h4 Compute Recency Column as difference between current date and RecentPurchaseDate n h4 Data Clean Up Drop Columns RecentPurchaseDate and CurrentDate h4 Data Integrity Shape Check on Recency Dataframe n h3 Frequency n h4 Compute Frequency Dataframe grouping on Customer ID by count of InvoiceNo n h4 Data Shape Quality Check on Frequency Dataframe n h3 Monetary n h4 Compute Monetary Value Dataframe grouping on Customer ID by sum of TotalCost n h4 Data Shape Quality Check on monetary Dataframe n h3 Build RFM Table n h4 Combine Recency Frequency and Monetary into aggregated RFMModel dataframe n h4 Data Shape Quality Check on RFMModel Dataframe n h4 Data Integrity Check on Unique Customers on Baselined Data dataframe n h4 Set Customer ID as index for RFMModel dataframe n h3 Validate RFM Table Integrity from Customer ID R F am M perspectives n h4 Match RFMData Customer ID and RFMModel Index and display the head of the comparison result in RFMData n h4 Validate Recency for first Customer ID n h4 RFM Recency Frequency Monetary model RFMModel created n h3 Build RFM Segments Give recency frequency and monetary scores individually by dividing them into quartiles h4 Create RFM Score for R F and M on a scale of 1 to 4 and concatenate as string to assign Customer Segment h4 Create Quartiles Dictionary for RFM h4 Create Quantiles Dataframe for RFM n h4 Plot Recency Quantiles Distribution n h4 Plot Frequency Quantiles Distribution h4 Monetary Quantiles Distribution h4 Plot Quantiles Distribution Bar Spread 0 25 50 75 n h4 RFM Quantile Summary h4 Copy RFMModel dataframe into RFMSegment for RFM Segment Table n h4 Perform head operation on RFMSegment to check data integrity n h4 Compute R F and M Quantiles for each Customer ID n h4 Compute R Quantile n h4 Compute F Quantile n h4 Compute M Quantile n h4 Build RFM Segment and RFM Score n h4 Print RFM Unique String Values n h4 Validate RFMSegment Information n h4 Reset the index of RFMSegment Dataframe n h4 Data Integrity Check on RFMSegment n h4 Below is a table with key RFM segments n h4 Create segment customer function on RFMtable created above to map RFM segments to customer segments n h4 Check head of RFMSegment Dataframe for Data Integrity n h4 Check the distribution of CustomerSegment h4 Random Sample on RFMSegment to check data h4 Grouping by RFM Score for Market Campaigns To be used in visualization n h4 Customer Segment Spread by Categories h3 Data Modeling Completed For n h3 Data Modeling n h3 Create clusters using k means clustering algorithm n h4 Prepare the data for the algorithm If the data is asymmetrically distributed manage the skewness with appropriate transformation Standardize the data n h4 Check Description of Dataframe RFMModel to identify negative values n h4 Log Transformation of RFMModel and Scaling the Transformed Log Model into Scaled Model RFMModelScaled n h4 Revalidate Distribution Subplot to check data skewness after log transformation and scaling n h4 Decide the optimum number of clusters to be formed using Kmeans n h4 Compute Within Cluster Sum of Squares WCSS Error through Elbow Method h4 Plot WCSS Elbow Graph from computed WCSS Inertia Dataframe WCSSKmeansOut n h4 Validate silhouette Score n h4 Check Silhouette score Dataframe to Validate Cluster with maximum score n h4 Decide the optimum number of clusters to be formed as 4 n h4 Build KMeans Model with 4 Clusters and fix random state as 1 to ensure no variation during rerun n h4 Print the KMeans Model h4 Validate if of entries cluster label array matches RFMSegment dataframe size in terms of rows should be equal to count of customer IDs n h4 Build ClusterData Table n h4 Check Shape of Dataframe ClusterData h4 Identify Split of customer ID s by Cluster h4 Create BoxPlot on Cluster Count Spread h4 Sample the Cluster Table data to check correctness h4 Analyze these clusters and comment on the results n h4 Sample the Cluster Table data for Cluster 3 n h4 Sample the Cluster Table data for Cluster 2 h4 Sample the Cluster Table data for Cluster 1 n h4 Sample the Cluster Table data for Cluster 0 n h4 Scatter Plot n h4 Snake Plot n h4 Dataframe Melt n h4 Check shape of RFMModelScaledMelt dataframe n h4 RFM Snake Plot Visualization n h4 Heat Map h4 Clusterwise Related Dependence Heatmap h4 Check Customer Segment Spread for Cluster 0 n h4 Check Customer Segment Spread for Cluster 1 n h4 Check Customer Segment Spread for Cluster 2 n h4 Check Customer Segment Spread for Cluster 3 h3 Data Modeling Completed for h3 Data Reporting h4 Export Dataframes Data and ClusterData to Excel h4 Tableau Visualization n h3 Data Reporting Completed ", "stargazers_count": 0, "forks_count": 0, "description": "Deciding the optimum number of clusters to be formed. 83 for R Insight is most recent Medium Negative Value of 0. 86 for F across clusters Insight is least frequent and least active Highest Negative Value of 0. For example let s look at a customer who is within the group who purchased most recently R 4 is within the group who purchased most quantity F 4 is within the group who spent the most M 4 Increased revenue This customer belongs to RFM segment 4 4 4 Best Customer R 4 F 4 M 4 Copy EDA completed Data dataframe into RFMData for RFM AnalysisInference s RFMData dataframe has 375665 rows of data spread across 9 columns which matches the data dataframePerform head operation on RFMData to check data integrityInference s First 5 rows of RFMData checked and passed data quality checkRecencyCreate a hypothetical snapshot currentDate data as if we re doing analysis recentlyInference s Variable CurrentDate computed as 1st December 2011 Hypothetical Snapshot DateCompute Recent Purchase Date column to have Date part alone of Invoice date Inference s RecentPurchaseDate column created and data quality check successful on first 5 rows validationCompute Recency by Grouping RFMData on CustomerID and Maximum of RecentPurchaseDateInference s Recency Dataframe Computed with CustomerID and RecentPurchaseDate Data quality check successful on first 5 rows validation Add column CurrentDate column to Recency DataframeInference s CurrentDate column added to Recency Dataframe Data quality check successful on first 5 rows validation Compute Recency Column as difference between current date and RecentPurchaseDateInference s Recency column computed and added to Recency Dataframe Data quality check successful on first 5 rows validation Data Clean Up Drop Columns RecentPurchaseDate and CurrentDateInference s RecentPurchaseDate and CurrentDate columns dropped from recency dataframe Data quality check successful on first 5 rows validation Data Integrity Shape Check on Recency DataframeInference s Recency dataframe has 2 columns with 4296 rows 1 pertaining to each customer ID Data Integrity shape test successful on recency dataframe Frequency Frequency is about the number of purchase in a given period. This cluster accounts for more than 6 million sales in the 1 year and for this cluster the customers need to be marketed with new niche gift premium products which appeal to the sensibilities to ensure consistent monetary capitalization. 92 for F Insight is most active customer base Highest Positive Value of 2. Analyze the RFM segments by summarizing them and comment on the findings. RFM Analysis RFM analysis is a customer segmentation technique that uses past purchase behavior to divide customers into groups. 62 268478 Found Above 75th Percentile Copy RFMModel dataframe into RFMSegment for RFM Segment TableInference s RFM Segment Dataframe created from RFMModel Dataframe RFM Segment Dataframe has 4296 rows and 3 columns which match the RFMModeldataframe Perform head operation on RFMSegment to check data integrityInference s RFMSegment data quality checked validating first 5 rows of data Compute R F and M Quantiles for each Customer ID Process of calculating percentiles 1. Assign a label to each group Compute R Quantile Highest score to the best metric best is not always highest e. Calculating RFM metrics. 5 for F Insight is not so frequent Medium to High Negative Value of 0. Removed duplicate data records c. Exciting sector for marketing as it has a plethora of opportunities and needs a comprehensive SWOT analysis to improve capitalization and see how these customers can be moved up the value chain Heat MapHeat map to visualize the relative importance of each attributes across 4 clusters. The dashboard must entail the following a. Strategy for this cluster is to lure customers with new economy products with discounts and good recommendations to keep the transaction count high and plan for loyalty programs. The silhouette ranges from 1 to 1 where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. Create clusters using k means clustering algorithmPrepare the data for the algorithm. Combine three ratings to get a RFM segment as strings. Preparing the data for the algorithm. Size cohorts refer to the various sizes of customers who purchase company s products or services. Retail Capstone Project Problem Statement It is a critical requirement for business to understand the value derived from a customer. a. hours throughout the day d. Data Modeling 1. Customers who signed up for basic level services might have different needs than those who signed up for advanced services. 3 Lets plot KMeans with 4 clusters Decide the optimum number of clusters to be formed as 4Build KMeans Model with 4 Clusters and fix random state as 1 to ensure no variation during rerun Inference s KMeans model is built on 4 clusters and Cluster Labels are generated Print the KMeans ModelInference s KMeans Model is built with 4 clusters and we have used random state 1 KMeans algorithm auto copy_x True init k means max_iter 300 n_clusters 4 n_init 10 n_jobs None precompute_distances auto random_state 1 tol 0. RFM is a method used for analyzing customer value. Cluster 2 Cluster 2 has high negative values for R and high positive values for F and highest positive values for M implying this is the cluster with high RFM and caters to all platinum and gold with maximum sales most recent and most frequent. 42 for M Insight is low to medium spending customer base with values mostly over median varying between 2 and 3 High amount of silver customers and mix of low monetary gold customers is due to this. 01 items where unit price is 0 free items Records with UnitPrice Less than 0 are removedInference s 40 items with unit price 0 removed Boxplot Validation on UnitPrice after removing inappropriate dataInference s Boxplot shows unit price positive distribution with 1 high value valid outlier Check Input Data Spread until and after December 2011Inference s Above 4 of overall data is part of December 2011 where we have partial month data Remove Partial Month Data of December 2011Inference s December 2011 Partial Month data removedPost EDA Validation of Top 20 Customers by Spend Inference s After EDA preprocessing Customer 14646 from Netherlands has shopped for 268K during the given period which is the maximum EDA on Countries DataframeInference s EDA on Countries showed missing values of country code for 4 countries and they were removed Create Dataframe dataTableau merging EDA completed dataframe data and EDA completed dataframe countries on Country using left joinInference s Merged Dataframe dataTableau created and the first 5 rows validated fine Add Region column based on Country value to classify as UK and Others for VisualizationInference s Region column added to dataTableau dataframe and validated fine while checking the head Add MonthYear column based on InvoiceDate to filter for Visualization Tableau gives MonthYear in long format and take space hence export in short form from PythonInference s MonthYear column added to dataTableau dataframe and validated fine while checking the head Check Info of dataTableau dataframe to validate DType and Missing ValuesInference s Dataframe dataTableau has 375665 rows of information which matches the count of rows on data Dataframe and there are no missing values ready for Tableau Visualization with additional data of Country_Code Region and InvoiceMonth Compute Number of Refunded Invoices for Tableau Visualization KPI Inference s 20 Unique refund invoices found Create Dataframe refundedInvoices to compute count of Distinct Refunded Invoices for Tableau Visualization KPI Inference s Dataframe refundedInvoices created with 1 row having RefundedInvoices count Data Cleaning Completed 1. Getting the RFM score by adding up the three ratings. The number represents the number of months passed since the first purchase. Inference s Centroids and distribution seem even for RF and RM Plots RF and RM Plot has best values for cluster 2 and the worst values for cluster 1 RF and RM Plot has lower recency values for cluster 3 than cluster 2 RF and RM Plot has lower frequency values for cluster 0 than cluster 2 Centroids for cluster 0 and 3 are closer for FM Plot and distribution seem well distributed except for segments 0 and 3 which overlap FM Plot has lowest values for cluster 1 medium for clusters 0 and 3 which overlap and high values for cluster 2 Snake Plot Market research technique to compare different segments Visual representation of each segment s attributes Need to first normalize data center scale Plot each cluster s average normalized values of each attribute To plot this we should have normalized data distribution and all the attributes in a single column. 67 for M Insight is low spending customer base High amount of silver customers and mix of low monetary gold customers is due to this Cluster 1 Highest Positive Value of 0. Checked for missing data and formulated an apt strategy to treat them b. Therefore big spenders will be differentiated among other customers such as MVP Minimum Viable Product or VIP. This is the cluster which need be prioritized for campaigns as a tactical approach as the monetary capitalization and the RFM analysis show this cluster can have minimum campaigns loyalty program or encouraging spend here may not get much traction. Data Reporting 1. 8 for R Insight is most recent with few cases above median Highest Positive Value of 1. c. hours throughout the day Check Sales Dash filtering on Month and Region and use reset filters to reset d. Visualize to compare the RFM values of the clusters using heatmap Export Dataframes Data and ClusterData to ExcelTableau VisualizationTableau Visualization DashboardsData Reporting Completed 1. Build a RFM Recency Frequency Monetary model. Revalidate Distribution Subplot to check data skewness after log transformation Set title Compute Within Cluster Sum of Squares WCSS Error through Elbow Method Choose range of 1 to 14 as we have 13 Customer Segments Plot WCSS Elbow Graph Optimum Cluster Validation using Silhouette Score Using 3 as lower range number as typically best score for Silhouette is obtained for 2 clusters With 13 segments selected 2 clusters is not ideal plot Silhouette graph Set title Build KMeans Model with 4 Clusters Assign the clusters as column to each customer Compute counts of CustomerIDs assigned to different clusters Sample the Cluster Table data to check data correctness Plot 2D plots of RF FM and RM Assign Cluster values to each customer in normalized dataframe Melt normalized dataframe into long form to have all metric in same column RFM Snake Plot Visualization Assign Cluster labels to RFMModelCluster table Average attributes for each cluster Calculate the population average Calculate relative importance of attributes by Export datasets with pd. b. Check Description of Dataframe RFMModel to identify negative valuesInference s No negative values proceed with log transformation. 23 for M Insight is maximum spending customer base Highest amount of best customers Platinum with few infrequent best customers and few churned best customers and medium high spending loyal active customers make this segment Gold Cluster 3 Medium Positive Value of 0. We can observe how a cohort behaves across time and compare it to other cohorts. Item Abbreviation Definition Recency R Days since last customer transaction Frequency F Number of transactions in the last 12 months Monetary M Total spend in the last 12 months Benefits of RFM analysis Increased customer retention Increased response rate Increased conversion rate Increased revenue To perform RFM analysis we divide customers into four equal groups according to the distribution of values for recency frequency and monetary value. Created month cohorts and analyze active customers for each cohort. Frequency is the number of purchase in a given period. Note Rate frequency and monetary higher because the company wants the customer to visit more often and spend more moneyCreate RFM Score for R F and M on a scale of 1 to 4 and concatenate as string to assign Customer SegmentCreate Quartiles Dictionary for RFMInference s Quantiles Dictionary List created for Recency Frequency Monetary for 25th 50th and 75th percentile Create Quantiles Dataframe for RFM Inference s RFM Quantile Dataframe computed Data quality check successful on all rows validation Significant Outliers found in Recency Frequency and Monetary beyond 75th percentile Plot Recency Quantiles DistributionInference s Recency Quantile Distribution Boxplot shows outliers beyond 75th percentile Plot Frequency Quantiles DistributionInference s Frequency Quantile Distribution Boxplot shows outliers beyond 75th percentile Monetary Quantiles DistributionInference s Monetary Quantile Distribution Boxplot shows outliers beyond 75th percentile Plot Quantiles Distribution Bar Spread 0 25 50 75Inference s Distribution RFM sub plot to show the distribution across first 3 quantile splits Top quantile not plotted as it had outliers and plot would have miniscule values for first 3 quantiles RFM Quantile Summary RFM Type 0th Percentile 25th Percentile 50th Percentile 75th Percentile 100th Percentile Outliers Comments Recency 1 16 50 144. Observeed how a cohort behaves across time and compare it to other cohorts. Inference s Data Visualization shows skewness for Recency Frequency and Monetary Let s check for negative values before doing log transformation. 50 365 Found Above 75th Percentile Frequency 1 17 40 97 7288 Found Above 75th Percentile Monetary 2. number of clusters selected Check Cluster Dash filtering on Cluster and use reset filters to reset f. Create clusters using k means clustering algorithm. The bigger the value is the more engaged the customers areCompute Frequency Dataframe grouping on Customer ID by count of InvoiceNoInference s frequency Dataframe computed and it has 2 columns CustomerID and Frequency Data quality check successful on first 5 rows validation Data Shape Quality Check on Frequency Dataframe Inference s frequency dataframe has 2 columns with 4296 rows 1 pertaining to each customer ID Data Integrity shape test successful on frequency dataframe Monetary Monetary is the total amount of money a customer spent in that given period. RFM helps divide customers into various categories or clusters to identify customers who are more likely to respond to promotions and also for future personalization services. Recency means the number of days since a customer made the last purchase. Variables Description Item Purpose Type Metadata Description InvoiceNo Invoice number Nominal A six digit integral number uniquely assigned to each transaction. If this code starts with letter c it indicates a cancellation StockCode Product item code. 1 lowest Random Sample on RFMSegment to check dataInference s CustomerSegment sample showed a variety of RFM scores and CustomerSegments showing up data quality check verified and passed Grouping by RFM Score for Market Campaigns To be used in visualization Inference s MarketSegment field imputed On an average the 398 platinum customers spent 9484 while the 1259 bronze customers spent on an average 264 showing a huge disparity between the High Spending and the low spending customers On an average the 398 platinum customers visited 7 days ago and did 363 transactions against average of 190 days and only 15 transactions per person for the 1259 bronze customers Customer Segment Spread by CategoriesInference s Data Visualization shows 1233 Churned Low Spending Infrequent Customers 29 of customer base Data Visualization shows 619 Medium High Spending Active Loyal Customers 14 of customer base Data Visualization shows 398 Best Customers 9 of customer base Data Visualization shows 382 customers across Churned Inactive Best Customers 9 of customer base Data Visualization shows 354 Churned Loyal Customer 8 of customer baseData Modeling Completed For 1. Creating clusters using k means clustering algorithm. For cohort analysis there are a few labels that we have to create Invoice period A string representation of the year and month of a single transaction invoice. Combine three ratings to get a RFM segment as strings b. Inference s AttributeInterDependence computed for each cluster for Recency Frequency and Monetary Cluster 2 alone has high values on Frequency and Monetary Interdependence Cluster 0 and Cluster 2 have high negative values in Recency Cluster 0 and Cluster 1 have high negative values in Monetary Let s plot heatmap visualization to get more insights Clusterwise Related Dependence HeatmapInference s Heatmap executed between cluster Mean and Population Mean across Metrics of R F and M to identify the interdependence Cluster 0 Highest Negative Value of 0. Analyze the retention rate of customers. Understanding the needs of the various cohorts can help a company design custom made services or products for particular segments. Plot the distribution of RFM values using histogram and frequency charts e. Log Transformation of RFMModel and Scaling the Transformed Log Model into Scaled Model RFMModelScaledInference s Log Transformation completed Scaled Output stored in dataframe RFMModelScaled First 5 values of RFMModelScaled checked and passed data quality check Revalidate Distribution Subplot to check data skewness after log transformation and scalingInference s Distribution seems to follow a normal pattern for Frequency and Monetary Recency shows mild skewness which we will ignore for the momentDecide the optimum number of clusters to be formed using Kmeans. This categorization can be based on the amount of spending in some periodic time after acquisition or the product type that the customer spent most of their order amount in some period of time. Performed preliminary data inspection and data cleaning a. Country wise analysis to demonstrate average spend. Sample the Cluster Table data for Cluster 3Inference s Cluster 3 sample has Gold Silver and Bronze customers RFM Score for this cluster sample varied from value of 5 Bronze to 10 Gold Recency Frequency and Monetary varied from 1 to 4 considering minimum RFMScore for the sample was 5 below median value Churned customers Recency Infrequent customers Frequency and Low Spending customers Monetary were all spotted in the sample Medium High Spending Active Loyal Customers Gold were all in the cluster 3 sample mix Sample the Cluster Table data for Cluster 2Inference s Cluster 2 sample has Gold and Platinum customers Elite Cluster The RFM scores are all 10 and higher in the sampler and this cluster would account for maximum monetary Sales and also account for most frequent and recent transactions Inactive and Churned Best Customers also made the sample mix under Gold Category Sample the Cluster Table data for Cluster 1Inference s Cluster 1 sample has Bronze customers RFM Score is 5 or lower in the sample Sample had mostly churned customers or Low Spending Inactive Customers Monetary capitalization of this cluster is very low of this cluster is very low Sample the Cluster Table data for Cluster 0Inference s Cluster 0 sample has Gold and Silver customers RFM Scores are above the median of 6 with sample values till 10 Cluster accounts for the frequent customers with all samples above median value of 2 and the recency is also above median value for this cluster while the monetary value of the cluster varies from median value of 2 to above median value of 3. Prepare the data for the algorithm. Get the RFM score by adding up the three ratings c. recency In this case the label is inverse the more recent the customer the better Inference s R quantile segment Values created in RFMSegment Dataframe RFMSegment data quality checked validating first 5 rows of data Compute F Quantile Inference s F quantile segment Values created in RFMSegment Dataframe RFMSegment data quality checked validating first 5 rows of data Compute M Quantile Inference s M quantile segment Values created in RFMSegment Dataframe RFMSegment data quality checked validating first 5 rows of data Build RFM Segment and RFM Score Concatenate RFM quartile values to RFM_Segment Sum RFM quartiles values to RFM_Score Inference s RFM Segments are created RFMSegment data quality checked validating first 5 rows of data Best Recency score 4 Best Frequency score 4 Best Monetary score 4 Best RFM Segment 444 Best RFM Score 12 Print RFM Unique String Values Inference s 61 unique RFM Segment Values Created based on RFM values Validate RFMSegment Information Inference s RFMSegment has 8 columns of size 4296 number of Unique Customer IDs Recency Frequency are Integer values while Monetary is a float value R Quantile F Quantile and M Quantile are Integer values RFM_Segment is a string object RFM_Score is a integer object Reset the index of RFMSegment Dataframe Inference s Column size increased from 8 to 9 for the same 4296 rows Lets check head operation to validate data integrity Data Integrity Check on RFMSegmentInference s RFMSegment data quality checked validating first 5 rows of data Index became numeric and CustomerID became a column Below is a table with key RFM segments Customer Segment RFM Segment Criteria Marketing Best Customers 444 Recency Highest Frequency Highest Monetary Value Highest No price incentives new products and loyalty program Churned Best Customer 144 244 Recency Below Median Frequency Highest Monetary Value Highest Incentivise via price to buy in near future and also frequently new products and loyalty program Churned Frequent Customer 131 132 141 142 231 232 241 242 Recency Below Median Frequency Below Median Monetary Value Above Median Incentivise via price to buy in near future and also frequently new economy products and loyalty program Churned Low Spending Infrequent Customer 111 112 121 122 211 212 221 222 Recency Below Median Frequency Below Median Monetary Value Below Median Limited campaign to buy new economy products with price incentives check casually on loyalty program interest Churned Loyal Customer 133 134 143 233 234 243 Recency Below Median Frequency Above Median Monetary Value Above Median Focus on Loyalty Program Incentivise to Buy Churned Medium High Spender 113 114 123 124 213 214 223 224 Recency Below Median Frequency Below Median Monetary Value Above Median Focus on Loyalty Program Incentivise to Buy Again with new products Inactive Best Customer 344 Recency 3 Frequency Highest Monetary Value Highest No price incentives new products and loyalty program Low Spending Inactive Customer 311 312 321 322 Recency Above Median Frequency Below Median Monetary Value Below Median High price incentives new products and loyalty program Low Spending Active Loyal Customer 431 432 441 442 Recency Highest Frequency Above Median Monetary Value Below Median High price incentives market niche products in economy segment increasing spend Low Spending Inactive Loyal Customer 331 332 341 342 Recency 3 Frequency Above Median Monetary Value Below Median High price incentives market niche products in economy segment increasing spend Low Spending New Customer 411 412 421 422 Recency Highest Frequency Below Median Monetary Value Below Median High price incentives market niche products in economy segment increasing spend try loyalty program Medium High Spending Active Customer 313 314 323 324 413 414 423 424 Recency Above Median Frequency Below Median Monetary Value Above Median Low price incentives market niche products in premium segment increasing spend go for loyalty program Medium High Spending Active Loyal Customer 333 334 343 433 434 443 Recency Above Median Frequency Above Median Monetary Value Above Median Low price incentives market niche products in premium segment market associated products based on previous items surfed purchased Create segment_customer function on RFMtable created above to map RFM segments to customer segments Inference s 13 unique customer segments mapped Churned Low Spending Infrequent Customer segment had 1233 of 4296 customers Low Spending Active Loyal Customer segment had 91 of 4296 customers Check head of RFMSegment Dataframe for Data Integrity Inference s RFMSegment data quality checked validating first 5 rows of data Check the distribution of CustomerSegmentInference s Churned Low Spending Infrequent Customer segment has 28. It could be 3 months 6 months or 1 year. Plot error cost vs. Therefore big spenders will be differentiated with other customers such as MVP or VIP. Building RFM Segments. Elements of cohort analysis Pivot table Assigned cohort in rows Cohort Index in columns Metrics in the table Create month cohorts and analyze active customers for each cohort Monthly Cohort Assignment Setting up a cohort is the pre cursor to perform cohort analysis. This is understandable as this cluster has mostly customers with RFM scores below median score of 6 and a few just over the median. 7 highest Low Spending Active Loyal Customer segment has 2. Visualize to compare the RFM values of the clusters using heatmap Check Customer Dash filtering on CustomerID and use reset filters to reset numpy for matehmatical computations pandas for data computations warnings to supress second and subsequent repeated warnings datetime imports for date time computations json for handling json data Visualization Imports matplotlib inline StandardScaler Data Normalization Imports Kmeans cluter algorithm import Identify Silhouette score for best KMeans cluster import Supress Scientific notation in python import Display all columns of long dataframe Import input datasets Bonus Steps Import Country Dataset For Visualization in Tableau have added a Country to Country Code Mapping Check the shape of dataframe Check the shape of dataframe Set notebook mode to work in offline Use hole to create a donut like pie chart Set notebook mode to work in offline Use hole to create a donut like pie chart We don t need records with Null customer id for RFM analysis so let s remove those first title function in python to convert the character column to title case or proper case Convert CustomerID to int type Convert CustomerId to str type Create feature total cost of the transactions Count of transactions in different years Count of transactions in 2011 Outliers InterQuartile Range IQR 1. Analyze these clusters and comment on the results. The farther a ratio is from 0 the more important that attribute is for a segment relative to the total population. Behavior cohorts are customers who purchased a product or subscribed to a service in the past. ExcelWriter outputPath Online_Retail_EDA. 75 Million Average Purchase Per Transaction by Country Inference s USA ranked lowest on Mean Purchases 6 per transaction Netherlands ranked highest on Mean Purchases greater than 120 per transaction Transaction Spread by YearInference s 2011 had more than 375K transactions Transaction Spread by Month for Year 2011Inference s Feb 2011 ranked lowest on Purchases in 2011 with 19800 transactions Nov 2011 ranked highest on Purchases in 2011 with 64000 transactions Dec 2011 had partial month data and hence had significantly lower volume of transactions Top 20 Purchase Split By Item DescriptionInference s Most Procured Item White Hanging Heart T Light Holder Top 20 Purchases by InvoicesInference s groupByTotalCost dataframe summarized at InvoiceNo level aggregating sum of TotalCost for Top 20 Invoices Data quality check successful on first 5 rows validation Plot Bar Plot Top 20 Purchases by Invoice Number Inference s Customer 16446 from UK has shopped for 168. 94 for R Insight is least recent and churned Highest Negative Value of 0. Give recency frequency and monetary scores individually by dividing them into quartiles. Create a dashboard in tableau by choosing appropriate chart types and metrics useful for the business. xlsx engine xlsxwriter mode w as writer. 87 for M across clusters Insight is low spending customer base Highest amount of churned customers bronze and small mix of low spending new customers with RFM close to median value of 6 silver is due to this Cluster 2 High Negative Value of 0. The resulting segments can be ordered from most valuable highest recency frequency and value to least valuable lowest recency frequency and value. Building a RFM Recency Frequency Monetary model. Giving recency frequency and monetary scores individually by dividing them into quartiles a. If the data is asymmetrically distributed manage the skewness with appropriate transformation. 0001 verbose 0 Validate if of entries cluster label array matches RFMSegment dataframe size in terms of rows should be equal to count of customer IDsInference s Validation of Data Integrity successful between clusterLabels and RFMSegment 4296 was the number of rows returned for each which is correct and equal to unique Customer ID s Build ClusterData TableInference s ClusterData Table Built from RFMSegment with Cluster column getting added Data Quality Check Validated Fine while verifying the first few rows Check Shape of Dataframe ClusterDataInference s ClusterData Table Bhas 4296 rows equal to unique customer ID s and has 12 columns Data Quality Check Validated Fine while verifying the first few rows for 12 columns in previous step Identify Split of customer ID s by ClusterInferences ClusterDataCount Split Computed Four clusters created with sizes equal to Cluster 0 838 Cluster 1 1206 Cluster 2 963 Cluster 3 1289 Create BoxPlot on Cluster Count SpreadInference s ClusterData Plot Summary of Records in Four created clusters by KMeans algorithm are Cluster 0 838 Cluster 1 1206 Cluster 2 963 Cluster 3 1289 Sample the Cluster Table data to check correctnessInference s Sample Data validated fine and gave some intersting insights Cluster Data Sample has records across clusters and segments Cluster 0 sample has No customers Cluster 1 sample has Bronze customers Cluster 2 sample has Gold customers Cluster 3 sample has Gold and Silver customers Analyze these clusters and comment on the results. Bar graph of top 15 products which are mostly ordered by the users to show the number of products sold c. Bar graph to show the count of orders vs. Break customers into a pre defined number of groups of equal size 3. Note Rate frequency and monetary higher because the company wants the customer to visit more often and spend more moneyBuild a RFM Recency Frequency Monetary model. Compute Monetary Value Dataframe grouping on Customer ID by sum of TotalCost Inference s monetary Dataframe computed and it has 2 columns CustomerID and Monetary Data quality check successful on first 5 rows validation Data Shape Quality Check on monetary Dataframe Inference s monetary dataframe has 2 columns with 4296 rows 1 pertaining to each customer ID Data Integrity shape test successful on monetary dataframe Build RFM TableCombine Recency Frequency and Monetary into aggregated RFMModel dataframeInference s RFMModel Dataframe computed and it has 4 columns CustomerID Recency Frequency and Monetary Data quality check successful on first 5 rows validation Data Shape Quality Check on RFMModel Dataframe Inference s RFMModel dataframe has 4 columns with 4296 rows 1 pertaining to each customer ID Data Integrity shape test successful on RFMModel dataframe Data Integrity Check on Unique Customers on Baselined Data dataframe Inference s Data Dataframe had 4296 unique customers which matches the RFMModel Dataframe size Set Customer ID as index for RFMModel dataframe Validate RFM Table Integrity from Customer ID R F am M perspectives Match RFMData Customer ID and RFMModel Index and display the head of the comparison result in RFMDataInference s First 5 Matched rows of RFMData Customer ID and RFMModel Index displayed from dataframe RFMData Data quality check successful on first 5 rows validation Validate Recency for first Customer IDInference s Validation of Recency computation between RFMData and RFMModel was successful and return positive boolean output for first CustomerID on RFMModel dataframe RFM Recency Frequency Monetary model RFMModel createdBuild RFM Segments. info Inference s Missing values are found on CustomerID and Description columns 4 Object Columns InvoiceNo StockCode Description Country 1 Integer Columns Quantity 2 Float Columns UnitPrice CustomerID 1 Datetime Columns InvoiceDate Identify statistics of numeric data using describe Inference s UnitPrice has negative values and potential outliers beyond 75 percentile Quantity has negative values refunds and has potential outliers beyond 75 percentile and below 25th percentile Let s ignore CustomerID describe statistics as its actually unique ordinal Identify DuplicatesInference s Less than 1 duplicates found let s drop them before moving forwardDrop Identified DuplicatesInference s data dataframe now has 536641 unique rows and 8 columns after removing duplicatesIdentify count of CustomerID which have Valid DataInference s 401604 rows out of 536641 have CustomerID PopulatedValidate percentage of missing customer IDsInference s 25. Use a bar chart to show the monthly figures b. 4 in October 3 Consistent Cohort by Mean Items Procured December 2010 to March 2011 June 2011 Atleast 9. 5 IQR Rule for Numeric Data Sort the data in ascending order GET Q1 and Q3 Calc IQR Calc LowerRange Calc Upper Range Set notebook mode to work in offline Use hole to create a donut like pie chart We don t need records with Quantity 0 and positive outliers which are cancelled for RFM analysis so let s remove those records Set notebook mode to work in offline Use hole to create a donut like pie chart We don t need records with UnitPrice 0 for RFM analysis so let s remove those records Set notebook mode to work in offline Use hole to create a donut like pie chart We need only 1 year of data removing data of December 2011 which has partial month data Create Dataframe dataTableau Parse Year Month of InvoiceMonth column into invoiceYear invoiceMonth columns using function obtainDateInterval Parse Year Month of CohortMonth column into cohortYear cohortMonth columns using function obtainDateInterval Calculate difference between invoiceYear and the assigned cohortYear in years for every row item Calculate difference between invoiceMonth and the assigned cohortMonth in months for every row item Set CohortIndex as diffYears 12 diffMonths 1 1 is added so that CohortIndex is never 0 if the first and subsequent transaction for customer are in same month Create Individual Months List for cohort analysis Create a groupby object MonthlyActiveCustomerGroup and pass the monthly cohort and cohort index as a list Calculate the sum of the TotalCost column Reset the index of cohort_data Create a pivot Display Monthly Customer Cohort count Initialize plot figure Add a title Create the heatmap Create a groupby object TotalCostGroup and pass the monthly cohort and cohort index as a list Calculate the sum of the TotalCost column Reset the index of cohort_data Create a pivot Initialize plot figure Add a title Create the heatmap Create a groupby quantityGroup object and pass the monthly cohort and cohort index as a list Calculate the average of the Quantity column Reset the index of cohort_data Create a pivot Initialize plot figure Add a title Create the heatmap Count the number of unique values per customer ID Create a pivot Select the first column and store it to cohort_sizes Divide the cohort count by cohort sizes along the rows Initialize inches plot figure Add a title Create the heatmap Set variable current_date to this max of Invoice date in dataframe RFMData Lets create a date column RecentPurchaseDate for date part only of InvoiceDate Create column currentDate in dataframe recency Compute Recency as difference between current date and RecentPurchaseDate Data Clean Up Drop Columns RecentPurchaseDate and CurrentDate Match RFMData Customer ID and RFMModel Index and display the head of the comparison result in RFMData Check if the number difference of days from the purchase date in original record is same as shown in RFMModel RFM Quartiles Set title Set title Set title Set title RScore Function Arguments Getting Passed S Score P Recency Q quantiles dict FMScore Function Arguments Getting Passed S Score P Frequency Monetary Q quantiles dict Compute RFM Score as a String Reset the index to create customerID column Create Customer Segment Function Check head of RFMSegment Dataframe for Data Integrity Create Market Segment Function Validate Distribution Skewness using distplot subplots Set title Let s describe the table to see if there are any negative values Transform the data before K Means clustering Taking log first because normalization forces data for negative values Normalize the data for uniform averages and means in the distribution. Performed descriptive analytics on the given data Data Transformation Copy cleaned EDA dataframe data into cohortdata dataframe for cohort analysisInference s cohortdata dataframe has 375665 rows of data spread across 9 columns which matches the data dataframe Perform head operation on cohortdata to check data integrity Inference s cohortdata dataframe passed data integrity test on examining head of the data Cohort Analysis What is Cohort Analysis A cohort is a group of subjects who share a defining characteristic. 26 for R Insight is near the median values and not recent Medium Negative Value of 0. number of clusters selected f. Cohort period Index An integer representation a customer s stage in its lifetime. It has a small population of low spending customers with recency 3 who are under bronze category with RFM score less than 6 major share of silver customers with good mix of active and loyal customers who have various levels of frequency and monetary and a gold share of gold customers with high recency loyal customers. Analyzing these clusters and comment on the results. Decide the optimum number of clusters to be formed. No price discounts need to be planned for this cluster campaign. This group will have cross over of some bronze customers if Monetary value is lower as the other 2 parameters are lower Check Customer Segment Spread for Cluster 0Inference s Good volume of Medium High Spending Active Loyal Customer Good volume of recent Low Spending New Customer and recent Low Spending Inactive Customer Good volume of Medium High Spending Active Customer Good volume of Low Spending Active Loyal Customer Check Customer Segment Spread for Cluster 1Inference s Maximum volume of Churned Low Spending Infrequent Customer Good volume of Low Spending Inactive Customer Check Customer Segment Spread for Cluster 2Inference s Maximum volume of Best customers Maximum volume of Inactive Best customers High volume of Medium High Spending Active Loyal Customer Check Customer Segment Spread for Cluster 3Inference s Maximum volume of Churned Loyal Customer Good volume of Churned Low Spending Infrequent Customer Good volume of Churned Medium High Spender Good volume of Churned Frequent Customer Good volume of Medium High Spending Active Loyal Customer Notable volume of Churned Best Customer Data Modeling Completed for 1. Customer segmentation is the practice of segregating the customer base into groups of individuals based on some common characteristics such as age gender interests and spending habitsPerform customer segmentation using RFM analysis. So we can understand this value as for how often or how many a customer used the product of a company. Based on 12 month data provided assigning customers to cohorts based on date of first purchase based on data provided for performig cohort analysisInference s InvoiceMonth Column computed from InvoiceDate having only the date part CohortMonth Column computed based on month of first purchase Compute time offset in months for InvoiceMonth and CohortMonth to obtain Year and MonthInference s obtainDateInterval function run on InvoiceMonth and CohortMonth to parse the year and month parts Compute Cohort Index using the year and month parts of cohort and invoice datesInference s Cohort Index generates fine and head data validated fine Compute Ordered Month List for usage on HeatMaps on CohortMonthInference s Ordered List of 12 unique Months created from Dec 2010 to Nov 2011 Sum Total of Items Purchased Spread by CohortMonthInference s TotalMonthlyCustomers Monthly Cohort Count by customer computed It has nan values below the diagonal which is as expected Cohort Monthly Customer Count Heatmap Easiest way to visualize cohort analysis Includes both data and visuals Inference s Drawn from Monthly Cohort Customer Counts Heatmap Description Affected Cohorts Remarks 1 First Cohort December 2010 885 out of overall 4296 which is over 20 of all customers across cohorts 2 Last Cohort November 2011 323 New Customers 3 High Intake Of New Customers January 2011 and March 2011 Greater than 400 new customers each in the cohort December 2010 excluded while computing this as existing customers vs new customer data unknown 4 Low Intake Of New Customers July 2011 and August 2011 Less than 200 new customers in each cohort 5 Shopping increased in October 2011 November 2011 All Cohorts Probably pre holiday season purchases Sum Total of Gift Items Purchased Spread by CohortMonthInference s TotalPurchase Monthly Cohort Spend computed First cohort December2010 has maximum Sales as expected It has nan values below the diagonal which is as expected Plot Bar Graph on dataframe TotalPurchaseInference s TotalPurchase Monthly Cohort Spend computed shown in bar plot November 2011 had maximum Cumulative Sales Create Heatmap on Total Items Purchased Spread by Cohort Month Inference s Drawn from Total Items Purchased Spread by Cohort Month Heatmap Description Affected Cohorts Remarks 1 Maximum Items Procured Cohort December 2010 Four months over 450K plus purchases 2 Minimum Items Procured Cohort Feb 2011 Eight months under 64K purchases 3 Promising Cohort by Items January 2011 Greater than 50K purchases every month Cohort Mean Quantity of Gift Items Purchased Spread by CohortMonth Inference s Drawn from Mean Quantity of Items Purchased Spread by Cohort Month Heatmap Description Affected Cohorts Remarks 1 Maximum Mean Items Procured Cohort December 2010 Consistently over 12 items 2 Minimum Mean Items Procured Cohort August 2011 Consistently less than 11 items with minimum mean of 5. Created a dashboard in tableau by choosing appropriate chart types and metrics useful for the business. Mutually exclusive segments cohorts Compare metrics across product lifecycle Compare metrics across customer lifecycle Types of cohorts Time Cohorts are customers who signed up for a product or service during a particular time frame. Analyzing these cohorts shows the customers behavior depending on the time they started using the company s products or services. Exciting low spend category who have shopped recently Cluster 1 Cluster 1 has negative values significantly further away from 0 for F further away from 0 for M and high positive values for R implying all these 3 values are below the median values for R F and M mostly. 5K on a single transaction 581483 for Birdie Paper Craft Bottom 20 Purchases by InvoicesInference s groupByTotalCost2 dataframe summarized at InvoiceNo level aggregating sum of TotalCost for Bottom 20 Invoices Data quality check successful on first 5 rows validation Plot Bar Plot Bottom 20 Purchases by Invoice Number Inference s We infer that the top 2 invoices were cancelled and refunded Top 20 Customers by Spending Inference s Customer 14646 from Netherlands has shopped for 279K during the given period which is the maximum Handling Inappropriate Data Boxplot on Quantity to Identify Outliers in Data DistributionInference s Quantity has outliers spread on both sides and needs further preprocessing InterQuartile Range IQR 1. Four equal groups across three variables create 64 4x4x4 different customer segments which is a manageable number. 6 mean items procured every month Analyse the retention rate of customersCustomer retention is a very useful metric to understand how many of all the customers are still active. The company mainly sells unique and all occasion gifts. Validate silhouette Score Inference s Data Visualization shows Highest Silhouette score value is seen for cluster 4 Lets confirm it once by looking at underlying scores Check Silhouette score Dataframe to Validate Cluster with maximum score Inference s Cluster 4 has best Silhouette score with 0. We will use pandas melt facility on RFMModelScaled to achieve thatDataframe MeltInference s Single Metric computed each for R F amd M for customer New variable Metric Data quality check validated okay lets check the shape Check shape of RFMModelScaledMelt dataframeInference s 12888 rows of data with 4 columns is the shape Each of the 4296 CustomerID s now has 3 metric values one for Recency Frequency and Monetary but we have only 4 columns Melt is successful let s do snake plot visualization RFM Snake Plot VisualizationInference s Snakeplot executed to identify RFM attributes for each cluster and will for basis for market capitalization by executing specific focused campaigns for the cluster to improve Sales and loyalty Cluster 0 Cluster 0 has negative values closer to 0 on F and M and negative values farther away on R from 0 implying recency above median with the other 2 values varying from 1 to 4. Dataset Description This is a transnational data set which contains all the transactions that occurred between 01 12 2010 and 09 12 2011 for a UK based and registered non store online retail. Cohort group A string representation of the year and month of a customer s first purchase. Standardize the data. Nominal A five digit integral number uniquely assigned to each distinct product Description Product item name Nominal Product item name Quantity The quantities of each product item per transaction Numeric The quantities of each product item per transaction InvoiceDate Invoice Date and time Numeric The day and time when each transaction was generated UnitPrice Unit price Numeric Product price per unit in sterling CustomerID Customer number Nominal A six digit integral number uniquely assigned to each customer Country Country name Nominal The name of the country where each customer resides Import LibrariesSet relative path of input filesImport Input DatasetsImport Bonus Country Country Code Mapping Dataset for Tableau Visualization Data Cleaning Data Pre processing Check Shape of Input Train DatasetInference s train dataframe has 379336 rows of information and 8 columns Validate First Few Records of Input train dataframeInference s Train Dataframe has nan value on CustomerID Column for first record Data quality check successful on first 5 rows validation Check the shape of Test DataframeInference s test Dataframe has 162573 rows of information and 8 columns Validate First Few Records of Input Test DataframeInference s test Dataframe has 2 nan value on CustomerID Column in the first 5 records Data quality check successful on first 5 rows validation Concatenate train and test Dataframes into Single Merged dataframe dataInference s data Dataframe has 541909 rows of information and 8 columns Validate First Few Records of data DataframeInference s data Dataframe displays fine and has 8 columns Description column is in Capitals and can be converted to Title Proper Case after numeric EDA Data quality check successful on first 5 rows validation Identify Missing Values and Type of Data using data. Plot the distribution of RFM values using histogram and frequency charts Check Cluster Dash filtering on Cluster and use reset filters to reset e. Combinining three ratings to get a RFM segment as strings. Monetary is the total amount of money a customer spent in that given period. It gives you the percentage of active customers compared to the total number of customers Create summarization cohortGroup on CohortMonth and CohortIndexInference s cohortGroup summarization created on CohortMonth and CohortIndexCompute Retention RateInference s Retention percentage computed across Months for cohortsCreate Heatmap Customer Retention Rate Spread by Cohort Month in Percentage Inference s Drawn from Customer Retention Rate Spread by Cohort Month in Percentage Heatmap Description Affected Cohorts Remarks 1 Maximum Retention Rate Cohort December 2010 Average Retention of 36 2 Minimum Retention Rate Cohort May 2011 Average Retention of 20 3 Average Retention Rate Across Cohorts All Cohorts 25 except for seasonal changes in October and November 2011 Data Transformation Completed Performed cohort analysis a cohort is a group of subjects that share a defining characteristic. 31 for F Insight is not so frequent with values near the median Medium Negative Value of 0. 5 IQR Rule on Quantity to Identify Outliers in Data DistributionInference s Quantity outliers found based on IQR test on both sides Inference s More than 2 quantity is negative indicating returns refunds Inference s 4 significant outlier records with 2 on either side of the distribution are present in quantity which was earlier highlighted in boxplot Records with Quantity 20000 which are cancelled are removed Inference s 2 percent negative quantity items removed 2 Positive outlier quantities 20000 which were part of refunds are removed Validate Quantity Distribution after removing inappropriate dataInference s Boxplot on quantity shows positive distribution with 1 valid high value Perform Boxplot Test for Outliers on UnitPriceInference s Boxplot shows unit price positive distribution with 1 high value outlier Perform IQR Test for Outliers on UnitPriceInference s IQR shows unit price high positive outlier lets ignore as its valid Visualise the UnitPrice DistributionInference s There are about 0. Compute Within Cluster Sum of Squares WCSS Error through Elbow Method Inferences WCSS scores computed for clusters 1 to 13 4 or 5 would be a good number considering the WCSS error tapers down after this Let s plot WCSS elbow graph to check our inference Plot WCSS Elbow Graph from computed WCSS Inertia Dataframe WCSSKmeansOut Inference s based on WCSS Elbow Graph Elbow graph WCSS Line starts smoothening from cluster 4 Lets validate with Silhouette score a measure of how similar an object is to its own cluster cohesion compared to other clusters separation. This cluster needs to be looked at closely and more than 1 strategy devised to improve frequency where applicable improve spend for new customers and target churned loyal customers and churned medium to high spenders. Used a bar chart to show the monthly figures Check Sales Dash filtering on Month and Region and use reset filters to reset b. This label is common across all invoices for a particular customer. Cluster 3 Cluster 3 has positive values closer to 0 for F and M and positive values slightly further from 0 for R indicating this is the cluster with RFM scores above median and has a combination of Bronze Silver and Gold and is our target cluster to improve Sales and Loyalty. Most of these customers in this cluster are churned low spending customers churned loyal customers churned medium spenders and inactive not so frequent low spending customers. Based on sample this cluster can be targeted with new niche economy products for improving market capitalization Scatter PlotThese will help us visualize the division of customers into different segments based on the RFM atributes. Analyzing the RFM segments by summarizing them and comment on the findings. Analyze the RFM segments by summarizing them and comment on the findings Note Rate recency for customer who has been active more recently higher than the less recent customer because each company wants its customers to be recent. It also has a few new customers who are spending lower and have lower frequency. The time may be monthly or quarterly even daily. Get the RFM score by adding up the three ratings. 1 records have Customer ID Missing Apt strategy is to remove these records Retain only records where CustomerID is populated and drop the remaining 25 Inference s data Dataframe has 401604 records retained with 8 ColumnsRecheck the missing values information on data dataframe Inference s No missing values found in data dataframe for any of the 8 Columns Change the case of column Description from Upper to Title Proper for better readabilityInference s data Dataframe displays fine and has 8 columns Description column converted to Title Proper Case Data quality check successful on first 5 rows validation Change the DType of CustomerID to IntegerInference s data Dataframe displays fine and has 8 columns CustomerID column converted to Integer Type Data quality check successful on first 5 rows validation Change the DType of CustomerID to StringInference s data Dataframe has 8 columns and 401604 rows CustomerID column converted to String Type Purchase Transactions Split By CountryInference s groupByCountry dataframe summarized at Country level aggregating count on InvoiceNoPlot Bar Plot Transaction Count of Purchases by Country Inference s United Kingdom UK tops on transactions with over 356K transactions Summarize Top 3 Countries Transactions Count as Percentage Inference s United Kingdom has approximately 89 of Purchase Sales Split By Country Create Feature Total Cost as Quantity UnitPriceInference s TotalCost column added as last column of dataframe data and first 5 rows displays right computation as multiplication product of UnitPrice and Quantity Data quality check successful on first 5 rows validation Overall Purchase by Country Inference s Saudi Arabia ranked lowest on Overall Purchases UK ranked highest on Overall Purchases greater than 6. Sort customers based on that metric 2. Bar graph of top 15 products which are mostly ordered by the users to show the number of products sold Check Sales Dash filtering on Month and Region and use parameter top N and use reset filters to reset filters no reset on parameter c. Note Rate recency for customer who has been active more recently higher than the less recent customer because each company wants its customers to be recent. Calculate RFM metrics. It groups customers by the type of product or service they signed up. ", "id": "rishikeshsreedhar/online-retail-superstore-cohort-and-rfm-analysis", "size": "86127", "language": "python", "html_url": "https://www.kaggle.com/code/rishikeshsreedhar/online-retail-superstore-cohort-and-rfm-analysis", "git_url": "https://www.kaggle.com/code/rishikeshsreedhar/online-retail-superstore-cohort-and-rfm-analysis", "script": "sklearn.metrics plotly.offline sklearn.cluster obtain_CohortMonth KMeans plot FigureFactory as FF FMScore iplot seaborn numpy download_plotlyjs plotly.graph_objs obtain_TableauMonthYear cufflinks date plotly plotly.express obtainDateInterval plotly.tools matplotlib.pyplot pandas outlierDetection StandardScaler RScore segment_market __version__ init_notebook_mode FigureFactory sklearn.preprocessing segment_customer timedelta silhouette_score datetime ", "entities": "(('outliers', 'InterQuartile Range further IQR'), 'k') (('number', 'first purchase'), 'represent') (('50 365', 'Percentile 75th Monetary'), 'find') (('Insight', 'Highest Negative least frequent least 0'), '86') (('RM Assign Cluster values', 'pd'), 'obtain') (('Quantity', '5'), 'provide') (('92', 'customer base Highest most active Positive 2'), 'be') (('customer', 'RFM Recency Frequency Monetary model'), 'frequency') (('Retail Capstone Project Problem It', 'customer'), 'Statement') (('3 which', 'percentiles'), 'find') (('forces data', 'distribution'), 'Sort') (('resulting segments', 'recency valuable lowest frequency'), 'order') (('spending customer base low Highest amount', '0'), '87') (('object', 'neighboring poorly clusters'), 'range') (('Assign', 'best metric'), 'be') (('who', 'products'), 'refer') (('monthly figures', 'b.'), 'use') (('we', 'recency frequency'), 'spend') (('company design custom', 'particular segments'), 'help') (('how cohort', 'other cohorts'), 'observe') (('where applicable', 'high spenders'), 'need') (('83', 'Medium Negative most recent 0'), 'be') (('who', 'advanced services'), 'have') (('how cohort', 'other cohorts'), 'observeed') (('Monthly Cohort Assignment Setting', 'pre cohort analysis'), 'cohort') (('R Insight', 'Medium Negative recent 0'), 'be') (('who', 'lower lower frequency'), 'have') (('company', 'occasion gifts'), 'sell') (('they', 'product'), 'group') (('Loyal 354 Churned Customer', '1'), 'show') (('31', '0'), 'be') (('loyal customers', 'spending so frequent low customers'), 'churn') (('label', 'particular customer'), 'be') (('Consistent 3 Cohort', 'December 2010 March'), 'Procured') (('0 Cluster', '4'), 'use') (('so s', '2011'), 'dataset') (('how object', 'clusters other separation'), 'be') (('how customers', '4 clusters'), 'see') (('RefundedInvoices', 'Data Cleaning'), 'be') (('Therefore big spenders', 'MVP Minimum Viable such Product'), 'differentiate') (('Monetary s', 'log transformation'), 'show') (('cluster 4 Lets', '0'), 'show') (('customer segmentation that', 'groups'), 'be') (('that', '12 2010 12 UK'), 'Description') (('price discounts', 'cluster campaign'), 'need') (('Check Sales Dash', 'd.'), 'hour') (('Strategy', 'transaction loyalty good programs'), 'be') (('customers', 'more recently less recent customer'), 'recency') (('5', '0'), 'be') (('UnitPrice DistributionInference', 'valid Visualise'), 'find') (('we', 'Kmeans'), 'complete') (('which', 'RFMModel dataframe RFM Frequency Monetary model RFMModel createdBuild RFM Recency Segments'), 'compute') (('number', 'f.'), 'select') (('cluster', 'just median'), 'be') (('negative negative values', 'log transformation'), 'check') (('Frequency', 'given period'), 'be') (('this', 'maximum sales'), 'have') (('us', 'RFM atributes'), 'target') (('which', 'customer 64 4x4x4 different segments'), 'create') (('3Inference Maximum volume', '1'), 'cross') (('it', '1 16 50 144'), 'compute') (('high positive R', 'R F'), 'have') (('the more attribute', 'relative total population'), 'be') (('multiplication product', '6'), 'have') (('which', 'customer missing 25'), 'find') (('customer', 'last purchase'), 'mean') (('Check', '28'), 'recency') (('dashboard', 'following a.'), 'entail') (('product customer', 'time'), 'base') (('copy_x True k', 'max_iter'), 'decide') (('Procured Item White Hanging Heart T Light Holder Most Top 20 Purchases', '168'), 'rank') (('who', 'time particular frame'), 'cohort') (('customers', 'more recently less recent customer'), 'analyze') (('we', 'transaction single invoice'), 'be') (('which', 'consistent monetary capitalization'), 'account') (('encouraging', 'here much traction'), 'be') (('Therefore big spenders', 'such MVP'), 'differentiate') (('that', 'defining characteristic'), 'give') (('data', 'appropriate transformation'), 'manage') (('it', 'cancellation StockCode Product item code'), 'start') (('8', '1'), 'be') (('columns Description fine 8 column', 'data'), 'number') (('they', 'products'), 'show') (('which', 'c.'), 'graph') (('we', 'single column'), 'seem') (('who', 'high recency loyal customers'), 'have') (('customer', 'company'), 'understand') (('94', '0'), 'be') (('who', 'personalization also future services'), 'help') (('this', 'target Sales'), 'have') (('Spending Active Loyal Customer 7 highest Low segment', '2'), 'have') (('Gold customers', 'results'), 'be') (('Monetary', 'period'), 'be') (('monetary value', '3'), 'have') (('spending customer base High low amount', '0'), 'be') (('who', 'past'), 'be') (('very useful how many', 'customers'), 'procure') (('Related Dependence Clusterwise Heatmap', 'Negative 0 Highest 0'), 'compute') (('number', 'parameter c.'), 'graph') (('RFM', 'customer value'), 'be') (('Customer segmentation', 'RFM analysis'), 'be') (('few churned best medium high spending loyal active segment', '0'), 'be') (('RecentPurchaseDate columns', 'given period'), 'let') (('ID Data Integrity shape frequency dataframe Monetary successful Monetary', 'period'), 'be') (('42', 'this'), 'be') (('who', 'defining characteristic'), 'clean') ", "extra": "['gender', 'test']", "label": "Perfect_files", "potential_description_queries": ["account", "active", "advanced", "age", "algorithm", "analyze", "approach", "array", "assign", "associated", "attribute", "auto", "average", "basic", "behavior", "best", "boolean", "boxplot", "cancellation", "case", "category", "center", "chain", "character", "chart", "check", "checking", "classify", "cleaning", "close", "cluster", "clustering", "code", "column", "comment", "company", "compare", "comparison", "computation", "compute", "concatenate", "conversion", "convert", "correct", "cost", "could", "count", "country", "create", "current", "custom", "customer", "data", "dataframe", "date", "datetime", "day", "describe", "diagonal", "dict", "difference", "digit", "display", "distplot", "distributed", "distribution", "division", "drop", "duplicate", "ensure", "equal", "error", "even", "every", "expected", "export", "feature", "field", "figure", "filter", "fix", "float", "following", "form", "format", "found", "frequency", "frequent", "function", "future", "gender", "generated", "graph", "group", "groupby", "head", "heatmap", "help", "high", "histogram", "id", "ignore", "import", "importance", "improve", "index", "inference", "info", "init", "input", "int", "integer", "interest", "item", "json", "key", "label", "least", "left", "let", "letter", "level", "list", "log", "look", "looking", "lower", "major", "manage", "map", "market", "match", "matplotlib", "max", "max_iter", "maximum", "mean", "measure", "median", "method", "metric", "might", "mild", "minimum", "missing", "mode", "model", "month", "most", "name", "near", "need", "negative", "new", "no", "non", "normal", "normalization", "normalize", "normalized", "not", "notation", "notebook", "number", "numeric", "numpy", "object", "offline", "offset", "operation", "order", "ordered", "out", "outlier", "output", "overall", "overlap", "parameter", "parse", "part", "partial", "past", "path", "pattern", "per", "percent", "percentage", "perform", "period", "person", "pie", "plot", "population", "positive", "potential", "practice", "pre", "preprocessing", "present", "price", "processing", "product", "python", "quantity", "random", "range", "ratio", "re", "record", "relative", "remove", "representation", "research", "reset", "response", "result", "return", "right", "row", "run", "sample", "sampler", "scale", "score", "seasonal", "second", "segment", "segmentation", "selected", "service", "set", "shape", "short", "side", "silhouette", "similar", "single", "six", "size", "space", "spread", "stage", "state", "step", "store", "str", "strategy", "string", "sub", "sum", "table", "target", "technique", "test", "those", "through", "time", "title", "total", "train", "transaction", "transformation", "try", "type", "under", "uniform", "unique", "unit", "until", "up", "usage", "valid", "validate", "validation", "value", "variable", "variation", "visit", "visualization", "visualize", "volume", "while", "who", "wise", "work", "worst", "year"], "potential_description_queries_len": 287, "potential_script_queries": ["datetime", "iplot", "plot", "plotly", "seaborn", "sklearn", "timedelta"], "potential_script_queries_len": 7, "potential_entities_queries": ["best", "dataframe", "frequent", "high", "least", "missing", "most", "positive", "shape", "total"], "potential_entities_queries_len": 10, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 292}
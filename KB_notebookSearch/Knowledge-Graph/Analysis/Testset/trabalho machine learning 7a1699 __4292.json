{"name": "trabalho machine learning 7a1699 ", "full_name": " h1 Introdu\u00e7\u00e3o h1 Importa\u00e7\u00e3o dos dados h1 An\u00e1lise dos dados h1 Tratamento dos dados h1 Iniciando o treinamento do modelo h1 Proposta de aplica\u00e7\u00e3o do problema ao neg\u00f3cio ", "stargazers_count": 0, "forks_count": 0, "description": "com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. O presente estudo procura estimar as caracter\u00edsticas determinantes para inadimpl\u00eancia em contratos de ve\u00edculos. A partir da observa\u00e7\u00e3o dos tipos de cada vari\u00e1vel algumas decis\u00f5es ser\u00e3o executadas Transformar as vari\u00e1veis do tipo object em tipo inteiro ou dummy Transformar as datas em tipo datetime e criar colunar para contabilizar a idade da observa\u00e7\u00e3o em ano ou dia Popular os dados faltantes com um valor desconhecido pela coluna como por exemplo o um valor 1 em uma coluna de inteiros n\u00e3o negativosNeste trabalho a vari\u00e1vel dependente target ser\u00e1 o campo LOAN_DEFAULT. Observa se que a vari\u00e1vel target possui um volume de valores 0 Inadimplente muito maior que valores 1 Adimplente. Proposta de aplica\u00e7\u00e3o do problema ao neg\u00f3cioEm rela\u00e7\u00e3o aos dados obtidos pela aplica\u00e7\u00e3o do modelo de Random Forest foi poss\u00edvel perceber que os principais fatores s\u00e3o LTV Loan to value of the asset \u00e9 um indicador usado para definir qual o percentual m\u00e1ximo do valor do bem que pode ser emprestado para o cliente. Diante deste cen\u00e1rio torna se cada vez mais relevante a aplica\u00e7\u00e3o de modelos estat\u00edsticos adequados para prever os riscos envolvidos nos contratos celebrados e permitir a concess\u00e3o para clientes com menor risco de cr\u00e9dito. Importa\u00e7\u00e3o dos dados An\u00e1lise dos dadosDe acordo com o relat\u00f3rio apresentado pela fun\u00e7\u00e3o ProfileReport h\u00e1 233. Conforme abaixo vemos que em m\u00e9dia at\u00e9 74 do valor do bem \u00e9 concedido para empr\u00e9stimos para os clientes. Quando se observa os clientes com inadimpl\u00eancia este percentual chega pr\u00f3ximo de 77 desta forma \u00e9 recomend\u00e1vel que os empr\u00e9stimos sejam menores em rela\u00e7\u00e3o ao valor do ve\u00edculo financiadoDISBURSED AMOUNT \u00c9 o valor concedido de empr\u00e9stimo. html Compute confusion matrix Only use the labels that appear in the data We want to show all ticks. Loop over data dimensions and create text annotations. Introdu\u00e7\u00e3oAs institui\u00e7\u00f5es financeiras est\u00e3o sujeitas \u00e0 perdas significativas em decorr\u00eancia de inadimpl\u00eancia nas opera\u00e7\u00f5es de financiamento de ve\u00edculos. Plotando a matriz de confus\u00e3o com valores absolutos para Plotando a matriz de confus\u00e3o com valores normalizados Defini\u00e7\u00e3o do modelo GCM Realiza\u00e7\u00e3o do treino do modelo Realizando as predi\u00e7\u00f5es no modelo criado a partir do dataset de valida\u00e7\u00e3o Exibindo o score da valida\u00e7\u00e3o Plotando a matriz de confus\u00e3o com valores absolutos para Plotando a matriz de confus\u00e3o com valores normalizados Defini\u00e7\u00e3o do modelo XGBoost Realiza\u00e7\u00e3o do treino do modelo Realizando as predi\u00e7\u00f5es no modelo criado a partir do dataset de valida\u00e7\u00e3o Exibindo o score da valida\u00e7\u00e3o Plotando a matriz de confus\u00e3o com valores absolutos para Plotando a matriz de confus\u00e3o com valores normalizados Fun\u00e7\u00e3o para cria\u00e7\u00e3o de um DF de features importantes para o modelo Fun\u00e7\u00e3o para plotar o features importance do modelo Criando o DF das principais features do modelo de RandomFlorest Imprimindo as principais features utilizadas no modelo RandonFlorest Criando o DF das principais features do modelo GBM Imprimindo as principais features utilizadas no modelo GBM Criando o DF das principais features do modelo XGB Imprimindo as principais features utilizadas no modelo XGB. Aqui podemos observar que os empr\u00e9stimos com inadipl\u00eancia possuem em m\u00e9dia valor mais altos de desembolso. Observa se que h\u00e1 alguns warning registrados para algumas vari\u00e1veis do dataset que apontam alguns potenciais problemas para o modelo. A eleva\u00e7\u00e3o dos \u00edndices de inadimplemento resulta em maior taxa de rejei\u00e7\u00e3o de pedidos de financiamento e no aumento das taxas de juros que encarece o produto para consumidores finais e dessestimula muitos compradores. Nota se que os modelos t\u00eam acur\u00e1cia muito pr\u00f3ximas embora o modelo tenha tido a maior acur\u00e1cia dentre os tr\u00eas. Carregando os dados Avaliando o shape do dataset de treino e teste Avaliando os t\u00edpos das vari\u00e1veis Aval Analisando a quantidade de inadimplencias atrav\u00e9s da vari\u00e1vel target LOAN_DEFAULT Cria\u00e7\u00e3o de c\u00f3pia do dataframe de treino Os dataframes de teste e treino ser\u00e3o unidos afim de facilitar o processo de transforma\u00e7\u00e3o e de feature engineering Verificando como est\u00e3o os dados da coluna AVERAGE_ACCT_AGE Vamos criar nova coluna AVERAGE_ACCT_AGE_EM_MESES que vai contabilizar a quantidade de meses que est\u00e3o dispostas na coluna AVERAGE_ACCT_AGE Verificando como est\u00e3o os dados da coluna CREDIT_HISTORY_LENGTH Vamos criar nova coluna CREDIT_HISTORY_LENGTH_EM_MESES que vai contabilizar a quantidade de meses que est\u00e3o dispostas na coluna CREDIT_HISTORY_LENGTH Verifica se que a data de nascimento est\u00e1 na coluna DATE_OF_BIRTH Iremos transformar a data de nascimento em idade Verificando a nova coluna Idade DISBURSAL_DATE data do desembolso Esta coluna ser\u00e1 tranformada em dias afim de verificar se o tempo decorrido a partir da concess\u00e3o do cr\u00e9dito \u00e9 determinante do inadimplemento dos clientes verificando a quantidade de dias de desembolso Verificando como est\u00e3o os dados da coluna EMPLOYMENT_TYPE Categorizando os dados inclusive os valores nulos Verificando a quantidade de valores nulos em todo a base Verificando como est\u00e3o os dados da coluna PERFORM_CNS_SCORE_DESCRIPTION transformando em dummies dividindo os data sets Criando uma base de valida\u00e7\u00e3o Verificando as dimens\u00f5es dos dataset selecionar as colunas para uso no treinamento e valida\u00e7\u00e3o lista das colunas n\u00e3o usadas lista das features colunas usadas no modelo Defini\u00e7\u00e3o dos hiperpar\u00e2metros dos modelos Defini\u00e7\u00e3o do modelo de arvor\u00e9 Realiza\u00e7\u00e3o do treino do modelo Exibindo o score do out of bag do modelo Realizando as predi\u00e7\u00f5es no modelo criado a partir do dataset de valida\u00e7\u00e3o Exibindo o score da valida\u00e7\u00e3o M\u00e9todo para gerar um gr\u00e1fico da matrix de confus\u00e3o Fonte https scikit learn. RISCO DE CR\u00c9DITO Este \u00e9 o risco atribu\u00eddo pela institui\u00e7\u00e3o no momento do cr\u00e9dito do ve\u00edculo P\u00f3ss\u00edvel perceber inadipl\u00eancia maior em clientes com maior risco isso sugere que a institui\u00e7\u00e3o financeira j\u00e1 det\u00e9m expertise ao atribuir risco para os clientes que pode ser melhorada atrav\u00e9s deste modelo This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. Acredita se que a principal causa dessa anomalida seja a propor\u00e7\u00e3o desbalanceada dos valores presentes na vari\u00e1vel target. H\u00e1 diversas solu\u00e7\u00f5es para esse problema a principal delas \u00e9 normalizar a base de dados de modo que a propor\u00e7\u00e3o entre as classes seja o mais igualit\u00e1rio poss\u00edvel. ser\u00e3o criadas novas colunas no dataframe a partir de colunas j\u00e1 existentes feature engineering dummeriza\u00e7\u00e3o de vari\u00e1veis Iniciando o treinamento do modeloDe forma preliminar ao treinamento os dados j\u00e1 tratados ser\u00e3o dividos novamente em treino e teste. read_csv Input data files are available in the. Para isto ser\u00e3o utilizadas caracter\u00edsticas hist\u00f3ricas de clientes e empr\u00e9stimos realizados por uma institui\u00e7\u00e3o financeira. Tratamento dos dadosNesta fase do trabalho os dados ser\u00e3o tratados de forma a permitir a aplica\u00e7\u00e3o de algoritmos de machine learning. and label them with the respective list entries Rotate the tick labels and set their alignment. S\u00e3o eles alta cardinalidade grande quantidade de valores zero na coluna valores faltantes e um desequil\u00edbrio na distribui\u00e7\u00e3o dos valores da vari\u00e1veis y1. Essa ser\u00e1 uma oberva\u00e7\u00e3o importante para a an\u00e1lise do modelo. Essas observa\u00e7\u00f5es ser\u00e3o tratadas ao longo da an\u00e1lise. Outra informa\u00e7\u00e3o importante est\u00e1 relacionada aos falsos positivos gerados a partir do modelo. Al\u00e9m disso uma base de valida\u00e7\u00e3o para avaliar o modelo tamb\u00e9m ser\u00e1 gerada. org stable auto_examples model_selection plot_confusion_matrix. 154 linhas e 41 vari\u00e1veis no dataset sendo elas 25 n\u00famericas 6 categ\u00f3ricas 6 do tipo boolean e 4 do tipo constante rejected. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. Como h\u00e1 um percentual maior de inadimplentes logo o modelo tende a taxar a maioria dos novos valores como inadimplentes tamb\u00e9m. ", "id": "modesto/trabalho-machine-learning-7a1699", "size": "4292", "language": "python", "html_url": "https://www.kaggle.com/code/modesto/trabalho-machine-learning-7a1699", "git_url": "https://www.kaggle.com/code/modesto/trabalho-machine-learning-7a1699", "script": "sklearn.metrics plot_feature_importance IPython.core.interactiveshell unique_labels seaborn numpy plot_confusion_matrix XGBClassifier GradientBoostingClassifier sklearn.ensemble confusion_matrix sklearn.model_selection LabelEncoder RandomForestClassifier matplotlib.pyplot sklearn.utils.multiclass pandas accuracy_score create_df_feature_importance InteractiveShell sklearn.preprocessing xgboost train_test_split ", "entities": "(('deste cen\u00e1rio torna se cada vez Diante mais', 'nos contratos celebrados para clientes com menor risco de envolvidos concess\u00e3o cr\u00e9dito'), 'relevante') (('It', 'python docker image https kaggle github'), 'este') (('tipo 4 constante', '25 6 6 tipo'), 'linha') (('propor\u00e7\u00e3o desbalanceada dos valores', 'vari\u00e1vel presentes target'), 'seja') (('dos dadosNesta fase', 'tratados de forma'), 'trabalho') (('coluna zero valores', 'dos valores da vari\u00e1veis distribui\u00e7\u00e3o y1'), 'faltante') (('ser\u00e1 uma oberva\u00e7\u00e3o importante', 'modelo'), 'para') (('que apontam alguns potenciais problemas', 'para o modelo'), 'dataset') (('clientes e empr\u00e9stimos realizados por utilizadas caracter\u00edsticas hist\u00f3ricas de uma', 'financeira'), 'ser\u00e3o') (('percentual maior de inadimplentes', 'maioria dos valores como taxar novos inadimplentes'), 'logo') (('coluna de inteiros', 'vari\u00e1vel dependente target ser\u00e1 o n\u00e3o negativosNeste campo LOAN_DEFAULT'), 'executadas') (('caracter\u00edsticas', 'contratos de ve\u00edculos'), 'determinante') (('modelos t\u00eam acur\u00e1cia muito pr\u00f3ximas modelo tenha', 'os tr\u00eas'), 'embora') (('propor\u00e7\u00e3o classes', 'o mais igualit\u00e1rio poss\u00edvel'), 'diversas') (('ser\u00e3o criadas novas partir de colunas j\u00e1', 'dividos treino e novamente teste'), 'colunas') (('Introdu\u00e7\u00e3oAs institui\u00e7\u00f5es financeiras est\u00e3o', 'decorr\u00eancia de inadimpl\u00eancia nas financiamento de opera\u00e7\u00f5es de ve\u00edculos'), 'sujeitas') (('you', 'output'), 'list') (('da', 'an\u00e1lise'), 'ser\u00e3o') (('We', 'ticks'), 'use') (('partir', 'modelo'), 'do') (('aumento de juros que produto das taxas para', 'finais e dessestimula muitos compradores'), 'resulta') (('read_csv Input data files', 'the'), 'be') (('Al\u00e9m disso uma valida\u00e7\u00e3o base de para', 'tamb\u00e9m ser\u00e1 o modelo gerada'), 'avaliar') (('\u00e9 concedido para empr\u00e9stimos para', 'Conforme abaixo vemos m\u00e9dia'), 'que') (('principais', 'modelo XGB'), 'para') (('respective list', 'alignment'), 'label') (('ProfileReport', 'relat\u00f3rio apresentado pela fun\u00e7\u00e3o'), 'dados') (('os empr\u00e9stimos sejam menores', 'AMOUNT \u00c9 concedido de o empr\u00e9stimo'), 'este') (('Exibindo score da para da confus\u00e3o Fonte https gerar matrix de scikit', 'de valida\u00e7\u00e3o'), 'os') (('principais fatores', 'para \u00e9 usado qual percentual valor'), 'pela') ", "extra": "['annotation', 'test', 'bag']", "label": "Perfect_files", "potential_description_queries": ["appear", "asset", "bag", "boolean", "confusion", "create", "current", "data", "dataframe", "dataset", "datetime", "directory", "dummy", "engineering", "environment", "feature", "file", "image", "importance", "input", "kaggle", "label", "linear", "list", "load", "matrix", "modelo", "no", "object", "out", "para", "principal", "processing", "python", "run", "running", "scikit", "score", "set", "several", "shape", "target", "text", "treinamento", "value", "volume", "warning", "write"], "potential_description_queries_len": 48, "potential_script_queries": ["core", "numpy", "seaborn", "sklearn", "xgboost"], "potential_script_queries_len": 5, "potential_entities_queries": ["image", "matrix", "para", "target"], "potential_entities_queries_len": 4, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 53}
{"name": "build gan assignment 2 ", "full_name": " h1 Deep Convolutional GAN DCGAN h3 Goal h3 Learning Objectives h2 Getting Started h4 DCGAN h2 Generator h2 Discriminator h2 Training ", "stargazers_count": 0, "forks_count": 0, "description": "You will implement a Deep Convolutional GAN DCGAN a very successful and influential GAN model developed in 2015. Train a powerful generative model. com uc id 1kcGhcT EuR6gzZJoD6_xClaaLIncJjt export view Figure Architectural drawing of a generator from DCGAN from Radford et al 2016 https arxiv. This is because with DCGAN you use convolutions which don t depend on the number of pixels on an image. You are also given a function to create a noise vector. 02 Dataloader returns the batches Keep track of the average discriminator loss Update gradients Update optimizer Keep track of the average generator loss. Generator architecture https drive. pdf is the paper if you are interested It might look dense now but soon you ll be able to understand many parts of it Learning Objectives1. There are also tests at the end for you to use. 3 Follow each batchnorm with a ReLU activation. Get hands on experience making a widely used GAN Deep Convolutional GAN DCGAN. You will build a generator using 4 layers 3 hidden layers 1 output layer. These functions are the same as the ones from the last assignment. Conv2d https pytorch. com uc id 1SvEV3Xz5n1kC48_VG7iehRXdL4g4l1a8 export view Set for testing purposes please do not change UNQ_C1 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED FUNCTION Generator Build the neural network Steps 1 Do a transposed convolution using the given parameters. 4 If its the final layer use a Tanh activation after the deconvolution. pub 2017 momentum but you don t need to worry about it for this course You can tranform the image values to be between 1 and 1 the range of the tanh activation You initialize the weights to the normal distribution with mean 0 and standard deviation 0. Use ReLU activation in generator for all layers except for the output which uses Tanh. html useful Here s the test for your generator block DiscriminatorThe second component you need to create is the discriminator. BatchNorm2d https pytorch. You are also provided a visualizer function to help see the images your GAN will create. Optional hint for make_disc_block1. For every batch you will update the discriminator and generator. Use LeakyReLU activation in the discriminator for all layers except for the output which does not use an activationYou will begin by importing some useful packages and data that will help you create your GAN. You are supplied with some tests following the code cell so you can see if you re on the right track At the end of the generator class you are given a forward pass function that takes in a noise vector and generates an image of the output dimension using your neural network. Getting Started DCGANHere are the main features of DCGAN don t worry about memorizing these you will be guided through the implementation Architecture guidelines for stable Deep Convolutional GANs Replace any pooling layers with strided convolutions discriminator and fractional stridedconvolutions generator. On CPU this can take about 8 hours per thousand steps. LeakyReLU https pytorch. html useful Here s a test for your discriminator block TrainingNow you can put it all together Remember that these are your parameters criterion the loss function n_epochs the number of times you iterate through the entire dataset when training z_dim the dimension of the noise vector display_step how often to display visualize the images batch_size the number of images per forward backward pass lr the learning rate beta_1 beta_2 the momentum term device the device type Change runtime type and set hardware accelerator to GPU and replace device cpu with device cuda. On GPU this takes about 30 seconds per thousand steps. As a result it may have ended up tricking the discriminator so well that there would be no more improvement known as mode collapse MNIST Digits Progression https drive. Deep Convolutional GAN DCGAN GoalIn this notebook you re going to create another GAN using the MNIST dataset. Use LeakyReLU activation in the discriminator for all layers. 3 Follow each batchnorm with a LeakyReLU activation with slope 0. The code should then run without any more changes over 1 000 times faster. 2 Do a batchnorm except for the last layer. You will use 3 layers in your discriminator s neural network. Note here https arxiv. You may notice that instead of passing in the image dimension you will pass the number of image channels to the generator. Then you can see DCGAN s results Here s roughly the progression you should be expecting. GeneratorThe first component you will make is the generator. Use BatchNorm in both the generator and the discriminator. Build the neural block Final Layer UNQ_C2 UNIQUE CELL IDENTIFIER DO NOT EDIT Test the hidden block Check that it works with other strides Test the whole thing UNIT TESTS UNQ_C3 UNIQUE CELL IDENTIFIER DO NOT EDIT GRADED FUNCTION Discriminator Steps 1 Add a convolutional layer using the given parameters. However the number of channels is important to determine the size of the filters. Optional hint for make_gen_block1. Use convolutions without any pooling layers Use batchnorm in both the generator and the discriminator Don t use fully connected hidden layers Use ReLU activation in the generator for all layers except for the output which uses a Tanh activation. Like with the generator you will need create the function to create a single neural network block for the discriminator. Finally you can train your GAN For each epoch you will process the entire dataset in batches. Then you can initialize your generator discriminator and optimizers. Since in DCGAN the activation function will be different for the output layer you will need to check what layer is being created. Build the neural block Final Layer UNQ_C4 UNIQUE CELL IDENTIFIER DO NOT EDIT Test the hidden block Test the final block Test the whole thing Test the hidden block Because of the LeakyReLU slope Test the final block Test the whole thing A learning rate of 0. Remove fully connected hidden layers for deeper architectures. ConvTranspose2d https pytorch. As before you will need to write a function to create a single block for the generator s neural network. You might notice that in the image of Step 5000 the generator is disproprotionately producing things that look like ones. If the discriminator didn t learn to detect this imbalance quickly enough then the generator could just produce more ones. 0002 works well on DCGAN These parameters control the optimizer s momentum which you can read more about here https distill. org docs master generated torch. ", "id": "amoghjrules/build-gan-assignment-2", "size": "6478", "language": "python", "html_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-2", "git_url": "https://www.kaggle.com/code/amoghjrules/build-gan-assignment-2", "script": "torch.utils.data __init__ torch make_grid Discriminator(nn.Module) tqdm.auto show_tensor_images DataLoader forward torchvision nn matplotlib.pyplot torchvision.datasets get_noise make_disc_block MNIST tqdm Generator(nn.Module) weights_init unsqueeze_noise transforms torchvision.utils make_gen_block ", "entities": "(('02 Dataloader', 'generator average loss'), 'return') (('functions', 'last assignment'), 'be') (('You', 'output 4 layers 3 hidden layers 1 layer'), 'build') (('whole thing', 'learning 0'), 'build') (('it', 'given parameters'), 'build') (('you', 'also end'), 'be') (('you', 'generator block'), 'useful') (('you', 'generator'), 'notice') (('You', '2015'), 'implement') (('don t', 'image'), 'be') (('Deep Convolutional GAN you', 'MNIST dataset'), 'DCGAN') (('Then you', 'generator discriminator'), 'initialize') (('layer', 'output layer'), 'be') (('which', 'Tanh'), 'use') (('you', 'discriminator'), 'update') (('that', 'neural network'), 'supply') (('this', 'thousand steps'), 'take') (('you', 'neural network'), 'need') (('it', 'mode collapse MNIST Digits Progression https so well more drive'), 'end') (('code', 'then more changes'), 'run') (('you', 'convolutions strided discriminator'), 'be') (('you', 'batches'), 'train') (('You', 'neural network'), 'use') (('Here roughly you', 'results'), 'see') (('you', 'GAN'), 'begin') (('that', 'ones'), 'notice') (('now soon you', 'Learning Objectives1'), 'be') (('Steps', 'given parameters'), 'com') (('quickly enough then generator', 'just more ones'), 'produce') (('However number', 'filters'), 'be') (('You', 'noise vector'), 'give') (('which', 'Tanh activation'), 'use') (('how often images', 'device cuda'), 'useful') (('final layer', 'deconvolution'), '4') (('export Figure d 1kcGhcT EuR6gzZJoD6_xClaaLIncJjt Architectural drawing', 'et al'), 'com') (('You', 'mean 0 deviation'), 'momentum') (('you', 'discriminator'), 'create') (('GAN', 'images'), 'provide') (('you', 'https distill'), 'work') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["accelerator", "architecture", "average", "backward", "batch", "batch_size", "block", "build", "cell", "check", "code", "control", "convolution", "convolutional", "could", "course", "create", "criterion", "data", "dataset", "depend", "detect", "device", "dimension", "display", "distribution", "end", "epoch", "every", "experience", "export", "final", "following", "forward", "function", "generated", "generator", "help", "https here arxiv", "https pytorch", "id", "image", "imbalance", "implement", "implementation", "improvement", "initialize", "layer", "learn", "learning", "look", "lr", "main", "mean", "might", "mode", "model", "momentum", "need", "network", "neural", "no", "noise", "normal", "not", "notebook", "number", "optimizer", "output", "pdf", "per", "pooling", "pub", "range", "re", "read", "replace", "result", "right", "run", "runtime", "second", "set", "single", "size", "standard", "tanh", "term", "test", "testing", "through", "track", "train", "training", "type", "up", "update", "vector", "view", "visualize", "write"], "potential_description_queries_len": 101, "potential_script_queries": ["nn", "torch", "torchvision", "tqdm"], "potential_script_queries_len": 4, "potential_entities_queries": [], "potential_entities_queries_len": 0, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 104}
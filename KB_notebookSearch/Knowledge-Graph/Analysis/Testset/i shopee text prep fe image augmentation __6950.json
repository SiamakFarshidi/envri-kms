{"name": "i shopee text prep fe image augmentation ", "full_name": " h1 Data Preprocessing h1 1 Introduction h3 Goal h3 Challenges h3 Libraries W B h1 2 Data Images h2 2 1 Duplicated Images h3 Clean Duplicates Function h2 2 2 Label Group h2 2 3 Image Augmentation h1 3 Data Texts h2 3 1 Text Preprocessing step by step h3 Text Preprocessing Function h2 3 2 Text Features Extraction h3 Explore the Features h2 3 3 Text Exploration h3 Wordcloud h2 3 4 Create Text Embeddings h1 4 Final Preprocessing Function h3 Training Submission Notebook here II Shopee Model Training with Pytorch x RAPIDS h1 Specs on how I prepped explored h3 on my local machine ", "stargazers_count": 0, "forks_count": 0, "description": "1 Duplicated ImagesThere are 1 246 images that have 2 or more apparitions The title differs for most of them The label_group is usually the same but there are a few cases where it differs as well You can check the plot in the W B Project I also wanted to look at how these images with same image name look and what trully differentiates them The description usually reffers to the same object but the wording is different The Group ID can sometimes be different although the image is exactly the same this means that the text description is the one that is indicating the category in these instances. log the plot Get all titles Wordcloud stopwords_wc. And this is the plot in the W B Project Let s also observe the images within some of the groups There is definitely a resemblance between products for the human eye For some groups however the overall structure of the images is very different 2. com andradaolteanu ii shopee model training with pytorch x rapids Specs on how I prepped explored on my local machine Z8 G4 Workstation 2 CPUs 96GB Memory NVIDIA Quadro RTX 8000 RAPIDS version 0. com textfeatures library for extracting basic features from text data f98ba90e3932 for more about the textfeatures library. test test_images the product photos to be predicted 70 000 hidden files only 3 showing test. You can check out this article https towardsdatascience. and rotations as they display the product in different positions without changing its color or texture attributes. Now the same function takes about 8 9 minutes. More on that in my next notebook https www. cvtColor to display them in the RGB colorspace. html text POS 20Tagging 20in 20NLTK 20is each 20word 20of 20the 20sentence. The extractions were word_count counts how many words are in a sentence char_count counts how many characters are in a sentence avg_word_length counts what s the average word length in a sentence stopwords_count counts how many stopwords are in a sentence numerics_count counts how many numbers are in a sentence Explore the Features Within out title variable the texts are usually 10 words long with 50 characters and containing 1 to 2 numerics. Note We ll end up with 26 705 columns instead of the 12 we are working with now or 5 in the original training dataset. Training Submission Notebook here II. Create Custom Plot for W B Let s also explore the pos Part of Speech column WRB wh adverb how WP wh pronoun who VBZ verb present tense with 3rd person singular bases VBP verb present tense not 3rd person singular wrap RP particle about You can find full list here https www. Note If you re using cv2 to visualize the images note that they will be displayed in the BGR colorspace blue green red order for some reason this is the default of this library. I am thinking numbers might actually give a huge insight for our prediction. csv the corresponding metadata 2. Check out preprocessing methodology below 3. 1 Text Preprocessing step by stepBefore analyzing the text we ll have to prepare it a little bit so the insights we ll gain afterwards will be as accurate as possible. Data Preprocessing 1. 2 Text Features ExtractionAnother method was to extract features from the title column in an attempt to feed into the final model more useful information. Challenges Finding near duplicates of the product and NOT the image Erasing the impact of the background the area surrounding the product Using the description of the image or the title Libraries W B Create an account on https wandb. 3 Text ExplorationNow let s look at the newly created title_prep. 4 Create Text EmbeddingsLet s append now the TF IDF CountVectorizer embeddings explored above to our training dataframe. 2 Label Group Note If there are 2 or more images with the same label_group it means that these have been already mapped as being identical. Final Preprocessing FunctionWe ll need the functions we created in this notebook to preprocess the test dataframe as well before applying the ML model. log the plot Retrieve a sample of 6 images from this group Plot Example 1 Example 2 Example 3 Read in original image Transformations Apply transformations Plot END of EXPERIMENT Original Convert to lower case Remove punctuation Remove whitespaces Tokenize words Remove stopwords Lemmatization Part of speech tagging ner_text ne_chunk pos_tag lemmatized_text print NER ner_text Lower Case Remove Punctuation Remove whitespaces Tokenize Remove stopwords Lemmatization Part of speech tagging Process preprocessed title Add part of speech Read in prepped data Save also as artifact Extract Features Plot Another W B Experiment Get bag of words from the title Plot Make a custom plot to save into W B Prepare data Create Table. To correct that you can use cv2. io en docs_pytorch_fix api augmentations. Data Images train train_images the product photos 32 400 files train. You can check the GitHub repo here https github. update yes Plot END of EXPERIMENT Vectorizer functions don t support NAs so we need to remove if any title vectorizer Create dataframe pos vectorizer Create dataframe Concatenate all data together Get title and pos embeddings Let s also save it to W B project Clean duplicates Preprocess title get POS Extract title features Get embeddings from title and pos Test the preprocess_df function. You can find the albumentations documentation here https vfdev 5 albumentations. com nalepae pandarallel. Shopee Model Training with Pytorch x RAPIDS https www. ai andrada shopee kaggle workspace user andrada. Hence is best to create a preprocess_df function that contains the necessary metadata process pipeline. com andradaolteanu ii shopee model training with pytorch x rapids. csv the corresponding metadata each product is assigned a label_group that marks the images with identical products. Remember We ll use an Unsupervised ML Technique to make our prediction for this competition. Hence all methodologies we ll apply for the CV score we ll also need to use for the submission notebook. Introduction Goal Building a model that can identify which images contain the same product s. 3 Image AugmentationAnother aspect I wanted to explore was the different kinds of augmentation that might be performed on the images so that the model can better pick up unique patterns. Note From my research the best performing augmentations for this type of problem were flips vertical flip horizontal flip etc. Text Preprocessing Function Note This function takes 30 mins in the Kaggle environment. com pos tagging chunking nltk. log the plot Read in the image corresponding metadata Plot image Example 1 Example 2 Example 3 Clean duplicates Get count of values on each group Print info Make a custom plot to save into W B Prepare data Create Table. Disclaimer I chose NOT to remove numbers as they might be very important when it comes to how many ml or how many pieces are in the package of a product. Create Custom Plot for W B Wordcloud 3. log the plot Get bag of words from pos column Plot Make a custom plot to save into W B Prepare data Create Table. Below you can see an example of an image and 11 different applied augmentations. 17 Libraries Enable progress tracking Environment check Secrets Color scheme Read in data Log into W B Get the count of apparitions per image Make a custom plot to save into W B Prepare data Create Table. com maximvlah came in the comments with the amazing library called pandarallel which enables parallelisation when applying. Clean Duplicates FunctionHence we ll clean these duplicates by selecting only the first appearence for each. But Maxim Vlah https www. crops center crop random crop etc. ai Input your personal key of the project mine will be secret as it is confidential You can find my project in the W B Dashboard by clicking here https wandb. apply function in pandas. ", "id": "andradaolteanu/i-shopee-text-prep-fe-image-augmentation", "size": "6950", "language": "python", "html_url": "https://www.kaggle.com/code/andradaolteanu/i-shopee-text-prep-fe-image-augmentation", "git_url": "https://www.kaggle.com/code/andradaolteanu/i-shopee-text-prep-fe-image-augmentation", "script": "show_values_on_bars albumentations HueSaturationValue stopwords WordNetLemmatizer UserSecretsClient preprocess_df TextBlob TfidfVectorizer PorterStemmer extract_title_features _show_on_single_plot seaborn numpy sklearn.feature_extraction.text HorizontalFlip get_POS color display_augmentations PIL RGBShift clean_duplicates textblob preprocess_title get_group_info CountVectorizer get_image_info Image matplotlib.pyplot WordCloud pandas word_tokenize wordcloud nltk.stem STOPWORDS get_embeddings pos_tag pandarallel nltk.tokenize nltk.corpus albumentations.augmentations.transforms ne_chunk STOPWORDS as stopwords_wc ImageColorGenerator kaggle_secrets nltk ", "entities": "(('we', 'it'), 'step') (('You', 'https here github'), 'check') (('images', 'same product'), 'build') (('You', 'https here wandb'), 'be') (('they', 'color attributes'), 'rotation') (('here https', '5 albumentations'), 'find') (('Below you', 'image'), 'see') (('wrap', 'https here www'), 'Let') (('count', 'W B Prepare data Create Table'), 'log') (('s', 'newly created title_prep'), 'let') (('how many pieces', 'product'), 'choose') (('however overall structure', 'images'), 'be') (('Clean FunctionHence we', 'each'), 'Duplicates') (('G4 GB Memory NVIDIA Workstation 2 CPUs 96 Quadro', 'machine local Z8'), 'training') (('these', 'Label Group 2 2 same label_group'), 'Note') (('Data Images', 'product files 32 400 train'), 'train') (('which', 'parallelisation'), 'come') (('we', 'ML as well model'), 'need') (('We', 'competition'), 'remember') (('we', 'submission also notebook'), 'need') (('Text Preprocessing Function function', 'Kaggle environment'), 'Note') (('Create Text TF IDF CountVectorizer 4 now embeddings', 'training above dataframe'), 'append') (('title texts', '1 to 2 numerics'), 'be') (('best performing augmentations', 'problem'), 'note') (('we', 'training original dataset'), 'note') (('that', 'identical products'), 'csv') (('model', 'better unique patterns'), 'be') (('that', 'instances'), '1') (('Plot', 'W B Prepare data Create Table'), 'log') (('POS Extract title features', 'title Test'), 'update') (('that', 'process necessary metadata pipeline'), 'be') (('Read', 'W B Prepare data Create Table'), 'Enable') (('numbers', 'prediction'), 'think') (('Now same function', '8 about 9 minutes'), 'take') (('test product photos', '70 000 hidden files'), 'test_images') (('Text ExtractionAnother 2 method', 'more useful information'), 'Features') (('this', 'library'), 'note') (('You', 'article https towardsdatascience'), 'check') ", "extra": "['test', 'bag']", "label": "Perfect_files", "potential_description_queries": ["account", "api", "append", "apply", "area", "article", "artifact", "augmentation", "average", "background", "bag", "basic", "best", "bit", "case", "category", "center", "check", "clean", "color", "column", "contain", "correct", "count", "create", "crop", "csv", "custom", "cv2", "data", "dataframe", "default", "description", "display", "en", "end", "explore", "extract", "eye", "feed", "final", "find", "flip", "function", "green", "group", "human", "image", "info", "io", "kaggle", "key", "length", "let", "library", "list", "little", "local", "log", "look", "lower", "metadata", "method", "might", "ml", "model", "most", "my", "name", "near", "need", "next", "not", "notebook", "object", "order", "out", "overall", "package", "pandarallel", "part", "per", "performing", "person", "plot", "prediction", "prepare", "preprocessing", "present", "print", "problem", "product", "project", "punctuation", "pytorch", "random", "re", "reason", "remove", "research", "sample", "save", "score", "secret", "sentence", "step", "structure", "submission", "support", "test", "text", "title", "train", "train_images", "training", "type", "unique", "up", "update", "user", "variable", "version", "vertical", "visualize", "who", "word"], "potential_description_queries_len": 126, "potential_script_queries": ["nltk", "numpy", "seaborn"], "potential_script_queries_len": 3, "potential_entities_queries": ["local", "overall", "product", "unique"], "potential_entities_queries_len": 4, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 127}
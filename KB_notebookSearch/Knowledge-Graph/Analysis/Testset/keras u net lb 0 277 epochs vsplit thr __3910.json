{"name": "keras u net lb 0 277 epochs vsplit thr ", "full_name": " h1 Intro h1 Get the data h1 Create our Keras metric h1 Build and train our neural network h1 Make predictions h1 Encode and submit our results ", "stargazers_count": 0, "forks_count": 0, "description": "png Next we fit the model on the training data using a validation split of 0. I ll just train for 10 epochs which takes around 10 minutes in the Kaggle kernel with the current parameters. Seems good Create our Keras metricNow we try to define the mean average precision at different intersection over union IoU thresholds metric in Keras. Build and train our neural networkNext we build our U Net model loosely based on U Net Convolutional Networks for Biomedical Image Segmentation https arxiv. I downsample both the training and test images to keep things light and manageable but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run length encodings later on. It also seems to just increase over time no matter what when you train. com rakhlin fast run length encoding python excellent implementation of run length encoding. All right looks good Loss seems to be a bit erratic though. How about the validation data Not too shabby Definitely needs some more training and tweaking. TensorFlow has a mean IoU metric but it doesn t have any native support for the mean over multiple thresholds so I tried to implement this. and then finally create our submission This scored 0. Remember to load the best saved model if you ve used early stopping and checkpointing. IntroHello This rather quick and dirty kernel shows how to get started on segmenting nuclei using a neural network in Keras. I believe they also have a tendency to work quite well even on small datasets. The model is at least able to fit to the training data Certainly a lot of room for improvement even here but a decent start. pdf and very similar to this repo https github. I ll leave it to you to improve the model architecture and parameters Make predictionsLet s make predictions both on the test set the val set and the train set as a sanity check. 277 LB Set some parameters original seed 42 Get train and test IDs Get and resize train images and masks Get and resize test images Check if training data looks all right Define IoU metric Build U Net model Fit model setup fitting Predict on train val and test Threshold predictions Create list of upsampled test masks Perform a sanity check on some random training samples Perform a sanity check on some random validation samples Run length encoding stolen from https www. We use a small batch size because we have so little data. Encode and submit our resultsNow it s time to submit our results. That was with version 2 of this notebook be aware that the results from the neural network are extremely erratic and vary greatly from run to run version 3 is significantly worse for example. Let s iterate over the test IDs and generate run length encodings for each seperate mask identified by skimage. 04597 which is very common for image segmentation problems such as this. I ve stolen this https www. com rakhlin fast run length encoding python Create submission DataFrame. 277 You should easily be able to stabilize and improve the results just by changing a few parameters tweaking the architecture a little bit and training longer with early stopping. There are definitely better ways to handle this but it works fine for now Let s see if things look all right by drawing some random images and their associated masks. Let s get started importing everything we need Get the dataLet s first import all the images and associated masks. com jocicmarko ultrasound nerve segmentation from the Kaggle Ultrasound Nerve Segmentation competition. Update Added early stopping and checkpointing and increased to 30 epochs. I m by no means certain that this implementation is correct though Any assistance in verifying this would be most welcome Update This implementation is most definitely not correct due to the very large discrepancy between the results reported here and the LB results. The architecture used is the so called U Net https arxiv. I recommend using checkpointing and early stopping when training your model. de people ronneber u net u net architecture. Have fun LB score history Version 7 0. I won t do it here to make things a bit more reproducible although it s very likely that your results will be different anyway. ", "id": "del=cca345899d608f0a/keras-u-net-lb-0-277-epochs-vsplit-thr", "size": "3910", "language": "python", "html_url": "https://www.kaggle.com/code/del=cca345899d608f0a/keras-u-net-lb-0-277-epochs-vsplit-thr", "git_url": "https://www.kaggle.com/code/del=cca345899d608f0a/keras-u-net-lb-0-277-epochs-vsplit-thr", "script": "skimage.transform keras.layers keras.callbacks keras.layers.core mean_iou EarlyStopping chain skimage.morphology itertools imread Conv2D numpy Input imread_collection Conv2DTranspose ModelCheckpoint keras.layers.convolutional matplotlib.pyplot label tensorflow pandas Lambda resize tqdm imshow load_model rle_encoding Model concatenate MaxPooling2D prob_to_rles backend backend as K keras.layers.pooling keras concatenate_images keras.models keras.layers.merge skimage.io ", "entities": "(('Update', '30 epochs'), 'add') (('you', 'early stopping'), 'remember') (('so I', 'this'), 'have') (('model', 'improvement'), 'be') (('rather quick kernel', 'Keras'), 'show') (('Threshold predictions', 'https www'), 'Set') (('s', 'skimage'), 'let') (('we', 'metric Keras'), 'seem') (('com rakhlin', 'length encoding python Create submission fast DataFrame'), 'run') (('it', 'results'), 'Encode') (('dataLet', 'first images'), 'let') (('too shabby', 'Definitely more training'), 'about') (('we', 'Biomedical Image Segmentation https arxiv'), 'build') (('I', 'early when model'), 'recommend') (('com rakhlin', 'length run encoding'), 'run') (('This', '0'), 'create') (('de people', 'u net u net architecture'), 'ronneber') (('we', 'so little data'), 'use') (('things', 'all random images'), 'be') (('we', 'length correct run encodings'), 'downsample') (('train', 'sanity check'), 'leave') (('which', 'such this'), '04597') (('most implementation', 'results'), 'm') (('they', 'quite well even small datasets'), 'believe') (('results', '3 significantly example'), 'be') (('very results', 'it'), 'win') (('when you', 'matter what'), 'seem') (('Next we', '0'), 'png') (('You', 'little bit longer early stopping'), '277') (('which', 'current parameters'), 'train') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["architecture", "associated", "average", "batch", "best", "bit", "build", "check", "correct", "create", "current", "data", "define", "downsample", "encoding", "even", "everything", "fit", "fitting", "fun", "generate", "handle", "history", "image", "implement", "implementation", "import", "improve", "improvement", "increase", "intersection", "kernel", "least", "leave", "length", "light", "list", "little", "load", "look", "lot", "mask", "mean", "metric", "model", "most", "multiple", "need", "network", "neural", "no", "not", "notebook", "nuclei", "pdf", "people", "png", "precision", "python", "random", "recommend", "record", "resize", "right", "room", "run", "score", "segmentation", "set", "setup", "similar", "size", "split", "submission", "support", "test", "time", "train", "training", "try", "val", "validation", "version", "work"], "potential_description_queries_len": 84, "potential_script_queries": ["backend", "chain", "concatenate", "imread", "imshow", "io", "label", "numpy", "skimage", "tensorflow", "tqdm"], "potential_script_queries_len": 11, "potential_entities_queries": ["correct", "even", "python", "run"], "potential_entities_queries_len": 4, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 94}
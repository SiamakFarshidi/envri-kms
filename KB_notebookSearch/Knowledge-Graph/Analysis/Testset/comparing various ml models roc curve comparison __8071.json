{"name": "comparing various ml models roc curve comparison ", "full_name": " h3 Importing all the libraries h3 Reading the file h3 Let us check if there is any null values h3 Checking the encoded values h3 Plotting boxplot to see the distribution of the data h1 Standardising the data h1 Principal Component Analysis h3 Let us take only first two principal components and visualise it using K means clustering h3 Thus using K means we are able segregate 2 classes well using the first two components with maximum variance h1 Performing PCA by taking 17 components with maximum Variance h3 Splitting the data into training and testing dataset h1 Default Logistic Regression h1 Logistic Regression Tuned model h3 Taking a look at the correlation h1 Gaussian Naive Bayes h1 Support Vector Machine h1 Support Vector Machine without polynomial kernel h1 Support Vector machine with polynomial Kernel h3 Trying default model h3 Thus default Random forest model is giving us best accuracy h3 Let us tuned the parameters of Random Forest just for the purpose of knowledge h3 n jobs h3 Default Decision Tree model h3 Thus default decision tree model is giving us best accuracy score h3 Let us tune the hyperparameters of the Decision tree model h2 Neural Network h3 Applying default Neural Network model h3 Tuning the hyperparameters of the neural network ", "stargazers_count": 0, "forks_count": 0, "description": "If only a subset of features are correlated with the label lasso outperforms ridge as in lasso model some coefficient can be shrunken to zero. 3 log2 It is another option which takes log to the base 2 of the features input. I am going to apply 6 Supervised machine learning models on the given dataset. Let us take only first two principal components and visualise it using K means clustering Thus using K means we are able segregate 2 classes well using the first two components with maximum variance. Thus we perform label encoding on the data. 0001 4 max_iter Maximum number of iterations. 1 Auto This will simply take all the features which make sense in every tree. B n_estimators This is the number of trees you want to build before taking the maximum voting or averages of predictions. The C parameter trades off misclassification of training examples against simplicity of the decision surface. Support Vector machine with polynomial Kernel Trying default model Thus default Random forest model is giving us best accuracy. all rows all the features and no labels all rows label only Scale the data to be between 1 and 1 This will give you positive class prediction probabilities This will threshold the probabilities to give class predictions. This will give you positive class prediction probabilities This will threshold the probabilities to give class predictions. Gaussian Naive Bayes Support Vector MachineThe gamma parameter defines how far the influence of a single training example reaches with low values meaning far and high values meaning close. The GridSearchCV instance implements the usual estimator API when fitting it on a dataset all the possible combinations of parameter values are evaluated and the best combination is retained. default 200 This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. Checking the encoded values Plotting boxplot to see the distribution of the data Separating features and label Standardising the data Note We can avoid PCA here since the dataset is very small. com kaggle docker python For example here s several helpful packages to load in Input data files are available in the. Here we simply do not put any restrictions on the individual tree. The 1st 17 components retains more than 90 of the data. We need to convert all the unique values to integers. Either the mushroom is poisonous or edible Thus we have 22 features 1st one is label and 8124 instances. But it is proving computationally expensive here. The details of Gini and entropy needs detail explanation. 2 sqrt This option will take square root of the total number of features in individual run. For instance if the total number of variables are 100 we can only take 10 of them in individual tree. A smaller leaf makes the model more prone to capturing noise in train data. L1 is the first moment norm x1 x2 w for regularization case that is simply the absolute d\u0131stance between two points where L2 is second moment norm corresponding to Eucledian Distance that is x1 x2 2 w 2 for regularization case. Principal Component Analysis We can see that the last 4 components has less amount of variance of the data. 2 Adding parameters that do not influence the performance does not decrease efficiency. Higher number of trees give you better performance but makes your code slower. This has two main benefits over an exhaustive search 1 A budget can be chosen independent of the number of parameters and possible values. The strategy is to apply default model first with no tuning of the hyperparameter and then tuned them with different hyperparameter values and then I ll plot ROC curve to select the best machine learning model. Default Decision Tree model Thus default decision tree model is giving us best accuracy score Let us tune the hyperparameters of the Decision tree model 1 Criterion Decision trees use multiple algorithms to decide to split a node in two or more sub nodes. Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub nodes. Both L1 and L2 regularization prevents overfitting by shrinking imposing a penalty on the coefficients. Also any suggestion to improvise it is welcome. If all the features are correlated with the label ridge outperforms lasso as the coefficients are never zero in ridge. max_features and min_samples_leaf is same as Random Forest classifier Neural Network Applying default Neural Network model Tuning the hyperparameters of the neural networkIt is turning out to be computationally expensive for me with tuned model. 1 hidden_layer_sizes Number of hidden layers in the network. A low C makes the decision surface smooth while a high C aims at classifying all training examples correctly by giving the model freedom to select more samples as support vectors. C relu the rectified linear unit function returns f x max 0 x 3 alpha L2 penalty regularization term parameter. The models used are as follows 1 Principal Component Analysis 2 Logistic Regression 3 Gaussian Naive Bayes 4 Support Vector Machine 5 Random Forest Classifier 6 Decision trees 7 Simple neural network Importing all the libraries Reading the file Let us check if there is any null values Thus we have two claasification. Taking a look at the correlation The grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the tuned_parameter. Let us tuned the parameters of Random Forest just for the purpose of knowledge There are 3 features which can be tuned to improve the performance of Random Forest 1 max_features 2 n_estimators 3 min_sample_leaf A max_features These are the maximum number of features Random Forest is allowed to try in individual tree. But for sure you decrease the speed of algorithm by increasing the max_features. You should choose as high value as your processor can handle because this makes your predictions stronger and more stable. They re used to avoid overfiting. C min_sample_leaf Leaf is the end node of a decision tree. A value of 1 means there is no restriction whereas a value of 1 means it can only use one processor. 2 max_depth Maximum depth of tree vertical depth Used to control over fitting as higher depth will allow model to learn relations very specific to a particular sample. Large number may overfit the data. 2 activation Activation function for the hidden layer. RandomizedSearchCV implements a randomized search over parameters where each setting is sampled from a distribution over possible parameter values. The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors. degree 2 3 4 5 6 C 1 10 100 500 1000 kernel poly tuned_parameters min_samples_leaf range 5 10 5 n_estimators range 50 200 50 max_depth range 5 15 5 max_features range 5 20 5 This will give you positive class prediction probabilities This will threshold the probabilities to give class predictions. Support Vector Machine without polynomial kernelThe grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the tuned_parameter. A logistic the logistic sigmoid function returns f x 1 1 exp x. The solver iterates until convergence determined by tol or this number of iterations. Hence I am not running this. We can see that the dataset has values in strings. In simple words L2 Ridge shrinks all the coefficient by the same proportions but eliminates none while L1 Lasso can shrink some coefficients to zero performing variable selection. Now let us check which features constitutes maximum information. Hence you need to strike the right balance and choose the optimal max_features. n_jobs This parameter tells the engine how many processors is it allowed to use. B tanh the hyperbolic tan function returns f x tanh x. Increasing max_features generally improves the performance of the model as at each node now we have a higher number of options to be considered. Hence it is important to try different values to get good estimate. Performing PCA by taking 17 components with maximum Variance Splitting the data into training and testing dataset Default Logistic Regression Logistic Regression Tuned model L1 and L2 are regularization parameters. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. So I am opting for RandomizedSearchCV. ", "id": "nirajvermafcb/comparing-various-ml-models-roc-curve-comparison", "size": "8071", "language": "python", "html_url": "https://www.kaggle.com/code/nirajvermafcb/comparing-various-ml-models-roc-curve-comparison", "git_url": "https://www.kaggle.com/code/nirajvermafcb/comparing-various-ml-models-roc-curve-comparison", "script": "sklearn.metrics PCA cross_val_score sklearn.naive_bayes sklearn.tree sklearn.cluster KMeans pyplot as plt sklearn.neural_network DecisionTreeClassifier pyplot numpy seaborn auc sklearn.grid_search sklearn.decomposition sklearn.ensemble sklearn.model_selection sklearn metrics LabelEncoder RandomForestClassifier matplotlib.pyplot pandas subprocess StandardScaler LogisticRegression check_output GridSearchCV SVC sklearn.linear_model matplotlib sklearn.preprocessing roc_curve GaussianNB sklearn.svm RandomizedSearchCV MLPClassifier train_test_split ", "entities": "(('which', 'maximum information'), 'let') (('Support Vector Machine', 'tuned_parameter'), 'generate') (('far values', 'low values'), 'define') (('coefficients', 'ridge'), 'correlate') (('C min_sample_leaf Leaf', 'end decision tree'), 'be') (('details', 'detail explanation'), 'need') (('where setting', 'parameter possible values'), 'search') (('This', 'class predictions'), 'degree') (('sigmoid logistic function', 'f 1 exp 1 x.'), 'return') (('now we', 'options'), 'have') (('I', 'given dataset'), 'go') (('sure you', 'max_features'), 'decrease') (('best combination', 'parameter values'), 'implement') (('then I', 'machine learning best model'), 'be') (('us', 'sub two nodes'), 'model') (('This', 'class predictions'), 'give') (('one', 'features 22 1st'), 'be') (('2 option', 'individual run'), 'sqrt') (('1st 17 components', 'data'), 'retain') (('null Thus we', 'two claasification'), 'be') (('it', 'only one processor'), 'value') (('Thus we', 'data'), 'perform') (('it', 'how many processors'), 'tell') (('model', 'train data'), 'make') (('Here we', 'individual tree'), 'put') (('We', 'integers'), 'need') (('last 4 components', 'data'), 'Analysis') (('Hence you', 'optimal max_features'), 'need') (('gamma parameters', 'support vectors'), 'see') (('which', '2 features'), 'log2') (('we', 'individual tree'), 'take') (('This', 'class predictions'), 'row') (('Used', 'very specific particular sample'), '2') (('Hence it', 'good estimate'), 'be') (('which', 'sub most homogeneous nodes'), 'split') (('high C', 'support vectors'), 'make') (('you', 'output'), 'list') (('dataset', 'strings'), 'see') (('relu', 'linear unit function f alpha L2 penalty regularization term rectified max 0 3 parameter'), 'return') (('C parameter', 'decision surface'), 'trade') (('networkIt', 'tuned model'), 'be') (('L1 Lasso', 'zero performing variable selection'), 'coefficient') (('that', 'x1 regularization 2 2 case'), 'be') (('that', 'efficiency'), 'decrease') (('Also suggestion', 'it'), 'be') (('we', 'maximum variance'), 'let') (('predictions', 'high value'), 'choose') (('which', 'tree'), '1') (('grid search', 'tuned_parameter'), 'take') (('here dataset', 'PCA'), 'check') (('1 budget', 'parameters'), 'have') (('Thus default Random forest model', 'best accuracy'), 'machine') (('solver', 'iterations'), 'iterate') (('code', 'better performance'), 'give') (('Default Logistic Regression Logistic model Tuned L1', 'training'), 'perform') (('are', 'individual tree'), 'let') (('tan hyperbolic function', 'f tanh x.'), 'return') (('coefficient', 'zero'), 'shrink') (('you', 'predictions'), 'n_estimators') (('It', 'python docker image https kaggle github'), 'default') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["absolute", "accuracy", "algorithm", "apply", "balance", "best", "boxplot", "build", "case", "check", "choose", "classifier", "clustering", "code", "coefficient", "control", "convergence", "convert", "correlation", "current", "curve", "data", "dataset", "decision", "default", "degree", "depth", "detail", "directory", "distribution", "encoding", "end", "entropy", "environment", "estimator", "every", "exp", "file", "fitting", "forest", "freedom", "function", "gamma", "grid", "handle", "high", "hyperparameter", "image", "improve", "individual", "influence", "input", "instance", "kaggle", "kernel", "knowledge", "label", "leaf", "learn", "learning", "let", "linear", "list", "load", "log", "look", "main", "max", "max_depth", "max_features", "max_iter", "maximum", "meaning", "model", "moment", "most", "multiple", "need", "network", "neural", "no", "node", "noise", "none", "norm", "not", "null", "number", "option", "out", "overfit", "overfitting", "parameter", "perform", "performance", "performing", "plot", "poly", "positive", "prediction", "principal", "purpose", "python", "range", "re", "regularization", "right", "run", "running", "score", "search", "second", "select", "selected", "sense", "several", "sigmoid", "simplicity", "single", "smooth", "speed", "split", "sqrt", "square", "strategy", "sub", "subset", "support", "surface", "tanh", "term", "testing", "threshold", "total", "train", "training", "tree", "try", "tune", "tuning", "unique", "unit", "until", "value", "variable", "variance", "vertical", "visualise", "while", "write"], "potential_description_queries_len": 150, "potential_script_queries": ["auc", "matplotlib", "numpy", "plt", "pyplot", "seaborn", "sklearn"], "potential_script_queries_len": 7, "potential_entities_queries": ["decision", "exp", "function", "kaggle", "max", "most", "regularization", "term", "variable"], "potential_entities_queries_len": 9, "potential_extra_queries": ["test"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 158}
{"name": "predicting chest x ray pathologies ", "full_name": " h1 Dataset h1 Showing some sample images h1 class labels distributions ", "stargazers_count": 0, "forks_count": 0, "description": "com kaggle docker python For example here s several helpful packages to load linear algebra data processing CSV file I O e. set_title l drop unused columns create new columns for each decease remove Y after age remove Y after age with multiple pathologies without with single pathologies 7 images as arrays labels Read and resize image Reduce Sample Size for DeBugging Encode labels to hot vectors ex 2 0 0 1 0 0 0 0 0 0 0 Helper Functions Learning Curves and Confusion Matrix try to add loss to see the loss learning curve summarize history for loss In Conv2D relu 2 MaxPool2D Dropout 2 Flatten Dense Dropout Out Define the optimizer set input mean to 0 over the dataset set each sample mean to 0 divide inputs by std of the dataset divide each input by its std apply ZCA whitening randomly rotate images in the range degrees 0 to 180 randomly shift images horizontally fraction of total width randomly shift images vertically fraction of total height randomly flip images randomly flip images Add a new top layer This is the model we will train First train only the top layers which were randomly initialized. Dataset Showing some sample images class labels distributions This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python Docker image https github. read_csv Input data files are available in the read only. walk kaggle input for filename in filenames print os. join dirname filename You can write up to 5GB to the current directory kaggle working that gets preserved as output when you create a version using Save Run All You can also write temporary files to kaggle temp but they won t be saved outside of the current session. input directory For example running this by clicking run or pressing Shift Enter will list all files under the input directory for dirname _ filenames in os. ", "id": "ashery/predicting-chest-x-ray-pathologies", "size": "77", "language": "python", "html_url": "https://www.kaggle.com/code/ashery/predicting-chest-x-ray-pathologies", "git_url": "https://www.kaggle.com/code/ashery/predicting-chest-x-ray-pathologies", "script": "Flatten sklearn.utils __init__ tensorflow.keras.utils MetricsCheckpoint(Callback) runCNNconfusion tensorflow.keras.optimizers tensorflow.keras.layers VGG16 tensorflow.keras.preprocessing.image tensorflow.keras.callbacks EarlyStopping Dropout Sequential MaxPool2D plot_learning_curve tensorflow.keras.models on_epoch_end Conv2D Adagrad seaborn numpy plot_confusion_matrix gridspec ReduceLROnPlateau class_weight ModelCheckpoint sklearn.model_selection ImageDataGenerator matplotlib.pyplot Dense tensorflow pandas proc_images to_categorical vgg16network BatchNormalization Callback plotKerasLearningCurve tensorflow.keras.applications.vgg16 Model matplotlib train_test_split ", "entities": "(('It', 'kaggle python Docker image https github'), 'come') (('t', 'outside current session'), 'join') (('input directory', 'os'), 'list') (('read_csv Input data files', 'read'), 'be') (('which', 'First only top layers'), 'create') ", "extra": "", "label": "No_extra_files", "potential_description_queries": ["age", "apply", "create", "current", "curve", "data", "dataset", "directory", "drop", "environment", "ex", "file", "filename", "flip", "height", "history", "hot", "image", "input", "join", "kaggle", "layer", "learning", "linear", "list", "load", "mean", "model", "multiple", "new", "optimizer", "output", "print", "processing", "python", "range", "read", "remove", "resize", "rotate", "run", "running", "sample", "set", "several", "shift", "single", "std", "summarize", "total", "train", "try", "under", "up", "version", "walk", "width", "write"], "potential_description_queries_len": 58, "potential_script_queries": ["gridspec", "matplotlib", "numpy", "preprocessing", "seaborn", "tensorflow"], "potential_script_queries_len": 6, "potential_entities_queries": ["data", "python"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 64}
{"name": "applied machine learning ", "full_name": " h1 For learning Data Visualizaiton and NLP do check following notebooks h1 Data Visualization h1 Table of Content h1 Machine Learning h1 Supervised Machine Learning h1 Unsupervised Machine Learning h1 Reinforcement Machine Learning h1 Application of Supervised Machine Learning h1 Application of Unsupervised Machine Learning h1 Application of Reinforcement Machine Learning h1 We can apply machine learning model by following six steps h1 Factors help to choose algorithm h1 Linear Regression h1 TheilSen Regressor h1 RANSAC Regressor h1 Huber Regressor h1 Logistic Regression h1 Gaussian Process Classifier h1 Support Vector Machine h1 Nu Support Vector Classification h1 Naive Bayes Algorithm h1 KNN h1 Perceptron h1 Random Forest h1 Decision Tree h1 Extra Tree h1 AdaBoost Classifier h1 Passive Aggressive Classifier h1 Bagging Classifier h1 Gradient Boosting h1 Light GBM h1 XGBoost h1 Catboost h1 Stochastic Gradient Descent h1 Lasso h1 Ridge Classifier CV h1 Kernel Ridge Regression h1 BayesianRidge h1 Elastic Net Regression h1 LDA h1 K Means Algorithm h1 CNN h1 LSTM h1 Principle Component Analysis h1 Apriori h1 Prophet h1 Arima h1 Evaluate Algorithms h1 If you like this notebook do hit upvote h1 Thanks ", "stargazers_count": 0, "forks_count": 0, "description": "These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables. Application of Machine Learning3. Library and Data Preprocessing Model and Accuracy XGBoost XGBoost is a decision tree based ensemble Machine Learning algorithm that uses a gradient boosting framework. It is mainly used for sorting large amounts of data. However the machines must first be programmed to learn from data. Itis used in statistics pattern recognition and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events. Pattern recognition Application of Unsupervised Machine Learning 1. Machine Learning and Types2. Unsupervised learning problems can be further grouped into clustering and association problems. Database marketing 4. Libraries and Data Model and Accuracy Gaussian NB BernoulliNB KNN KNN does not learn any model. 2 Select k points at random as cluster centers. Libraries and Data Model and Accuracy Decision Tree Decision tree algorithm is classification algorithm under supervised machine learning and it is simple to understand and use in data. What s neat here is that you can inspect the dataframe and see the predictions as well as the lower and upper boundaries of the uncertainty interval. It extracts low dimensional set of features from a high dimensional data set with a motive to capture as much information as possible and to visualise high dimensional data it also reduces noise and finally makes other algorithms to work better because we are injecting fewer inputs. Social Network Analysis to define groups of friends. Time of predicting Linear Regression It is a basic and commonly used type of predictive analysis. 097 Library and Data Model with plots and accuracy TheilSen Regressor RANSAC Regressor Huber Regressor Logistic Regression It s a classification algorithm that is used where the response variable is categorical. It is capable of learning order dependence LSTM can be used for machine translation speech recognition and more. This algorithm consist of a target outcome variable or dependent variable which is to be predicted from a given set of predictors independent variables. Y a bX where Y Dependent Variable a intercept X Independent variable b Slope Example University GPA 0. It differs from standard supervised learning in that correct input output pairs need not be presented and sub optimal actions need not be explicitly corrected. Simple reward feedback is required for the agent to learn its behaviour this is known as the reinforcement signal. Interpret and report results If you like this notebook do hit upvote Thanks Data is used the same as LGB Data is used the same as LGB Data is used the same as LGB Data is used the same as LGB Data is used the same as LGB Data is used the same as LGB Data is used the same as LGB Data is used the same as LGB increse to epochs to 30 for better accuracy project data. Example Suppose we have a bowl of 100 unique numbers from 0 to 99. Supervised Machine Learning 2. Traffic Light Control 3. Object recognition in computer vision 9. Reinforcement Machine Learning Supervised Machine Learning It is a type of learning in which both input and desired output data are provided. So first let s convert the dataframe to the appropriate format. Evaluate Algorithm 5. SVM supports both regression and classification tasks and can handle multiple continuous and categorical variables Example One class is linearly separable from the others like if we only had two features like Height and Hair length of an individual we d first plot these two variables in two dimensional space where each point has two co ordinates Libraries and Data Model and Accuracy Nu Support Vector Classification Library and Data Model and Accuracy Naive Bayes Algorithm A naive Bayes classifier is not a single algorithm but a family of machine learning algorithms which use probability theory to classify data with an assumption of independence between predictors It is easy to build and particularly useful for very large data sets. Library and Data Model and Forecast Arima Library and Data Model Prediction Evaluate Algorithms The evaluation of algorithm consist three following steps 1. and stores the entire training data set which it uses as its representation. The model fits a Gaussian density to each class assuming that all classes share the same covariance matrix. Factors help to choose algorithm5. Library and Data Model and Accuracy K Means Algorithm K means clustering is a type of unsupervised learning which is used when you have unlabeled data and the goal of this algorithm is to find groups in the data Steps to use this algorithm 1 Clusters the data into k groups where k is predefined. Make sure you handle missing data well before you proceed with the implementation. Instead the focus is on performance which involves finding a balance between exploration of uncharted territory and exploitation of current knowledge Application of Supervised Machine Learning 1. 3 Assign objects to their closest cluster center according to the Euclidean distance function. If we put the number back in the bowl it may be selected more than once. Information extraction 8. Examples Behavioral segmentation like segment by purchase history or by activities on application website or platform Separate valid activity groups from bots Libraries and Data Checking for number of clusters Fitting Model Plotting Clusters CNN Library and Data Preprocessing and Data Split Model Compiling model LSTM LSTM blocks are part of a recurrent neural network structure. Application of Reinforcement Machine Learning 1. Deep Learning We can apply machine learning model by following six steps 1. Web System Configuration 5. It is a perfect combination of software and hardware optimization techniques to yield superior results using less computing resources in the shortest amount of time. This is suitable for smaller dataset less than 100 samples Library and Data Model and Accuracy BayesianRidge Bayesian regression is a regression model defined in probabilistic terms with explicit priors on the parameters. odds p x 1 p x probability of event occurrence probability of not event occurrence Example When we have to predict if a student passes or fails in an exam when the number of hours spent studying is given as a feature the response variable has two values pass and fail. The idea of Logistic Regression is to find a relationship between features and probability of particular outcome. Call predict to make a prediction and store it in the forecast dataframe. Algorithm Linear Regression TheilSenRegressor RANSAC Regressor HuberRegressor Logistic Regression GaussianProcessClassifier Support Vector Machine Nu Support Vector Classification Naive Bayes Algorithm KNN Perceptron Random Forest Decision Tree Extra Tree AdaBoost Classifier PassiveAggressiveClassifier Bagging Classifier Gradient Boosting Light GBM XGBoost Catboost Stochastic Gradient Descent Lasso RidgeC lassifier CV Kernel Ridge Regression Bayesian Ridge Elastic Net Regression LDA K Means Algorithm CNN LSTM PCA Apriori Prophet ARIMA6. hough using the whole dataset is really useful for getting to the minima in a less noisy or less random manner but the problem arises when our datasets get really huge and for that SGD come in action Library and Data Model and Accuracy Lasso In statistics and machine learning lasso least absolute shrinkage and selection operator also Lasso or LASSO is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces. The training process continues until the model achieves a desired level of accuracy on the training data. Market Segmentation of companies by location industry vertical. The main idea behind unsupervised learning is to expose the machines to large volumes of varied data and allow it to learn and infer from the data. Unsupervised Machine Learning Unsupervised learning is the training of an algorithm using information that is neither classified nor labeled and allowing the algorithm to act on that information without guidance. We want to select a random sample of numbers from the bowl. Then specify the number of days to forecast using the periods parameter. In prediction problems involving unstructured data images text etc. Quantitative structure 3. Bayesian approach is a general way of defining and estimating statistical models that can be applied to different models. Each instance in essence votes for their class and the class with the most votes is taken as the prediction Example Should the bank give a loan to an individual Would an individual default on his or her loan Is that person closer in characteristics to people who defaulted or did not default on their loans Libraries and Data As Classifier Model and Accuracy As Regression Library and Data Model and Accuracy Perceptron It is single layer neural network and used for classification Random Forest Random forest is collection of tress forest and it builds multiple decision trees and merges them together to get a more accurate and stable prediction. It combines feature elimination from Lasso and feature coefficient reduction from the Ridge model to improve your model s predictions. Example To analyse data for frequent if then patterns and using the criteria support and confidence to identify the most important relationships. Information retrieval 6. com vanshjatana data visualization NLP https www. Evaluate Algorithms Machine Learning Machine Learning is the science of getting computers to learn and act like humans do and improve their learning over time in autonomous fashion by feeding them data and information in the form of observations and real world interactions. Personalized Recommendations 6. Clustering A clustering problem is where you want to discover the inherent groupings in the data such as grouping customers by purchasing behaviour. Handwriting recognition 5. Capable of handling large scale data. Steps of Machine Learning4. For learning Data Visualizaiton and NLP do check following notebooks Data Visualization https www. Reinforcement Machine Learning Reinforcement Learning is a type of Machine Learning which allows machines to automatically determine the ideal behaviour within a specific context in order to maximize its performance. Create an instance of the Prophet class and then fit our dataframe to it. A spam filter looks at email messages for certain key words and puts them in a spam folder if they match. artificial neural networks tend to outperform all other algorithms or frameworks. It can be used for both classification and regression problems. Library and Data Model and Accuracy LDA A classifier with a linear decision boundary generated by fitting class conditional densities to the data and using Bayes rule. Faster training speed and higher efficiency. Library and Data Model and Accuracy Catboost Catboost is a type of gradient boosting algorithms which can automatically deal with categorical variables without showing the type conversion error which helps you to focus on tuning your model better rather than sorting out trivial errors. com vanshjatana text classification Table of Content1. It is primarily a classier method that performs classification tasks by constructing hyperplanes in a multidimensional space that separates cases of different class labels. Create a dataframe with the dates for which we want a prediction to be made with make_future_dataframe. Using these set of variables we generate a function that map inputs to desired outputs. Library and Data Model and Accuracy Elastic Net Regression Elastic net is a hybrid of ridge regression and lasso regularization. It is designed to be distributed and efficient with the following advantages 1. Resources management in computer clusters 2. The resulting combination may be used as a linear classifier or more commonly for dimensionality reduction before later classification. Though originally defined for least squares lasso regularization is easily extended to a wide variety of statistical models including generalized linear models generalized estimating equations proportional hazards models and M estimators in a straightforward fashion Library and Data Model and Accuracy Ridge Classifier CV Library and Data Model and Accuracy Kernel Ridge Regression KRR combine Ridge regression and classification with the kernel trick. Sorting data often occurs because of association rules. Human Behaviour Analysis 2. Library and Data Model and Accuracy Stochastic Gradient Descent Stochastic means random so in Stochastic Gradient Descent dataset sample is choosedn random instead of the whole dataset. In this new tree is boosted over the previous tree Libraries and Data Model and Accuracy Light GBM LightGBM is a gradient boosting framework that uses tree based learning algorithms. Libraries and data Model and Accuracy Confusion Matrix Report Gaussian Process Classifier Support Vector Machine Support Vector Machines are perhaps one of the most popular and talked about machine learning algorithms. Organizing computing clusters based on similar event patterns and processes. Present Results Factors help to choose algorithm 1. The choice of priors can have the regularizing effect. Recurrent neural networks are made to utilize certain types of artificial memory processes that can help these artificial intelligence programs to more effectively imitate human thought. Problem Definition 2. Association An association rule learning problem is where you want to discover rules that describe large portions of your data such as people that buy X also tend to buy Y. ProphetProphet is an extremely easy tool for analysts to produce reliable forecasts1. Overfitting tendency 5. Example When we have to bring out strong patterns in a data set or to make data easy to explore and visualize Apriori It is a categorisation algorithm attempts to operate on database records particularly transactional records or records including certain numbers of fields or items. Library and Data Preprocessing Model Compiling Model Prediction and Accuracy Principle Component Analysis It s an important method for dimension reduction. Unsupervised Machine Learning 3. Along with simplicity Naive Bayes is known to outperform even highly sophisticated classification methods Example Emails are given and we have to find the spam emails from that. 4 Calculate the centroid or mean of all objects in each cluster. 675 High School GPA 1. The idea of Decision tree is to split the big data root into smaller leaves Extra Tree Library and Data Model and Accuracy AdaBoost Classifier Library and Data Model and Accutacy Passive Aggressive Classifier Library and Data Model and Accuracy Bagging Classifier Library and Data Model and Accuracy Gradient Boosting Gradient boosting is an alogithm under supervised machine learning boosting means converting weak into strong. It is similar to Support vector Regression but relatively very fast. There are many algorithm for getting machines to learn from using basic decision trees to clustering to layers of artificial neural networks depending on what task you re trying to accomplish and the type and amount of data that you have available. Explore and select algorithms 3. Prophet only takes data as a dataframe with a ds datestamp and y value we want to forecast column. There are three types of machine learning 1. Input and output data are labeled for classification to provide a learning basis for future data processing. Support of parallel and GPU learning. The output can be calculated as the class with the highest frequency from the K most similar instances. Optical character recognition 10. ", "id": "vanshjatana/applied-machine-learning", "size": "16945", "language": "python", "html_url": "https://www.kaggle.com/code/vanshjatana/applied-machine-learning", "git_url": "https://www.kaggle.com/code/vanshjatana/applied-machine-learning", "script": "Flatten sklearn.metrics PCA statsmodels.tsa.arima_model sklearn.gaussian_process Dropout MaxPool2D MinMaxScaler Lasso DecisionTreeClassifier fbprophet pyplot plotly.express RidgeClassifierCV confusion_matrix sklearn.model_selection TransactionEncoder KFold Perceptron classification_report LogisticRegression sklearn.datasets GaussianProcessClassifier sklearn.svm datasets BernoulliNB train_test_split cross_val_score sklearn.naive_bayes sklearn.discriminant_analysis KMeans pyplot as plt apriori KNeighborsClassifier mean_squared_error numpy sklearn.pipeline make_blobs LinearDiscriminantAnalysis BayesianRidge tensorflow pandas NuSVC ElasticNet RobustScaler ARIMA GridSearchCV sklearn.linear_model matplotlib statistics keras.models transform preprocessing tensorflow.keras.utils mlxtend.preprocessing plotly.offline RANSACRegressor BaggingClassifier LassoLarsIC add_changepoints_to_plot sklearn.kernel_ridge r2_score Conv2D make_pipeline ExtraTreesClassifier fbprophet.plot HuberRegressor accuracy_score fit GaussianNB mode TheilSenRegressor SGDRegressor KernelRidge __init__ plot_plotly sklearn.tree keras.layers PassiveAggressiveClassifier lightgbm sklearn.cluster AdaBoostClassifier KNeighborsRegressor Sequential LSTM CatBoostRegressor GradientBoostingClassifier sklearn.ensemble sklearn RandomForestClassifier Dense StandardScaler to_categorical mlxtend.frequent_patterns plot_model sklearn.neighbors SVC sklearn.preprocessing catboost xgboost Prophet LinearRegression ", "entities": "(('well you', 'implementation'), 'make') (('optimal actions', 'input output correct pairs'), 'differ') (('output', 'K'), 'calculate') (('It', 'classification problems'), 'use') (('it', 'data'), 'be') (('choice', 'regularizing effect'), 'have') (('idea', 'particular outcome'), 'be') (('it', 'together more accurate prediction'), 'take') (('it', 'back bowl'), 'select') (('artificial neural networks', 'other algorithms'), 'tend') (('Data Arima Data Model Prediction Evaluate evaluation', 'steps'), 'Library') (('this', 'reinforcement signal'), 'require') (('It', 'machine translation speech LSTM recognition'), 'be') (('it', 'statistical model'), 'be') (('It', 'data'), 'use') (('It', 'data particularly very large sets'), 'support') (('data Confusion Matrix Report Gaussian Process Classifier Support Vector Machine Support Vector Libraries Machines', 'machine learning algorithms'), 'be') (('classes', 'covariance same matrix'), 'fit') (('gradient boosting that', 'learning based algorithms'), 'boost') (('We', 'bowl'), 'want') (('Data Gaussian BernoulliNB KNN KNN', 'model'), 'library') (('we', 'that'), 'know') (('It', 'basic commonly predictive analysis'), 'time') (('Data Accuracy Ridge Classifier CV Data Kernel Ridge Regression KRR', 'kernel trick'), 'extend') (('Y where Dependent', 'variable b Slope Example University intercept X Independent GPA'), 'bx') (('Data Elastic Net Regression Elastic Library net', 'ridge regression'), 'be') (('Deep Learning We', 'six steps'), 'apply') (('LGB same Data', 'accuracy project better data'), 'hit') (('we', '99'), 'Suppose') (('algorithm', 'guidance'), 'be') (('Data Visualizaiton', 'notebooks Data Visualization https www'), 'check') (('you', 'that'), 'be') (('better we', 'fewer inputs'), 'extract') (('resulting combination', 'later classification'), 'use') (('machines', 'performance'), 'be') (('Data Accuracy AdaBoost Classifier Data Passive Aggressive Classifier Data Bagging Classifier Data Gradient Boosting Gradient boosting', 'strong'), 'be') (('two values', 'feature'), 'probability') (('where you', 'behaviour'), 'be') (('Present Results Factors', 'algorithm'), 'help') (('dependent which', 'predictors independent variables'), 'consist') (('response where variable', '097 Library plots'), 'Model') (('output Input data', 'data future processing'), 'label') (('However machines', 'first data'), 'program') (('It', 'predictions'), 'combine') (('that', 'outputs'), 'generate') (('they', 'spam folder'), 'look') (('Call', 'forecast dataframe'), 'predict') (('that', 'different models'), 'be') (('here you', 'uncertainty as well lower interval'), 'be') (('which', 'Machine Supervised Learning'), 'be') (('Fitting Plotting CNN Data Data Split Model Compiling LSTM LSTM blocks', 'network recurrent neural structure'), 'segmentation') (('Preprocessing Compiling Model Principle Component Library Prediction It', 'dimension important reduction'), 'Analysis') (('model', 'training data'), 'continue') (('So first s', 'appropriate format'), 'let') (('it', 'representation'), 'store') (('It', 'fields'), 'example') (('Data BayesianRidge Bayesian regression', 'parameters'), 'be') (('that', 'more effectively human thought'), 'make') (('humans', 'observations'), 'be') (('y we', 'column'), 'take') (('It', 'time'), 'be') (('that', 'also Y.'), 'be') (('where k', 'k groups'), 'Means') (('you', 'better rather trivial errors'), 'Library') (('extremely easy analysts', 'reliable forecasts1'), 'be') (('It', 'following advantages'), 'design') (('Sorting data', 'association often rules'), 'occur') (('output input data', 'which'), 'supervise') (('It', 'Support vector Regression'), 'be') (('sample', 'instead whole dataset'), 'Library') (('that', 'objects'), 'use') (('that', 'boosting gradient framework'), 'be') (('prediction', 'make_future_dataframe'), 'create') (('that', 'class different labels'), 'be') (('learning Unsupervised problems', 'further clustering problems'), 'group') (('Algorithm Linear TheilSenRegressor RANSAC Regressor HuberRegressor Logistic Regression GaussianProcessClassifier Support Vector Nu Support Vector Naive Bayes Algorithm KNN Perceptron Random Forest Decision Tree Extra Tree AdaBoost Classifier PassiveAggressiveClassifier Bagging Classifier Gradient Boosting GBM XGBoost Catboost Stochastic Gradient lassifier CV Kernel Ridge Regression Bayesian Ridge Elastic Net LDA Lasso RidgeC K', 'Algorithm CNN'), 'Regression') (('regression estimates', 'one dependent variable'), 'use') ", "extra": "['biopsy of the greater curvature', 'outcome', 'test', 'bag']", "label": "Perfect_files", "potential_description_queries": ["absolute", "accuracy", "agent", "algorithm", "application", "apply", "approach", "association", "balance", "bank", "basic", "boosting", "boundary", "build", "categorical", "center", "centroid", "character", "check", "choice", "choose", "classification", "classifier", "classify", "cluster", "clustering", "coefficient", "collection", "combine", "computer", "confidence", "context", "conversion", "convert", "correct", "covariance", "criteria", "current", "data", "database", "dataframe", "dataset", "decision", "default", "define", "dependent", "describe", "dimension", "dimensionality", "distance", "distributed", "enhance", "ensemble", "error", "essence", "evaluation", "even", "event", "explore", "extraction", "family", "fashion", "feature", "feedback", "filter", "find", "fit", "fitting", "folder", "following", "forecast", "forest", "form", "framework", "frequency", "frequent", "function", "future", "general", "generate", "generated", "gradient", "grouped", "handle", "help", "high", "history", "human", "idea", "improve", "including", "individual", "industry", "input", "instance", "interpretability", "kernel", "key", "knowledge", "labeled", "layer", "learn", "learning", "least", "length", "let", "level", "linear", "loan", "lower", "main", "manner", "map", "mean", "memory", "method", "missing", "model", "most", "multiple", "naive", "need", "network", "neural", "new", "noise", "not", "notebook", "number", "operator", "optimization", "order", "out", "outcome", "output", "parallel", "part", "pattern", "people", "performance", "person", "plot", "point", "predict", "prediction", "probability", "problem", "project", "provide", "random", "re", "recurrent", "regression", "regularization", "relationship", "report", "response", "sample", "scale", "science", "segment", "segmentation", "select", "selected", "selection", "set", "shortest", "similar", "simplicity", "single", "six", "space", "speed", "split", "standard", "store", "structure", "student", "sub", "supervised", "support", "target", "task", "text", "theory", "time", "tool", "training", "tree", "tuning", "type", "under", "unique", "unlabeled", "until", "upper", "valid", "value", "variable", "vector", "vision", "visualise", "visualization", "visualize", "website", "who", "work", "world"], "potential_description_queries_len": 208, "potential_script_queries": ["apriori", "catboost", "fbprophet", "lightgbm", "matplotlib", "mode", "numpy", "plt", "preprocessing", "pyplot", "sklearn", "tensorflow", "transform", "tsa", "xgboost"], "potential_script_queries_len": 15, "potential_entities_queries": ["clustering", "dependent", "gradient", "input", "lower", "output", "recurrent"], "potential_entities_queries_len": 7, "potential_extra_queries": ["bag", "biopsy"], "potential_extra_queries_len": 2, "all_components_potential_queries_len": 224}
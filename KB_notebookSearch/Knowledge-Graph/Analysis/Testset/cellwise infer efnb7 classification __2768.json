{"name": "cellwise infer efnb7 classification ", "full_name": " h1 About h2 Training h1 Imports h2 Focal Loss h1 1 BACKGROUND INFORMATION h3 1 1 APPROACH OVERVIEW h3 1 2 VISUAL HELPER h1 2 NOTEBOOK SETUP h1 3 HELPER FUNCTIONS h1 4 INFERENCE LOOP h3 4 1 LOAD THE MODEL h2 4 2 INFER h1 5 SUBMIT h1 6 BLENDING ", "stargazers_count": 0, "forks_count": 0, "description": "com h053473666 Training HPA Eff B7 Train All 4 Channels https www. ORIGINAL NOTEBOOK CREATED BY DARIEN SCHETTLER https www. Crop RGBY image around each cell4. For the result I ve just changed some hyperparameters then got 0. Segment slide level images get RLEs for all cells in all applicable slide level images 3. Use CellSegmentator to do instance segmentation on images in test dataset2. com aristotelisch hpa classification efnb7 train 13cc0d. Pad each RGBY tile to be square5. 14935 seconds 2 t 0. 00108 seconds 9 t 0. Train a model to classify these tile level images accurately INFERENCE 1. Record this mask in the appropriate format for later submission3. com aristotelisch efnb7 classification model added to cellwise infer aristotelisch https www. Augment the dataset rotation flipping horizontal and vertical minor skew 9. 00002 seconds 3 t 29. 9057 seconds 4 t 1. Define paths to nucleus and cell models for the cellsegmentator class Define the path to the competition data directory Define the paths to the training and testing tfrecord and image folders respectively for the competition data Capture all the relevant full image paths for the competition dataset Define paths to the relevant csv files Create the relevant dataframe objects Test Time Augmentation Information helps us control whether this is the full submission or just the initial pass If demo submission display we only do a subset of the data check input mask convert input mask to expected COCO API input RLE encode mask compress and base64 encoding convert the compressed string to a 3D uint8 tensor resize the image to the desired size This is for cellsegmentator Get batch of images 0. Identify slide level images containing only one label2. iloc 1 2 axis 1 break Start making individul label Get the multi labels. It s all for having fun here. 00066 seconds 10 t 0. findContours return signature yet again and I have no idea WTH is going on return the actual contours array Initialize We can only display one color so we pick the first Border and fill Text create new image batch tf automatically deep copies Load inference model Parameters Switch what we will be actually infering on Make subset dataframes Load Segmentator Make subset dataframes 0 t 1. 00015 seconds Step 0 Get batch of images as numpy arrays Step 1 Get Bounding Boxes Step 2 Get RGB Images which are actually just labelled as RGBY Step 3 Get Submission RLEs Optional Step Get the Masks Step 1 Do Prediction On Batch Step 2 Perform Cell Labelling on Batch Step 3 Reshape the RGBY Images so They Are Channels Last Across the Batch Step 4 Get Bounding Boxes For All Cells in All Images in Batch Step 5 Generate Submission RLEs For the Batch Step 6 Cut Out Pad to Square and Resize to 224x224 Step 7 OPTIONAL Test Time Augmentation Step 8 Perform Inference Step 9 Post Process Optional Viz Step Step 10 Format Predictions To Create Prediction String Easily Step 11 Save Predictions to Be Added to Dataframe At The End Start making individul label Get the multi labels if colour green sub_df pd. iloc 1 sub_dfs 1. 2 VISUAL HELPER basic_idea_graph https i. png 2 NOTEBOOK SETUP 3 HELPER FUNCTIONS 4 INFERENCE LOOP4. 2 INFER 5 SUBMIT 6 BLENDING Cell Segmentator Tool Machine Learning and Data Science Imports Built In Imports Visualization Imports Submission Imports PRESETS Stop Tensorflow From Eating All The Memory Currently memory growth needs to be the same across GPUs Memory growth must be set before GPUs have been initialized Used by the model here https www. Resize each RGBY tile to be 256px by 256px 6. com chienhsianghung hpa models Imports Focal Loss 1 BACKGROUND INFORMATION1. TBD Filter the images based on certain additional factors to obtain a better training dataset7. co y6YfBzN basic idea. Infer on each slide 7. com dschettler8845 classification added by Alien https www. 01442 seconds 6 t 0. 1 LOAD THE MODEL Load the models Define the parameters Make subset dataframes Initialize 4. 000001 seconds Do segmentation post processing pad height pad width if the length the contours tuple returned by cv2. com chienhsianghung hpa eff b7 train all 4 channels HPA Models https www. findContours is 2 then we are using either OpenCV v2. 26723 seconds 7 t 4. Please be noted I m not going to submit this kernel as my final selection. Combine cell level classification with segmentation as RLE when submitting1. 03042 seconds 1 t 8. AboutFor the Efn B7 adding part I ve sorted them for you to easier to read. 4 v4 beta or v4 official if the length of the contours tuple is 3 then we are using either OpenCV v3 v4 pre or v4 alpha otherwise OpenCV has changed their cv2. 10871 seconds 8 t 0. 30675 seconds 5 t 0. Copy and Edit from here https www. 1 APPROACH OVERVIEW TRAINING 1. Seperate the channels and store as seperate datasets8. ", "id": "chienhsianghung/cellwise-infer-efnb7-classification", "size": "2768", "language": "python", "html_url": "https://www.kaggle.com/code/chienhsianghung/cellwise-infer-efnb7-classification", "git_url": "https://www.kaggle.com/code/chienhsianghung/cellwise-infer-efnb7-classification", "script": "glob plot_ex decode decode_img augment_with_labels get_contour_bbox_from_raw build_dataset hpacellseg.cellsegmentator preprocess_row binary_focal_loss label_cell create_segmentation_maps efficientnet.tfkeras plotly.graph_objects matplotlib.patches convert_rgby_to_rgb collections seaborn numpy auto_select_accelerator grab_contours binary_mask_to_ascii build_augmenter decode_with_labels plot_predictions PIL load_image plotly.express typing rle_to_mask build_decoder hpacellseg.utils Image matplotlib.pyplot pycocotools create_pred_col tqdm.notebook tensorflow pandas plot_rgb preprocess_path_ds binary_focal_loss_fixed matplotlib.colors Counter tqdm cut_out_cells tta _mask pad_to_square get_img_list get_contour_bbox_from_rle rle_encoding focal_loss flatten_list_of_lists augment ListedColormap BinaryFocalLoss  # Used by the model here: https://www.kaggle.com/aristotelisch/hpa-classification-efnb7-train-13cc0d. _mask as coco_mask datetime ", "entities": "(('individul', 'multi labels'), 'iloc') (('subset dataframes', 'parameters'), 'LOAD') (('I', 'final selection'), 'note') (('you', 'them'), 'b7') (('Segment slide level images', 'slide level applicable images'), 'get') (('com aristotelisch efnb7 classification model', 'infer aristotelisch https www'), 'add') (('com chienhsianghung hpa eff b7', '4 channels'), 'train') (('I', 'then 0'), 'change') (('Load Segmentator', 'subset dataframes'), 'signature') (('then we', 'OpenCV v2'), 'use') (('dataset rotation', 'horizontal vertical skew'), 'augment') (('GPUs', 'model'), 'SUBMIT') (('h053473666 Training', 'HPA Eff Channels https 4 www'), 'com') (('tuple', 'cv2'), 'do') (('This', 'images'), 'define') (('label', 'multi labels'), '00015') (('v4 otherwise OpenCV', 'cv2'), 'beta') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["array", "basic", "batch", "beta", "cell", "cellsegmentator", "check", "classification", "classify", "color", "competition", "control", "convert", "create", "csv", "data", "dataframe", "dataset", "directory", "display", "encode", "encoding", "expected", "fill", "final", "format", "fun", "green", "growth", "height", "idea", "image", "inference", "input", "instance", "kernel", "label", "labelled", "length", "level", "mask", "memory", "model", "my", "new", "no", "not", "numpy", "official", "pad", "part", "path", "png", "post", "pre", "processing", "resize", "result", "return", "segmentation", "set", "size", "skew", "slide", "store", "string", "submission", "subset", "tensor", "test", "testing", "tf", "tfrecord", "tile", "train", "training", "tuple", "v3", "vertical", "width"], "potential_description_queries_len": 80, "potential_script_queries": ["augment", "datetime", "decode", "glob", "kaggle", "numpy", "seaborn", "tensorflow", "tqdm", "tta"], "potential_script_queries_len": 10, "potential_entities_queries": ["level", "vertical"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 89}
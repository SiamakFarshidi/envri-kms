{"name": "housing price model build ", "full_name": " h2 Feature Prep h1 Model Fit h2 Checkout Result h1 Model Interpretation h2 Score On Test ", "stargazers_count": 0, "forks_count": 0, "description": "Checkout ResultA check of the overall model predictions as well as predictions for some of the major variables was conducted. Everything seemed to be within a range of reasonable. Score On TestProduces a prediction on the test data which was then submitted to the competition. Create features for numeric columns Features are normal distributed at this point so the z values For percentiles can be hard coded Numeric columns get imputed scaled then feature created scale 0 to 1 Categorical columns get one hot encoded Select columns into one of those groups l2 penalty Model Result Model that Predicts Median. Categorical features had missing values treated as a seperate attribute and then one hot encoded Model FitA hyperparameter search over the alpha parameter an l2 regularizer was conducted. Model InterpretationThe SHAP package was used to get some high level inference about the predictive power and direction of the of the input variables. This also included a search over the tweedie power and link function. This visual includes the full model pipeline including all transformations and the actual model prediction. Feature PrepBased upon EDA conducted in prior week selected the top 25 predictors on a univariate basis to use further Numeric features were median imputed quantile scaled to a normal distribution passed through polynomial transformations as well as piecewise transformations and then finally scalled between 0 1. Surprisingly a slightly lower parameter than Gamma p 2 was selected. Pink values mean the input is high and blue values mean the input is low in the range. ", "id": "tylerrosacker/housing-price-model-build", "size": "1309", "language": "python", "html_url": "https://www.kaggle.com/code/tylerrosacker/housing-price-model-build", "git_url": "https://www.kaggle.com/code/tylerrosacker/housing-price-model-build", "script": "sklearn.metrics plotnine.scales scale_x_continuous FeatureUnion score_model set_config plotnine plotnine.labels log_rmse numpy sklearn.pipeline theme_classic make_column_selector SimpleImputer sklearn.impute VarianceThreshold pretty_up_table TweedieRegressor sklearn.model_selection sklearn.compose sklearn pandas Pipeline labs sklearn.feature_selection GridSearchCV ColumnTransformer sklearn.linear_model sklearn.preprocessing plotnine.themes make_scorer ", "entities": "(('visual', 'transformations'), 'include') (('as well predictions', 'major variables'), 'conduct') (('Feature PrepBased', 'piecewise as well then finally 0'), 'select') (('This', 'tweedie power function'), 'include') (('that', 'Median'), 'be') (('Everything', 'reasonable'), 'seem') (('which', 'then competition'), 'score') (('l2 regularizer', 'alpha parameter'), 'have') (('Model InterpretationThe SHAP package', 'input variables'), 'use') (('input', 'range'), 'mean') ", "extra": "['biopsy of the greater curvature', 'test']", "label": "Perfect_files", "potential_description_queries": ["attribute", "check", "data", "direction", "distributed", "distribution", "feature", "high", "hot", "hyperparameter", "including", "inference", "input", "l2", "level", "link", "lower", "major", "mean", "median", "missing", "model", "normal", "numeric", "overall", "package", "parameter", "pipeline", "point", "power", "prediction", "range", "scale", "scaled", "search", "selected", "test", "those", "through", "week"], "potential_description_queries_len": 40, "potential_script_queries": ["numpy", "plotnine", "sklearn"], "potential_script_queries_len": 3, "potential_entities_queries": [], "potential_entities_queries_len": 0, "potential_extra_queries": ["biopsy of the greater curvature", "biopsy"], "potential_extra_queries_len": 2, "all_components_potential_queries_len": 45}
{"name": "lyft training with multi mode confidence ", "full_name": " h1 Lyft Training with multi mode confidence h1 Environment setup h2 Function h2 Model h2 Training with Ignite h2 Configs h1 Main script h2 Loading data h2 Prepare model optimizer h2 Write training code h1 Items to try h1 Next to go h1 Further reference h3 If this kernel helps you please upvote to keep me motivated Thanks ", "stargazers_count": 0, "forks_count": 0, "description": "2 pred bs x modes x time x 2D coords confidences bs x modes Training utils Utils NOQA Lyft configs eval_every_n_steps 1 Data configs Model configs Training configs set env variable for data Rasterizer Train dataset dataloader Only use 1000 dataset for fast check. com corochann lyft prediction with multi mode confidence Try yourself how good score you can get using only single model without ensemble To understand the competition in more detail please refer my other kernels too. pt every epoch Check Save best validation predictor. Modelpytorch model definition. pt every epoch manager. Items to tryThis kernel shows demonstration run of the training debug True. Lyft Comprehensive guide to start competition https www. 14480 jpbremer lyft scene visualisations https www. AgentDataset train 22496709 valid 21624612 ActualDataset train 100 valid 100 Train setup Save log to file Run evaluation for valid dataset in each epoch. Lyft Training with multi mode confidence http www. com lyft l5kit blob 20ab033c01610d711c3d36e1963ecec86e8b85b6 l5kit l5kit evaluation metrics. htmlContinued from the previous kernel Lyft Comprehensive guide to start competition https www. This will resolve relative paths from the config using the L5KIT_DATA_FOLDER env variable we have just set. 7 patience 5 min_lr 1e 10 Show lr column in log HACKING to fix ProgressBarNotebook bug Let s see training results directory. com corochann lyft deep into the l5kit library In this kernel I will run pytorch CNN model training. com pfnet pytorch pfn extras releases tag v0. Note Why training abstraction library is used You may feel understanding training abstraction code below is a bit unintuitive compared to writing raw training loop. com jpbremer lyft scene visualisations If this kernel helps you please upvote to keep me motivated Thanks https github. To go further these items may be nice to try Change the cnn model now simple resnet18 is used as baseline modeling Training the model using full dataset lyft full training set https www. FailOnNonNumber Stop training when nan is detected. com corochann lyft pytorch implementation of evaluation metric Further reference Paper of this Lyft Level 5 prediction dataset One Thousand and One Hours Self driving Motion Prediction Dataset https arxiv. zarr for actual model training validation prediction. Consider much better scheme to predict multi trajectory The model just predicts multiple trajectory at the same time in this kernel but it is possible to collapse trivial solution where all trajectory converges to same. Only use 1000 dataset for fast check. com philculliton lyft full training set Write your own rasterizer to prepare input image as motivation explained in previous kernel. com mathurinache kaggle l5kit does not work with pytorch GPU. com corochann save your time submit without kernel inference Lyft pytorch implementation of evaluation metric https www. Here exponential decay of learning rate is applied by calling scheduler. Useful for logging printing evaluating saving the model scheduling the learning rate during training. report see LyftMultiRegressor for reporting point method and save to log file. Official utility script philculliton kaggle l5kit https www. You don t need to write code for saving models logging training loss metric show progressbar etc. The history log and model s weight are saved by extensions LogReport and E. snapshot_freq iteration lr scheduler scheduler torch. pytorch ignite https github. Especially just training much longer time may improve the score. com c lyft motion prediction autonomous vehicles overview evaluation page we can predict 3 modes of motion trajectory. Prepare model optimizer Write training codepytorch ignite pytorch pfn extras are used here. PrintReport PrintReportNotebook Prints the value which LogReport collected in formatted style. pt trigger MinValueTrigger validation main nll trigger flags. You can try these things to see how the score changes at first set debug False to train with actual training dataset change training hyperparameters training epoch change optimizer scheduler learning rate etc. 1 plotly models setup Dataset utils Function utils Original code from https github. Let s start writing main script to train the model Loading dataHere we will only use the first dataset from the sample set. Especially followings are new items to try Predict multi mode with confidence As written in evaluation metric https www. LogReport Logging metrics reported by ppe. observe_lr LogReport will check optimizer s learning rate using this extension. com pytorch ignite for training abstraction. Official Document IGNITE YOUR NETWORKS https pytorch. Only use 100 dataset for fast check. It automatically collects reported value in each iteration and saves the mean of reported value for regular frequency for example every 1 epoch. FunctionTo define loss function to calculate competition evaluation metric in batch. py assert all data are valid convert to batch_size num_modes future_len num_coords add modes add modes and cords error batch_size num_modes future_len reduce coords and use availability when confidence is 0 log goes to inf but we re fine with it error batch_size num_modes reduce time use max aggregator on modes for numerical stability error batch_size num_modes error are negative at this point so max gives the minimum one reduce modes print error error pred bs x time x 2D coords bs x mode 1 x time x 2D coords create confidence bs x mode 1 Model utils TODO support other than resnet18 This is 512 for resnet18 and resnet34 And it is 2048 for the other resnets X Y coords for the future positions output shape Bx50x2 You can add more layers here. Even you quit training using Ctrl C without finishing all the epoch the intermediate trained model is saved and you can use it for inference. We re building a LocalDataManager object. snapshot_object predictor best_predictor. Here model outputs both multi mode trajectory prediction confidence of each trajectory. com corochann lyft comprehensive guide to start competition Lyft Deep into the l5kit library https www. snapshot_object respectively easily which is a benefit of using training abstration. com jpbremer lyft config files as dataset See previous kernel Lyft Comprehensive guide to start competition https www. The advantage of abstracting the code is that we can re use implemented handler class for other training other competition. zarr data is used for visualization please use train. org ignite Configs Main scriptNow finished defining all the util codes. jpg The image from L5Kit official document http www. It works with pytorch tensor so it is differentiable and can be used for training Neural Network. Training with IgniteI use pytorch ignite https github. step every iteration. com pestipeti lyft l5kit unofficial fix as utility script. com corochann lyft comprehensive guide to start competition for details. How to avoid this Next to go Update 2020 9 6 Published prediction kernel Lyft Prediction with multi mode confidence https www. com corochann bengali seresnext training with pytorch So what is happening in above training abstraction Let s understand what each extension did. lambda function with scheduler. Training loss with competition evaluation metric Use Training abstraction library pytorch ignite and pytorch pfn extras. pfnet pytorch pfn extras https github. So you can follow how the learning rate changed through the training. com corochann lyft deep into the l5kit library Save your time submit without kernel inference https www. step You can invoke any function in regular interval specified by trigger. Update 2020 9 6 Published prediction kernel Lyft Prediction with multi mode confidence https www. com corochann lyft prediction with multi mode confidence Try yourself how good score you can get using only single model without ensemble Environment setup Please add pestipeti lyft l5kit unofficial fix https www. com pfnet pytorch pfn extras It provides several extensions useful for training. com pytorch ignite It provides abstraction for writing training loop. Such many functionalities can be added easily using extensions You can obtrain training history results really easily by just accessing LogReport class which is useful for managing a lot of experiments during kaggle competitions. Show progress bar during training Show log on jupyter notebook Save predictor. These are done by provided util classes in pytorch pfn extras library You may refer my other kernel in previous competition too Bengali SEResNeXt training with pytorch https www. Extensions Each role ProgressBar ProgressBarNotebook Shows training progress in formatted style. ReduceLROnPlateau optimizer mode min factor 0. Here the model is saved in regular interval flags. Engine defines the 1 iteration of training update. Please add lyft config files https www. snapshot_object Saves the object. Evaluator Evaluate on validation dataset. ", "id": "corochann/lyft-training-with-multi-mode-confidence", "size": "7893", "language": "python", "html_url": "https://www.kaggle.com/code/corochann/lyft-training-with-multi-mode-confidence", "git_url": "https://www.kaggle.com/code/corochann/lyft-training-with-multi-mode-confidence", "script": "ignite.engine animation ChunkedDataset l5kit.visualization optim PERCEPTION_LABELS draw_trajectory collections plotly.graph_objs pytorch_pfn_extras plotly.express l5kit.configs typing sklearn.model_selection ceil KFold Tensor save_yaml __len__ prettytable Callable torch.utils.data PrettyTable load_yaml seaborn numpy torch.utils.data.dataset tools nn IPython.core.display LyftMultiRegressor(nn.Module) tqdm.notebook pandas TransformDataset(Dataset) Dataset Counter DotDict(dict) IgniteExtensionsManager LyftMultiModel(nn.Module) create_trainer Subset pytorch_neg_multi_log_likelihood_batch matplotlib transform plotly.figure_factory HTML preprocessing display rc plotly.offline eval_func pytorch_pfn_extras.training.triggers pytorch_pfn_extras.training.extensions forward AgentDataset update_fn build_rasterizer plotly.io EgoDataset LocalDataManager scipy resnet18 pytorch_pfn_extras.training l5kit.data l5kit.rasterization IPython.display __init__ torch lightgbm Engine pytorch_neg_multi_log_likelihood_single TARGET_POINTS_COLOR Path DataLoader Dict MinValueTrigger __getitem__ pathlib plotly load_config_data sklearn matplotlib.pyplot l5kit.dataset tqdm subplots l5kit.geometry catboost xgboost transform_points torchvision.models math ", "entities": "(('log', 'extensions LogReport'), 'save') (('I', 'pytorch CNN model training'), 'lyft') (('respectively easily which', 'training abstration'), 'snapshot_object') (('org ignite Configs Main scriptNow', 'util codes'), 'finish') (('step You', 'trigger'), 'invoke') (('com corochann lyft pytorch implementation', 'Motion Prediction Dataset https One arxiv'), 'dataset') (('Bx50x2 You', 'more layers'), 'be') (('learning how rate', 'training'), 'follow') (('Show', 'jupyter notebook Save predictor'), 'log') (('Train setup 100 valid 100 Save', 'epoch'), 'train') (('you', 'me'), 'visualisation') (('dataset', 'Lyft competition https Comprehensive www'), 'com') (('it', 'where trajectory same'), 'consider') (('understanding', 'training below bit raw loop'), 'note') (('You', 'pytorch https www'), 'do') (('Update', 'mode confidence https multi www'), 'kernel') (('motivation', 'previous kernel'), 'write') (('We', 'LocalDataManager object'), 'build') (('Lyft Comprehensive', 'competition https www'), 'guide') (('it', 'Neural Network'), 'work') (('image', 'www'), 'jpg') (('env variable', 'fast check'), 'pre') (('you', 'Environment ensemble setup'), 'try') (('LogReport Logging metrics', 'ppe'), 'report') (('Especially followings', 'evaluation https metric www'), 'be') (('com pfnet pytorch pfn It', 'useful training'), 'extras') (('FunctionTo', 'competition evaluation batch'), 'define') (('Here exponential decay', 'scheduler'), 'apply') (('epoch Check', 'validation best predictor'), 'pt') (('observe_lr LogReport', 'extension'), 'check') (('com pytorch It', 'training loop'), 'ignite') (('we', 'handler implemented other training other competition'), 'be') (('Especially just training', 'score'), 'improve') (('changes', 'epoch change optimizer scheduler learning rate etc'), 'try') (('which', 'kaggle competitions'), 'add') (('Items', 'True'), 'show') (('we', 'L5KIT_DATA_FOLDER env variable'), 'resolve') (('extension', 'what'), 'training') (('You', 'training loss show progressbar metric etc'), 'need') (('com corochann', 'evaluation https metric www'), 'save') (('s', 'training results directory'), 'patience') (('report', 'log file'), 'see') (('zarr data', 'train'), 'use') (('when nan', 'training'), 'stop') (('com mathurinache kaggle l5kit', 'pytorch'), 'work') (('now simple resnet18', 'training set https full www'), 'be') (('we', 'sample set'), 'let') (('It', '1 epoch'), 'collect') (('you', 'inference'), 'quit') (('com pfnet pytorch pfn extras', 'tag v0'), 'release') (('com lyft motion vehicles overview evaluation autonomous we', 'motion'), 'c') (('LogReport', 'formatted style'), 'Prints') (('ProgressBar ProgressBarNotebook Shows', 'formatted style'), 'extension') (('Here model', 'regular interval flags'), 'save') (('Lyft Training', 'www'), 'http') (('Engine', 'training update'), 'define') (('you', 'other kernels'), 'try') (('multi', 'trajectory'), 'mode') ", "extra": ""}
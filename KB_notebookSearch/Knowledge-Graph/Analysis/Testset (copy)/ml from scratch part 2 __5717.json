{"name": "ml from scratch part 2 ", "full_name": " h2 Hello Kagglers h3 Checking The Data h3 Basic EDA h3 Brief Analysis of the data h3 Analysis Of Diabetic Cases h3 PairPlots h3 Observations h3 Let s Do Some Predictive Modeling h3 Stratification h3 SVM h3 Logistic Regression h3 Decision Tree h3 K Nearest Neighbours h3 In a Nutshell h2 Feature Extraction Selection h3 Correlation Matrix h3 Observations h3 Random Forest Classifier h3 Observations h2 Standardisation h3 Using Only Important Features And Standardisation h2 Cross Validation h2 Ensembling h3 Linear and Radial SVM h3 Linear SVM with Logistic Regression h3 Logistic Regression with Radial SVM h3 All 3 classifiers combined ", "stargazers_count": 0, "forks_count": 0, "description": "e Linaer SVM Radial rbf SVM and Logistic Regression classifiers. com ash316 ml from scratch with iris notebook. The models used to create such ensemble models are called base models. The accuracies and errors are then averaged to get a average accuracy of the algorithm. If your are completely new to Machine Learning I would suggest you to go through this basic tutorial to ML https www. This can be improved by using Feature Selection and using only relevant features. 2 The scatter plots shows the relation between each and every attribute or features taken pairwise. Random Forest Classifier Observations 1 The important features are Glucose BMI Age DiabetesPedigreeFunction StandardisationThere can be a lot of deviation in the given dataset. So the classifier with single accuracy will be assigned the highest weight and so on. Basic EDA Brief Analysis of the data Analysis Of Diabetic Cases PairPlots Lets us see the distribution of the features in the dataset Observations 1 The diagonal shows the distribution of the the dataset with the kernel density plots. Thus we should train and test our algorithm on each and every instance of the dataset. I have tried to explain the general idea behind these concepts so that it is helpful for begineers also. SVM Logistic Regression Decision Tree K Nearest Neighbours In a NutshellThe above algorithms are not giving vey high accuracy. This high variance has to be standardised. Hello Kagglers This notebook is sort of a guide to some important concepts in Machine Learning like 1 Feature Selection2 Standardisation3 Ensembling etc. Thus the instances of each class label or outcome in the train or test datasets is random. Thus we may have many instances of class 1 in training data and less instances of class 2 in the training data. 1 The K Fold Cross Validation works by first dividing the dataset into k subsets. We will do ensembling with the Voting Ensemble. A Voting Classifier can then be used to wrap your models and average the predictions of the sub models when asked to make predictions for new data. 4 An algorithm may underfit over a dataset for some training data and sometimes also overfit the data for other training set. Thus we stratify the data so that we have proportionate data for all the classes in both the training and testing data. This is called K Fold Cross Validation. Then we can take an average of all the noted accuracies over the dataset. It works by first creating two or more standalone models from your training dataset. 3 We continue the process by changing the testing part in each iteration and training the algorithm over the other parts. Linear and Radial SVM Linear SVM with Logistic Regression Logistic Regression with Radial SVM All 3 classifiers combinedSo the maximum Accuracy which we could get by using ensemble models is 78. com kaggle docker python For example here s several helpful packages to load in Input data files are available in the. EnsemblingEnsemble methods are techniques that create multiple models and then combine them to produce improved results. So we cannot eliminate any features just by looking at the correlation matrix. Please Upvote if Useful This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. Thus with cross validation we can achieve a generalised model. If You find this notebook useful PLEASE UPVOTE Checking The DataThe data looks clean. The above boxplot shows that SVM and LR perform the best while Decision Tree performs the worst. I would like you all for having a look at this notebook. An example in the dataset can be the BMI where it has 248 unique values. stratify the outcome Gaussian Standardisation for K fold cross validation score evaluation k 10 split the data into 10 equal parts for Voting Classifier. e there may be a high number of class1 instances but less number of other class instances. Feature Extraction Selection 1 A lot many features can affect the accuracy of the algorithm. In our case we will use the Top 3 classifiers i. We can also use ensembling or averaging of different algorithms. Using Only Important Features And StandardisationThe above dataframe shows the new accuracy of the models after feature selection. We will be using weighted Voting Classifier. 2 Feature Extraction means to select only the important features in order to improve the accuracy of the algorithm. 3 It reduces training time and reduces overfitting4 We can choose important features in 2 ways a Correlation matrix selecting only the uncorrelated features. Let s Do Some Predictive Modeling Stratification When we split the dataset into train and test datasets the split is completely random. b RandomForestClassifier It gives the importance of the features Correlation Matrix Observations 1 All the features look to be uncorrelated. For LR the accuracy decreases Cross ValidationMany a times the data is imbalanced i. Ensemble methods usually produces more accurate solutions than a single model would. We reserve 1 part for testing and train the algorithm over the 4 parts. 2 Let s say we divide the dataset into k 5 parts. We will assign to the classifiers according to their accuracies. So we can start with the analysis. We can see that the Accuarcy for linear Svm increases by 1 whereas it increases about 12 for Radial Svm. Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1. I will do these things in subsequent parts. Looking at the scatter plots we can say that no two attributes are able to clearly seperate the two outcome class instances. Voting is one of the simplest ways of combining the predictions from multiple machine learning algorithms. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. So during classification we may have accurate predictions for class1 but not for class2. ", "id": "ash316/ml-from-scratch-part-2", "size": "5717", "language": "python", "html_url": "https://www.kaggle.com/code/ash316/ml-from-scratch-part-2", "git_url": "https://www.kaggle.com/code/ash316/ml-from-scratch-part-2", "script": "sklearn.tree VotingClassifier #for Voting Classifier KNeighborsClassifier DecisionTreeClassifier cross_val_score #score evaluation seaborn numpy sklearn.ensemble sklearn sklearn.model_selection metrics KFold RandomForestClassifier matplotlib.pyplot pandas subprocess KFold #for K-fold cross validation LogisticRegression check_output svm StandardScaler #Standardisation sklearn.neighbors sklearn.linear_model sklearn.cross_validation sklearn.preprocessing train_test_split ", "entities": "(('k 10', 'Voting Classifier'), 'stratify') (('we', '5 parts'), 'let') (('1 diagonal', 'kernel density plots'), 'Lets') (('we', 'classifiers Top 3 i.'), 'use') (('Voting Classifier', 'new data'), 'use') (('We', 'also different algorithms'), 'use') (('we', 'ensemble models'), 'SVM') (('Using', 'feature selection'), 'show') (('Feature Extraction 1 lot many features', 'algorithm'), 'selection') (('Standardization', 'standard 1'), 'be') (('It', 'python docker image https kaggle github'), 'please') (('Voting', 'machine multiple learning algorithms'), 'be') (('we', 'class2'), 'have') (('Thus we', 'dataset'), 'train') (('Thus we', 'training 2 data'), 'have') (('you', 'ML https www'), 'suggest') (('we', 'training data'), 'stratify') (('Correlation Matrix 1 features', 'features'), 'b') (('We', '4 parts'), 'reserve') (('We', 'accuracies'), 'assign') (('3 We', 'other parts'), 'continue') (('Decision Tree', 'worst'), 'show') (('single model', 'usually more accurate solutions'), 'produce') (('So classifier', 'highest weight'), 'assign') (('that', 'improved results'), 'be') (('accuracies', 'algorithm'), 'average') (('you', 'output'), 'list') (('We', 'Voting Ensemble'), 'do') (('it', 'begineers'), 'try') (('It', 'training dataset'), 'work') (('it', 'Radial Svm'), 'see') (('Hello notebook', 'Feature Standardisation3 Ensembling 1 Selection2 etc'), 'Kagglers') (('two attributes', 'outcome class clearly two instances'), 'say') (('Then we', 'dataset'), 'take') (('Feature 2 Extraction', 'algorithm'), 'mean') (('split', 'train'), 'let') (('relation', 'pairwise'), '2') (('times data', 'Cross ValidationMany'), 'decrease') (('we', 'generalised model'), 'achieve') (('Correlation matrix', 'only uncorrelated features'), '3') (('BMI Age DiabetesPedigreeFunction StandardisationThere', 'given dataset'), 'observation') (('algorithm', 'training other set'), '4') (('This', 'only relevant features'), 'improve') (('We', 'Voting weighted Classifier'), 'use') (('Cross Validation', 'k subsets'), '1') (('So we', 'correlation just matrix'), 'eliminate') (('SVM Logistic Regression Decision Tree K Nearest NutshellThe algorithms', 'vey high accuracy'), 'Neighbours') (('I', 'notebook'), 'like') (('where it', '248 unique values'), 'be') (('I', 'subsequent parts'), 'do') (('Thus instances', 'train'), 'be') ", "extra": "['biopsy of the greater curvature', 'outcome', 'test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "algorithm", "assign", "attribute", "average", "basic", "best", "boxplot", "case", "choose", "classification", "classifier", "combine", "correlation", "could", "create", "current", "data", "dataframe", "dataset", "diagonal", "directory", "distribution", "ensemble", "ensembling", "environment", "equal", "evaluation", "every", "feature", "find", "fold", "general", "high", "idea", "image", "importance", "improve", "input", "instance", "iteration", "kaggle", "kernel", "label", "learning", "linear", "list", "load", "look", "looking", "lot", "matrix", "maximum", "mean", "ml", "model", "multiple", "new", "no", "not", "notebook", "number", "order", "outcome", "overfit", "part", "perform", "python", "relation", "run", "running", "scatter", "score", "scratch", "select", "several", "single", "sort", "split", "standard", "start", "sub", "technique", "test", "testing", "through", "time", "train", "training", "transform", "tutorial", "unique", "validation", "variance", "weight", "while", "write"], "potential_description_queries_len": 97, "potential_script_queries": ["numpy", "seaborn", "sklearn", "svm"], "potential_script_queries_len": 4, "potential_entities_queries": ["image", "learning", "multiple"], "potential_entities_queries_len": 3, "potential_extra_queries": ["biopsy"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 101}
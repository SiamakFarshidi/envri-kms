{"name": "pokemon data analysis tutorial ", "full_name": " h2 Table of Contents h1 Exploratory Data Analysis h2 Missing Values h2 Find the top 10 Pokemon with the worse win percentage h2 Find the top 10 Pokemon with the best win percentage h2 Basic statistics of the data h2 Visualizing the Data h2 Seaborn Pairplot h3 Seaborn PairGrid h2 Correlation Table h1 Exploratory Data Analysis Conclusions h3 What else are we missing and further analysis h1 Machine Learning h2 Preprocessing Data h2 Feature Scaling h1 Regression Models h2 Multiple Linear Regression h2 Polynomial Regression h2 SVM h2 Decision Tree Regression h2 Random Forest h2 XGBoost h1 Principle Component Analysis h2 Validation h1 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "Select Data Preprocessing DataThe data is broken into a testing and training to prevent against over fitting. Basic statistics of the data The above table displays the basic statistics of each variable like the mean min max ect. In this section I will be exploreing these relationships as well as some other visualizations that will better explain the trends in the Pokeverse. Some poemon don t have a secondary type thus the NA value. Missing Values Missing Values 1. From the combats dataset we will calculate the win percentage of each pokemon. I will conclude the venture with some machine learning and PCA to try and predict the win percentage of the pokemon. All models performed significantly worse under PCA. Add Shuckle to the data so that the array lengths are the same. Exploratory Data Analysis ConclusionsThis is where we communicate all the insight we have developed into a concise manner. The more components the more variance the model will have. For most of the independent variables look realtively normal distribution with a right skew. 4 Regression Tree Regression Tree 2. This is why understanding the buisness and where the data is coming from is so very crutial to helping the business out. We can further break down the data by looking at type by generation legendary by generation stats by type stats by generation stats by lengendary and so on. For this dataset we want to build a model that will predict the liklihood of a pokemon winning a battle. Regression scatter plot in the upper right 2. Poor Shuckle It appears that he has very strong defense but is very weak in all other catergories. If we look back at the top 10 most winning pokemon all have speeds over 100 and attacks over 100 except for Greninja s attack As data consultants it might not be enough to only work with this dataset. The greater the slope m the more correlated the values are in determining the liklihood of winning. 5 Principle Component Analysis Principle Component Analysis 2. As you drive into the data there might be anolomlies that dont make sense but you have a gut feeling that there might be a correlation to the outcome. Exploratory Data AnalysisWe begin by importing the proper libraries files and taking a look at what we re dealing with Missing ValuesSome quick notes on my initial thought and comments about the data. Win Percentage values range 0 1 while the independent vairables HP Attack. range from 0 200. This can only mean there is one pokemon that was unable to win during it s fights. We can see that water normal bug and grass are the most common type 1 and flying ground and poison are the most common type 2. I like the PairGrid better because it provides more customizable options compared to the Pairplot. I chose to do 80 to 20 There is no correct ratio to split it depends on the size of the data you are working with. Generation is which season of the show the pokemon come out. Validate model 6. The most obvious reason to me are the vast differences in their stats. Drive Business Decisions Once out analysis is complete relate it back to the business and make suggestions for areas Team Rocket could improve in. My plans are as followsvisualization add several more seaborn bar plots pie charts ect Machine Learning I want to add these machine learning approaches as a simple implementation and practice. As you can tell I can have two different kinds of graphs on the upper and lower halves of the grid. Speed and Attack Defense doesn t win championships in the Pokeverse. This was the case where we only used attack and speed to predict the win percentage. These are regression plots with a line of best fit. While this seems stright forward given that we have looked at the data it might not always be apparent to those who have not. Remeber its not enought to simply state the results. Transform Data 4. The bivariate desity plots cannot plot due to the different scale of values. 5 Rangom Forest Random Forest 2. Parameter tuningI combine steps 4 and 5 together since step 5 is relatively short. 1 Multiple Linear Regression Multiple Linear Regression 2. Conclusion Conclusion Data analysis is a powerful tool. Density Plot down the diagonal 3. I will do my best to explain each figure and calculation and how it could be useful to a business in the Pokemon Universe. To do this we will be testing several suprvised learning algortithms. Perhaps asking my 7 year old cousin about the difference could help. We need powerful attacks and quickness. Thus we would expect to see a simialr pattern if we were to build a heat map or a correlation table. This means a majority of the pokemon stats are on average higher than the median value for the set. I keep Type 1 in the data because later on I want to see how the relationships break down by type. Water normal bug and grass are the most common type 1 and flying ground and poison are the most common type 2. In addition Schuckle was a pokemon that lost all of his battles. If you have looked through the code you will see that I used mean absolute error. Exploratory Data Analysis Exploratory Data Analysis 1. Lastly we will utilize an unsupervised learning method called Principle Component Analysis which transforms the data space and reduces the dimensionality of the problem. Think of it as a similar concept to baby boomers and millennials 2. From there we notice that there are some pokemon that dont have any recoreded battles. From a quick glance it appears that attack and speed are significantly higher in Pokemon that win. Primeape is the missing Pokemon. Pokemon Type Weaknesses https pokemondb. This can be difficult because there in not much direction given for the analysis. The diagonal shows the density plots. A level 1 Pikachu would lose to a level 50 Blastoise regardless of the fact Pikachu has the type advantage. there are 1 million grass type 1 pokemon in the world what it doesnt tell me is which attributes are most apparent. This is because I am a template that works very well for easy implementation Feel free to use this structure The only difference is the library we are using and when we initialize the regressor object. Correlation TableThe table and the correlation figure provide the exact same information. Fit data to model predict 5. To dive deeper lets take a look at if there any trends when we further break down the data into Type 1. Try and relate it back to the Team Rocket business model. We wil then try to reduce the number of features being used and run the model again. It can also be normalized or transformed using PCA which we will use later. 3 SVM SVM 2. I defined the indepenent variables to be HP Attack Defense Sp. Let s break down the task. We begin by replicating the regplot to that we can see it better. We know from the TV show that Pokemon have their own personalities some pokemon are stubborn don t work well with others or listen to their masters. There are several winning pokemon with the Prefix Mega. 4 Regression Models Regression Models 2. 1 Select Data Select Data 2. Thus we scale A to capture the variances of each vairable. Below we develope the new feature add it to our data set then we merge the two datasets. There is one name that is missing. If you have these pokemon fairy rock steel poison you should avoid wasting resources and release any you have into the wild so you can reduce your overhead cost. To correct the issue we would need to run a grid search with k folds cross validation. Understand the business Team Rocket funds their illegal activities through winning pokemon battles and tournaments. The question still remains how do we know how accurate our predictions are Well there are many metrics that the Sklearn library provides us. The Pokemon type that win the least are fairy rock steel poison. SVM Regression Tree Random Forrest XGboot improve the PCA section by looking at the loadings of the principle components validation add the other validation metrics Final thoughts relate back to our business example I will continue to edit the grammar and update my commentary of graphs throughout this process Thank you for taking the time to read my kernel If you found it useful or helpful please give it an upvote. Then we can dive deeper to try and determine which stats contribute most to winning or which type of pokemon win the most. There are two sub categories of supervised learning and those are regression and classification. Team Rocket should have pokemon in their battle squads to counter these types. We will want to explore that instance maybe we can fix it. Looks like our inital hunch was correct There were some Pokemon that did not battle. 2 Correlation Table Correlation Table 1. Lets find the pokemon that did not win a single fight. Run the machine learning algorithms using the data after PCA. Re run the code but change n_components from 2 to the desired number. Seaborn Pairplot Seaborn PairGridWow this figure has a lot going on But thats okay we only need to look at it peice by piece do derive some meaningful understanding. For example a water type pokemon. One you look at how much variance each independent variable provide decide how many components you want for the model. In this kernal we will be using regression models such as Multiple Linear Regression Polynomial Regression SVM Decision Tree Regression Random Forest XGBoost. However simply creating visualizations and preditions is not enough to drive decisions in the business world. Update his name in the database. In this case of Mega vs non Mega maybe finding Mega pokemon in the wild is much more difficult and cost a lot more resources ie Time pokeball quality more potions and stronger pokemon to catch it. Part of this notebook is being built off the process used in Rachel Tatman s kernal https www. The diagonal of the plot all the correlations are 1. Mean Absolute Error2. This is what I am thinking. Later on we will use some machine learning techniques to predict their liklihood of winning. In the PairGrid above we see 3 types of graphs 1. I broke up the data into a smaller subset for this section. The Pokemon type that win the most are flying dragon electric and dark. Comparing the density plot with the frequency plot in the pairplot for Win Percentage we see a more uniformly distribution of the rate at which pokemon win with a slight decrease of the frequency at higher levels. The goal of this technique is to reduce the amount of features we are using for our model and simplify. Machine LearningWhat is a Kaggle kernel without throwing in some machine learning Machine learning is broken up into two categories supervised learning and unsupervised learing. Multiple Linear Regression Polynomial Regression SVM Decision Tree Regression Random Forest XGBoost Principle Component Analysis Principle component analysis PCA is a dimensionality reduction technique. The model with the least error was the XGBoost with reduced factors. The upper right section is the most easy to understand and probably the most useful for our analysis. There are 386 pokemon without a Type 2. My hypothesis is that there are many pokemons whos attacks are ineffective while the other pokemon is flying thus giving the other pokemon a significant advantage. Root Mean Squared Error4. The principle components consist of component loadings. Regression ModelsI put each regression model into a function so that I don t have to rewrite the code when I change the dimensionality of the data. Getting textual review data about what people think about each pokemon could be helpful in understanding how Team Rocket could train them. It uses linear algebra to tranform the data into a new space of principle components. We can start to analyze what kinds of pokemon are used at the competative level. Looking at the features with the highest correlation to winning which are speed and atatck. 3 Exploratory Data Analysis Conclusion Exploratory Data Analysis Conclusion 2. The figure with colors is more pleasant to look at and when discussing results with Team Rocket executives I would used the Pokemon Feature Correlation plot. Can we get the data of pokemon battle squads from previous tournaments. Def Speed and the dependent variable to be Win Percentage. com rtatman which pokemon win the most notebook. I was thinking maybe we would see dragon type pokemon clustered at the higher end of win percentage. Find the top 10 Pokemon with the worse win percentage Find the top 10 Pokemon with the best win percentageThere is a clear difference between Poekmon that win and lose. Each principle component explains some variance of the dataset. I appreciate any and all comments questions or suggestions and I will do my best to respond in a timely manner. For example one pokemon might be able to breath fire and fly. ConclusionThis kernel and analysis are incomplete. However the density for the win percentage is different. Other metrics are as follows. Explained Variance ScoreThe above table provides a comparision of the mean absolute error for each machine learning model and the different dimensionality approaches we took. Let s say there is a company called Team Rocket who makes millions of dollars off of pokemon battles I do not condone animal violence in any way shape or form and no Pokemon were injured during this analysis. I suppose the saying the best offense is a good defense doesnt apply in the Pokemon universe. While it might be interesting to look at how the independent features are correlated I think for our business problem we investigate the features correlated to win. Lets say a new pokemon is discovered based on its stats can we predict how much it will win But before we do that let s do some more exploratory data analysis The process of creating the Win Percentage column is known as feature engineering. net wiki List_of_Pok C3 A9mon_by_National_Pok C3 A9dex_number. Lets aggregate our win percentage by type 1. I am interested in improving my python skills so I will replicate her work from R to python and develop further analysis. 6 Validation Validation 3. I think this might be useful down the road. In this stage we can also encode any categorical variables we may have. The reason I find this helpful is it gives a better understanding of the range of values we are working with and the average of these values. This gives the average amount our predictions were off. If we make some predictions and the data is well outside the range we are working with then we can make a reasonable assumption that our model is not working correctly. I will be looking at missing values and getting some simple calcualtions in. Preprocess data 3. 2 Polynomial Regression Polynomial Regression 2. 0 which is perfectly positively correlated. Since we know water pokemon are weak agaisnt grass or electric it might be a good idea to keep one of those types in our battle squad. Flying dragon and electric type pokemon have a significant win percentage over the other types. I do realize the type of Pokemon is very important to the outcome of the battle for simplicity purposes I plan on leaving that out for now and may revisit this issue in the future. Why did we plot the same figure twice The top plot with one solid color was to look at the relationship between the independent and dependent variable as a whole. For this data I did not use feature scaling. The loadings are the correlation coefficients between the variables and factors. Standardizing is important because it brings all the variables withing the same range. I did not expect these results. I also would like to point out two other oberservations. Could there be pokemon that didnt battle at all What I do now is caculate the win percentage of each pokemon and add that feature to the data frame. This will make merging the two datasets easier. You will notice that the code looks pretty much identical for each model. I will then visualize some results using Matplotlib and Seaborn. I belive we shoud start very basic and take one step at a time. In our case this would be Type 1 Type 2 Generation and Lengendary. Esentially the slope of the line y mx b where m is the slope is the correlation value between the two variables. How this can be usefull is possibly predicting the liklihood of battling a particular type of pokemon and having a counter type to it. I used this link https bulbapedia. Which actually brings up a good point. This is becase the diagonal compares each feature to itself. So its Type 1 would be fire but it would also can fly so its Type 2 would be flying. The top half above the diagonal provides the same information as the lower half. The motivation behind this analysis is to further understand the dynamics of the pokemon universe through data. Validation So far we have fited our data to various regression models and predicted the likilhood of a pokemon winning a battle. Geographic location of where to find the different Pokemon would be a tremendous help into advising Team Rocket. The process for machine learning can be broken into several steps. Feature ScalingFrom there the data is standardized. Start shallow and dive deeper As we explore the data I think its best practice to start the investigation at a higher lever then work our way down and traverse the data. Hopefully this can help us lean more about which pokemon win. What I am most interested in is the relationship between each independent variable and the dependent variable Win Percentage. It is a TV series that has expanded into video games card games movies merchandise and everything inbetween. As a data consultant Team Rocket gives you this data set and ask you to come up with some useful insight on how to improve their business. If variable A ranges 1 1million and variable B ranges 0 1 variable A will completly dominate B. Lets take a closer look into these two plots given below. Breaking down the data further it was subset by type 1 in hopes that a new pattern would appear. 1 Seaborn Pairplot Seaborn Pairplot 1. It is the process of using given data and combining it in come combination to create new variable or features to be used in the analysis and is an important part of machine learning. I definetly didnt put very much effort into trying to optomize the results. I may eventually work on step 6 parameter tuning however this is a much more in depth and complex subject. 2 Preprocessing Data Preprocessing Data 2. Just by eye balling it not the most mathmematically correct method but it appears that speed and attack have the largest relationship to winning. Type 2 there is are NA values. The three approaches will be comapred. We can see that the number of dimensions is different in the total wins. It could be because of a combiantion of the parameters I am using for each of the models. I am not sure the difference between Mega Aerodactyl and regular Aerodactyl but I m confident that plays a role. But the message I want to send is to think of new ways to continue to break down the data and dive deeper. For these reasons even though the Mega Aerodactyl wins more often the business cost might outweight the potential business revenue. Machine Learning Machine Learning 2. We can continually increase the granularity of our analysis to derive better understanding. Also if we were to fold the matrix in half down the diagonal it would be perfectly semmetical. It our job to ask what else is missing or what further analysis can we do given more data What else are we missing and further analysis I m not sure if this data is similar to the video game but maybe pokemon level ie 1 100 plays a role in this. B would essentially become negligible. In addition some machine learning models we might want to standardize or normalize the data. Communicating to Team Rocket Hey these are the kinds of Pokemon flying dragon electric and dark you should be spending your resources on because they win. Thus we will want our analysis to be directed towards finding the best pokemon. We then look at the shape of the data frames and find a very interesting anomaly. 3 Feature Scaling Feature Scaling 2. 6 XGBoost XGBoost 2. Even though it doesnt tell me the exact population ie. She has done some fanstatic work and does an excellent job explaing her thought process. 2 Visualizing the Data Visualizing the Data 1. There are 800 different pokemon in the dataset and 50k battles recorded Let s begin by finding the missing pokemon Assuming that the indexes follow the same numbering system as the National Pokedex Number we can look up the missing Pokemon that falls between the two by looking him up. Bivariate Denisty plot with contour levels In the bottow row we see 6 empty graphs. Some Pokemon have secondary classification. Visualizing the DataAs I stated in the begining I think data analyst often get too excited not that there is anything wrong with that about the project and they begin their exploration with too much detail. The structure is as follows Table of Contents 1. Pokemon is a global icon to children and adults everywhere. ", "id": "mmetter/pokemon-data-analysis-tutorial", "size": "22113", "language": "python", "html_url": "https://www.kaggle.com/code/mmetter/pokemon-data-analysis-tutorial", "git_url": "https://www.kaggle.com/code/mmetter/pokemon-data-analysis-tutorial", "script": "sklearn.metrics PCA sklearn.tree DecisionTreeRegressor pyplot as plt SVR ml_xgboost correlation_matrix seaborn numpy pyplot RandomForestRegressor sqrt sklearn.decomposition sklearn.ensemble sklearn.model_selection LabelEncoder matplotlib.pyplot pandas cm OneHotEncoder StandardScaler ml_decisiontree ml_randomforest mean_absolute_error sklearn.linear_model matplotlib cm as cm sklearn.preprocessing ml_svm sklearn.svm ml_linearreg math train_test_split LinearRegression ", "entities": "(('1 100', 'this'), '-PRON-') (('I', 'also two other oberservations'), 'like') (('that', 'least'), 'be') (('we', 'Multiple Linear Regression Polynomial Regression SVM Decision Tree Regression Random Forest such XGBoost'), 'use') (('Machine LearningWhat', 'learning'), 'be') (('it', 'same range'), 'be') (('we', 'values'), 'be') (('I', 'models'), 'be') (('us', 'more which'), 'help') (('we', 'it'), 'begin') (('predictions', 'average amount'), 'give') (('Team how Rocket', 'them'), 'be') (('model', 'more variance'), 'have') (('Lets', 'type'), 'aggregate') (('Lets', 'two plots'), 'take') (('diagonal', 'itself'), 'be') (('I', 'results'), 'put') (('structure', 'Contents'), 'be') (('that', 'clear Poekmon'), 'be') (('top half', 'lower half'), 'provide') (('comments I', 'timely manner'), 'appreciate') (('features', 'business problem'), 'be') (('that', 'recoreded battles'), 'notice') (('Water normal bug', 'most common 1 ground'), 'be') (('majority', 'set'), 'mean') (('I', 'pokemon'), 'conclude') (('Principle Component which', 'problem'), 'utilize') (('Correlation TableThe table', 'correlation exact same information'), 'provide') (('one pokemon', 'fire'), 'be') (('I', 'simple implementation'), 'be') (('we', 'time'), 'belive') (('you', 'model'), 'decide') (('this', 'case'), 'be') (('however this', 'much depth'), 'work') (('principle components', 'component loadings'), 'consist') (('We', 'model'), 'try') (('I', 'Pokemon Feature Correlation plot'), 'be') (('It', 'machine important learning'), 'be') (('code', 'pretty much model'), 'notice') (('new pattern', '1 hopes'), 'be') (('Even it', 'population exact ie'), 'tell') (('I', 'data frame'), 'be') (('number', 'total wins'), 'see') (('this', 'road'), 'think') (('I', 'future'), 'realize') (('upper right section', 'most probably most analysis'), 'be') (('business more often cost', 'business potential revenue'), 'outweight') (('agaisnt weak it', 'battle squad'), 'be') (('min mean max', 'ect'), 'display') (('I', 'section'), 'break') (('principle component', 'dataset'), 'explain') (('poemon don t', 'secondary type'), 'have') (('that', 'him'), 'be') (('you', 'overhead cost'), 'avoid') (('Sklearn many library', 'us'), 'remain') (('most type', 'most'), 'dive') (('those', 'sub two supervised learning'), 'be') (('above we', 'graphs'), 'see') (('loadings', 'correlation variables'), 'be') (('TV that', 'movies merchandise'), 'be') (('we', 'learning several suprvised algortithms'), 'test') (('that', 'significantly Pokemon'), 'appear') (('most obvious reason', 'vast stats'), 'be') (('bivariate desity plots', 'values'), 'plot') (('I', 'data'), 'be') (('A', 'completly B.'), 'range') (('Pokemon', 'secondary classification'), 'have') (('that', 'dragon electric'), 'fly') (('other pokemon', 'thus other significant advantage'), 'be') (('4 together step', 'steps'), 'combine') (('pokemon', 'masters'), 'know') (('is', 'Pokemon good universe'), 'suppose') (('These', 'best fit'), 'be') (('we', 'previous tournaments'), 'get') (('correlations', 'plot'), 'be') (('type Flying dragon pokemon', 'other types'), 'have') (('they', 'resources'), 'communicate') (('that', 'single fight'), 'find') (('non maybe finding', 'ie Time pokeball quality more stronger it'), 'in') (('we', 'folds cross k validation'), 'need') (('be', 'it'), 'predict') (('only one that', 'fights'), 'mean') (('you', 'data'), 'choose') (('we', 'meaningful understanding'), 'have') (('I', 'simple calcualtions'), 'look') (('water normal bug', 'most common 1 ground'), 'see') (('when I', 'data'), 'put') (('pokemon', 'higher levels'), 'see') (('am', 'most independent variable'), 'be') (('However simply creating', 'business world'), 'be') (('She', 'thought process'), 'do') (('it', 'diagonal'), 'be') (('machine learning we', 'data'), 'model') (('maybe we', 'it'), 'fix') (('I', 'mean absolute error'), 'look') (('that', 'battles'), 'be') (('Pokemon', 'global children'), 'be') (('that', 'battle'), 'want') (('This', 'analysis'), 'be') (('we', '6 empty graphs'), 'plot') (('Pokemon', 'analysis'), 'let') (('process', 'feature engineering'), 'say') (('top plot', 'whole'), 'plot') (('we', 'concise manner'), 'be') (('Thus we', 'vairable'), 'scale') (('business Team Rocket', 'pokemon battles'), 'understand') (('Team Rocket', 'areas'), 'Decisions') (('We', 'generation stats'), 'break') (('we', 'model'), 'be') (('the more values', 'liklihood'), 'slope') (('So far we', 'battle'), 'validation') (('Later on we', 'liklihood'), 'use') (('best practice', 'down data'), 'start') (('dimensionality different we', 'machine learning model'), 'Explained') (('it', 'upvote'), 'improve') (('It', 'principle components'), 'use') (('that', 'role'), 'be') (('attributes', 'me'), 'be') (('We', 'very interesting anomaly'), 'look') (('array lengths', 'data'), 'Add') (('who', 'always those'), 'be') (('model', 'reasonable assumption'), 'be') (('how relationships', 'type'), 'keep') (('Team Rocket', 'types'), 'have') (('pokemon', 'season show'), 'be') (('analysis', 'best pokemon'), 'want') (('Select Preprocessing DataThe data', 'fitting'), 'datum') (('when we', 'regressor object'), 'be') (('kinds', 'competative level'), 'start') (('process', 'several steps'), 'break') (('then we', 'two datasets'), 'develope') (('they', 'too much detail'), 'think') (('where data', 'so very business'), 'be') (('I', 'feature scaling'), 'use') (('maybe we', 'win percentage'), 'think') (('Geographic location', 'Team tremendous Rocket'), 'be') (('Perhaps asking', 'difference'), 'help') (('model', 'reduced factors'), 'be') (('it', 'only dataset'), 'have') (('I', 'grid'), 'have') (('we', 'heat map'), 'expect') (('However density', 'win percentage'), 'be') (('we', 'also categorical variables'), 'encode') (('motivation', 'data'), 'be') (('as well other that', 'Pokeverse'), 'explore') (('how it', 'Pokemon Universe'), 'do') (('Part', 'Rachel https kernal www'), 'build') (('Pikachu', 'type advantage'), 'lose') (('We', 'better understanding'), 'increase') (('we', 'pokemon'), 'dataset') (('I', 'further analysis'), 'be') (('I', 'indepenent variables'), 'define') (('you', 'outcome'), 'be') (('better it', 'Pairplot'), 'like') (('where m', 'correlation two variables'), 'be') (('we', 'which'), 'normalize') (('he', 'very other catergories'), 'Shuckle') (('which', 'highest correlation'), 'look') (('speed', 'largest relationship'), 'ball') (('I', 'Matplotlib'), 'visualize') (('where we', 'win percentage'), 'be') (('com pokemon', 'most notebook'), 'rtatman') (('we', 'data'), 'begin') (('data consultant Team Rocket', 'how business'), 'give') (('models', 'significantly PCA'), 'perform') (('when we', 'Type'), 'take') ", "extra": "['outcome', 'test']", "label": "Perfect_files", "potential_description_queries": ["absolute", "aggregate", "analyze", "animal", "apply", "array", "average", "basic", "become", "best", "build", "calculate", "calculation", "case", "categorical", "children", "clear", "code", "color", "column", "combine", "company", "concept", "contour", "correct", "correlation", "correlations", "cost", "could", "create", "data", "dataset", "dependent", "depth", "derive", "develop", "diagonal", "difference", "dimensionality", "direction", "distribution", "drive", "effort", "empty", "encode", "end", "error", "even", "everything", "explore", "eye", "fact", "feature", "figure", "find", "fix", "fly", "fold", "form", "forward", "found", "frequency", "function", "game", "generation", "grid", "ground", "half", "help", "him", "idea", "implementation", "improve", "increase", "initialize", "instance", "issue", "job", "kernel", "largest", "learning", "least", "let", "level", "library", "line", "linear", "link", "look", "looking", "lost", "lot", "lower", "majority", "map", "matrix", "max", "mean", "median", "merge", "message", "method", "might", "min", "missing", "model", "most", "motivation", "my", "name", "need", "new", "no", "non", "normal", "normalize", "normalized", "not", "notebook", "number", "out", "outcome", "parameter", "part", "pattern", "people", "percentage", "pie", "plot", "point", "population", "potential", "practice", "predict", "prevent", "problem", "project", "provide", "python", "question", "range", "ratio", "re", "read", "reason", "reduce", "regression", "relationship", "review", "right", "role", "row", "run", "scale", "scatter", "seaborn", "search", "section", "sense", "set", "several", "shape", "similar", "simplicity", "single", "size", "space", "speed", "split", "stage", "start", "state", "step", "structure", "sub", "subset", "supervised", "system", "table", "technique", "template", "testing", "think", "those", "thought", "through", "time", "total", "train", "training", "try", "tuning", "type", "under", "understanding", "up", "update", "upper", "validation", "value", "variable", "variance", "video", "visualize", "while", "who", "work", "world", "year"], "potential_description_queries_len": 209, "potential_script_queries": ["cm", "math", "matplotlib", "numpy", "plt", "pyplot", "sklearn", "sqrt"], "potential_script_queries_len": 8, "potential_entities_queries": ["categorical", "learning", "most", "potential", "several"], "potential_entities_queries_len": 5, "potential_extra_queries": ["test"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 217}
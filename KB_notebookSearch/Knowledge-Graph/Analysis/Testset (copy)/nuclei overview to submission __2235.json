{"name": "nuclei overview to submission ", "full_name": " h1 Overview h1 Read in the labels h1 Load in all Images h1 Create Training Data h1 Show a few images h1 Look at the intensity distribution h1 Check Dimensions h2 Making a simple CNN h1 Loss h1 Simple Training h1 Apply Model to Test h2 Show a few predictions h1 Check RLE h2 Calculate the RLEs for a Train Image h2 Take the RLEs from the CSV h2 Check h1 Calculate RLE for all the masks ", "stargazers_count": 0, "forks_count": 0, "description": "creating the RLE test data Read in the labelsLoad the RLE encoded output for the training set Load in all ImagesHere we load in the images and process the paths so we have the appropriate information for each image Create Training DataHere we make training data and load all the images into the dataframe. We take a simplification here of grouping all the regions together rather than keeping them distinct. Show a few imagesHere we show a few images of the cells where we see there is a mixture of brightfield and fluorescence which will probably make using a single segmentation algorithm difficult Look at the intensity distributionHere we look briefly at the distribution of intensity and see a few groups forming they should probably be handled separately. LossSince we are being evaulated with intersection over union we can use the inverse of the DICE score as the loss function to optimize Simple TrainingHere we run a simple training with each image being it s own batch not a very good idea but it keeps the code simple Apply Model to TestHere we apply the model to the test data Show a few predictions Check RLECheck that our approach for RLE encoding stolen from here https www. For this we use a batch normalization to normalize the inputs. com rakhlin fast run length encoding python works Calculate the RLEs for a Train Image Take the RLEs from the CSV CheckSince we made some simplifications we don t expect everything to be perfect but pretty close Calculate RLE for all the masksHere we generate the RLE for all the masks and output the the results to a table. Check Dimensions Here we show the dimensions of the data to see the variety in the input images Making a simple CNNHere we make a very simple CNN just to get a quick idea of how well it works. read_csv use dilations to get a slightly larger field of view the final processing label regions. We cheat a bit with the padding to keep problems simple. T sets Fortran order down then right ensure at least one prediction per image. applying the model to the test data1. OverviewThe kernel goes through1. We use a few morphological operations to clean up the images before submission since they can be very messy remove single pixels connect nearby regions etc linear algebra data processing CSV file I O e. a quick visualization of the color space1. training a simple CNN1. the preprocessing steps to load the data1. ", "id": "kmader/nuclei-overview-to-submission", "size": "2235", "language": "python", "html_url": "https://www.kaggle.com/code/kmader/nuclei-overview-to-submission", "git_url": "https://www.kaggle.com/code/kmader/nuclei-overview-to-submission", "script": "glob clean_img keras.layers Sequential skimage.morphology read_and_stack closing imread dice_coef_loss Conv2D seaborn numpy opening simple_gen matplotlib.pyplot pandas Lambda dice_coef disk BatchNormalization label # label regions UpSampling2D rle_encoding prob_to_rles backend backend as K keras keras.models skimage.io ", "entities": "(('We', 'together rather them'), 'take') (('We', 'problems'), 'cheat') (('T', 'image'), 'set') (('a few predictions', 'https www'), 'evaulate') (('we', 'inputs'), 'use') (('how well it', 'just quick idea'), 'check') (('they', 'a few groups'), 'show') (('they', 'very messy remove single nearby regions'), 'use') (('read_csv', 'processing label final regions'), 'use') (('we', 'table'), 'run') (('Create Training we', 'dataframe'), 'create') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["algorithm", "apply", "approach", "batch", "bit", "clean", "close", "code", "color", "data", "distribution", "encoding", "ensure", "everything", "field", "file", "final", "function", "generate", "idea", "image", "input", "intensity", "intersection", "kernel", "label", "least", "length", "linear", "load", "look", "mixture", "model", "normalization", "normalize", "not", "optimize", "order", "output", "padding", "per", "prediction", "preprocessing", "processing", "python", "remove", "right", "run", "score", "segmentation", "set", "simplification", "single", "submission", "test", "training", "up", "view", "visualization"], "potential_description_queries_len": 59, "potential_script_queries": ["backend", "closing", "disk", "glob", "imread", "io", "numpy", "opening", "seaborn"], "potential_script_queries_len": 9, "potential_entities_queries": ["label", "single"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 67}
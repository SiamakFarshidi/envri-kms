{"name": "coref by mlp cnn coattention ", "full_name": " h1 Import Data h1 Explore Features for Building Mention Pair Distributed Representation h2 Embedding Features h3 Parse Text h3 Generate Embedding Features h3 Generate Training Validation and Testing Data h1 Define DL Models h2 Baseline Model MLP h2 Multi Channel CNN h2 Coattention Model h4 Define Co attention Layer h4 Define Inter Mention Pair Coattention Model h4 Intra Mention Pair Coattention Model h1 Build and Train Model h2 Baseline Model MLP h3 Build Model h3 Train Model h2 Multi Channel CNN h3 Build Model h3 Train Model h2 Inter Mention Pair Coattention Model h3 Build Model h3 Train Model h2 Intra Mention Pair Coattention Model h3 Build Model h3 Train Model h3 Make Prediction ", "stargazers_count": 0, "forks_count": 0, "description": "com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. GlobalAveragePooling1D name global_pooling_layer str i conv pooled_outputs. Average word embeding of the five preceding words five following words all words in the mention all words in the sentences. t char offset to token offset mention_word token offset to sentence offset mention sentence dependency parent last word and first word two preceding words and two following words five preceding words and five following words sentence words char offset to token offset token offset to sentence offset buckets relative distance buckets absolute position in the sentence inputs define feature map layers MLP Layers MLP Layers inputs define feature map layers CNN Layers MLP Layers todo check that this is correct pass the mask to the next layers u Wx b u Activation Wx b atten exp u1 u2 T don t pass the mask to the next layers apply mask after the exp. will be re normalized next Cast the mask to floatX to avoid float64 upcasting in theano in some cases especially in the early stages of training the sum may be almost zero and this results in NaN s. Features extraction used in this kernel follows Clark and Mannings work https nlp. Concatenate name concated_layer pooled_outputs else x conv MLP Layers attention compare inputs define feature map layers MLP Layers From mention pair embeddings pooled_outputs for i in range len filter_sizes conv layers. Parse TextExample Generate Embedding Features Position FeaturesEncode the absolute positions in the sentence and the relative position between the pronoun and the entities. All the model in this kernel are Non RNN Based DL models. A workaround is to add a very small positive number \u03b5 to the sum. This kernel implements 4 DL models for coreference resolution. Import Data Explore Features for Building Mention Pair Distributed Representation Embedding FeaturesFollow the idea from the work by Clark and Manning extract word embedding of head word dependency parent first word last word two preceding words and two following words of the mention. edu pubs clark2016improving. append conv if len pooled_outputs 1 x layers. read_csv Input data files are available in the. pdfIf you are interested in RNN based End2End coreference solution model please check this kernel https www. Concatenate name concated_layer pooled_outputs else x conv MLP Layers. Generate Training Validation and Testing Data Define DL Models Baseline Model MLP Multi Channel CNN Coattention Model Define Co attention Layer Define Inter Mention Pair Coattention Model Intra Mention Pair Coattention Model Build and Train Model Baseline Model MLP Build Model Train Model Multi Channel CNN Build Model Train Model Inter Mention Pair Coattention Model Build Model Train Model Intra Mention Pair Coattention Model Build Model Train Model Make Prediction This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. GlobalMaxPooling1D name global_pooling_layer str i conv else conv layers. Conv1D num_filters i kernel_size filter_sizes i padding padding activation relu x if pooling max conv layers. com keyit92 end2end coref resolution by attention rnn. sum a axis 1 keepdims True K. floatx inputs define feature map layers MLP Layers From mention pair embeddings attention compare pooled_outputs for i in range len filter_sizes conv layers. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. ", "id": "keyit92/coref-by-mlp-cnn-coattention", "size": "1558", "language": "python", "html_url": "https://www.kaggle.com/code/keyit92/coref-by-mlp-cnn-coattention", "git_url": "https://www.kaggle.com/code/keyit92/coref-by-mlp-cnn-coattention", "script": "Tree _get_following_words __init__ DependencyParser create_dist_features keras.layers _dot_product compute_mask extrac_positional_features RemappedCoAttentionWeight(merge._Merge) English FeatureNormalization(Layer) compute_output_shape _mlp_channel2 _merge_function bs_ _mlp_channel1 Layer build callbacks numpy models coatten_compare spacy.lang.en optimizers to_nltk_tree initializers get_config keras.backend merge build_multi_channel_cnn_model constraints matplotlib.pyplot build_intra_coattention_cnn_model call optimizers as ko pandas activations create_embedding_features spacy.pipeline keras.engine regularizers build_inter_coattention_cnn_model _get_preceding_words build_mlp_model callbacks as kc layers _row_to_y bs backend keras extrac_embed_features_tokens SVG ohe_dist IPython.display nltk ", "entities": "(('Wx b u Activation Wx atten exp u1 u2 T don u b t', 'exp'), 'offset') (('GlobalAveragePooling1D name global_pooling_layer i', 'pooled_outputs'), 'str') (('Embedding idea', 'mention'), 'feature') (('read_csv Input data files', 'the'), 'be') (('you', 'kernel https www'), 'be') (('workaround', 'sum'), 'be') (('you', 'output'), 'list') (('compare inputs', 'range len filter_sizes conv layers'), 'pooled_outputs') (('model', 'kernel'), 'be') (('i', 'max conv layers'), 'num_filters') (('Parse TextExample', 'relative pronoun'), 'Generate') (('Features extraction', 'work https Clark nlp'), 'follow') (('It', 'python docker image https kaggle github'), 'Generate') (('kernel', 'coreference resolution'), 'implement') (('floatx inputs', 'range len filter_sizes conv layers'), 'define') (('name global_pooling_layer GlobalMaxPooling1D i', 'conv else layers'), 'str') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["absolute", "append", "apply", "char", "check", "compare", "conv", "correct", "current", "data", "define", "directory", "distance", "embedding", "environment", "exp", "extract", "extraction", "feature", "file", "following", "head", "idea", "image", "input", "kaggle", "kernel", "len", "linear", "list", "load", "map", "mask", "max", "mention", "model", "name", "next", "normalized", "number", "offset", "padding", "pair", "parent", "pooling", "position", "positive", "processing", "python", "range", "re", "relative", "resolution", "run", "running", "sentence", "several", "solution", "str", "sum", "token", "training", "word", "work", "write"], "potential_description_queries_len": 65, "potential_script_queries": ["backend", "build", "call", "kc", "ko", "lang", "merge", "nltk", "numpy"], "potential_script_queries_len": 9, "potential_entities_queries": ["data", "image", "len"], "potential_entities_queries_len": 3, "potential_extra_queries": ["test"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 75}
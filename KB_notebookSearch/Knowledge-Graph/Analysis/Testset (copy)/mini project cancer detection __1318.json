{"name": "mini project cancer detection ", "full_name": " h3 ROC curve and AUC h2 Remember AUC is the metric that is used for evaluating submissions We can calculate it here for ou validation set but it will most likely differ from the final score h1 Submit predictions h3 TTA h3 Submit the model for evaluation h2 We need to submit the tumor probability for each test sample in this competition The probability ranges from 0 to 1 h1 Deploy example ", "stargazers_count": 0, "forks_count": 0, "description": "You may need to do some debugging. On a new machine We need to create an empty DataBunch and load it to a learner. The predictions are then averaged. The probability ranges from 0 to 1. Image file descriptors Description Format TIF Size 96 x 96 Channels 3 Bits per channel 8 Data type Unsigned label statistics Plot some images with and without cancer tissue for comparison OpenCV reads the image in bgr format by default We flip it to rgb for visualization purposes random sampling Negatives Create a Rectangle patch Positives Create a Rectangle patch label of the image is influenced only by the center region 32 x 32px crop data to that region only. Next we will transform class probabilities to just tumor class probabilities If we wanted to get the predicted class argmax would get the index of the max get test id s from the sample_submission. reset learner Plot weight decays ax ranges may need some tuning with different model architectures predict the validation set with our model save the model at this stage Save the finetuned model get accuracy top losses will return all validation losses and indexes sorted by the largest first Random Most incorrect or top losses Most correct or least losses hook into forward pass we hook into the convolutional part m 0 of the model We can create a utility function for getting a validation image with an activation map this gets the model create a batch from the one image convert batch tensor image to grayscale image with opencv attach hooks get convolutional activations and average from channels Grad CAM Then modify our plotting func a bit top losses will return all validation losses and indexes sorted by the largest first Random Most incorrect or top losses Most correct or least losses probs from log preds Compute ROC curve Compute ROC area make sure we have the best performing model stage loaded Fastai has a function for this but we don t want the additional augmentations it does our image loader has augmentations so we just use the get_preds We do a fair number of iterations to cover different combinations of flips and rotations. ROC curve and AUCRemember AUC is the metric that is used for evaluating submissions. The augmentations used for this data random rotation random crop random flip horizontal and vertical both random lighting We use OpenCV with image operations original size of the images AUGMENTATION VARIABLES final size after crop range 0 180 180 allows all rotation variations 0 no change center crop shift in x and y axes 0 no change. As we have test time augmentation our results will probably improve if we do predictions multiple times per image and average out the results. Deploy example Now that we have a working model. Negatives Baseline model Fastai v1 min viable model the simplest accepted model Prepare the data and split train Split train data to 90 training and 10 validation parts. This function will convert image to the prediction format crop to center to the correct size and convert from 0 255 range to 0 1 range. I haven t tried these so I cannot guarantee these will work straight away. We could deploy this for inference to another machine a web server for example. This saves the internal information classes etc need for inference in a file named export. We can calculate it here for ou validation set but it will most likely differ from the final score. This shows the activation maps of the predicted category so if the label is tumor the visualization shows all the places where the model thinks the tumor patterns are. These are in the order of our test dataset and not necessarily in the same order as in sample_submission To know the id s we create a dict of id pred Now we can create a new list with the same order as in sample_submission Next a Pandas dataframe with id and label columns. 0 import all the models from torchvision specify model input size is the crop size this will extrat the model name as the model file name create test dataframe This ndarray image has to be converted to tensor before passing on as fastai Image we can use pil2tensor Create ImageDataBunch using fastai data block API Where to find the data How to split in train valid Where are the labels dataframe pointing to the test set We have our custom transformations implemented in the image loader but we could apply transformations also here Even though we don t apply transformations here we set two empty lists to tfms. Official documentation https docs. For this we need our saved model and then we need to export the DataBunch. csv and keep their original order List of tumor preds. Train and Validation augmentations convert to databunch Normalize with training set stats. This cannot be more than ORIGINAL_SIZE CROP_SIZE 2 range 0 100 0 no change range 0 100 0 no change 0 or 1 random turn to left or right OpenCV reads the image in bgr We flip it to rgb for visualization purposes random rotation the center point is the rotation anchor random x y shift crop to center and normalize to 0 1 range Random flip Random brightness Random contrast clip values to 0 1 range Negatives Positives To see the effects of our augmentation we plot one image multiple times. Submit the model for evaluationWe need to submit the tumor probability for each test sample in this competition. Submit predictions TTATo evaluate the model we run inference on all test images. pkl file that you ll need to copy with your model file if you want to deploy it on another device. Export to csv This is what the first 10 items of submission look like This will create an export. These are means and std s of each three channel and we calculated these previously in the stats step. ", "id": "smithstrivedi17it/mini-project-cancer-detection", "size": "1318", "language": "python", "html_url": "https://www.kaggle.com/code/smithstrivedi17it/mini-project-cancer-detection", "git_url": "https://www.kaggle.com/code/smithstrivedi17it/mini-project-cancer-detection", "script": "sklearn.utils sklearn.metrics randint fastai.vision MyImageItemList(ImageList) readImage open tqdm_notebook random *=all the models from torchvision imageToTensorImage matplotlib.patches shuffle numpy getLearner auc hooked_backward sklearn.model_selection plot_heatmap_overview * # fastai 1.0 fastai.callbacks.hooks matplotlib.pyplot pandas getHeatmap tqdm fastai roc_curve readCroppedImage torchvision.models train_test_split plot_overview ", "entities": "(('We', 'example'), 'deploy') (('tumor patterns', 'places'), 'show') (('Rectangle patch label', 'crop 32 32px region'), 'plot') (('We', 'flips'), 'need') (('etc', 'file'), 'save') (('probably we', 'results'), 'improve') (('we', 'stats previously step'), 'be') (('here we', 'two empty lists'), 'import') (('then we', 'DataBunch'), 'need') (('AUCRemember that', 'submissions'), 'be') (('you', 'device'), 'file') (('function', '0 1 range'), 'convert') (('rotation variations', 'change center crop 0 x'), 'flip') (('Now we', 'working model'), 'deploy') (('i', 'sample_submission'), 'transform') (('Train augmentations', 'training stats'), 'convert') (('We', 'learner'), 'need') (('I', 'these'), 'try') (('it', 'most likely final score'), 'calculate') (('Now we', 'i d columns'), 'be') (('Negatives Baseline model', '90 training'), 'prepare') (('This', 'export'), 'be') (('we', 'one image'), 'be') (('we', 'test images'), 'evaluate') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "apply", "area", "attach", "augmentation", "average", "batch", "best", "bit", "block", "calculate", "cancer", "category", "center", "channel", "clip", "comparison", "contrast", "convert", "convolutional", "copy", "correct", "could", "create", "crop", "csv", "curve", "custom", "data", "dataframe", "dataset", "default", "dict", "documentation https docs", "empty", "evaluate", "export", "fastai", "file", "final", "find", "flip", "format", "forward", "func", "function", "grayscale", "hook", "id", "image", "import", "improve", "index", "inference", "input", "label", "largest", "learner", "least", "left", "list", "load", "loader", "log", "look", "map", "max", "metric", "min", "model", "most", "multiple", "name", "need", "new", "no", "normalize", "not", "number", "order", "out", "part", "patch", "per", "performing", "plot", "plotting", "point", "pred", "predict", "prediction", "probability", "random", "range", "region", "reset", "return", "rgb", "right", "run", "sample", "sample_submission", "sampling", "save", "set", "shift", "size", "split", "stage", "std", "submission", "tensor", "test", "time", "tissue", "torchvision", "train", "training", "transform", "tumor", "tuning", "turn", "type", "valid", "validation", "vertical", "visualization", "web", "weight", "work"], "potential_description_queries_len": 130, "potential_script_queries": ["auc", "numpy", "open", "randint", "shuffle", "sklearn", "tqdm"], "potential_script_queries_len": 7, "potential_entities_queries": ["crop", "final"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 134}
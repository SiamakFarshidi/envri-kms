{"name": "in depth guide to convolutional neural networks ", "full_name": " h1 Introduction h3 If you like this kernel or wish to fork it please give it an UPVOTE to show your appreciation h1 Import Libraries h2 Loading Training Data EDA h2 Setting up Train Data for Pytorch h2 Setting up Test Data h2 Visualize Images h2 Viewing an Image in More Detail h2 Multi Layer Perceptrons MLP Vs Convolutional Neural Networks CNN h2 Understanding CNNs h3 If you like this kernel or wish to fork it please give it an UPVOTE to show your appreciation h2 Define the Network Architecture h2 Training our CNN h2 Performance Graph h2 Make Predictions on Test Set h3 If you like this kernel or wish to fork it please give it an UPVOTE to show your appreciation ", "stargazers_count": 0, "forks_count": 0, "description": "We re going to build a CNN in the next few sections to ultimately achieve just that or even better performance. com media jrzu0JxxZydz0valeu giphy. com topher 2018 May 5b10723a_screen shot 2018 05 31 at 3. samplerSubsetRandomSampler function to split our data into training and validation sets which is similar to train_test_split fuction of scikit learn. How it is done is a window of fixed size of made to stroll over the image and inside the window a specific value according to a metric is calculated an a new tensor is formed. I ll use an example of classifying a car here to explain different layers of a Convolutional Neural Network. This tutorial won t assume much in regards to prior knowledge of PyTorch but it might be helpful to checkout my previous introductory CV tutorial https www. We then go on and define the pooling layers where a window size and stride of 2 is set. There are several pre processing steps involved which we ll discuss in detail in this section. Each time we can pull out data of the size of the batch_size defined. com media U7PsR7cv9oIcB6eEAd giphy. We then convert the images into a PyTorch tensor then we normalize the them. This is one type of early stopping. First you must define a Model class and fill in two functions __init__ and __forward__. We ll use the Aerial Cactus Dataset from this currently running Kaggle competition https www. But in the end it s just another hyperparameter you can tune. CNNs on the other hand work exactly the other way around capable of working with and elucidating patterns from multi dimensional data that is why they are so powerful. Step 3 Batch size is set. com abhinand5 CNNs in PyTorch blob master cifar cnn FireShot 20Capture 20084 20 20Intro 20to 20Deep 20Learning 20with 20PyTorch 20 20Udacity 20 20classroom. This is how images are represented in our computers. Details can be mostly interpreted from the comment lines itself. FeaturedImage https i. These filters can be modified to get different filters as output. jpeg I know this may not be the best of definitions you would see for CNNs but the goal here is to make it atleast vaguely understandable. If the dataset you are using contains almost or above 90 of the training data belonging to one single class then it will greatly impact your results. We have also applied the transformations there. The images contain color channels we should keep in mind and they are 32x32 images. Hope it made sense to you. Dropout is a regularization technique to avoid overfitting which is also added. Example http cs231n. com c aerial cactus identification overview. Import Libraries Loading Training Data EDAThe train data contains 17500 images which can be found in a seperate directory also we have a csv file but we can t directly visualize them as we ll see later. Step 1 First up we define a custom class that extends PyTorch s torch. jpg In this notebook we ll train a CNN to classify images based on whether they have a columnar cactus or not. Here we conert it to a PIL image first. png The depth of each consecutive convolutional layers may increase resulting in the networks capturing some incredibly complex features patterns from the images. There are also alternatives to Pooling like Capsule Networks which is out of the score of this kernel. Now that you understand how a CNN works everything is pretty much self explanatory. Conv2d to know more about the parameters. We ve achieved state of the art results as promised. If we do the same for color images we throw away vital information by flattening it which almost never works for real world images. Setting up Train Data for Pytorch We cannot simply use the raw image data to make predictions using PyTorch. However we still need to convert it to a tensor and normalize it. I encourage you to go out and explore on your own to find those awesome stuff. Example https github. This is because augmentation is only done on the training set to improve the performance by giving our model complex variations that might make it generalize well to new samples on the test set so it doesn t make sense to do data augmentation on the test data as well. Viewing an Image in More DetailHere we look at the normalized red green and blue RGB color channels as three separate grayscale intensity images for illustration purposes. As you might have guessed already color images are actually three dimensional where Greyscale images for example are 1D. Make Predictions on Test Set If you like this kernel or wish to fork it please give it an UPVOTE to show your appreciation. The outputs here don t need to be 0 or 1 what Kaggle expects is the probabilities so we don t need an activation function like sigmoid on the output layer. There is also average pooling which you may see out on the wild. png Convolutional Layer Turns out that in order to understand Convolutional layer first we have to understand a concept called Filters. 03 pm screen shot 2018 05 31 at 3. Note that these images are very low inresolution yet as humans we have evolved in such a way to make sense of even these kind of pictures. com abhinand05 linear algebra data processing CSV file I O e. io assets cnn convnet. 77 million colors which is awesome. For this we first contstruct a filter according to a size called window size which is nothing but a matrix like this. These filters produce an output that shows edges of objects and differing textures. Convolutional Layers Pooling Layers Fully Connected LayersWe ll go over each one of there layers in great detail. Finally we ll get the best model params learned. We can make an iterator with iter trainloader that can help us grab data. There are sevaral transformations that can be applied for which you may want to have a look at the documentation here https pytorch. Unlike MLPs CNNs actually understand the information from pixels that are in close proximity to each other and are more related to each other than those pixels that are far apart and unrelated. Note that we don t augment our data on the training set. In the next steps we use the torch. 36 pm screen shot 2018 05 31 at 2. When we take the maximum element from the window it is known as Max Pooling which is the most common pooling technique. Transforms We can use the transforms feature in PyTorch to apply Data Augmentations which help us improve the accuracy of our model when done right. Example https media. There is much more happening behind the scenes which I skipped. Expecially high pass filters. MNIST dataset is an exception as it comes already well processed. Multi Layer Perceptrons MLP Vs Convolutional Neural Networks CNN As you might have seen in my previous tutorial https www. png raw true So all it sees is a vector and treats it just as a vector with no special structure. Here is an illustration which you might find helpful. Creating our Dataset We then use our CreateDataset class to covert the raw data in the way PyTorch expects. An even more refined form is passed on to FC layers to make the final prediction. png In the example shown 4 different filters produce 4 differently filtered output images. Pooling Layer Pooling is used in Convolutional Neural Networks to make the detection of certain features somewhat invariant to scale and orientation changes. We define the convolutional layers first. Our image RGB has 3 channels so depth 3 that s why our first conv layer has 3 incoming channels I ve decided to have 16 filters for the first conv layer so out_channels 16 as it produces 16 different filters the kernel size aka window size is set to 3 with padding 1 which makes up extra spaces on the edges of the image to help the 3x3 kernel slide over all the edge pixels of the image in case of size mismatch. Visualize ImagesVisualizing the images and inspecting them to get a better idea of what they are is always helpful before going on the construct our model to make predictions. But let me just explain one. The convolutional layer is produced by applying a series of many different image filters also known as convolutional kernels to an input image. Another way of thinking about what pooling does is that it generalizes over lower level more complex information. Here comes our final model. Here in an example gif. So this is a perfect beginners competition as someone rightly said in the discussion forums. Random horizontal flipping of sample images is applied along with random rotation of 10 degrees for random training examples. Larger value means brighter lower means darker. This is called skewed classes we can use data augmentation sampling and several ways to overcome this. Then the percentage of data needed for validation is set to 20 which almost always seem to work for me. 07 pm screen shot 2018 05 31 at 3. read_csv OpenCV Image Library Import PyTorch Counting the number of sample data for each class Data paths Our own custom class for datasets Set Batch Size Percentage of training set to use as validation obtain training indices that will be used for validation Create Samplers prepare data loaders combine dataset and sampler creating test data prepare the test loader unnormalize convert from Tensor image and display obtain one batch of training images convert images to numpy for display plot the images in the batch along with the corresponding labels display 20 images Convolutional Layer sees 32x32x3 image tensor Convolutional Layer sees 16x16x16 image tensor Convolutional Layer sees 8x8x32 image tensor Convolutional Layer sees 4 4 64 image tensor Maxpooling Layer Linear Fully Connected Layer 1 sees 2 2 128 image tensor Linear FC Layer 2 Set Dropout add sequence of convolutional and max pooling layers flatten image input add dropout layer add 1st hidden layer with relu activation function add dropout layer add 2nd hidden layer with relu activation function check if CUDA is available create a complete CNN Move model to GPU if available specify loss function categorical cross entropy loss specify optimizer number of epochs to train the model track change in validation loss keeping track of losses as it happen keep track of training and validation loss train the model move tensors to GPU if CUDA is available clear the gradients of all optimized variables forward pass compute predicted outputs by passing inputs to the model calculate the batch loss backward pass compute gradient of the loss with respect to model parameters perform a single optimization step parameter update update training loss validate the model move tensors to GPU if CUDA is available forward pass compute predicted outputs by passing inputs to the model calculate the batch loss update average validation loss calculate average losses print training validation statistics save model if validation loss has decreased Load Best parameters learned from training into our model to make predictions later Turn off gradients Create Submission file. com topher 2018 May 5b10729b_screen shot 2018 05 31 at 3. com c aerial cactus identification data. Exactly same as the example gif you saw previously. co ws3htpn 2088474 6a86 3. Later we ll use this to loop through the dataset for training. For more information about the dataset visit this page https www. Image Credits Stanford CS231n Udacity Define the Network ArchitectureHere comes the important part of defining a CNN which will can done using the torch. gif These windows are usually of size 3x3 which helps CNNs identify the patterns in an image. Performance GraphI told you how powerful CNNs are now look at that graph. In fact this is very much similar to how our brains interpret images in an instant. Setting up Test DataThis section of code should make sense to you now. When we combine all three channels we get a color image. Read the docs for nn. Understanding CNNsConolutional Neural Networks make use of three different classes of layers which distinctly differ with each other. We can see aerial images of cactus. To detect changes in intensity in an image we ll be using and creating specific image filters that look at groups of pixels and react to alternating patterns of dark light pixels. I think everything in there is pretty straight forward. org docs stable torchvision transforms. When we stack these images we form a complete convolutional layer with a depth of 4 Example https s3. The test data has 4000 images and it is stored in a seperate directory. com abhinand05 mnist introduction to computervision with pytorch. One way to think about it is that smaller batches means that the number of parameter updates per epoch is greater. Training our CNNNow the training steps are same as that of training an MLP which I explained in a previous kernel. gif When we combine pooling layers with convolutional layers we reduce the dimension of the layers which helps in computation but more than that it picks the pixel values of higher significance. You might also want to use Batch Normalization but I decided not to because I achieved more than 99 accuracy without it. We ll be using PyTorch for this tutorial. There may be several filters in a Convolutional layer. So our model so far looks something like this. co V06mcY0 Intro to Deep Learning with Py Torch Udacity classroom udacity com. It has no knowledge whatsoever of the fact that it was previously arranged in a grid losing important information. This RGB color scheme can represent about 16. I picked this competition because I felt it is the best place for beginners to practice their new found skills with CNNs as MNIST is just way too simple to bring CNNs into play a regular Multi layer perceptron may well do the job. IntroductionIn this notebook we ll go over defining training and testing as well as the pre processing steps needed to feed an image into CNNs to get state of the art results. It is the final piece of the puzzle that makes it special and powerful. The only difference here is that I m saving the model everytime the validation loss decreases. Here in an example gif of Max Pooling. png Fully Connected Layers Fully connected layers are no different from the ones you already know from MLPs. If you like this kernel or wish to fork it please give it an UPVOTE to show your appreciation. As we can see about 2 3 of the training data belongs to one class. However I don t believe that s a problem here as we have enough data for CNNs to get great results. com abhinand05 mnist introduction to computervision with pytorch on MNIST dataset MLPs were good enough to score more than 90 accuracy. The same steps used above are repeated for the test data as well. Authored By Abhinand https www. Note that it doesn t have a csv file as we saw for the train data. Example https s3. Step 2 Now that we ve defined our class it is time to pass the raw data and convert it to PyTorch understandable form. But when combined they give extraordinary results. Everything is put together in a forward propagation function later. We define our constructors and add two different methods len and getitem which essentially replaces the parent definitions. Here we inspect the data to see the amount of training samples for each class. com topher 2018 May 5b1070e4_screen shot 2018 05 31 at 2. Each little square you can see are pixels with their normalized values. The batch size is usually set between 64 and 256. We have the training data passed into the trainloader. PyTorch is a powerful deep learning framework which is rising in popularity and it is thoroughly at home in Python which makes it really easy to learn and use. The outputs are then connected to a FC layer. It turns out that they re nowhere near good enough to achieve similar results on complex datasets mainly because they expect a flattened vector of the original image like the one below. This helps me explain CNNs later. The batch size does have an effect on the final test accuracy. ", "id": "abhinand05/in-depth-guide-to-convolutional-neural-networks", "size": "14423", "language": "python", "html_url": "https://www.kaggle.com/code/abhinand05/in-depth-guide-to-convolutional-neural-networks", "git_url": "https://www.kaggle.com/code/abhinand05/in-depth-guide-to-convolutional-neural-networks", "script": "torch.optim torch.utils.data __init__ DataLoader forward torch.nn numpy __getitem__ matplotlib.pyplot pandas Dataset __len__ imshow torch.nn.functional TensorDataset CreateDataset(Dataset) torch.utils.data.sampler CNN(nn.Module) SubsetRandomSampler torchvision.transforms ", "entities": "(('validation everytime loss', 'decreases'), 'be') (('new tensor', 'metric'), 'be') (('We', 'PyTorch'), 'set') (('Greyscale actually three where images', 'example'), 'be') (('number', 'epoch'), 'be') (('Details', 'comment mostly lines'), 'interpret') (('beginners perfect someone', 'discussion rightly forums'), 'be') (('batch size', 'usually between 64'), 'set') (('filters', 'output'), 'modify') (('you', 'appreciation'), 'give') (('they', 'columnar cactus'), 'jpg') (('First you', '_ _ forward _'), 'define') (('that', 'pixels'), 'understand') (('2018 5b10729b_screen', '2018 05 31 3'), 'com') (('you', 'tutorial https previous www'), 'CNN') (('I', 'awesome stuff'), 'encourage') (('which', 'parent essentially definitions'), 'define') (('So model', 'this'), 'look') (('they', 'predictions'), 'be') (('we', 'output layer'), 'need') (('you', 'already MLPs'), 'be') (('it', 'test data'), 'be') (('it', 'special structure'), 'true') (('then we', 'them'), 'normalize') (('which', 'torch'), 'Credits') (('I', 'which'), 'be') (('May 2018 5b1070e4_screen', '2018 05 31 2'), 'com') (('here it', 'CNNs'), 'jpeg') (('that', 'torch'), 'step') (('it', 'Python'), 'be') (('I', 'Convolutional Neural Network'), 'use') (('outputs', 'FC then layer'), 'connect') (('why they', 'multi dimensional data'), 'cnn') (('we', 't directly them'), 'have') (('Conv2d', 'parameters'), 'know') (('We', 'art results'), 'achieve') (('MNIST', 'well job'), 'pick') (('com', 'enough more than 90 accuracy'), 'be') (('1 which', 'size mismatch'), 'have') (('we', 'section'), 'be') (('then it', 'greatly results'), 'impact') (('us', 'model'), 'transform') (('window where size', '2'), 'go') (('we', 'pictures'), 'note') (('when they', 'extraordinary results'), 'give') (('which', 'scikit'), 'learn') (('even more refined form', 'final prediction'), 'pass') (('first we', 'concept'), 'turn') (('you', 'appreciation'), 'make') (('it', 'understandable form'), 'step') (('they', 'mind'), 'contain') (('here we', 'great results'), 'believe') (('We', 'convolutional layers'), 'define') (('Random horizontal flipping', 'training random examples'), 'apply') (('you', 'normalized values'), 'be') (('time we', 'batch_size'), 'pull') (('we', 'train data'), 'note') (('very much how brains', 'instant'), 'be') (('it', 'lower level more complex information'), 'be') (('about 2 3', 'one class'), 'belong') (('Everything', 'propagation together forward function'), 'put') (('just you', 'end'), 's') (('you', 'wild'), 'be') (('We', 'also transformations'), 'apply') (('that', 'objects'), 'produce') (('window which', 'this'), 'contstruct') (('which', 'kernel'), 'be') (('batch size', 'test final accuracy'), 'have') (('we', 'color image'), 'combine') (('I', 'previous kernel'), 'train') (('4 different filters', 'output 4 differently filtered images'), 'png') (('I', 'it'), 'want') (('you', 'Exactly example gif'), 'same') (('skewed we', 'several this'), 'call') (('CNNs', 'image'), 'be') (('Py Torch Udacity', 'V06mcY0 Deep Learning'), 'Intro') (('depth', 'images'), 'png') (('2018 5b10723a_screen', '2018 05 31 3'), 'com') (('However we', 'it'), 'need') (('notebook we', 'art results'), 'introductionin') (('you', 'which'), 'be') (('convolutional layer', 'input image'), 'produce') (('Convolutional Layers Pooling Layers Connected Fully LayersWe', 'great detail'), 'go') (('PyTorch', 'way'), 'create') (('which', 'distinctly other'), 'make') (('which', 'almost always me'), 'set') (('it', 'important information'), 'have') (('Later we', 'training'), 'use') (('which', 'Max Pooling'), 'know') (('we', 'Example https 4 s3'), 'form') (('which', 'regularization overfitting'), 'be') (('you', 'documentation'), 'be') (('that', 'data'), 'make') (('predictions', 'Create Submission file'), 'count') (('Here we', 'class'), 'inspect') (('detection', 'somewhat invariant scale changes'), 'use') (('how images', 'computers'), 'be') (('We', 'tutorial'), 'use') (('mainly they', 'one'), 'turn') (('We', 'Kaggle competition https currently running www'), 'use') (('same steps', 'test above data'), 'repeat') (('we', 'training set'), 'note') (('Larger value', 'brighter lower means'), 'mean') (('it', 'higher significance'), 'reduce') (('it', 'seperate directory'), 'have') (('which', 'world almost real images'), 'throw') (('We', 'ultimately just that'), 'go') (('we', 'illustration purposes'), 'look') (('it', 'final puzzle'), 'be') (('Setting', 'you'), 'make') (('how CNNs', 'now graph'), 'tell') (('RGB color scheme', 'about 16'), 'represent') (('training data', 'trainloader'), 'have') (('that', 'dark light pixels'), 'detect') (('it', 'CV tutorial https previous introductory www'), 'win') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "apply", "art", "augment", "augmentation", "average", "backward", "batch", "batch_size", "best", "blob", "build", "calculate", "car", "case", "categorical", "check", "classify", "clear", "close", "cnn", "code", "color", "combine", "combined", "comment", "competition", "computation", "compute", "concept", "contain", "conv", "convert", "convolutional", "create", "csv", "custom", "data", "dataset", "define", "depth", "detail", "detect", "detection", "difference", "dimension", "directly", "directory", "display", "edge", "effect", "end", "entropy", "epoch", "even", "everything", "explained", "explore", "fact", "feature", "feed", "file", "fill", "filter", "filtered", "final", "find", "fixed", "form", "forward", "found", "framework", "function", "getitem", "grab", "gradient", "grayscale", "green", "grid", "hand", "help", "high", "http", "https github", "hyperparameter", "idea", "image", "improve", "increase", "input", "intensity", "io", "iter", "kernel", "knowledge", "layer", "learn", "learning", "len", "let", "level", "light", "linear", "little", "loader", "look", "loop", "lower", "matrix", "max", "maximum", "metric", "might", "mind", "mnist", "model", "most", "move", "my", "near", "need", "new", "next", "no", "normalize", "normalized", "not", "notebook", "number", "numpy", "optimization", "optimizer", "order", "orientation", "out", "output", "overfitting", "padding", "page", "parameter", "parent", "part", "per", "percentage", "perform", "performance", "pixel", "place", "plot", "png", "pooling", "practice", "pre", "prepare", "print", "problem", "processing", "propagation", "pytorch", "random", "raw", "re", "reduce", "regularization", "running", "sample", "sampler", "sampling", "save", "saving", "scale", "scikit", "score", "screen", "section", "sense", "separate", "sequence", "set", "several", "sigmoid", "similar", "single", "size", "slide", "something", "special", "split", "square", "stack", "state", "step", "stride", "technique", "tensor", "test", "testing", "think", "those", "through", "time", "torchvision", "track", "train", "training", "tutorial", "type", "up", "update", "validate", "validation", "value", "vector", "visit", "visualize", "window", "work", "world"], "potential_description_queries_len": 218, "potential_script_queries": ["forward", "imshow", "nn", "torch"], "potential_script_queries_len": 4, "potential_entities_queries": ["competition", "filtered", "forward", "light", "random", "scale"], "potential_entities_queries_len": 6, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 220}
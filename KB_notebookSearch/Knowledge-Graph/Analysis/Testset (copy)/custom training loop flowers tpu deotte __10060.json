{"name": "custom training loop flowers tpu deotte ", "full_name": " h2 my tests h1 TPU or GPU detection h1 Competition data access h1 Configuration h2 Visualization utilities h1 AugMix h1 Deotte s spatial transforms h1 Datasets h1 Dataset visualizations h1 Keras training h2 Model h2 Training h1 Custom training loop h2 Model h2 Step functions h2 Training loop h1 distribute the datset according to the strategy h1 Optimized custom training loop h2 Model h2 Step functions h2 Training loop h1 Confusion matrix h1 test val on ext datasets h1 Predictions h1 Visual validation h1 Timing summary ", "stargazers_count": 0, "forks_count": 0, "description": "my tests ex1 base with ep18 EN B5 aug rndflip time 46. scope pretrained_model tf. LearningRateSchedule def __call__ self step return lrfn epoch step STEPS_PER_EPOCH optimizer tf. Interpolate Interpolation means we always stay within 0 and 255. loss_fn lambda a b tf. SparseCategoricalAccuracy train_loss tf. format epoch_time loss 0. sum n Peek at training data run this cell again for next set of images peer at test data run this cell again for next set of images False transfer learning True fine tuning Instiate optimizer with learning rate schedule this also works but is not very readable Instantiate metrics Loss The recommendation from the Tensorflow custom training loop documentation is loss_fn lambda a b tf. Dense len CLASSES activation softmax model. numpy history. For optimal performance reading from multiple files at once and disregarding data order. AugMix Deotte s spatial transforms Datasets Dataset visualizations Keras training Modelwith strategy. summary Trainingstart_time time. However whith the setting Tensorflow produces batches of a known size and although XLA the TPU compiler can now handle variable batches it is slightly faster on fixed batches. history val_loss loss 211 display_training_curves history. reset_states if epoch EPOCHS break simple_ctl_training_time time. disable order increase speed automatically interleaves reads from multiple files uses data as soon as it streams in rather than in its original order returns a dataset of image label pairs if labeled True or image id pairs if labeled False data augmentation. Works on CPU and single GPU. 940 maybe restore best weights B5 224x224 ep30 f1 score 0. Losses are reported through Keras metrics. time epoch_start_time print nEPOCH d d. GlobalAveragePooling2D tf. update_state loss tf. The value of addition is between 128 and 128. history sparse_categorical_accuracy history. is there any better way than manually typing all of these conditions I tried to randomly select transformation from array of functions but tensorflow didn t let me to you can play with these parameters level of transformations as described above in transformations integer from 1 to 10 number of different chains of transformations to be mixed number of transformations in one chain 1 means random from 1 to 3 returns 3x3 transformmatrix which transforms indicies CONVERT DEGREES TO RADIANS ROTATION MATRIX SHEAR MATRIX ZOOM MATRIX SHIFT MATRIX input image is one image of size dim dim 3 not a batch of b dim dim 3 output image randomly rotated sheared zoomed and shifted fix for size 331 GET TRANSFORMATION MATRIX LIST DESTINATION PIXEL INDICES ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS FIND ORIGIN PIXEL VALUES convert image to floats in 0 1 range explicit size needed for TPU tf. the training dataset must repeat for several epochs slighly faster with fixed tensor sizes prefetch next batch while training autotune prefetch buffer size slighly faster with fixed tensor sizes prefetch next batch while training autotune prefetch buffer size prefetch next batch while training autotune prefetch buffer size def count_data_items filenames n int re. Order does not matter since we will be shuffling the data anyway. to compute mins and maxes. The loop will be compiled to thanks to tf. Since the iterator is passed into the step function which is then compiled for TPU thanks to tf. This could change numerics. On the validation dataset this setting can drop some validation images. range in the step function. GradientTape as tape probabilities model images training True loss loss_fn labels probabilities grads tape. tfrec TRAINING_FILENAMES_OX predictions on this dataset should be submitted for the competition 00 09 10 19 20 29 30 39 40 49 50 59 60 69 70 79 80 89 90 99 100 102 Learning rate schedule for TPU GPU and CPU. Compute the cumulative sum shifting by step 2 and then normalization by step. It is not the case here because the validation dataset happens to contain an integral number of batches. Using a custom training loop1. Sum loss as recommended by the custom training loop Tensorflow documentation https www. history val_sparse_categorical_accuracy accuracy 212 Custom training loop Modelwith strategy. Otherwise build lut from the full histogram and step and then index from it. glob GCS_PATH val. convert degrees to radians define rotation matrix For each pixel in the image select the pixel if the value is less than the threshold. range aggregating losses returned from multiple batches becomes impractical. tfrec TRAINING_FILENAMES_IN17 TRAINING_FILENAMES_IN18 TRAINING_FILENAMES_IN19 TRAINING_FILENAMES_TF TRAINING_FILENAMES_OX else TRAINING_FILENAMES tf. format keras_fit_training_time display_training_curves history. numpy VALIDATION_STEPS report metrics epoch_time time. 949 21sec ep B7 512x512 ep30 fail in ep2 test val on ext datasets B0 std train ep20 in17 in18 in19 ox tf IN17 18 19 Predictions Visual validation Timing summary Detect hardware return appropriate distribution strategy TPU detection. It is possible to return values from step function and return losses in that way. prefetch AUTO statement in the next function below this happens essentially for free on TPU. numpy and matplotlib defaults binary string in this case these are image ID strings If no labels only image IDs return None for labels this is the case for test data data auto squaring this will drop data that does not fit into square or square ish rectangle size and spacing display magic formula tested to work from 1x1 to 10x10 images set up the subplots on the first call input image is one image of size dim dim 3 not a batch of b dim dim 3 fix for size 331 ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS FIND ORIGIN PIXEL VALUES Do addition in float. Extrapolate We need to clip and then cast. update_state labels probabilities train_loss. However in the optimized version of the custom training loop using tf. Shift lut prepending with 0. Using a repeated validation set instead. Sequential pretrained_model tf. 372e 05 steps val_steps 99 29 V1 deotte ep 30 dd 4 augmix ep 30 dd TPU or GPU detection Competition data accessTPUs read data directly from Google Cloud Storage GCS. available image sizes if not SKIP_VALIDATION TRAINING_FILENAMES tf. Thanks to the dataset. history val_loss 1 val_acc 0. append train_accuracy. Using an LR ramp up because fine tuning a pre trained model. For each pixel in the image less than threshold we add addition amount to it and then clip the pixel value to be between 0 and 255. Data pipeline code is executed on the CPU part of the TPU while the TPU itself is computing gradients. SparseCategoricalAccuracy valid_accuracy tf. format simple_ctl_training_time display_training_curves history. The validation dataset iterator is not reset between validation runs. apply_gradients zip grads model. Assumes RGB for now. trainable True False transfer learning True fine tuning model tf. Sum valid_loss tf. 932B3 224x224 ep30 f1 score 0. Configuration Visualization utilitiesdata pixels nothing of much interest for the machine learning practitioner in this section. time distribute the datset according to the strategytrain_dist_ds strategy. experimental_distribute_dataset get_training_dataset valid_dist_ds strategy. Optimizations specific to the TPU optimized custom training loop The training and validation step functions run multiple batches at once. history val_sparse_categorical_accuracy 1 lr 0. Adam learning_rate lambda lrfn tf. Using a custom training loop specifically optimized for TPU Optimization that benefit all three models use dataset. This is achieved by placing a loop using tf. time start_timeprint KERAS FIT TRAINING TIME 0. you can list the bucket with gsutil ls GCS_DS_PATH At this size a GPU will run out of memory. It happens that in this example the validation dataset is used exactly once per validation. fit whre the recommendation is to use a non repeating validation dataset run training step validation run at the end of each epoch validation run compute metrics report metrics set up next epoch since we are splitting the dataset and iterating separately on images and labels order matters. Otherwise subtract 255 from the pixel. If you have multiple datasets attached to the notebook you can pass the name of a specific dataset to the get_gcs_path function. fit the validation data iterator is repeated and it is not reset for each validation run different from model. A possibly cheaper version can be done using cumsum unique_with_counts over the histogram values rather than iterating over the entire image. all in one batch run this cell again for next set of images. compile r 0 9. With a validation at the end of every epoch this would be slow. This is done in the C code for image. reset_states valid_accuracy. No parameters necessary if TPU_NAME environment variable is set. the training data iterator is repeated and it is not reset for each validation run same as model. get everything as one batch normalized since we are splitting the dataset and iterating separately on images and ids order matters. Starting with a high LR would break the pre trained weights. function and executed on TPU. Compute the histogram of the image channel. compile optimizer adam loss sparse_categorical_crossentropy metrics sparse_categorical_accuracy lr_callback tf. experimental_distribute_dataset get_validation_dataset print Steps per epoch STEPS_PER_EPOCH History namedtuple History history history History history loss val_loss sparse_categorical_accuracy val_sparse_categorical_accuracy epoch 0for step images labels in enumerate train_dist_ds run training step strategy. batch BATCH_SIZE drop_remainder True The training dataset is infinitely repeated so drop_remainder True should not be needed. trainable_variables optimizer. Use ls kaggle input to list attached datasets. sparse_categorical_crossentropy a b global_batch_size BATCH_SIZE Step functions tf. update_state loss Training loopstart_time epoch_start_time time. The validation dataset is made to repeat indefinitely because handling end of dataset exception in a TPU loop implemented with tf. string means bytestring shape means single element class is missing this competitions s challenge is to predict flower classes for the test dataset returns a dataset of image s Read from TFRecords. functiondef train_step images labels with tf. Xception weights imagenet include_top False input_shape IMAGE_SIZE 3 pretrained_model. numpy STEPS_PER_EPOCH history. format lrfn epoch flush True set up next epoch epoch step 1 STEPS_PER_EPOCH epoch_start_time time. history sparse_categorical_accuracy 1 val_loss 0. sparse_categorical_crossentropy a b global_batch_size BATCH_SIZE https www. float32 STEPS_PER_EPOCH Instantiate metrics train_accuracy tf. experimental_run_v2 valid_step args image labels print end flush True compute metrics history. Scale the image making the lowest value 0 and the highest value 255. update_state labels probabilities valid_loss. If step is zero return the original image. glob GCS_PATH train. On Kaggle this is always the case. org tutorials distribute custom_training define_the_loss_function This works too and shifts all the averaging to the training loop which is easier update metrics this loop runs on the TPU update metrics this loop runs on the TPU distribute the datset according to the strategy Hitting End Of Dataset exceptions is a problem in this setup. org tutorials distribute custom_training define_the_loss_function Here a simpler loss_fn tf. Scales each channel independently and then stacks the result. tfrec TRAINING_FILENAMES_IN17 TRAINING_FILENAMES_IN18 TRAINING_FILENAMES_IN19 TRAINING_FILENAMES_TF tf. This will introduce a slight inaccuracy because the validation dataset now has some repeated elements. compute_average_loss tf. reset_states valid_loss. history sparse_categorical_accuracy. history val_sparse_categorical_accuracy. This notebooks shows three ways of training a model on TPU 1. sparse_categorical_crossentropy would work the same. fit get_training_dataset steps_per_epoch STEPS_PER_EPOCH epochs EPOCHS validation_data get_validation_dataset callbacks lr_callback keras_fit_training_time time. For the purposes of computing the step filter out the nonzeros. group 1 for filename in filenames return np. trainable_variables update metrics train_accuracy. history val_sparse_categorical_accuracy accuracy 212 Optimized custom training loopOptimized by calling the TPU less often and performing more steps per call Model Step functions Training loop Confusion matrixB0 224x224 ep30 f1 score 0. range is not yet possible. string means bytestring shape means single element returns a dataset of image label pairs tf. Validation is adjusted to always use exactly or more than the entire validation dataset. reset_states train_loss. Clip the counts to be in range. Using Keras and model. The name of the dataset is the name of the directory it is mounted in. experimental_run_v2 train_step args images labels print end flush True validation run at the end of each epoch if step 1 STEPS_PER_EPOCH epoch print end flush True validation run for image labels in valid_dist_ds strategy. functiondef valid_step images labels probabilities model images training False loss loss_fn labels probabilities update metrics valid_accuracy. Adam learning_rate LRSchedule this also works but is not very readable optimizer tf. history loss 1 accuracy 0. default distribution strategy in Tensorflow. history loss history. time train_accuracy. function passing a fresh iterator for every validation run would trigger a fresh recompilation. format epoch 1 EPOCHS print time 0. 939B5 331x331 ep30 f1 score 0. LearningRateScheduler lrfn verbose True model. time history model. For GPU training please select 224 x 224 px image size. This Kaggle utility will copy the dataset to a GCS bucket co located with the TPU. time start_timeprint SIMPLE CTL TRAINING TIME 0. summary Instiate optimizer with learning rate schedule class LRSchedule tf. append valid_accuracy. 68e 05 steps val_steps 99 29 ex2 ep 30 abort error after ep 21 time 46. ", "id": "romanweilguny/custom-training-loop-flowers-tpu-deotte", "size": "10060", "language": "python", "html_url": "https://www.kaggle.com/code/romanweilguny/custom-training-loop-flowers-tpu-deotte", "git_url": "https://www.kaggle.com/code/romanweilguny/custom-training-loop-flowers-tpu-deotte", "script": "scale_values sklearn.metrics train_step rotate int_parameter equalize load_dataset autocontrast pyplot as plt transformDeotteSpacial solarize shear_x recall_score precision_score lrfn efficientnet.tfkeras collections pyplot numpy get_validation_dataset get_training_dataset float_parameter display_confusion_matrix color affine_transform read_unlabeled_tfrecord substract_means display_one_flower solarize_add batch_to_numpy_images_and_labels shear_y inner_loop_cond data_augment display_batch_of_images get_test_dataset count_data_items confusion_matrix f1_score outer_loop_body get_mat brightness apply_op outer_loop_cond decode_image read_labeled_tfrecord tensorflow int_div_round_up kaggle_datasets sample_level inner_loop_body train_step_fn title_from_label_and_target translate_x resize augmix valid_step LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule) posterize normalize contrast display_training_curves scale_channel namedtuple KaggleDatasets matplotlib __call__ build_lut translate_y valid_step_fn blend ", "entities": "(('value', 'addition'), 'be') (('val_loss', '211'), 'history') (('value', 'threshold'), 'define') (('Starting', 'pre trained weights'), 'break') (('experimental_run_v2 valid_step args image labels print end', 'compute metrics True history'), 'flush') (('challenge', 'TFRecords'), 'mean') (('we', 'data'), 'matter') (('TPU', 'gradients'), 'execute') (('V1 deotte dd GPU detection Competition data 05 99 29 ep 30 dd 4 augmix 30 accessTPUs', 'Google Cloud Storage directly GCS'), 'step') (('three models', 'use dataset'), 'use') (('org tutorials', 'custom_training define_the_loss_function'), 'distribute') (('loss loss_fn labels False probabilities', 'metrics valid_accuracy'), 'label') (('format', 'keras_fit_training_time history'), 'display_training_curve') (('Instantiate metrics also very readable recommendation', 'Tensorflow custom training loop documentation'), 'run') (('group', 'np'), 'return') (('validation', 'now repeated elements'), 'introduce') (('loop', 'tf'), 'compile') (('ORIGIN PIXEL VALUES', 'float'), 'default') (('True loss loss_fn labels probabilities', 'tape'), 'grad') (('trainable_variables', 'metrics train_accuracy'), 'update') (('This', 'tf'), 'achieve') (('Losses', 'Keras metrics'), 'report') (('LearningRateScheduler lrfn', 'True model'), 'verbose') (('next epoch we', 'separately images'), 'be') (('in19 18 Predictions validation Timing summary Detect ox tf 19 Visual hardware', 'distribution strategy TPU appropriate detection'), 'b7') (('ids order', 'separately images'), 'get') (('STEPS_PER_EPOCH namedtuple History history History history 0for step images History sparse_categorical_accuracy labels', 'train_dist_ds training step enumerate strategy'), 'step') (('Hitting End', 'setup'), 'distribute') (('this', 'epoch'), 'be') (('notebooks', 'TPU'), 'show') (('optimal performance', 'data order'), 'for') (('it', 'slightly fixed batches'), 'whith') (('ORIGIN PIXEL VALUES', 'tf'), 'be') (('step', 'zero original image'), 'return') (('training dataset', 'prefetch buffer def count_data_items next batch autotune size filenames'), 're') (('which', 'thanks tf'), 'pass') (('all', 'images'), 'run') (('validation dataset', 'tf'), 'make') (('prefetch', 'essentially free TPU'), 'happen') (('range', 'multiple batches'), 'become') (('validation', 'different model'), 'fit') (('function', 'fresh recompilation'), 'trigger') (('possibly cheaper version', 'rather entire image'), 'do') (('as soon it', 'data False augmentation'), 'return') (('it', 'directory'), 'be') (('Validation', 'validation entire dataset'), 'adjust') (('we', '0'), 'add') (('custom training step optimized training functions', 'multiple batches'), 'loop') (('you', 'get_gcs_path function'), 'pass') (('STEPS_PER_EPOCH epoch print step 1 end', 'valid_dist_ds strategy'), 'label') (('single element', 'image label pairs'), 'mean') (('TRAINING_FILENAMES_OX tfrec predictions', 'TPU GPU'), 'submit') (('validation', 'same model'), 'repeat') (('Configuration Visualization utilitiesdata', 'section'), 'pixel') (('It', 'way'), 'be') (('validation dataset iterator', 'validation runs'), 'reset') (('Datasets Dataset visualizations Keras', 'strategy'), 'AugMix') (('validation dataset', 'exactly once validation'), 'happen') (('drop_remainder infinitely True', 'BATCH_SIZE drop_remainder'), 'batch') (('we', 'always 0'), 'mean') (('format', 'lrfn True'), 'flush') (('epoch EPOCHS', 'simple_ctl_training_time time'), 'reset_states') (('validation here dataset', 'batches'), 'be') (('Kaggle utility', 'TPU'), 'copy') (('GPU', 'memory'), 'list') (('time', 'strategytrain_dist_ds strategy'), 'distribute') (('train_step functiondef images', 'tf'), 'label') (('TRAINING_FILENAMES_IN18 TRAINING_FILENAMES_IN19 TRAINING_FILENAMES_TF TRAINING_FILENAMES_OX', 'TRAINING_FILENAMES_IN17'), 'tfrec') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "append", "array", "aug", "auto", "batch", "best", "binary", "build", "call", "case", "cell", "chain", "challenge", "channel", "clip", "code", "competition", "compile", "compiled", "compute", "contain", "convert", "copy", "could", "cumsum", "custom", "data", "dataset", "def", "default", "define", "detection", "dim", "directly", "directory", "display", "distribution", "drop", "end", "enumerate", "environment", "epoch", "error", "every", "everything", "f1", "fail", "faster", "filename", "filter", "fit", "fix", "fixed", "float32", "flower", "format", "formula", "function", "glob", "group", "handle", "high", "histogram", "history", "id", "image", "imagenet", "increase", "index", "input", "int", "integer", "interest", "itself", "kaggle", "label", "labeled", "learning", "learning_rate", "len", "let", "level", "list", "loop", "lr", "lrfn", "lut", "magic", "matplotlib", "matrix", "missing", "mixed", "model", "multiple", "my", "name", "namedtuple", "need", "next", "no", "non", "normalization", "normalized", "not", "notebook", "number", "numpy", "optimizer", "order", "out", "output", "part", "per", "performance", "performing", "pipeline", "pixel", "pre", "predict", "print", "problem", "random", "range", "read", "reading", "recommendation", "report", "reset", "restore", "return", "run", "schedule", "scope", "score", "select", "set", "several", "shape", "single", "size", "softmax", "spatial", "speed", "splitting", "square", "std", "step", "strategy", "string", "subtract", "sum", "summary", "tensor", "tensorflow", "test", "tf", "threshold", "through", "time", "train", "training", "transfer", "transformation", "trigger", "tuning", "up", "update", "val", "validation", "value", "variable", "version", "while", "work", "zip", "zoomed"], "potential_description_queries_len": 177, "potential_script_queries": ["blend", "color", "contrast", "equalize", "matplotlib", "normalize", "plt", "pyplot", "resize", "rotate", "solarize"], "potential_script_queries_len": 11, "potential_entities_queries": ["custom", "dataset", "detection", "enumerate", "fixed", "image", "loop", "next", "size", "strategy", "tf", "validation"], "potential_entities_queries_len": 12, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 185}
{"name": "santander ml explainability ", "full_name": " h3 CLEAR DATA MADE MODEL h2 Notebook Content h2 1 Introduction h2 2 A Data Science Workflow for Santander h2 2 1 Import h2 2 2 Setup h2 2 3 Version h2 3 Problem Definition h3 3 1 Problem Feature h3 3 2 Aim h3 3 3 Variables h2 3 4 evaluation h2 4 Exploratory Data Analysis EDA h2 4 1 Data Collection h1 Reducing memory size by 50 h2 4 1 1Data set fields h2 4 2 2 numerical values Describe h2 4 2 Visualization h2 4 2 1 hist h2 4 2 2 Mean Frequency h2 4 2 3 countplot h2 4 2 4 hist h2 4 2 6 distplot h2 4 2 7 violinplot h2 4 3 Data Preprocessing h2 4 3 1 Check missing data for test train h2 4 3 2 Binary Classification h2 4 3 3 Is data set imbalance h2 4 3 4 skewness and kurtosis h1 5 Machine Learning Explainability for Santander h2 5 1 Permutation Importance h3 Prepare our data for our model h3 Create a sample model to calculate which feature are more important h2 5 2 How to calculate and show importances h3 Here is how to calculate and show importances with the eli5 library h2 5 3 What can be inferred from the above h2 5 4 Partial Dependence Plots h2 5 5 Partial Dependence Plot h2 5 6 Chart analysis h2 5 7 SHAP Values h1 6 Model Development h2 6 1 lightgbm h2 6 2 RandomForestClassifier h2 6 3 DecisionTreeClassifier h2 6 4 CatBoostClassifier h2 6 5 Funny Combine h1 7 References credits ", "stargazers_count": 0, "forks_count": 0, "description": "The features shown in red indicate that they have a negative impact on our prediction1. 6 Model DevelopmentSo far we have used two models and at this point we add another model and we ll be expanding it soon. 4 Exploratory Data Analysis EDA In this section we ll analysis how to use graphical and numerical techniques to begin uncovering the structure of your data. The features that are shown in white indicate that they have no effect on our prediction1. The Goal behind of ML Explainability for Santander is 1. The features that are shown in green indicate that they have a positive impact on our prediction1. com dromosys sctp working lgb https www. References 7 1 IntroductionAt Santander https www. Imbalanced dataset is relevant primarily in the context of supervised machine learning involving two or more classes. How to calculate and show importances 52 1. DeepExplainer works with Deep Learning models. Permutation Importance 51 1. com learn machine learning explainability in Kaggle. org wiki Receiver_operating_characteristic between the predicted probability and the observed target. com arjanso reducing dataframe memory size by 65 1. Affect of each feature on the model s predictions. The y axis is interpreted as change in the prediction from what it would be predicted at the baseline or leftmost value. 5 5 Partial Dependence PlotIn this section we see the impact of the main variables discovered in the previous sections by using the pdpbox https pdpbox. Problem Definition 3 1. com mjbahmani Kaggle https www. Variables 33 1. in this section you will see following model 1. png 4 3 4 skewness and kurtosis 5 Machine Learning Explainability for SantanderIn this section I want to try extract insights from models with the help of this excellent Course https www. In this kernel we are going to create a Machine Learning Explainability for Santander based this perfect course https www. partial plots https www. com dansbecker permutation importance 1. com learn machine learning explainability in kaggle. DecisionTreeClassifier1. Machine Learning Explainability for Santander 5 1. com their mission is to help people and businesses prosper. com arjanso reducing dataframe memory size by 65 Keeps track of columns that have missing values filled in. Find the most inmortant feature in models. com mjbahmani 10 steps to become a data scientist Kaggle https www. 5 2 How to calculate and show importances Here is how to calculate and show importances with the eli5 https eli5. com dansbecker shap values 1. lightgbm 61 1. csv a sample submission file in the correct format. 6 5 Funny Combine you can follow me on GitHub https github. 300 MB before Reducing1. RandomForestClassifier1. com miklgr500 catboost with gridsearch cv 1. com dansbecker permutation importance https www. com brandenkmurray nothing works https www. com gpreda santander eda and prediction https www. A blue shaded area indicates level of confidence 5 7 SHAP Values SHAP SHapley Additive exPlanations is a unified approach to explain the output of any machine learning model. 3 3 VariablesWe are provided with an anonymized dataset containing numeric feature variables the binary target column and a string ID_code column. com brandenkmurray nothing works change 20 to 2000 change 25 to 3000 to get best performance good for submit. com dansbecker partial plots https www. Data Collection 41 1. com brandenkmurray nothing works for get better result chage fold_n to 5 import Dataset to play with it Based on this great kernel https www. 3 4 evaluation Submissions are evaluated on area under the ROC curve http en. Imbalance means that the number of data points available for different the classes is different Image source http api. Visualization 42 1. RandomForestClassifier 62 1. Exclude strings Print current column type make variables for Int max and min Integer does not support NA therefore NA needs to be filled test if column can be converted to an integer Make Integer unsigned Integer datatypes Make float datatypes 32 bit Print new column type Print final result written by MJ Bahmani written by MJ Bahmani for binary target Create the data that we will plot plot it Create the data that we will plot plot it Create the data that we will plot plot it Create the data that we will plot plot it use 1 row of data here. You can see my workflow in the below image You should feel free to adjust this checklist to your needs Go to top top 2 Load packages 2 1 Import 2 2 Setup 2 3 Version 3 Problem DefinitionIn this challenge we should help this bank identify which customers will make a specific transaction in the future irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem. 3 1 Problem Feature1. io en latest library 5 3 What can be inferred from the above 1. CatBoostClassifier 6 1 lightgbm 6 2 RandomForestClassifier 6 3 DecisionTreeClassifier 6 4 CatBoostClassifierNow you can change your model and submit the results of other models. DecisionTreeClassifier 63 1. Partial Dependence Plots 54 1. com dansbecker partial plots For the sake of explanation I use a Decision Tree which you can see below. com dansbecker shap values https www. What can be inferred from the above 53 1. But the SHAP package has explainers for every type of model. The test set contains some rows which are not included in scoring. 6 7 and partial dependence plots are calculated after a model has been fit. com dansbecker partial plots 1. CatBoostClassifier 64 1. The most important feature was Var_110. 7 References creditsThanks fo following kernels that help me to create this kernel. Leaves with children show their splitting criterion on the top1. Notebook Content1. com mjbahmani I hope you find this kernel helpful and some UPVOTES would be very much appreciated. but certainly the importance of each one is different 1. KernelExplainer works with all models though it is slower than other Explainers and it offers an approximation rather than exact Shap values. As you can see from the above we will refer to three important and practical concepts in this section and try to explain each of them in detail. Problem Feature 31 1. com en us azure machine learning studio algorithm choice https docs. com c porto seguro safe driver prediction 4 3 1 Check missing data for test train 4 3 2 Binary Classification 4 3 3 Is data set imbalance A large part of the data is unbalanced but how can we solve it 1. Could use multiple rows if desired package used to calculate Shap values Create object that can calculate shap values Calculate Shap values params is based on following kernel https www. image credits https github. 5 1 Permutation Importance In this section we will answer following question 1. TreeExplainer my_model. last update 10 03 2019You can Fork code and Follow me on GitHub https github. SHAP connects game theory with local explanations uniting several previous methods 1 7 and representing the only possible consistent and locally accurate additive feature attribution method based on expectations see the SHAP NIPS paper for details. com slundberg shap Note Shap can answer to this qeustion how the model works for an individual prediction If you look carefully at the code where we created the SHAP values you ll notice we reference Trees in shap. Funny Combine 65 1. 150 MB after ReducingReducing for train data setReducing for test data set 4 1 1Data set fields 4 2 2 numerical values Describe 4 2 Visualization 4 2 1 hist 4 2 2 Mean Frequency 4 2 3 countplot 4 2 4 histIf you check histogram for all feature you will find that most of them are so similar 4 2 6 distplot The target in data set is imbalance 4 2 7 violinplot 4 3 Data PreprocessingBefore we start this section let me intrduce you some other compitation that they were similar to this 1. Data Preprocessing 43 1. Model Development 6 1. com en us azure machine learning studio algorithm choice 1. What features have the biggest impact on predictions 1. com gpreda santander eda and prediction 1. com miklgr500 catboost with gridsearch cv https www. Load packages 2 1. com arjanso reducing dataframe memory size by 65 kernel https www. 3 2 AimIn this competition The task is to predict the value of target column in the test set. com c home credit default risk1. Extract insights from models. csv the training set. The pair of values at the bottom show the count of True values and False values for the target respectively of data points in that node of the tree. Exploratory Data Analysis EDA 4 1. Note Yes Var_81 are more effective on our model. As you move down the top of the graph the importance of the feature decreases. All features are senseless named. As guidance to read the tree 1. 5 4 Partial Dependence PlotsWhile feature importance shows what variables most affect predictions partial dependence plots show how a feature affects predictions. Data Collection Visualization Data Preprocessing Data Cleaning 4 1 Data Collection Reducing memory size by 50 Because we make a lot of calculations in this kernel we d better reduce the size of the data. com files vvHEZw33BGqEUW8aBYm4epYJWOfSeUBPVQAsgz7aWaNe0pmDBsjgggBxsyq 8VU1FdBshuTDdL2 bp2ALs0E 0kpCV5kVdwu imbdata. com dromosys sctp working lgb 1. Note how to extract insights from models 2 A Data Science Workflow for Santander Of course the same solution can not be provided for all problems so the best way is to create a general framework and adapt it to new problem. com artgor how to not overfit1. how to extract insights from models Prepare our data for our model Create a sample model to calculate which feature are more important. The task is to predict the value of target column in the test set. Santander ML Explainability CLEAR DATA. they are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals. 5 6 Chart analysis1. ", "id": "mjbahmani/santander-ml-explainability", "size": "12611", "language": "python", "html_url": "https://www.kaggle.com/code/mjbahmani/santander-ml-explainability", "git_url": "https://www.kaggle.com/code/mjbahmani/santander-ml-explainability", "script": "sklearn.metrics display sklearn.tree lightgbm pdp pyplot as plt PermutationImportance DecisionTreeClassifier matplotlib.patches seaborn numpy check_missing_data pyplot CatBoostClassifier scipy.stats info_plots sklearn.ensemble get_dataset sklearn.model_selection sklearn RandomForestClassifier matplotlib.pyplot pandas norm eli5.sklearn svm Pool reduce_mem_usage roc_auc_score StratifiedKFold catboost sklearn.svm roc_curve tree matplotlib xgboost check_balance train_test_split pdpbox IPython.display NuSVR ", "entities": "(('we', 'data'), 'EDA') (('What', 'above 1'), 'io') (('how we', 'it'), 'train') (('me', 'kernel'), '7') (('features', 'predictions'), 'have') (('section I', 'Course https excellent www'), 'Explainability') (('it', 'data'), 'make') (('customers', 'money'), 'see') (('nothing', 'https www'), 'work') (('6 1 6 2 3 6 4 you', 'other models'), 'catboostclassifier') (('you', 'feature decreases'), 'move') (('2 task', 'test set'), 'aimin') (('Imbalanced dataset', 'two classes'), 'be') (('it', 'approximation'), 'work') (('how feature', 'predictions'), 'show') (('you', 'which'), 'plot') (('task', 'test set'), 'be') (('we', 'question'), 'Importance') (('5 2', 'eli5 https eli5'), 'be') (('Image different source', 'api'), 'mean') (('we', 'shap'), 'answer') (('we', 'it'), 'use') (('works', 'kernel https great www'), 'brandenkmurray') (('which', 'scoring'), 'contain') (('certainly importance', 'one'), 'be') (('Var_81', 'more model'), 'note') (('What', 'above 53 1'), 'infer') (('SHAP package', 'model'), 'have') (('that', 'values'), 'arjanso') (('Leaves', 'top1'), 'show') (('it', 'baseline'), 'interpret') (('best performance', 'submit'), 'brandenkmurray') (('they', '1'), 'set') (('Calculate Shap values params', 'kernel https www'), 'use') (('so best way', 'new problem'), 'note') (('6 Funny 5 you', 'GitHub https github'), 'Combine') (('DeepExplainer', 'Deep Learning models'), 'work') (('you', 'model'), 'see') (('SHAP', 'NIPS details'), 'see') (('5 Partial Dependence 5 section we', 'pdpbox https pdpbox'), 'PlotIn') (('3 3 VariablesWe', 'target binary column'), 'provide') (('pair', 'tree'), 'show') (('they', 'prediction1'), 'indicate') (('evaluation 3 4 Submissions', 'ROC curve'), 'evaluate') (('we', 'course https perfect www'), 'go') (('SHAP Values SHAP SHapley Additive 5 7 exPlanations', 'machine learning model'), 'indicate') (('we', 'detail'), 'refer') (('we', 'available problem'), 'have') (('Goal', 'Santander'), 'be') (('feature', 'sample model'), 'prepare') (('them', 'monetary goals'), 'look') (('d', 'data'), 'size') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["adjust", "algorithm", "answer", "approach", "area", "bank", "baseline", "become", "best", "binary", "bit", "bottom", "calculate", "catboost", "challenge", "check", "children", "choice", "code", "column", "competition", "confidence", "context", "correct", "count", "countplot", "course", "create", "credit", "criterion", "csv", "current", "curve", "cv", "data", "dataframe", "dataset", "default", "distplot", "eda", "effect", "eli5", "en", "evaluation", "every", "extract", "feature", "file", "final", "find", "float", "following", "framework", "future", "game", "general", "graph", "green", "guidance", "help", "hist", "histogram", "hope", "http", "image", "imbalance", "import", "importance", "indicate", "individual", "integer", "io", "kernel", "learn", "learning", "let", "level", "lgb", "library", "lightgbm", "local", "look", "looking", "lot", "main", "max", "memory", "method", "might", "min", "missing", "model", "most", "move", "multiple", "my", "negative", "new", "no", "node", "not", "number", "numeric", "numerical", "object", "output", "package", "pair", "part", "partial", "pdpbox", "people", "performance", "permutation", "plot", "png", "point", "positive", "predict", "prediction", "probability", "question", "read", "reduce", "reference", "result", "row", "sample", "section", "set", "several", "similar", "size", "solution", "source", "splitting", "start", "string", "structure", "studio", "submission", "supervised", "support", "target", "task", "test", "theory", "track", "train", "training", "transaction", "tree", "try", "type", "under", "update", "value", "workflow"], "potential_description_queries_len": 158, "potential_script_queries": ["display", "matplotlib", "norm", "numpy", "pdp", "plt", "pyplot", "seaborn", "sklearn", "svm", "xgboost"], "potential_script_queries_len": 11, "potential_entities_queries": ["binary", "section"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 165}
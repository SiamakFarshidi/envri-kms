{"name": "aoe project ", "full_name": " h1 Art of Engineering BME Departmental Project h2 Goals h2 Dataset h2 Sections h2 Grading of 100 points h1 Section 1 General functions h3 Checklist h1 Section 2 Simple U Net h1 Section 3 Residual Attention U Net Your part h1 Section 4 Report and submission h3 Submission Checklist h3 Deadline ", "stargazers_count": 0, "forks_count": 0, "description": "This function is a general mode for multi class U Net however we only have one class. Then it will make data loaders for those datasets with the batch size that has been given. In below we implemented the BasicDataset class that does the job. Please read the functions and make sure you understand each line of them. This function will also save dice score and loss value for each individual input in a. To do so we need a BasicDataset instance that reads an image and respective segmentation mask. The following code blocks are just a draft for you to have some hints about what you need to do. gaussian_laplace ground 1 a cv2. com xiaopeng liao Pytorch UNet commit 8ebac70e633bac59fc22bb5195e513d5832fb3bd Input has three channels and we have one class to be segmented cell In fact we have two classes cells and background but with a probability between 0 to 1 we may seperate those. Consider this both in the implementations and final report. edu Hengda hh2699 columbia. Proper citing is a must if you are using other papers or codes publicly available. Take advantage of Markdown blocks to explain what you are trying to do in the next code block. Time to train our U Net using the train_net function for 10 epochs When the training is finished we may plot the training curve of our simple U Net using plot_learning_curve function. The report must include these sections 1. Does not maxpool different than previously definied down block for regular UNet Upscale then convolution batch normalization ReLU F_g F_l in the application g1 x1 ends up highlighting the convolution even more Attention block is only used when upscaling encoding path Maxpool is done in it s own function decoding concat path Train your model for as many epochs as you like be careful that the training should finish within the 9 hour session limitation you have. Deadline December 17 2020 11 59 pm EST Write yours and your teammates name s and UNI s like Joonsoo Lee jl5062 in here. If you are using the general function they are saved in the model s directory in Kaggle working model name model name _ figure name. Then make a binary map to be passed to dice_coeff_binary function Skip if there are no pixel assigned to class j neither on estimate nor on true mask. Furthermore if you wish to use other resources other than other students code please cite their work properly. If you wish to change your loss function or learning rate scheduler you need to modify this function. Innovative approaches i. png format with the size of 512 times512 pixels. Furthermore you can implement any kinds of preprocessing you wish to do in this implementation. Implement a Residual Attention U Net https arxiv. Free free to add remove edit or re write any part of it. Conv2d Convert weights to numpy array assumtion that number of filters are n 2 Get filters weidth and hights Compute sqrt of total filters to plot first nxn filters only Visualization reasons Take minimum and maximum values to display filters weights in a compareable way idx is just a counter Dont forget to convert CHW to HWC leave the function early if bilinear use the normal convolutions to reduce the number of channels input is CHW if you have padding issues see https github. Please choose meaningful names for your variables. This function returns the lenght of the dataset AKA number of samples in that set This function takes an index i which is between 0 to len BasicDataset The return of the previous function then returns RGB image mask Binary and the index of the file name Which we will use for visualization. Besides the few samples visualization which serves as a qualitative assessment we need to present some quantitative statistical analysis using the statistical_report function. Unfortunately because it is almost impossible to make a function that visualizes the weights of all possible models this function will only work for our Simple U Net example. json for further visualization. THRESH_BINARY maxval 1 b cv2. General functions for making dataset of train validation and test sets train the model save its weights plotting the learning curve and test the model on the test set and present the statistical results. Comment on your codes properly. This function will take the model net the number of epochs we would like to train our model epochs batch size batch_size and learning rate lr. threshold src LoG thresh 0. Its score varies from 0. However the MNIST dataset is relatively small and it was possible to do so. According to the test set s dice scores the plot_best_worst_samples function is designed to display five of the best and worst segmentation masks. This function is essentially our training core. Before moving on let s look into the number of samples we have for the train validate and test our models. The final general function is statistical_report that takes the model net and look for all the predicted masks for the test set and compares it with the True masks to print the Sensitivity Recall Precision F1 score https en. Then we add this sample to the original sample given to the function and output it. Feel free to use general functions defined in Section 1 or write your version of the training validation testing procedure. 2d convolution then batch normalization then ReLU then 2d convolution again then batch normilization again then ReLU. Successful results 35 points3. 5 it can be changed. com soroush361 singlecellsegmentation Add First we need to import all the packages we will need during the implementations. Both RGB and segmentation masks are in. The SingleCellSegmentation is larger than the MNIST and we need to read each image batch at a time and train validate test our model and then move to the next image batch. Don t forget that we need to reverse some of the preprocessing steps In the lectures we discussed some segmentation metrics. This function takes folder name train valid test as input and creates an instance of BasicDataset according to that fodler. Then we will print architecture. Submission Checklist Make sure you ve written your name s Make sure you save your Notebook correctly and it contains your notes codes and figures. 05548 paper and implement their proposed architecture. Additionally this function will save the predicted masks in model_name pred_mask directory with a file format of pred_mask_x. Important In order to use previously defined functions we need to have a name and n_classes property for our model. A quick reminder the input of both Loss functions CrossEntropyLoss and BCEWithLogitsLoss doesn t need to be normalized softmax is internally implemented in loss Load a batch and pass it to the device CPU or GPU Produce the estimated mask using current weights Compute the loss We need to multiply by batch_size since the batch_loss is the average of the loss over all samples in the batch If it s a ulti class segmentation the predicted mask would be made by passing the network output through a softmax convert it to probabliti between 0 and 1 then take the maximum value index over the channel axis as the final label. Art of Engineering BME Departmental Project Goals 1. We will utilize previously defined functions to test our best U net model on the test set and show its performance by reporting the statistical measures. Present the statistical analysis and model s performance. This will speed up the process and cause it to consume less memory. Click on Add button. This document will use Pytorch and Pytroch s inputs shape format is Channels Width Height rather than Width Height Channels we changed the image axis as well. This function will create a directory in kaggle working directory with the model name to save model weight at the end of each epoch as well as a training summary that contains training validation losses and dice scores in a. Therefore only BCEWithLogitsLoss will be used. In this project we are more interested in DICE score https en. png def my_loss ground pred LoG nd. 05548 to segment single cells using fluorescence widefield microscopy images. From opened window click on Search by URL3. In case of binary segmentation we need to pass values one channel output of the network through the Sigmoid function values between 0 and 1 then threshold it by 0. json file model_name model_name_TrainingSummary. Don t forget that your worst try is always better than cheating. Your implementation of Residual Attention U Net https arxiv. Furthermore this function will display the confusion matrix for the test set. png where the x is the input index. Please don t share the dataset with anyone else other than students in the class. You can change the probablity threshold Since the batch size is 1 you don t need to loop over the samples in the batch Save predicted mask First we need to remove batch and channel axis Knowing the batch size is one during test and then convert it to numpy After that we need to convert the dynamic range from 0 1 to 0 255 to save the predicted mask Now we use openCV to save our predicted mask with the name of the original image index Save testset dice score and loss value per each sample in a json file Sort based on dice scores print test_resuls. Section 3 Residual Attention U Net Your part In this section you are required to read Segmentation with Residual Attention U Net and an Edge Enhancement Approach Preserves Cell Shape Features https arxiv. Learn how to train and test a U Net. Make sure the GPU accelerator is selected. DatasetThe dataset consists of three folders named train valid and test that is for training validation and testing the model. How to add the Dataset 1. In addition all further plots will also be saved in this directory. Loop over samples in the batch Binary segmentation Automatically the background will be disregarded Multi class segmentation Skip 0 index as background Pick up all the pixels in both Ground Truth and estimated mask that has been assigned as class j. In addition we scaled the intensities from 0 255 to 0 1. The out put would be a numpy array with shape Batch that contains Dice score for each sample in the batch. You can change the probablity threshold Loop over the dice scores of all the samples in the batch Reset gradient values Compute the backward losses Clip gradient to avoid sudden changes Update weights This part is almost the same as training with the difference that we will set all layers to evaluation mode effects some layers such as BN and Dropout and also we don t need to calculate the gradient since we are only evaluating current state of the model. org wiki S C3 B8rensen E2 80 93Dice_coefficient metric. Decoding layers Up is an upsampling block that upsamples the input then pass it through a DoubleConv. Use this as an example to understand how you can create your own version of this function as it is requested to visualize your implementation s weights. items Don t forgt to resize the images like what we did in the Dataset implementation BGR to RGB Turn off gradients Search in all layers in the network However only the first convolution layer will be shown Check if that layer m is an instance of nn. Report and submission. com milesial Pytorch UNetPlease cite their work if you would use these functions in the future. Here we only visualize the first layer s weights using plot_weights_UNet function. The preprocessing step is also implemented in this function. edu along with your copy of this Notebook in. RGB images are named by integer numbers for trainset image_0001 to image_4140 for validation set image_0001 to image_1380 and for test set image_0001 to image_2070. Search for https www. 04597 and its results as an example. 0 for perfect overlap. Read this function thoroughly and make sure you understand most of it. Acknowledgment Most of the following implementations are a modified version of this repository https github. It trains the model for the given number of epochs and updates the weights and learning rate schedular. However in both scenarios it will be Cross Entropy. If you have any questions reach to CAs via email Soroush sa3617 columbia. DoubleCov is block that contains these layers Conv2d BatchNormalization ReLU Conv2d BatchNormalization ReLU Down is a downsampling block which contains Maxpooling and DoubleConv after Maxpooling. html and then submit the PDF version of it via CourseWorks https courseworks2. Extra 20 points Section 1 General functionsIn this section we implemented few functions to make reading the dataset training validating and saving the model testing and generating the results and presenting the statistical analysis easy for you. For example in this class we resized the resolutions to 256 times256 pixels to speed up the training process and reduce memory consumption. Section 4 Report and submissionPlease write a short report about your implementation and analyze your result in an IEEE conference paper template https www. Now that the test set predicted mask is saved we may show top five best and works cases in the test set usine plot_best_worst_samples function. com soroush361 singlecellsegmentation 4. Please don t copy other teams code. After training the model we are usually interested in looking at the learning curve Similar to what you had seen in the First Tutorial. com HaiyongJiang U Net Pytorch Unstructured Buggy commit 0e854509c2cea854e247a9c615f175f76fbb2e3a https github. org wiki Sensitivity_and_specificity. Then produce the predicted masks for the test set and analyze the performance of your implementation. Till Now we only defined our architecture here we need to make an instance of it and set its initial arguments. Let s test our trained U Net on the test set using test_net function. org conferences publishing templates. Learn how to implement a simple U Net. Checklist Make sure the session is started. Similarly the segmentation masks are mask_0001 to mask_x where x depends on the number of samples in the set. Grading of 100 points 1. edu or ask your questions during lecture office hours. Section 2 Simple U NetThis section will implement a simple U Net then train and validate it on the given dataset. Finally this function will print average and standard deviation on loss values and dice scores on the test set. Also let s check if our BasicDataset implementation works by pulling out a random sample of the training set. Important You are absolutely welcomed to use the paper s GitHub repository https github. org wiki Sensitivity_and_specificity and average accuracy https en. This function will take some time to finish its job The final step would be investigating visualizing the weights of our trained Simple U Net. changing loss function new preprocessing pipeline edge enhancment etc. Now we build our U Net using the blocks we defined above. An implementation of simple U Net https arxiv. The test_net function will load the weights of the Best Model that obtains the maximum dice score on the validation set If you wish to load the weights of a specific epoch you may set the epoch argument when you call this function then creates an instance of the BasicDataset using test set and predicts the segmentation masks on the test images. In the First Tutorial you had seen that we uploaded the whole MNIST dataset into Python variables and then we trained our model using those variables. Plot learning curve Test your model Display few samples of the results Print the statistical analysis Plot your model s weights Visualization. Make sure that you ve added the dataset Data Add data Search by URL search https www. Convert BGR to RGB Resize all images from 512 to 256 H and W Scale between 0 to 1 Make sure that the mask are binary 0 or 1 HWC to CHW Create train validation and test dataset instances Make sure that the masks shapes are Batch 1 W H Make a variable to report the dices per each sample in the bacth. If you changed the loss function during training you need also change it in this function to generate comparable results. Learn how to work with large image datasets. com SAIL GuoLab Cell_Segmentation_and_Tracking to get help for your implementation. In this function we automatically create an instance of the training set and validation set using our previously defined BasicDataset. text Create directory to save test masks Check if GPU is available Don t forget to change the criterion if you are using different loss function during training There is only one id in img_id since the batch size is one. 0 for no overlap and 1. Use the Section 2 Simple U Net implementation as an example for your implementation. Successful implementation 35 points2. Dataset description2. Check if GPU is available Change the optimizer and learning rate scheduler if these don t suits your model. png The DICE score shows how successfully our model could predict correct labels in the right location. Our next function is train_net. Therefore we have implemented a function that computes multi class DICE scores in general which works in our binary segmentation. This happens when there is no classes presented in the sample and everything is predicted as background. On right side panel click on Add Data 2. input singlecellsegmentation SingleCellSegmentation valid image image_0001. If you wish to use a different Loss function change criterion to what desires your model. The plot_learning_curve function will take a previously trained model net and looks for its summary then loads it and plot the losses and dices after each epoch for both training and validation sets. Each folder has two folders image containing RGB fluorescence widefield microscopy images as inputs and mask which contains segmentation masks as targets. com max 858 1 yUd5ckecHjWZf6hGrdlwzA. Discussion and ConclusionIf you want to include the figures you have made in this Notebook you need to save them in the working directory. For example if you have two classes cat and dog you must account for background too therefore n_classes 3 0 Background 1 Cat 2 Dog. THRESH_BINARY_INV maxval 1 Was trying to work on the edge detection algorithm described but I wasn t sure how to vectorize the outer and inner edge. Then you need to download them Click on the dots on right side of eachh file and Download. json format model_name model_name_TestResults. In this function the loss function will be selected based on the segmentation type Multi class or Binary. Here is a function that displays the weights of the first convolution layer of the Simple U Net called plot_weights_UNet. This function will take the model to search for its TestResults. Encoding Layers OutConv is just a 1 times1 2D convolution that serves as an output layer in our U Net model. Make sure internet access is granted. For multi class segmentation make sure you account for background 0 index as well. Now that the model is appropriately trained by looking at the training curve we need to test it on the test set to ensure that our trained model works on unseen data. You can change the probablity threshold We choose our best model based on validation dice score Now update our learning rate scheduler based on the average dice score over all validation samples Save this state as the best model if it is Training summary will be saved as a json file for further visualization. com 41ded1456b9dbe13b8d73d8da539dac95cb8aa721ebe5fb798af732ca9f04c92 68747470733a2f2f692e696d6775722e636f6d2f6a6544567071462e706e67 To implement the U Net we first define four blocks that we will use multiple times while designing the complete architecture. ", "id": "joonsoolee/aoe-project", "size": "13939", "language": "python", "html_url": "https://www.kaggle.com/code/joonsoolee/aoe-project", "git_url": "https://www.kaggle.com/code/joonsoolee/aoe-project", "script": "torch.optim torch.utils.data sklearn.metrics __init__ Down(nn.Module) torch.autograd dice_coeff_multiclass OutConv(nn.Module) statistical_report DataLoader plot_learning_curve forward torch.nn test_net plot_weights_UNet seaborn numpy scipy.ndimage Attention_block(nn.Module) __getitem__ Up(nn.Module) conv_block(nn.Module) Function confusion_matrix AttResUNet(nn.Module) UNet(nn.Module) plot_best_worst_samples matplotlib.pyplot dice_coeff_binary pandas classification_report Dataset __len__ DoubleConv(nn.Module) tqdm up_conv(nn.Module) torch.nn.functional my_loss scipy train_net BasicDataset(Dataset) resconv_block(nn.Module) ", "entities": "(('Important You', 'GitHub repository https absolutely github'), 'welcome') (('correctly it', 'notes codes'), 'make') (('Furthermore function', 'test set'), 'display') (('report', 'sections'), 'include') (('com HaiyongJiang U Net Pytorch Unstructured Buggy', 'https 0e854509c2cea854e247a9c615f175f76fbb2e3a github'), 'commit') (('upsampling that', 'DoubleConv'), 'be') (('RGB images', 'image_2070'), 'name') (('we', 'usine plot_best_worst_samples function'), 'now') (('don t', 'model'), 'check') (('you', 'what'), 'be') (('Acknowledgment Most', 'repository https modified github'), 'be') (('it', 'less memory'), 'speed') (('train validate', 'image then next batch'), 'be') (('Simple NetThis Section 2 U section', 'given dataset'), 'implement') (('which', 'binary segmentation'), 'implement') (('Finally function', 'dice test set'), 'print') (('Furthermore you', 'work'), 'cite') (('we', 'segmentation metrics'), 'forget') (('questions', 'email Soroush sa3617 columbia'), 'have') (('thoroughly you', 'it'), 'read') (('you', 'https github'), 'Convert') (('you', 'future'), 'cite') (('function', 'U only Simple Net example'), 'unfortunately') (('it', 'However scenarios'), 'be') (('we', 'model'), 'important') (('that', 'job'), 'implement') (('Extra 20 points Section 1 functionsIn we', 'easy you'), 'General') (('what', 'model'), 'wish') (('2d then ReLU then convolution', 'again then normilization'), 'batch') (('Then we', 'it'), 'add') (('you', 'too therefore n_classes 3 0 Background 1 2 Dog'), 'account') (('s', 'test_net function'), 'let') (('final step', 'Simple U trained Net'), 'take') (('test model', 'statistical results'), 'train') (('everything', 'background'), 'happen') (('we', 'those'), 'com') (('you', 'implementation'), 'implement') (('trained model', 'unseen data'), 'train') (('Then you', 'eachh file'), 'need') (('we', 'memory consumption'), 'resize') (('when you', 'test images'), 'load') (('few samples', 'statistical analysis'), 'test') (('validation', 'previously defined BasicDataset'), 'create') (('estimated that', 'class j.'), 'loop') (('Here we', 'plot_weights_UNet function'), 'visualize') (('we', 'blocks'), 'build') (('we', 'plot_learning_curve function'), 'time') (('you', 'hour session 9 limitation'), 'maxpool') (('you', 'background 0 index'), 'make') (('downsampling which', 'Maxpooling'), 'be') (('you', 'them'), 'read') (('how successfully model', 'right location'), 'png') (('BasicDataset implementation', 'training set'), 'let') (('that', 'image'), 'need') (('we', 'statistical_report function'), 'need') (('we', 'visualization'), 'return') (('you', 'other papers'), 'be') (('function', 'TestResults'), 'take') (('you', 'First Tutorial'), 'be') (('you', 'Residual Attention U Net'), 'section') (('Training summary', 'further visualization'), 'change') (('Deadline pm December 17 2020 11 59 EST', 'teammates Joonsoo Lee jl5062'), 'write') (('plot_learning_curve function', 'training sets'), 'take') (('loss function', 'segmentation type Multi class'), 'select') (('you', 'working directory'), 'want') (('you', 'URL search https www'), 'make') (('you', 'comparable results'), 'change') (('where x', 'set'), 'be') (('that', 'Sensitivity Recall Precision F1 score https'), 'be') (('training as well that', 'dice a.'), 'create') (('that', 'batch'), 'be') (('It', 'weights rate'), 'train') (('they', 'Kaggle working model name model name _ figure name'), 'use') (('we', '255 0'), 'scale') (('Section 4 Report', 'IEEE conference paper template https www'), 'write') (('which', 'targets'), 'have') (('Now we', 'dice scores print test_resuls'), 'change') (('then we', 'variables'), 'see') (('we', 'rate lr'), 'take') (('that', 'model'), 'consist') (('here we', 'initial arguments'), 'need') (('you', 'code next block'), 'take') (('function', 'fodler'), 'take') (('We', 'statistical measures'), 'utilize') (('we', 'models'), 'let') (('we', '0'), 'need') (('batch size', 'only one i img_id'), 'directory') (('times1 2D just 1 that', 'U Net model'), 'be') (('ulti class predicted mask', 'axis final label'), 'implement') (('it', 'weights'), 'use') (('we', 'DICE score more https'), 'be') (('I', 't how outer edge'), 'thresh_binary_inv') (('we', 'model'), 'change') (('plot_best_worst_samples function', 'segmentation best masks'), 'design') (('Additionally function', 'pred_mask_x'), 'save') (('we', 'complete architecture'), 'com') (('you', 'function'), 'need') (('however we', 'only one class'), 'be') (('we', 'image'), 'use') (('preprocessing step', 'also function'), 'implement') (('we', 'implementations'), 'com') (('that', 'Simple U Net'), 'be') (('that', 'batch size'), 'make') (('further plots', 'also directory'), 'save') (('W Batch 1 H', 'bacth'), 'convert') (('layer', 'nn'), 'forgt') (('function', 'a.'), 'save') ", "extra": "['test', 'procedure']", "label": "Perfect_files", "potential_description_queries": ["accelerator", "account", "accuracy", "advantage", "algorithm", "analyze", "application", "architecture", "argument", "array", "assessment", "average", "background", "backward", "batch", "batch_size", "best", "binary", "block", "build", "calculate", "call", "case", "cat", "cause", "cell", "channel", "check", "choose", "code", "confusion", "convert", "convolution", "copy", "correct", "could", "create", "criterion", "current", "curve", "data", "dataset", "def", "define", "detection", "device", "dice", "difference", "directory", "display", "document", "download", "edge", "encoding", "end", "ensure", "epoch", "evaluation", "even", "everything", "fact", "figure", "file", "final", "folder", "following", "format", "function", "general", "generate", "gradient", "ground", "help", "id", "image", "implement", "implementation", "import", "include", "index", "individual", "inner", "input", "instance", "integer", "job", "json", "kaggle", "layer", "learning", "leave", "lecture", "len", "let", "line", "load", "look", "looking", "loop", "map", "mask", "matrix", "max", "maximum", "memory", "minimum", "mode", "model", "most", "move", "multiple", "name", "need", "network", "new", "next", "no", "normal", "normalization", "normalized", "not", "number", "numpy", "optimizer", "order", "out", "outer", "output", "overlap", "padding", "panel", "part", "path", "per", "performance", "pipeline", "pixel", "plot", "plotting", "png", "pred", "predict", "preprocessing", "present", "print", "probability", "project", "property", "random", "range", "re", "read", "reading", "reduce", "remove", "report", "repository", "resize", "result", "return", "reverse", "right", "sample", "save", "saving", "scaled", "scheduler", "score", "search", "section", "segment", "segmentation", "selected", "session", "set", "shape", "short", "side", "single", "size", "softmax", "speed", "sqrt", "src", "standard", "state", "step", "summary", "template", "test", "testing", "text", "those", "threshold", "through", "time", "total", "train", "training", "try", "type", "up", "update", "upsampling", "valid", "validate", "validation", "value", "variable", "vectorize", "version", "visualization", "visualize", "weight", "while", "window", "work", "worst", "write"], "potential_description_queries_len": 219, "potential_script_queries": ["forward", "nn", "scipy", "seaborn", "torch", "tqdm"], "potential_script_queries_len": 6, "potential_entities_queries": ["figure", "model", "next", "print", "score", "session", "test"], "potential_entities_queries_len": 7, "potential_extra_queries": ["procedure"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 225}
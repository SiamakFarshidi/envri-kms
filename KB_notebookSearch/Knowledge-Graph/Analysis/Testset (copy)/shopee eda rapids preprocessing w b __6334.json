{"name": "shopee eda rapids preprocessing w b ", "full_name": " h1 Introduction h1 Diving into the Data h1 Evaluation metric F1 score h1 Import Libraries h1 Reading csv files h1 Getting image paths from the directory h1 Displaying images h1 Colour Histograms h1 Most frequent label groups h1 Least frequent label groups h1 Images with the same title h1 Wordcloud of image titles h1 Unigrams bigrams and trigrams h1 Plugging in RAPIDS u200d h3 Pre processing title h3 CountVectorizer for Feature Extraction h3 Titles with similar text h3 Similar Images ", "stargazers_count": 0, "forks_count": 0, "description": "npy Save the artifact version to W B and mark it as the output of this run run. Posts always self match. Here I m comparing the highlighted versions in the left sidebar i. Group sizes were capped at 50 so we need not predict more than 50 matches for a posting. ai ruchi798 shopee workspace user ruchi798 https i. init project shopee name image_embedding_val artifact wandb. save image_embedding_val. png Different versions of the artifacts can be stored in W B. png We can even specify filters on any column to limit the visible rows down to only rows that match. ai api cuml nightly api. These matches can be performed automatically with the help of machine learning and that is the goal of this competition. png We have 11014 unique label groups for products. com formigone my first custom theme for jupyter notebook a9c1e69efdfe Illustrations tools Canva https www. edu shervine blog keras how to generate data on the fly Inspiration Custom Jupyter Notebook Theme with plain CSS https medium. where TP True Positive FP False Positive TN True Negative FN False NegativeImport Libraries I will be integrating W B for visualizations and logging artifacts Shopee Project on W B Dashboard https wandb. Not provided for the test set matches Space delimited list of all posting IDs that match a particular posting. ai datasets and predictions This is a snapshot of the table I just created and added to an artifact. Here I ve filtered the table to see only the test images. add_file title_preprocessed_dataset. com cdeotte rapids cuml tfidfvectorizer and knn A very detailed explanation for data generation https stanford. \u2139 Multiple postings might have the exact same image ID but with different titles or vice versa. add_file image_embedding_val. Artifact title_preprocessed_dataset type dataset add a file to the artifact s contents artifact. npy ie run wandb. We have been provided with data of Shopee which is the leading e commerce platform in Southeast Asia and Taiwan. text Titles with similar text Similar Images Logging the image embeddings as an artifact This helps me to save on time since the model need not be trained over and over again A snapshot of the newly created artifacts https i. csv save the artifact version to W B and mark it as the output of this run run. Scanning through multiple shopping websites to get the perfect deal and keeping an eye on upcoming sales is one manual way to go about. finish ie model. png References RAPIDS cuML TfidfVectorizer and KNN https www. predict train_gen verbose 1 np. finish query W B for an artifact and mark it as input to this run download the artifact s contents converting from BGR to RGB. csv Each row contains the data for a single posting. Evaluation metric F1 score The evaluation metric for this competition is F1 Score or F Score. v1 with v2 in a split panel view We can see values from both artifact versions in a single table. Diving into the Data train test. Logging a dictionary of custom objects Most frequent label groups Least frequent label groups Since the shape of the training dataframe and number of unique titles differ we can infer that we have images with the same title. Images with the same title Observations from EDA Visually similar images in different label groups Same images with different titles Same titles have different imagesWordcloud of image titles Logging an image of the wordcloud of image titles Unigrams bigrams and trigrams Logging custom bar charts for unigrams bigrams and trigrams Plugging in RAPIDS Pre processing title Logging the preprocessed title dataset as an artifact CountVectorizer for Feature Extraction Documentation https docs. It finds the balance between precision and recall. posting_id the ID code for the posting image the image id md5sum image_phash a perceptual hash of the image title the product description for the posting label_group ID code for all postings that map to the same product. png Since I have already logged the image embeddings artifact I can directly use it in this manner Here s a snapshot of my project https wandb. Introduction Goal To build a model that predicts which items are the same products As a shopaholic I admit getting the best deals for products is a very rewarding experience. ai ruchi798 shopee workspace user ruchi798 To get the API key an account is to be created on the website first. log_artifact artifact run. Next use secrets to use API Keys more securely Reading csv files Getting image paths from the directory Number of images in each directoryChecking if images in each directory have the same shapeDisplaying images Colour Histograms Visualizing and querying the dataset with W B Documentation https docs. com en_gb colored output specifying directory paths function to get image paths from train and test directory function to display multiple images initializing the run creating an artifact setting up a WandB Table object to hold the dataset filling up the table raw image plotting histograms adding an artifact file adding a row to the table adding the table to the artifact logging the artifact getting count for most frequent and least frequent label groups getting most frequent and least frequent label groups color function for the wordcloud filter punctuation convert to lower case remove stopwords normalize spaces strip leading and trailing spaces run wandb. Comparison of any two artifact versions in the table is possible. init project shopee name title_preprocessed artifact wandb. Product matching is one of these strategies wherein a company to offers products at rates that are competitive to the same product sold by another retailer. Artifact name image_embedding_val type dataset Add a file to the artifact s contents artifact. We often find retail companies offering recommendations in which they promote their products in such a way that customers tend to get swayed and pick a similar product that is priced lower. ", "id": "ruchi798/shopee-eda-rapids-preprocessing-w-b", "size": "6334", "language": "python", "html_url": "https://www.kaggle.com/code/ruchi798/shopee-eda-rapids-preprocessing-w-b", "git_url": "https://www.kaggle.com/code/ruchi798/shopee-eda-rapids-preprocessing-w-b", "script": "getShape DataFrame nb display styling get_top_n_words stopwords plot_bt __init__ UserSecretsClient preprocess_df cuml.neighbors DataGenerator(tf.keras.utils.Sequence) display_multiple_img Javascript __data_generation seaborn numpy NearestNeighbors sklearn.feature_extraction.text Back tensorflow.keras.applications color_wc __getitem__ ResNet101 wb_hist get_top_n_bigram PIL display_hist get_top_n_trigram IPython.core.display CountVectorizer Image matplotlib.pyplot hist tensorflow WordCloud pandas wordcloud STOPWORDS __len__ path CountVectorizer as CV plot_wb Style nltk.corpus colorama text_preprocessing Fore cuml.feature_extraction.text kaggle_secrets HTML getImagePaths ", "entities": "(('that', 'same product'), 'code') (('Multiple postings', 'different titles'), 'have') (('png Different versions', 'W B.'), 'store') (('row', 'single posting'), 'csv') (('leading spaces', 'wandb'), 'run') (('png We', 'products'), 'have') (('which', 'e commerce Southeast leading Asia'), 'provide') (('Artifact', 'contents'), 'name') (('csv', 'run run'), 'save') (('png We', 'only rows'), 'specify') (('Scanning', 'upcoming sales'), 'be') (('images', 'W B Documentation https docs'), 'use') (('init project', 'shopee title_preprocessed artifact wandb'), 'name') (('model', 'artifacts https newly created i.'), 'Titles') (('we', 'same title'), 'log') (('Here I', 'test only images'), 'filter') (('metric', 'competition'), 'score') (('type Artifact title_preprocessed_dataset dataset', 'contents'), 'add') (('Comparison', 'table'), 'be') (('account', 'website'), 'ai') (('that', 'retailer'), 'be') (('best deals', 'products'), 'Goal') (('Here I', 'sidebar left i.'), 'compare') (('We', 'single table'), 'v1') (('Here snapshot', 'project https wandb'), 'use') (('It', 'precision'), 'find') (('Unigrams Logging', 'Feature Extraction Documentation https docs'), 'image') (('that', 'similar product'), 'find') (('that', 'particular posting'), 'provide') (('TP FP TN Negative FN False NegativeImport where True Positive False Positive True Libraries I', 'Shopee W B Dashboard https logging wandb'), 'integrate') (('that', 'competition'), 'perform') (('init project', 'artifact wandb'), 'name') (('so we', 'posting'), 'cap') (('I', 'just artifact'), 'dataset') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["account", "api", "artifact", "balance", "best", "blog", "build", "case", "code", "color", "colored", "column", "company", "competition", "convert", "count", "csv", "cuml", "custom", "data", "dataframe", "dataset", "description", "dictionary", "directly", "directory", "display", "download", "evaluation", "even", "eye", "file", "filter", "filtered", "find", "fly", "frequent", "function", "generate", "generation", "hash", "help", "id", "image", "init", "input", "key", "label", "learning", "least", "left", "list", "logging", "lower", "manner", "manual", "map", "match", "matching", "metric", "might", "model", "most", "multiple", "my", "name", "need", "normalize", "not", "notebook", "number", "object", "output", "panel", "plotting", "png", "precision", "predict", "processing", "product", "project", "punctuation", "query", "raw", "remove", "row", "run", "save", "score", "set", "shape", "similar", "single", "split", "table", "test", "text", "through", "time", "title", "train", "training", "type", "unique", "up", "user", "v2", "version", "view", "website"], "potential_description_queries_len": 110, "potential_script_queries": ["colorama", "core", "hist", "nb", "numpy", "path", "seaborn", "styling", "tensorflow"], "potential_script_queries_len": 9, "potential_entities_queries": ["left"], "potential_entities_queries_len": 1, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 118}
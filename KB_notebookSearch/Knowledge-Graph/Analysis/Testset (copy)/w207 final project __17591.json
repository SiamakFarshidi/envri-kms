{"name": "w207 final project ", "full_name": " h1 W207 Applied Machine Learning h2 Summer 2018 Final Project h4 Kaggle Datasets h4 Running this Notebook Locally h4 Credits h4 Libraries to Install h3 1 Introduction h3 2 Exploration Data Analysis h3 3 Images Pre processing h4 3 1 Extracting R G and B h4 3 2 Gaussian blur h4 3 3 Edge Detection h3 4 Feature Engineering Dimensionality Reduction with PCA h3 5 Model Development h4 5 1 K Nearest Neighbors h4 5 2 Bagged Trees h4 5 3 Support Vector Machines h3 6 Convolutional Neural Network h3 6 1 Data Processing Set Up h3 6 1 Model Specification h3 6 2 Validation Against Real World Data h3 7 Other Classifiers h4 Random forest h4 Naive Bayes h3 8 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "This blurred_data_set will then be returned. It s obvious that the images are made with one person s hand in basically one environment. In addition to a manual edging using parameters provided we also use a function to detect the image edges automatically. This leads to a blurring of the original image. 1 Data Processing Set UpIn the next snippet I make a generator for use by Keras. Overall each time we applied a blur we saw an increase in the accuracy over the original data. 1 Extracting R G and BSince each image has the color dimension that we saw above one of our pre processing steps is to extract each of these to create separate blue red and green training examples. In the final code block we tune the bagged trees classifier by trying a few more parameters for the number of estimators including 50 70 80 100. We will run the RGB and blurred data through it along with transformations through PCA to determine which data set has the highest accuracy. W207 Applied Machine Learning Summer 2018 Final Project Team Members Rachel Ho Dan Rasband Subha Vadakkumkoor Matt Vay Topic ASL Alphabet Kaggle Datasets ASL Alphabet https www. In the second code block we tune the bagged trees classifier by varying 1 the size of the underlying decision tree and 2 the number of estimators used for bagging. It is worth noting that while the Blur_Blue_PCA dataset had the highest score our Blur_PCA original mini training data with a blur applied came in second place with only an accuracy decrease of 0. After performing a grid search we have found the optimal parameters for C and gamma. NaiveBayes seems to work better on the contoured processed images better. There are two main hyperparameters to tune for a bagged trees classifier 1 the size of the underlying decision tree and 2 the number of estimators used for bagging. In both cases the accuray rates are similar at around 61 62. Exploration Data AnalysisWe will explore the data to ensure that all labels are read in and also to visually examine the variations in the images. Based off the confusion matrix shown above two of the most confused signs are C D the model incorrectly predicts them a total of 7 times. com grassknoted asl alphabet Libraries to InstallTo run this notebook you may have to run the following commands to install some prerequisites bashpip install upgrade opencv python tqdm scikit image pandas numpy matplotlib keras tensorflow scikit learn seaborn 1. The data sets we used included the original and the original with PCA applied. This lead to some interesting results such as the data set with the highest score was taking only the blue pixels from our image applying a PCA to it and then a gaussian blur lead to a 3. Feature Engineering Dimensionality Reduction with PCAAs the dimensions 7 500 of our training data are still quite large after re sizing the images we try to reduce the dimensions using PCA in order to see if we can make the algorithms run more efficiently and if we can improve the accuracy for some of the classifiers. This could mean a few things such as maybe the blue pixels did a better job at hiding images in the background and brining out the hand and shadows in the foreground. However based off the confusion matrix the signs are only confused for each other a total of 3 times. After this initial processing we used PCA to reduce the dimensionality of our images down to 110 components which explained 95 of the variance. In fact it was only about half as good. Because if this it seemed like a good idea to validate that the models were not overfitting to images in this controlled environment. pruning does not improve accuracy. We found that applying PCA to reduce the dimensionality and also performing a gaussian blur increased the accuracy over just using our original unfiltered data. Originally we wanted to retain 99 of the variance but discovered that this requires the number of componenets to go up to thousands essentially defeating the purpose of PCA. A low gamma means points far from the likely separation line are considered in the calculation while a high gamma means points close to the separation line are considered in the calculation. The make_generator function is versatile enough to be used for setting up a generator for training validation prediction and testing. For future iterations we would like to explore random forests naive bayes and multilayer perceptrons more in depth. Below we fit the KNN classifiers with both the dataset with original dimensions and the dataset with reduced dimensions. In this part we build out the convolutional neural network. The models we used first for our predictions were K Nearest Neighbors Bagged Trees and Support Vector Machines. The outright winner would be the nothing sign with an f1 score of 0. Each example in the dataset is a three dimensional array of 200 X 200 X 3 pixels. It is made up of 12 layers as is diagrammed below. 2 Validation Against Real World DataThe data provided in the ASL Alphabet data set is very much contrived. For small values of C it will look for a larger margin hyperplane even if that means misclassifying points. 2 which is likely insignificant. After performing the gridsearch on the these two parameters we were able to increase our accuracy from 60. Maybe increasing the brightness would be a further option for us to consider in future iterations of this model. We can see that a few of our letters stand out as being easier to predict than others. Our goal is to retain 95 of the variance. Initialize a blank data set that is the same size as the data set parameter passed to our function We then iterate through the rows in our data set transforming them into a 50X50 matrix and performing the gaussian blur on them for each 50X50 matrix we have made we iterate through each pixel excluding the edges and take the average of that respective pixel and its 8 closest neighbors and make that the pixel s new value. add channel for RGB Model saving for easier local iterations HISTORY is only available if the model was run this time around which won t be the case when the model is read in from a file so we just skip it in that case. From the output result we conclude that limiting the size of the underlying tree i. As can be seen from the results below if we set the number of principal components to 110 we can reach 95 explained variance. As we have 3000 images of each letter named in the format of A1 A2. The Gaussian blur takes the average of a pixel s 8 nearest neighbors and returns the average as its new pixel value. 3 Edge DetectionIn this segment we try various image processing functionalities available in Python to blur in the data ways other than Gaussian binarize and to extract the contour edges of images. Other ClassifiersThis section includes other classifiers we explored but did not tune in depth for this project. Yet the accuracy at 45 is low 8. The plot below shows the number of principal components vs. Support vector machines work by placing hyperplanes through the data in N dimensional space when a simple linear line can not separate the data. On the other hand as the number of estimators increases the accuracy rate increases accordingly. Define a hash table dict to store labels Image sizing Some visualization helpers Create label Read original image Append to data array Read in train and dev data Reshape the images from 3d to 2d arrays. The SVM s accuracy was also greatly helped by transformation through PCA. TRAIN_DIR directory path where training dataset is saved Note that the current structure is set to how things would look if this notebook were to be run on Kaggle. 2 Bagged TreesThis section covers the bagged trees classifier which is the bagging classifier with a decision tree as the underlying estimator. This is expected as the feature space is very sparse even for the dataset with reduced dimensions. For this first we need to break down the third dimension and reshape to a 2d array Reshape train data Reshape dev data This function will take a data set as an input and perform a gaussian blur to the data. Subset data for each letter Pulls the index for the symbol. A E also have a high count of incorrect predictions at 9 due to the signs being very similar. We were able to use Kaggle s GPU enabled kernels to train a model in less than 15 minutes. General libraries Deep Learning using Keras Visualizations Sci kit learn libraries Image Preprocessing Set random seeds so results are the same each time Define parameters and functions Change this to point to your data directory if the default relative path below does not work please provide complete path eg C Users subsh Documents 207 final_project asl alphabet asl_alphabet_train asl_alphabet_train Define train size this is the number of training samples for each letter Define the classes letters of the ASL alphabet that are being analyzed. Create subplots and titles. Therefore we proceed to tune the bagged trees classifier without dimensionality reduction. pip install upgrade opencv python tqdm scikit image pandas numpy matplotlib keras tensorflow scikit learn seaborn Credits1. We used a Bernoulli NB as the data is contoured and has only 2 levels of pixels. fit_transform traindata Define gridsearch parameters Call function once on data without PCA and one without Place data into lists to make it iterable for use in loops when running algorithms. com 2015 04 06 zero parameter automatic canny edge detection with python and opencv 3. In the first code block we train the bagged trees classifer with both the dataset with original dimensions and the dataset with reduced dimensions without tuning any parameters aside from setting the random state. Blur our mini train data and dev data for use in our models Take the blurred red green and blue data pixels and stack them back together into an array of the original size and shape of the mini training data. com paultimothymooney interpret sign language with deep learning2. The 3d images will be used for color based pre processing and plotting while the 2d arrays will be used for other analyses. Images Pre processing 3. Below we evaluate the CNN model against a set of images made with various backgrounds and with a different person s hand to see how well the model works on a related but different set of images. Install libraries below. In fact it s apparent that there are a few letters that do extremely well while others struggle. For our classification task it seems we should focus on precision and f1 score as a few false positives would not cause a great deal of harm unlike if we were predicting bank fraud or sick patient detection. I think much of the confusion boiled down to darker photos and not being able to distinguish the lines of the fingers. com manipulating image pixels with python scikit image color schemes Pick which image to use for training THIS DOES NOT SEEM TO BE WORKING FIX SIZE Reshape train data Reshape dev data Set the number of components to be used below. C also known as regularization will choose a smaller margin hyperplane to make sure all the data is classified correctly for large values of C. Convolutional Neural NetworkThe following section shows another methodology we tried out. K Nearest Neighbors performed the second with an accuracy of around 70. cumulative explained variance as we increase the number of components. We use the train_test_split functionality to split the indices into two disjoint train and test indices. For the purpose of this project in the step where the images are loaded from their corresponding sub folder we re size the images to 50 x 50 x 3 and 64 x 64 x 3 in the section on convolutional neural networks to make the run times of training more managable and reduce the number of pixels from 120 000 to 7 500. Filter data so it only has the symbol. Fit and score with the best parameter found pred gs. As can be seen the bagged trees classifer does much worse with dimensionality reduction. The model performs quite well on the original validation set as seen below Running predictions on another set of data however shows that the feature engineering is insufficient to have a reasonable success rate though the predictions are better than pure chance. This is a fairly easy one to classify though as it means no hand is found in the image. As seen from the results in both cases the optimal value of k is 1. Break the data into red green and blue mini training sets to use in our later algorithms. The length of the hands extent of background images color intensity and brightness all vary from image to image. Interestingly we find that the accuracy worsens for the tree classifiers including random forests and bagged tress but improves for other classifers including KNN and SVM. For each example grab the Red Green Blue and Complete representation of the data and show it in the subplot. com 2015 04 06 zero parameter automatic canny edge detection with python and opencv 4. Print maximum number of incorrect predictions for each digit. 1 Model SpecificationThe model used here is taken from a Kaggle kernel called Running Kaggle Kernels with a GPU https www. Edge detection can be tricky because there can be edges in the background as well and thus how tightly loosely to identify the edges can affect the quality of the output image and the prediction. From there we will tune the parameters C and gamma. This technique was used on a few different algorithms such as k nearest neighbors and support vector machines with varying degrees of success which will be discussed further on in our report. We reduce the dimensions of the training dataset and development dataset by transforming them with the fitted PCA and store them separately to be used for training. In this next section the model is fitted against the data splitting the data into training and validation sets. When plotting out all the images we realized the images varied greatly ranging from what was in the background the brightness to the angles of the hand. Along with those we took our Red Green and Blue data sets and applied PCA and or a gaussian blur. Random forest Naive BayesHere we briefly look at performance of Naive Bayes on the contoured data. This function has been adapted from https www. Next we looked at the gamma parameter. com grassknoted asl alphabet and is an example of a convolutional neural network. 3 Support Vector MachinesNext we will take a look at the support vector machine algorithm to predict our data. compute the median of the single channel pixel intensities apply automatic Canny edge detection using the computed median return the edged image Create label Read original image Process image Apply Guassian blur Convert to HSV Apply median blur need to pick one of Guassian or median Resize resized resize imgray2 IMAGE_SIZE IMAGE_SIZE 3 Convert to gray THIS IS NOT WORKING WITH CANNY Get the edges tight Try changing this for better edge detection Get the edges auto Convert to gray THIS IS NOT WORKING WITH CANNY Binarize to be done https sourcedexter. plot number of estimators vs accuracy without no limites on size of underlying decision tree output confusion matrix for bagged tree classifier with n_estimators 50 Print total number of incorrect predictions for each digit. Since accuracy hovers around 85 for estimators equal to or above 50 we picked this over a larger number of estimators to run things more efficiently. 6 accuracy increase over our original mini training data. com danrasband asl alphabet test this data set is used to test against more realistic images. Running this Notebook Locally1. Consistent with the results of the confusion matrix we see from the classification report that the hand sign B has the lowest F1 score among all the symbols. Lastly we spent time looking at classifying the images with Naive Bayes and Multi layer Perceptron classifiers but eventually pulled the Multi layer Perceptron classifier because of how long it was taking to run. Convolutional Neural Network https www. They both make fists with the only difference being E tucking in the thumb and A not tucking. We can see the the variations in gestures in sample plots below of 10 random images of each letter. These include C F G and M to name a few that have an f1 score falling between 0. From the confusion matrix we can see that for this classifier the most often mis labeled pairs of hand signs include B with A and D with C. When this model was applied to similar images from a less contrived environment it still performed better than chance but had much lower accuracy than when run on the validation set. IntroductionOur dataset contains 29 classes one for each letter from A to Z space delete and nothing. To combat some of this noise we used filtering techniques such as gaussian blurs cropping edge detection and even breaking the images down by their red green and blue pixels. We next tried a convolutional neural network. As the data size is huge instead of reading all the images we read in only a sample. com grassknoted asl alphabet this data set is the basis for all models. Image processing credited to Adrian Rosebrock https www. We set the mini training dataset to 2900 examples as there are 29 labels so there are 100 examples for each label. Our model found a C value somewhere in the middle to be optimal for our case. This may be an artifact of where those particular images were taken though further analysis would have to be made to determine the exact cause. ASL Alphabet Test https www. The parameters we try for tree size include 100 500 and 800 and number of estimators include 10 20 30 50. Here we show the history of the fitting process which shows the loss and the accuracy of the fit. ConclusionUsing 29 different classes we looked to take an image of a hand and predict the letter or symbol it was trying to sign. After determinig the optimal value of k is 1 with the mini training data and PCA lead to a slightly higher accuracy we ran the k nearest neighbors algorithm against 8 different variations of our mini train data with our optimal k value. When splitting up the dataset we collapse the three dimensional feature arrays 50X50X3 into one dimensional feature arrays 7 500 so they can be used for training. Transform mini training data and development data using PCA fitted with mini training data. Download the datasets from the links above and update the directory paths accordingly in the relevant cell blocks. 2 Gaussian blurWe create a Gaussian blur as a pre processing step to see if it can help improve training accuracy. Out of these 3 models Bagged Trees performed the best with an accuracy of 87 with the number of estimators set to 80. It will then return that data set with a blur meaning a pixel will take on the average of its 8 closest neighbors plus itself. Below you can see a video compilation of all the A images. As far as letters where our model struggled A U V and W all had low f1 scores which is interesting because the images for V and W seem fairly easy to distinguish compared to others. The least accurate model was SVM at around 60. The training exmmples are spread out far from each other. After the loop we then return that matrix back to its original shape and add it to a blurred_data_set that will end up being the transformed version of the original data parameter. This is also the label in our y data. B3000 we create a random sample of indices and then read in only the sampled indiced. It had good results with some minor preprocessing converting images using the Sobel method. We proceed to focus on tuning the number of estimators without limiting the size of the underlying decision tree. Again the model building process is skipped if the model has already been saved to disk. The best accuracy of 87 is achieved with 80 estimators. Code for loading images is credited to Paul Mooney https www. We use GridSearchCV to find the optimal value of k for both datasets. Classification report and error analysis on blurred data base bagged trees classifier with dimensionality reduction base bagged trees classifier without dimensionality reduction Bagged trees tuning by varying size of underlying decision tree leaf_nodes and number of estimators for bagging. 1 K Nearest NeighborsWe use KNN as a baseline model to compare against more sophisticated models including bagged trees SVM and neural networks. Model Development 5. Random sampling of filtered data with the number of examples specified. Based off the signs I would expect R U to be confused frequently as the only differnce between the two signs is R crosses the index and middle finger while U does not. As evident from the results accuracy increases steadily as the number of estimators increases until it starts to decrease again after the number of estimators reaches 80. In this section we perform error analysis for the bagged tree classifier with number of estimators set to 50. I ve provided a helper function below to load the model from disk so that this part of the notebook can be run without rebuilding the model each time. As we move towards signing full sentences instead of just predicting images we can likely use our image classification along with some kind of bag of letters model to determine which letters are likely to come after each other. Our optimal gamma value was fairly low which could mean our data was sparse and far from the decision boundary. First we read and load the data into arrays. ", "id": "danrasband/w207-final-project", "size": "17591", "language": "python", "html_url": "https://www.kaggle.com/code/danrasband/w207-final-project", "git_url": "https://www.kaggle.com/code/danrasband/w207-final-project", "script": "Flatten sklearn.metrics PCA plot_confusion_matrix_with_default_options Dropout DecisionTreeClassifier run_bagged_trees fit_and_tune_knn sklearn.decomposition skimage.color confusion_matrix sklearn.model_selection os classification_report fit_and_tune_svc set_random_seed getenv load_model sklearn.svm BernoulliNB MLPClassifier train_test_split make_decision_tree keras.preprocessing.image reduce_dimensionality sklearn.naive_bayes run_knn run_svc KNeighborsClassifier rgb2gray seaborn numpy MultinomialNB plot_confusion_matrix fit_and_tune_random_forest evaluate_validation_dataset ImageDataGenerator blur keras.utils tensorflow pandas plot_examples evaluate_model resize bagging_cm plot_bagging2 GridSearchCV keras.models skimage.transform make_generator_for reprocess_model BaggingClassifier build_model run_naive_bayes pca_transform print_summary Conv2D preprocess_image show_cnn_model_weights fit_and_tune get_data2 get_data plot_pca plot_bagging auto_canny GaussianNB make_generator plot_symbol load_model_from_disk keras.layers sklearn.tree run_bagged_trees2 Sequential Path sklearn.neural_network fit_model pathlib sklearn.ensemble RandomForestClassifier matplotlib.pyplot Dense tqdm evaluate_test_dataset sklearn.neighbors SVC show_class_counts ", "entities": "(('Fit', 'pred gs'), 'find') (('we', 'multilayer more depth'), 'like') (('goal', 'variance'), 'be') (('that', 'ASL alphabet'), 'library') (('Edge detection', 'output image'), 'be') (('it', 'letter'), 'ConclusionUsing') (('We', 'decision underlying tree'), 'proceed') (('bagged trees', 'aside random state'), 'train') (('accuracy rate', 'increases'), 'increase') (('data', 'pixels'), 'use') (('greatly what', 'hand'), 'plot') (('NaiveBayes', 'better contoured processed images'), 'seem') (('f1 score', '0'), 'include') (('we', 'data'), 'take') (('pixel', '8 closest neighbors'), 'return') (('I', 'fingers'), 'think') (('we', 'PCA'), 'include') (('C value', 'case'), 'find') (('2 Validation', 'ASL Alphabet data set'), 'be') (('few', 'others'), 'see') (('training exmmples', 'far other'), 'spread') (('It', '12 layers'), 'make') (('com paultimothymooney', 'deep learning2'), 'interpret') (('run times', 'to 7 500'), 're') (('Model SpecificationThe 1 model', 'Running Kaggle GPU https www'), 'take') (('further analysis', 'exact cause'), 'be') (('images', 'fairly others'), 'far') (('B3000 we', 'then only sampled'), 'create') (('Perceptron how long it', 'Multi eventually layer'), 'spend') (('7 500 they', 'training'), 'split') (('We', 'disjoint two train'), 'use') (('matplotlib keras tensorflow scikit', 'seaborn Credits1'), 'upgrade') (('k nearest neighbors', 'k optimal value'), 'lead') (('we', '50'), 'perform') (('100 500', '30 10 20 50'), 'include') (('forest Naive Random BayesHere we', 'contoured data'), 'look') (('First we', 'arrays'), 'read') (('We', 'separately training'), 'reduce') (('WORKING FIX SIZE Reshape train data Reshape dev data', 'components'), 'pixel') (('which', 'variance'), 'use') (('part', 'model'), 'provide') (('models', 'controlled environment'), 'because') (('Data Processing Set 1 next I', 'Keras'), 'UpIn') (('length', 'image'), 'vary') (('applying', 'just original unfiltered data'), 'find') (('middle U', 'index'), 'base') (('it', 'validation when set'), 'apply') (('such maybe blue pixels', 'foreground'), 'do') (('tqdm scikit image pandas', 'seaborn'), 'run') (('notebook', 'Kaggle'), 'path') (('We', 'datasets'), 'use') (('Edge 3 segment we', 'images'), 'detectionin') (('Therefore we', 'dimensionality reduction'), 'proceed') (('least accurate model', 'around 60'), 'be') (('It', 'Sobel method'), 'have') (('data set', 'models'), 'com') (('example', 'three dimensional 200 X 200 X 3 pixels'), 'be') (('up to thousands', 'PCA'), 'want') (('edges tight Try', 'https sourcedexter'), 'compute') (('we', 'red green pixels'), 'use') (('6 accuracy', 'training original mini data'), 'increase') (('that', 'data transformed original parameter'), 'return') (('it', 'training accuracy'), 'create') (('predictions', 'pure chance'), 'perform') (('we', 'methodology'), 'show') (('we', 'bank fraud'), 'seem') (('best accuracy', '80 estimators'), 'achieve') (('make_generator function', 'validation prediction'), 'be') (('This', 'original image'), 'lead') (('we', '95 explained variance'), 'reach') (('labels', 'images'), 'explore') (('points', 'calculation'), 'point') (('We', 'next convolutional neural network'), 'try') (('plot', 'principal components'), 'show') (('we', '50'), 'tune') (('we', 'image edges'), 'provide') (('we', 'original data'), 'apply') (('We', 'less than 15 minutes'), 'be') (('accuray rates', 'around 61'), 'be') (('we', 'neural convolutional network'), 'build') (('com danrasband asl alphabet data set', 'more realistic images'), 'test') (('They', 'tucking'), 'make') (('we', 'bagging'), 'tune') (('data', 'C.'), 'choose') (('we', 'respective pixel'), 'initialize') (('we', 'training separate blue red examples'), 'have') (('we', '60'), 'after') (('dimensionality reduction Bagged trees', 'bagging'), 'bag') (('further us', 'model'), 'be') (('linear when simple line', 'data'), 'work') (('Transform mini training data data', 'training mini data'), 'fit') (('it', 'when algorithms'), 'call') (('images', 'basically one environment'), 's') (('so we', 'case'), 'add') (('Below we', 'reduced dimensions'), 'fit') (('then gaussian blur', '3'), 'take') (('we', 'A1 A2'), 'have') (('we', 'data Blue PCA'), 'take') (('function', 'https www'), 'adapt') (('2d arrays', 'other analyses'), 'use') (('how well model', 'images'), 'evaluate') (('even that', 'misclassifying points'), 'look') (('Subset data', 'symbol'), 'pull') (('hand', 'image'), 'be') (('we', 'tree underlying i.'), 'conclude') (('data set', 'highest accuracy'), 'run') (('dataset', 'space delete'), 'contain') (('We', '29 100 label'), 'set') (('Below you', 'A images'), 'see') (('optimal value', 'k'), 'be') (('we', 'C.'), 'see') (('which', 'fit'), 'show') (('Bagged Trees', '80'), 'perform') (('again number', '80'), 'increase') (('we', 'C'), 'after') (('we', 'parameters'), 'tune') (('C model', '7 times'), 'base') (('Code', 'Paul Mooney https www'), 'credit') (('training Blur_PCA original mini data', '0'), 'be') (('data', 'decision boundary'), 'be') (('which', 'underlying estimator'), 'cover') (('total', '3 times'), 'base') (('model', 'training sets'), 'fit') (('we', 'things'), 'pick') (('trees bagged classifer', 'dimensionality much reduction'), 'do') (('we', 'only sample'), 'be') (('E', 'signs'), 'have') (('which', 'further report'), 'use') (('letters', 'other'), 'move') (('K Nearest Neighbors', 'around 70'), 'perform') (('model', 'already disk'), 'skip') (('K Nearest NeighborsWe', 'bagged trees'), '1') (('function', 'data'), 'need') (('accuracy', 'KNN'), 'find') (('outright winner', '0'), 'be') (('feature space', 'reduced dimensions'), 'expect') (('extremely well others', 'fact'), 's') (('Gaussian blur', 'pixel new value'), 'take') (('accuracy', 'PCA'), 'help') (('hand sign B', 'symbols'), 'consistent') (('We', 'letter'), 'see') (('we', 'project'), 'include') (('we', 'components'), 'explain') (('we', 'first predictions'), 'be') (('more efficiently we', 'classifiers'), 'Reduction') ", "extra": "['biopsy of the greater curvature', 'patient', 'test', 'bag']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "algorithm", "apply", "array", "artifact", "auto", "average", "background", "bag", "bagging", "bank", "baseline", "best", "binarize", "block", "build", "calculation", "canny", "case", "cause", "cell", "channel", "choose", "classification", "classifier", "classify", "close", "code", "color", "compare", "compute", "confusion", "consider", "contour", "convolutional", "could", "count", "create", "current", "data", "dataset", "decision", "default", "depth", "detect", "detection", "development", "dict", "difference", "dimension", "dimensionality", "directory", "disk", "edge", "eg", "end", "engineering", "ensure", "environment", "equal", "error", "evaluate", "even", "expected", "explained", "explore", "extent", "extract", "f1", "fact", "feature", "file", "filtered", "final", "find", "fit", "fitting", "folder", "following", "forest", "format", "found", "function", "future", "gamma", "gaussian", "generator", "grab", "gray", "green", "grid", "half", "hand", "hash", "help", "helper", "high", "history", "hyperplane", "idea", "image", "improve", "include", "including", "increase", "index", "input", "intensity", "job", "kernel", "label", "labeled", "language", "layer", "lead", "learn", "least", "length", "letter", "line", "linear", "load", "local", "look", "looking", "loop", "lower", "main", "manipulating", "manual", "margin", "matplotlib", "matrix", "maximum", "mean", "meaning", "median", "middle", "mini", "model", "most", "move", "naive", "name", "nearest", "need", "neural", "new", "next", "no", "noise", "not", "notebook", "number", "numpy", "option", "order", "out", "output", "overfitting", "parameter", "part", "path", "patient", "perform", "performance", "performing", "person", "pixel", "place", "plot", "plotting", "point", "pre", "precision", "pred", "predict", "prediction", "preprocessing", "principal", "processing", "project", "provide", "purpose", "python", "random", "re", "read", "reading", "reduce", "regularization", "relative", "report", "representation", "reshape", "resize", "result", "return", "run", "running", "sample", "sampling", "saving", "scikit", "score", "seaborn", "search", "second", "section", "segment", "separate", "separation", "set", "shape", "sign", "similar", "single", "size", "space", "sparse", "split", "splitting", "spread", "stack", "step", "store", "structure", "sub", "support", "table", "task", "technique", "tensorflow", "test", "think", "those", "through", "thumb", "time", "total", "tqdm", "train", "training", "transformation", "tree", "try", "tune", "tuning", "until", "up", "update", "validate", "validation", "value", "variance", "vector", "version", "video", "visualization", "while", "work"], "potential_description_queries_len": 261, "potential_script_queries": ["pathlib", "resize", "rgb2gray", "tensorflow"], "potential_script_queries_len": 4, "potential_entities_queries": ["data", "gaussian", "image", "nearest", "new", "random", "segment", "sign", "train"], "potential_entities_queries_len": 9, "potential_extra_queries": ["biopsy"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 262}
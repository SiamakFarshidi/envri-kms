{"name": "gans form scratch to advanced ", "full_name": " h2 Generative Adversarial Networks h3 1 What is a GAN h3 2 MNIST using GAN in TensorFlow h4 build a generator and discriminator h3 3 Deep convolutional GAN DCGAN h3 5 GAN architectures h4 a SRGAN Super Resolution GANs h3 What is a Perceptual Loss Function h3 How does a Perceptual Loss Function work h3 b CycleGAN h3 CycleGAN in TensorFlow 2 0 h4 Load dataset h4 Build our Generator h3 c InfoGAN ", "stargazers_count": 0, "forks_count": 0, "description": "The neural network model is trained on images where the perceptual loss function is optimized based upon high level features extracted from already trained networks. The idea is shown as follows To train the combined GANs the authors added besides the conventional GANadversarial loss a forward cycle consistency loss left figure and a backward cycleconsistency loss right figure. They made use of two GANs the generator of each GAN performing the image translation from one domain to anotherTo elaborate let us say the input is X then the generator of the first GAN performsa mapping G X Y thus its output would be Y G X. The generator of thesecond GAN performs an inverse mapping F Y X resulting in X F Y. The final output of the convolutional layer is flattened and feeds a one neuronclassifier layer. The batch normalized output thenundergoes ReLU activation in all the intermediate layers. Combined with the generator it works to form a mapping between random noise Zand its latent code c_hat. SRGANs use the perceptual loss function. We next add another Dense layer with512 hidden neurons followed by the third hidden layer with 1024 neurons andfinally the output layer with 784 neuronswe build a discriminator. Thefirst layer is a dense layer that takes the noise of 100 dimensions as an input. Its value was set to 1 in the paper and I c G Z c is the mutual information between the latent code c and the generator TensorFlow and tf. This vector is thenupsampled using TensorFlow Keras UpSampling2D layer. The100 dimensional input is expanded to a flat vector of size 128 7 7. shape generatedImages Labels for generated and real data One sided label smoothing Train discriminator Train generator we are saving the losses for each epoch and generating images after every 20 epochs Plot losses from every epoch input shape Build and compile the discriminator Build the generator The generator takes noise as input and generates imgs For the combined model we will only train the generator The discriminator takes generated images as input and determines validity The combined model stacked generator and discriminator Trains the generator to fool the discriminator load the data Rescale 1 to 1 Adversarial ground truths Train Discriminator Select a random half of images Sample noise and generate a batch of new images Train the discriminator real classified as ones and generated as zeros Train Generator Train the generator wants discriminator to mistake images as real Plot the progress If at save interval save generated image samples Rescale images 0 1 fig. GAN architectures a. Theupsampled image is passed to a convolutional layer. The generative model continues to improve its forgery capabilities andthe discriminative model continues to improve its forgery recognition capabilities. Later we freeze the weights ofthe discriminator and train the combined GAN this results in the training of thegenerator. The perceptual loss function is a more commonly used component as it often provides more accurate results regarding style transfer. So G and D play opposite games hence the nameadversarial training. png epoch Create a wall of generated MNIST images plt. This input is fed to a Dense layer with256 neurons with LeakyReLU activation. The output of the discriminator however is a single bit with 0 signifyinga fake image generated by generator and 1 signifying that the image is from thetraining datasetcombine the generator and discriminator together to form a GAN. The difference in the feature mapactivations in high layers of a VGG network between the network output part andthe high resolution part comprises the perceptual loss function. Eachdiscriminator is trained to distinguish between real images and synthesized images. shape imageBatch np. CycleGAN in TensorFlow 2. savefig images dcgan_mnist_ d. savefig images gan_generated_image_epoch_ d. png epoch Get a random set of input noise and images Generate fake MNIST images print np. Please remember thatin the paper the test network was trained for 200 epochs so our results will not bethat good c. The size of the noisy input is decided by the variable randomDim youcan initialize it to any integral value. For each epoch we take a sample of random noisefirst feed it to the generator and the generator produces a fake image. We first see thecode for the generator. Theselayers are defined in the functions downsample upsample and class basedon the TensorFlow Keras Model API ResnetIdentityBlock Build our GeneratorNow define the discriminator too. The GAN is trained such that it maximizesthe mutual information between the latent code c and the generated image G Z c. In general a value close to 1 denotes real while a value close to 0 denotes forgery. MNIST using GAN in TensorFlowLet us build a simple GAN capable of generating handwritten digitswill use a simple multi layered perceptron MLP and we will feed it an imageas a flat vector of size 784 build a generator and discriminatorThe purpose of thegenerator is to take in a noisy input and generate an image similar to the trainingdataset. This is done sothat finally we get an output of size 28 28 the standard size of MNIST handwrittendigits. The important new idea isto backpropagate through both the discriminator and the generator to adjust thegenerator s parameters in such a way that the generator can learn how to fool thediscriminator more often. This is achieved by adding aregularization term to the objective function of the conventional GANThe term Vg D G is the loss function of the conventional GAN and the second termis the regularization term where \u03bb is a constant. Notice now that the discriminator takes in theimages either from the training set or images generated by generator thus its inputsize is 784. This is in contrast to a per pixel loss function which sums all the absolute errors between pixels. In the GAN we ensure that the discriminator weights are fixed by setting the trainableargument to FalseThe trick to train the two is that we first train the discriminator separately weuse binary cross entropy loss for the discriminator. The authors found that we get morestable results with the Adam optimizer and a learning rate of 0. Generative Adversarial NetworksThis notebook is consists of code and some explanation from this awsome book Deep Learning with TensorFlow 2 and Keras Second Edition link https www. The InfoGAN uses theconcepts from information theory such that the noise term is transformed into latentcode that provides predictable and systematic control over the output. It aims to estimate c given X. Conventionally people set it to 100For ourimplementation we tried a value of 10. 0Here we will use a paired datasets for CycleGANs from TensorFlow s Dataset API dataset name is summer2winter_yosemite which contains imagesof Yosemite USA in summer Dataset A and winter Dataset B Load datasetSet hyperparameters normalize images in the range 1 1 for better performanceapply normalize to our train and test datasets and create a data generator thatwill provide images for training in batchesthe argument num_parallel_calls allows one to take benefitfrom multiple CPU cores in the system one should set its value to the numberof CPU cores in your systemlet us see an example of imagesTo construct the generator and discriminator we will require three sub modules theupsampling layer which will take in an image and perform a transpose convolutionoperation a downsampling layer which will perform the convention convolutionaloperation and a residual layer so that we can have a sufficiently deep model. The following figure shows the architecture of the InfoGAN The concatenated vector Z c is fed to the generator. png epoch get number of cores in your machine Downsampling through the model print skips Upsampling and establishing the skip connections bs 30 30 1 to use tf graph Translate images back to original domain. Note that we train G and D in an alternating manner whereeach one of their objectives is expressed as a loss function optimized via a gradientdescent. The fully connected classifying layers after the convolutions are removed. using the preceding defined generator and discriminator we construct the 2 CycleGANs We next define the loss and optimizers create placeholders for the labels of real and fake images define the function that trains the generator and discriminator in a batch a pair of images at a time. The generator is built by adding the layers sequentially. The pooling layers were replaced by strided convolutions in the discriminator and transposed convolutions in the generator. Besides perceptualloss the authors further added content loss and an adversarial loss so that imagesgenerated look more natural and the finer details more artistic. 2016 argues that perceptual loss functions are not only more accurate in generating high quality images but also do so as much as three times faster when optimized. The process isrepeated iteratively for a few thousand epochs. To achieve image translation the authors used a very simple and yet effective procedure. InfoGANInfoGAN provides control over various attributes of the images generated. D Y takes an input Y for instance an image andexpresses a vote to judge how real the input is. At each convolution step the images get downsampled using strides. CycleGAN A CycleGAN performs the image translation that is transfers an image given in one domain sceneryfor example to another domain in the absence of training examples. To help with the gradient flow batch normalization is done after every convolutional layer. We combinethe generated fake images and the actual training images in a batch with theirspecific labels and use them to train the discriminator first on the given batchin the same for loop we will train the generator. The convolutionalstrides and transposed convolutions are employed for the downsampling andupsampling of images. The layer has no weights so it is computationally cheap. The generator G Z is the one that makes the forgery and the discriminator D Y is the one that can judge how realistic the reproductions are based on its observations ofauthentic pieces of art and copies. Deep convolutional GAN DCGAN The main idea in the design was using convolutional layerswithout the use of pooling layers or the end classifier layers. The following diagram shows the generatorarchitecture The discriminator network takes in the images either generated by the generatoror from the real dataset and the images undergo convolution followed by batchnormalization. Generator kernel_initializer initializers. This ensures that if an image X is given as input thenafter the two translations F G X X the obtained image is the same X similarly thebackward cycle consistency loss ensures that G F Y Y. 02 Plot the loss from each batch plt. What is a GAN GANs train two neural nets simultaneously. The goal of training the discriminator D Y is to maximize D Y for every imagefrom the true data distribution and to minimize D Y for every image not fromthe true data distribution. How does a Perceptual Loss Function work In short the perceptual loss function works by summing all the squared errors between all the pixels and taking the mean. The SRGAN architectureconsists of three neural networks a very deep generator network which usesResidual modules a discriminator network and a pretrained VGG 16 network. com gb data deep learning with tensorflow 2 0 and keras second edition 1. Thetraining follows in the same manner as before that is we first train the discriminatoron a mini batch then freeze the discriminator and train the generator. org machine learning glossary and terms perceptual loss functionPerceptual loss functions are used when comparing two different images that look similar like the same photo but shifted by one pixel. SRGAN Super Resolution GANs GAN is trained in such a way that it can generate a photorealistic high resolution image when given a low resolution image. The CycleGAN s ability to perform image translation in the absence of training pairs is what makes it unique. CGAN for MNIST digitsLet us now build a DCGAN for generating handwritten digits. We are following the samearchitecture of discriminator and discriminator as in the paper by Zhu et al. The discriminator network usually a standard convolutional neural network tries to classify if an input image is real or generated. We repeat the structure that is upsampling convolution batch normalization ReLUIn the followinggenerator we have two such structures the first with 128 filters and the secondwith 64 filters in the convolution operation. A perceptual loss function is very similar to the per pixel loss function as both are used for training feed forward neural networks for image transformation tasks. G Z takes an input from randomnoise Z and it trains itself to fool D into thinking that whatever G Z produces is real. This convolutional layer learnsto fill in the details in the upsampled imageThe output of convolution is passedto batch normalization for better gradient flow. The basic idea of DCGANs is same as the vanilla GAN we have a generator thattakes in noise of 100 dimensions the noise is projected and reshaped and then ispassed through convolutional layers. The generator in an InfoGAN takes two inputs the latent space Z and a latent code c thus the output of the generator is G Z c. The Upsampling2D layer will now double the rows and columns of the 7 7 128 rows columns channels image yielding an output of size 14 14 128. The function is used to compare high level differences like content and style discrepancies between images. We want the imagesgenerated by the generator to be detected as real by the discriminator so we usea random vector noise as input to the generator this generates a fake imageand then trains the GAN such that the discriminator perceives the image as real 3. savefig images gan_loss_epoch_ d. The vector is reshaped to a tensor of size 7 7 128. The perceptualloss is defined as the weighted sum of content loss and adversarial loss What is a Perceptual Loss Function https deepai. Q c X is also a neural network. Before going into the details of the DCGAN architecture and its capabilities let us point out the major changes that were introduced in the paper The network consisted of all convolutional layers. Please note that this layersimply scales up the image by doubling rows and columns. The loss this time is also binary cross entropyperform the training. The two discriminators and the two generators are trainedvia this function with the help of the tape gradient define checkpoints to save the model weightsnow combine it all and train the network for 50 epochs. The final output is obtained froma pure convolutional layer with 3 filters and tan hyperbolic activation yieldingan image of size 28 28 1 5. RandomNormal stddev 0. At the end the generator will learn how to produce imagesthat are indistinguishable from the real ones 2. keras Helper libraries Set the seed for reproducible result normalize the input values such that each pixel has a value in range 1 1 Optimizer input dim. In the following diagram you can see the discriminatorThe generator and the discriminator are combined together to form the DCGAN. ", "id": "muhammedfathi/gans-form-scratch-to-advanced", "size": "13925", "language": "python", "html_url": "https://www.kaggle.com/code/muhammedfathi/gans-form-scratch-to-advanced", "git_url": "https://www.kaggle.com/code/muhammedfathi/gans-form-scratch-to-advanced", "script": "Flatten discriminator_loss __init__ Reshape tensorflow.keras.optimizers LeakyReLU plotLoss tensorflow.keras.layers save_imgs mnist tensorflow.keras.losses train Dropout Sequential Discriminator upsample tensorflow.keras.models Adam Conv2D mean_squared_error numpy downsample DCGAN() ResnetIdentityBlock(Model) Generator Input train_batch initializers build_generator Image matplotlib.pyplot Activation Dense tensorflow call tensorflow.keras.datasets build_discriminator tensorflow.keras saveGeneratedImages BatchNormalization normalize UpSampling2D tensorflow_datasets Model mean_absolute_error IPython.display ZeroPadding2D ", "entities": "(('whereeach one', 'gradientdescent'), 'note') (('authors', 'very simple yet procedure'), 'use') (('vector', 'TensorFlow Keras layer'), 'thenupsample') (('difference', 'resolution loss andthe high perceptual function'), 'comprise') (('batch normalized output', 'ReLU intermediate layers'), 'thenundergoe') (('Generative Adversarial NetworksThis notebook', 'Deep TensorFlow'), 'be') (('purpose', 'similar trainingdataset'), 'build') (('help', 'convolutional layer'), 'do') (('vector', 'size'), 'reshape') (('andthe discriminative model', 'forgery recognition capabilities'), 'continue') (('dimensional input', 'size'), 'expand') (('thus output', 'then first GAN performsa mapping'), 'make') (('that', 'time'), 'construct') (('loss', 'time also binary training'), 'be') (('us', 'handwritten digits'), 'build') (('images', 'batchnormalization'), 'show') (('Later we', 'thegenerator'), 'freeze') (('loss where perceptual function', 'already trained networks'), 'train') (('Perceptual Loss Function loss How short perceptual function', 'mean'), 'work') (('it', 'resolution when low image'), 'SRGAN') (('we', 'generator'), 'generate') (('that', 'output'), 'use') (('final output', 'one neuronclassifier layer'), 'flatten') (('generator', 'how thediscriminator'), 'backpropagate') (('it', 'training pairs'), 'be') (('we', 'learning 0'), 'find') (('png epoch', 'np'), 'get') (('both', 'image transformation tasks'), 'be') (('how imagesthat', 'real ones'), 'learn') (('goal', 'data true distribution'), 'be') (('pooling layers', 'generator'), 'replace') (('input', 'with256 LeakyReLU activation'), 'feed') (('more commonly used it', 'style transfer'), 'be') (('fill', 'passedto batch better gradient flow'), 'be') (('We', 'discriminator'), 'add') (('value', 'close to 1 denotes'), 'real') (('convolutionalstrides', 'images'), 'employ') (('how input', 'vote'), 'take') (('adversarial What', 'content loss'), 'define') (('two function', '50 epochs'), 'be') (('youcan', 'integral value'), 'decide') (('function', 'images'), 'use') (('network', 'convolutional layers'), 'let') (('authors', 'cycle consistency forward left figure'), 'show') (('I', 'c G Z latent code mutual c'), 'set') (('So G', 'opposite games'), 'play') (('GAN GANs', 'two neural nets'), 'be') (('mini batch', 'generator'), 'follow') (('image', 'together GAN'), 'be') (('png epoch', 'MNIST images generated plt'), 'create') (('such pixel', 'range'), 'librarie') (('we', 'convolution secondwith 64 operation'), 'repeat') (('thus inputsize', 'generator'), 'notice') (('we', '10'), 'set') (('We', 'Zhu et al'), 'follow') (('it', 'weights'), 'have') (('Theupsampled image', 'convolutional layer'), 'pass') (('that', 'training examples'), 'cyclegan') (('GAN Deep convolutional main idea', 'pooling layers'), 'DCGAN') (('InfoGANInfoGAN', 'images'), 'provide') (('generator', 'layers'), 'build') (('images', 'strides'), 'downsample') (('final output', 'activation yieldingan tan hyperbolic size'), 'obtain') (('downsample TensorFlow Keras Model ResnetIdentityBlock Build', 'discriminator'), 'define') (('where \u03bb', 'regularization term'), 'achieve') (('generator very deep which', 'discriminator usesResidual network'), 'network') (('dense that', 'input'), 'be') (('which', 'pixels'), 'be') (('noise', 'then convolutional layers'), 'be') (('produces', 'whatever'), 'take') (('gb data', 'deep tensorflow'), 'com') (('details', 'content further loss'), 'add') (('vector Z concatenated c', 'generator'), 'show') (('residual we', 'sufficiently deep model'), 'be') (('Eachdiscriminator', 'real images'), 'train') (('discriminatorThe generator', 'together DCGAN'), 'see') (('discriminator', 'image samples Rescale generated images'), 'side') (('Upsampling2D layer', 'size'), 'double') (('mapping F Y inverse X', 'X F Y.'), 'perform') (('it', 'latent code'), 'work') (('finally we', 'MNIST handwrittendigits'), 'do') (('separately binary', 'discriminator'), 'ensure') (('loss perceptual functions', 'quality only more high images'), 'argue') (('process', 'iteratively a few thousand epochs'), 'isrepeate') (('thebackward cycle consistency same X similarly loss', 'two translations'), 'ensure') (('generator', 'fake image'), 'take') (('such it', 'latent code maximizesthe mutual c'), 'train') (('that', 'one pixel'), 'use') (('results', 'good c.'), 'remember') (('Upsampling', 'back original domain'), 'get') (('discriminator', 'real 3'), 'want') (('how reproductions', 'ofauthentic art'), 'be') (('this', 'rows'), 'note') (('code latent thus output', 'generator'), 'take') ", "extra": "['biopsy of the greater curvature', 'test', 'procedure']", "label": "Perfect_files", "potential_description_queries": ["absolute", "adjust", "architecture", "argument", "art", "backward", "basic", "batch", "binary", "bit", "book", "build", "classifier", "classify", "close", "code", "combine", "combined", "compare", "compile", "consistency", "content", "contrast", "control", "convolution", "convolutional", "create", "cycle", "data", "dataset", "define", "detected", "difference", "distribution", "domain", "double", "downsample", "end", "ensure", "entropy", "epoch", "every", "faster", "feature", "feed", "figure", "fill", "final", "fixed", "flat", "flow", "following", "form", "forward", "found", "function", "gb", "general", "generate", "generated", "generator", "gradient", "graph", "ground", "half", "help", "high", "idea", "image", "improve", "initialize", "input", "instance", "interval", "itself", "label", "layer", "learn", "learning", "left", "let", "level", "link", "load", "look", "loop", "main", "major", "manner", "mapping", "mini", "minimize", "mistake", "model", "multiple", "mutual", "name", "network", "neural", "new", "next", "no", "noise", "normalization", "normalize", "normalized", "not", "notebook", "number", "objective", "optimizer", "out", "output", "pair", "part", "people", "per", "perform", "performing", "photo", "pixel", "png", "point", "pooling", "pretrained", "print", "provide", "purpose", "random", "range", "regularization", "residual", "resolution", "result", "right", "sample", "save", "saving", "second", "set", "shape", "short", "similar", "single", "size", "space", "squared", "standard", "step", "structure", "style", "sub", "sum", "system", "tensor", "tensorflow", "term", "test", "tf", "theory", "through", "time", "train", "training", "transformation", "transpose", "up", "upsampling", "value", "vanilla", "variable", "vector", "vote", "while", "work"], "potential_description_queries_len": 175, "potential_script_queries": ["call", "mnist", "numpy", "train"], "potential_script_queries_len": 4, "potential_entities_queries": ["binary", "consistency", "cycle", "generated", "high", "main", "neural", "short"], "potential_entities_queries_len": 8, "potential_extra_queries": ["biopsy", "procedure"], "potential_extra_queries_len": 2, "all_components_potential_queries_len": 178}
{"name": "panda wsi tiles preprocessing eda ", "full_name": " h1 PanDa tiles preprocessing h1 I Explorating code h2 Observations about I O times h2 Observation about unsignifiant pixel h2 Grid tile selection h2 Grid tile score h2 Tiles generation h2 Improve tiles generation h1 II Final code ", "stargazers_count": 0, "forks_count": 0, "description": "Open once a file 2. Note that with a multiprocess split we could drastically reduce the operations times. Moreover the tiles are often extract from the lower definition and if you want to keep more information or a different tile size you must put a new coin in the time machine Alternatively my assumption is that a reading on the fly of the slide is more efficient without local saving step. In the ideal on each file of the dataset we may follow these steps 1. It is equivalent of a grid of 32x32 tile on the low level 3. Let see how we can code this idea. Make any operation read extract. to proceed all the given dataset. Generate tiles from files in a given range Open Read lowest definition image Get number of gridsquares in x and y direction Browse each tiles Tile size depend on scale factor Localisation from the level 0 max scale interval to get coordinate Convert to black and white Keep only not blank tiles Close Extract tiles for all slides with multiprocessing Processes available Image per process split start tasks pooling OBSERVATION 1 1 5s to extract and score tiles from 1 slides OBSERVATION 2 10m to extract and score tiles of 961 slides from 1 process OBSERVATION 3 5m to extract and score tiles of 961 slides from 4 process Export tiles for further usage Import tiles dataframe for checkpoint purpose Free memory tiles_df pd. This notebook only concern image preprocessing before any model training. As we work with Radboud slides we will find details mask evaluated pixel by pixel. 5s to count white pixel on 1 slide Generate tiles for one slide Open Read lowest definition image Get number of gridsquares in x and y direction Browse each tiles Tile size depend on scale factor Localisation from the level 0 max scale interval to get coordinate Convert to black and white Keep only not blank tiles Close OBSERVATION 1 1 5s to extract and score tiles on 1 slides OBSERVATION 2 to keep an equivalent time we could use multiprocessing on a larger dataset of 5000 slides. But after testing some of this solutions I was disappointed by the time that it need several hours. I propose here an approach to generate tile information without having to save them locally but just by keeping any relevant information like coordinates and details Gleason score from Radboud mask. PanDa tiles preprocessingThis notebook is about the PanDa Dataset 2020 https www. With this grid we can select and display at different level any specific slide zone x y We can see here that a tile size of 128x128px on scale 4 can be a good trade off between size and quality details. Final codeBellow here is our final code to generate a tile label dataframe on all 5060 Radboud slides. read_csv kaggle input panda tiles EDA PANDA_tiles_EDA. Explorating code Observations about I O times As usually read write operations on the filesystem tend to increase a lot the global operations times. Then you can load this tiles selection to train your model. In the same conditions it will take more than 30 min. Secondly in the specific case of prostate biopsy there are at least 80 unusefull informations in the slide so you spend 80 of the time waiting for nothing relevant Thirdly saving any part of the original files is data redundant. So you can have a break take a coffe or play with your children You may also run reuse this separate script https www. head DEPENDANCIES DEPENDANCIES UTILITIES UTILITIES PARAMETERS PARAMETERS DATASET Get train label slides ID Keep only image_id Add filenames to dataframe Add train file column for each existing file in train folder Add label file column for each existing file in mask folder Split dataframe by provider we keep radboud scoring because their mask labels are more details Keep only row with both train and label file Release memory DATASET FUNCTIONS Open a slide Generate score tiles from files and masks Open files Read lowest definition image Get number of gridsquares in x and y direction Browse each tiles Tile size depend on scale factor Localization from the level 0 max scale interval to get coordinate Read biopsy file Convert to black and white Normalize the value between 0 and 1 0 white 1 black Keep only not empty tiles Read mask file Count by pixel score present on the first color channel Create a score dict Create an empty score list from 0 to 5 Update score list Add tile Close FUNCTIONS Launch timer EXTRACTION Extract label tiles for all slides with multiprocessing Processes available Image per process split start tasks pooling OBSERVATION 30m to extract and score 603602 tiles from 5060 slides on 4 process EXTRACTION OUTPUT Export tiles for further usage OBSERVATION output csv file of size 72 4Mb OUTPUT Print timer Use this to interrupt the multiprocess pool and free your CPUs after a Cancel run command. com iafoss panda 16x128x128 tiles and PAB97 https www. The overall runtime is about 30min. com c prostate cancer grade assessment Prostate Cancer Grade Assessment. Grid tile selectionAs we have seen previously opening and saving an important number of big files is not a great idea. csv index_col 0 tiles_df. com huynhdoo panda wsi tiles preprocessing script. com articles an automatic method to identify tissues from big whole slide images pt4. Tiles generationWe can extract tile informations slide region coordinate for only usefull tiles not empty Improve tiles generationThat seem a good way to decompose each in tiles that could be then send to any model. Grid tile scoreKnowing how to extract a specific tile from a slide we want now to score each tile for keeping only relevant information. Import common libraries Open a slide PARAMETERS Number slide Mask so we take the mask as the minimum value Keep only image_id Add filenames to dataframe Add train file column for each existing file in train folder Add label file column for each existing file in mask folder Split dataframe by provider we keep radboud scoring because their mask labels are more details Keep only row with both train and label file Check time to open and close a slide Open Close OBSERVATION 20ms by slide Keep only ISUP grade 5 Check times on this dataset Open Do something OBSERVATION 10s to open and close 964 slides Check time to open and close the lowest level image Open Read lowest definition image Close OBSERVATION 2 max scale interval to get coordinate Display Close OBSERVATION 330ms to display tiles on each level definition Display a heatmap of tile color intensities Open Read lowest definition image Get number of gridsquares in x and y direction Browse each tiles Tile size depend on scale factor Localisation from the level 0 max scale interval to get coordinate Convert to black and white Close Generate a heatmap Mask blank tiles OBSERVATION 1. Save once any export file 3. So I mention everytime is possibleYou can follow my details reflexion in part I Explorating code or jump and directly to the final code in part II Final code. Like layers in Photoshop you can create a tile grid on top of a slide that reveal only usefull informations like this proposition from Deron Eriksson Fei Hu https developer. I will particularly focus on runtime issue because it can be very frustating to wait too long between each iteration. Close once a file Observation about unsignifiant pixelAs we can observe there are a lot of unsignifiant regions on each slide with many empty white pixel from 80 to 98 of a slide. But can we add more usefull information during this generation process in order to save time for further exploration It is time to retrieve information from mask. But how can we deal with this so big images to send it to any learning algorithm in an efficient way Some Kaggle players have propose a tile extraction that keep the most relevant part of the image with most appearing tissues and less blank and save them to disk see Iafoss https www. Not so long in absolute time but for the purpose to iterate fastly on the dataset we should avoid any unusefull I O operation on the filesystem. We can apply the same previous process of white pixel counting on each tile. One of the first step will be to drop all these unsignifiant pixels by cropping our slide. It can be run alone without all previous codes. read_csv kaggle input panda tiles labels_EDA PANDA_tiles_labels_EDA. head Display a mask with tiles scoring Open Read lowest definition image Get number of tiles in x and y direction tiles with score dimension Browse each tiles Tile size depend on scale factor Localization from the level 0 max scale interval to get coordinate Create an empty score list Count by pixel score present on the first color channel Create a score dict Update score list Close Generate a heatmap Get negative zone score Mask threshold OBSERVATION 2s to score tiles from 1 slide Generate score tiles from files and masks Open files Read lowest definition image Get number of gridsquares in x and y direction Browse each tiles Tile size depend on scale factor Localization from the level 0 max scale interval to get coordinate Read biopsy file Convert to black and white Keep only not blank tiles Read mask file Count by pixel score present on the first color channel Create a score dict Create an empty score list from 0 to 5 Update score list Add tile Close Testing generate_tiles_labels Free memory Extract label tiles for all slides with multiprocessing Processes available Image per process split start tasks pooling OBSERVATION 1 2s to extract and score tiles from 1 slides OBSERVATION 2 6m to extract and score tiles from 964 slides on 4 process Use this to interrupt the multiprocess pool and free your CPUs after a Cancel run command Export tiles for further usage Import tiles with labels dataframe for checkpoint purpose Free memory tiles_labels_df pd. csv index_col 0 tiles_labels_df. Feel free to copy reuse and fork anything that you find usefull Author Do Huynh Date June 1st 2020 I. com rftexas better image tiles removing white spaces kernels. A stand alone script final version is also available PanDa Final script https www. Sounds good We can now add proportional gleason score on each tiles II. First if you want to benefit to the best definition the slide is to huge for the local memory and you will fastly face with not enough ressource. Like for white pixels we can use the corresponding masks to add 6 scores proportion column. ", "id": "huynhdoo/panda-wsi-tiles-preprocessing-eda", "size": "5169", "language": "python", "html_url": "https://www.kaggle.com/code/huynhdoo/panda-wsi-tiles-preprocessing-eda", "git_url": "https://www.kaggle.com/code/huynhdoo/panda-wsi-tiles-preprocessing-eda", "script": "__init__ elapsed_display Time generate_tiles matplotlib.ticker seaborn numpy generate_tiles_labels OpenSlideError elapsed Image matplotlib.pyplot get_tiles tqdm.notebook pandas tqdm open_slide IPython.display openslide ", "entities": "(('available Image', 'checkpoint purpose Free memory'), 'generate') (('Final codeBellow', 'Radboud 5060 slides'), 'be') (('We', 'II'), 'sound') (('we', 'only relevant information'), 'scoreknowe') (('reading', 'saving more local step'), 'be') (('72 OUTPUT Print 4Mb timer', 'Cancel run command'), 'parameter') (('tile here size', '4 good off size'), 'select') (('we', 'filesystem'), 'in') (('so you', 'original files'), 'be') (('You', 'script https also separate www'), 'have') (('you', 'fastly enough ressource'), 'first') (('that', 'then model'), 'extract') (('It', 'mask'), 'add') (('everytime possibleYou', 'part'), 'mention') (('It', 'alone previous codes'), 'run') (('PanDa notebook', 'https PanDa Dataset 2020 www'), 'tile') (('tiles', 'purpose memory tiles_labels_df checkpoint Free pd'), 'Display') (('we', 'scores proportion 6 column'), 'use') (('we', 'big files'), 'be') (('Then you', 'model'), 'load') (('that', 'Iafoss https www'), 'deal') (('it', 'more than 30 min'), 'take') (('we', 'operations drastically times'), 'note') (('that', 'Deron Eriksson Fei Hu https developer'), 'create') (('One', 'slide'), 'be') (('it', 'very too long iteration'), 'focus') (('usefull Author', 'Huynh Date'), 'feel') (('We', 'tile'), 'apply') (('details mask', 'pixel'), 'slide') (('we', 'slide'), 'observe') (('we', 'steps'), 'in') (('we', '5000 slides'), '5s') (('it', 'several hours'), 'disappoint') (('com', 'spaces white kernels'), 'rftexas') (('Mask blank tiles', '1'), 'open') (('It', 'low level'), 'be') (('I', 'details Gleason Radboud mask'), 'propose') ", "extra": "['biopsy', 'test']", "label": "Perfect_files", "potential_description_queries": ["absolute", "algorithm", "apply", "approach", "assessment", "best", "biopsy", "cancer", "case", "channel", "checkpoint", "children", "close", "code", "color", "column", "command", "copy", "could", "count", "create", "csv", "data", "dataframe", "dataset", "decompose", "depend", "dict", "dimension", "direction", "directly", "disk", "display", "drop", "empty", "export", "extract", "extraction", "face", "factor", "file", "final", "find", "fly", "folder", "generate", "generation", "grade", "grid", "head", "heatmap", "image", "increase", "input", "interval", "issue", "kaggle", "label", "learning", "least", "level", "list", "load", "local", "lot", "lower", "mask", "max", "memory", "mention", "method", "minimum", "model", "most", "multiprocessing", "my", "need", "negative", "new", "not", "notebook", "number", "open", "opening", "operation", "order", "output", "overall", "part", "per", "pixel", "pooling", "preprocessing", "present", "prostate", "provider", "purpose", "radboud", "range", "read", "reading", "reduce", "region", "row", "run", "runtime", "save", "saving", "scale", "score", "scoring", "script", "select", "selection", "separate", "several", "size", "slide", "something", "split", "start", "step", "testing", "threshold", "tile", "time", "timer", "train", "usage", "value", "version", "work", "write", "wsi"], "potential_description_queries_len": 134, "potential_script_queries": ["elapsed", "numpy", "openslide", "seaborn", "tqdm"], "potential_script_queries_len": 5, "potential_entities_queries": ["local", "purpose", "separate"], "potential_entities_queries_len": 3, "potential_extra_queries": ["test"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 140}
{"name": "cord 19 round 2 task 8 risk factors ", "full_name": " h1 Extracting information on covid 19 risk factors and constructing benchmark data for building machine learning models h2 Summary Tables of Studies Addressing 24 Different Risk Factors h1 Introduction h4 This notebook was organized in the following structure h1 Developing a Cleaned Dataset with Annotated Entity Types h2 Processing the CORD 19 Dataset h2 Entity Annotation h2 Aggregation and Indexing of CORD 19 Articles h1 Creating the Summary Tables h2 Loading the Data h2 Retrieving COVID 19 Related Articles h2 Keywords for Retrieving Articles Related to the Summary Table h3 Defining extended keyword lists for risk factors severity terms and mortality terms h2 Extracting relevant information h3 Extracting sentences with ratio pattern from Text column and add a new column called Sentence h3 Running the pipeline for all the other risk factors h2 Generating Summary Tables h1 Building machine learning models to answer specific questions h2 Sentence parsing h4 Loading the json files h2 Getting the Shortest Paths for Risk Factors h3 Finding the shortest pathes in the typed dependency graph between risk factor terms and disease severity fatality terms h3 Let s take risk factor age as an example finding the shortest path for age to severity fatality terms h3 Getting the shortest paths for all the risk factors ", "stargazers_count": 0, "forks_count": 0, "description": "The codes for extracting ids and article pre processing can be found as listed code for getting idscode for article process. First based on the CORD 19 dataset https www. com a deep learning powered search engine for biomedical literature. Sentence parsingTo build the machine learning models since the training sample size will be relatively small we will perform sentence parsing to generate more informative input for the machine learning model. keys Importing Python Packages and Tools Reading summary tables Displaying summary tables python preprocess_get_ids. es befree in our pipeline we modified a function of the package which can be found here https www. age hypertension etc. We call this as ratio pattern. gov research pubtator API we acquired annotations for the articles in the CORD 19 Dataset https www. All PubTator https www. Articles returned from the query were ranked by the counts of the keywords occuring in the articles. csv Save dataframes in a dictionary Get dataframe by risk factor name Study type extend keywords Regex for extracting sample size Filling Study Type Filling Sample Size Filling Ratios Saving risk factor dataframes into csv files Storing the files in a list and a dictionary Get the file from the dictionary Defining Graph data structure Note assumes edges are bi directional Defining dijsktra to get the shortest path from initial node to target node shortest paths is a dict of nodes whose value is a tuple of previous node weight next node is the destination with the lowest weight Work back through destinations in shortest path Reverse path Switching the order of a tuple Getting the intersection of two lists Getting the shortest path from initial node to target node with the dependecies print intersection sent_list combined_syn short_path dictionary take file name as a key and list of path as values gen_dic dictionary take touple from_node to_node file index as a key and path as a value file index is to distinguish those same from_node to_node print intersection sent_list combined_syn Saving gen_dic into a csv file. The manually verified information can be more valuable for scientists studying COVID 19 2. To be more specific the goal is to create summary tables report about Hypertension Diabetes Male gender Heart Disease COPD Smoking Status Age Cerebrovascular disease Cardio and cerebrovascular disease Cancer Respiratory system diseases Chronic kidney disease Chronic respiratory diseases Drinking Overweight or obese Chronic liver disease Asthma Chronic digestive disorder Dementia Endocrine diseases Heart Failure Immune system disorder Race Black vs White Ethnicity Hispanic vs non Hispacni This notebook was organized in the following structure 1. py python preprocess_cord_data. Extracting sentences with ratio pattern from Text column and add a new column called SentenceFollowing regex will find pattern like ratio keywords any word any word or ratio keywords In the dataframe defined above we store the sentences with the ratio pattern in the column Sentence. At the moment we are still working on generating high quality labelled data. The manually verified data can be used to build machine learning models to develop better information extraction systems. These manually curated data can also be used to build machine learning models. io scispacy includes different models for biomedical concept annotation among which two were used in our pipeline. We will first try some pre trained deep learning models. Addtional work can be done to decide if the paper is truly relevant to the target table based on the column Sentence. com gdsttian entities post tiabs to pubtator code for retrieving completed title and abstract annotations from PubTator https www. As most of the articles associated with COVID 19 were published in 2020 we limited the publication time to year 2020. Is a tagged number in the sentence the numerical result for such relationship If the answers to the above three questions are true then we can fill some important columns of the summary table. Task 8 is to create summary tables that address risk factor studies related to COVID 19 http www. gov pmc about covid 19 and manual reading of some relevant articles. Once the labelled training data are available we will build the model and update our notebook. com allen institute for ai CORD 19 research challenge asked participants to create summary tables with specific structures derived by expert curators. py python data_nodes_relations. git python entities_get_pubtator_annotation. es befree annotates entities of genes and diseases a python package needs to be installed from the BeFree repo https bitbucket. com gdsttian data nodes relations code for index by time https www. When annotations by different tools overlap with each other we selected the annotations with the largest span. One type of information we extract from sentence result is the shortest pathes between risk factor terms and disease terms. com allen institute for ai CORD 19 research challenge was organized by Kaggle as a call for actions to develop tools and information for answering scientific questions with high priority. Such sentences are stored in the Sentence column in the generated dataframes. com gdsttian data aggregation code for entities summary and relation building https www. com gdsttian befree ner covid19. In order to retrieve target articles we created indices of articles by publication time and keywords in titles and abstracts. gov research pubtator annotations were then parsed and organized in a consistent format for each article. Defining a function called get_odds to select papers with ratio pattern. We manually verified the summary tables generated by our pipeline for the following purposes 1. py python entities_process_pubtator_annotation. Developing a Cleaned Dataset with Annotated Entity Types Processing the CORD 19 Dataset https www. com and the department of statistics of Florida State University. Our information extraction pipeline consists of the following components. Each article was stored in a JSON file after the above pre processing. py data pathes folder for system data path of final json files dictionary mapping cord_uid to numeric id for each paper dictionary of list of papers for each publish year dictionary of list of papers for each word in title dictionary of list of papers for each word in abstract word counts by paper entity checking lists including disease list blacklist etc. com allen institute for ai CORD 19 research challenge including scholarly articles related to COVID 19 was created for global research community to generate helpful insight for the ongoing combat against this infectious disease using state of the art text mining NLP and other AI technologies. py pip install git https bitbucket. The two models and the entities annotated by each model are listed as follows en_ner_craft_md genes taxonomies sequence ontologies chemicals gene ontologies and cellline en_ner_jnlpba_md DNA cell type cellline RNA and proteinAll annotations were combined into a final set of annotations. Generating Summary Tables Building machine learning models to answer specific questionsFilling some columns of the summary table can be considered as answering certain questions. com allen institute for ai CORD 19 research challenge tasks taskId 888. We used spaCy https spacy. com gdsttian data indexing word Creating the Summary TablesAfter the clean annotated dataset was created we can start the query and information extraction process. gov research pubtator include Genes Diseases Chemicals Species Mutation CelllineBeside PubTator https www. For articles with pmids and or pmcids the pmids and pmcids will be used for getting entities annotations from PubTator. Sentence parsing was performed using Stanford Parser. to_csv csv riskfactor_name. com gdsttian entities retrieve tiabs from pubtator code for parsing PubTator annotations https www. The shortest pathes are used to further curate the relevant sentences. Loading the json files Getting the Shortest Paths for Risk Factors Finding the shortest pathes in the typed dependency graph between risk factor terms and disease severity fatality terms Let s take risk factor age as an example finding the shortest path for age to severity fatality terms. com gdsttian preprocess cord data. com gdsttian entities additional annotation esearch pubtator include Aggregation and Indexing of CORD 19 ArticlesWith all the CORD 19 articles processed and the annotations combined they were aggregated into a single JSON file. gov research pubtator provides annotations of biomedical concepts in PubMed abstracts and PMC full text articles. Our current pipeline can extract sentences with both risk factor keywords i. py python data_aggregation. py python data_indexing_word. Other information can also be extracted and used in the model building process. com allen institute for ai CORD 19 research challenge we verified the ids of doi pmid and pmcid of each article and organized all the articles in a consistent format. io for tokenization of titles and abstracts. com allen institute for ai CORD 19 research challenge last updated on June 09. com gdsttian mining search tool Loading the Data Retrieving COVID 19 Related ArticlesInformation for the summary tables need to be extracted from the articles relevant to COVID 19. Click code to see the code. io scispacy to annotate additional entities. com gdsttian preprocess get ids code for article process https www. com allen institute for ai CORD 19 research challenge we developed a dataset which is clean and annotated with different entities such as genes disease chemicals etc. Codes of the tools can be accessed by the following links code for utility tools https www. Query of relevant articles plays an important role in creating the summary tables. The CORD 19 competition https www. Using the PubTator https www. py python entities_post_tiabs_to_pubtator. and disease keywords COVID 19 severity mortality etc. When different tools annotate entities at the same span we gave priority to PubTator https www. To answer these questions the current question answering systems do not work well because the answers are highly specific to the questions. These tools can be used for data loading article query and display. If we manually annotate the sentences based on the questions we have proposed above then we can build machine learning models to extract the specific information required by the summary table. There are more than 35 thousand articles identified as relevant to COVID 19 in the CORD 19 dataset https www. For each article the entities identified were summarized and relations between entities were extracted if they co occur in the same sentence. gov research pubtator index. Running the pipeline for all the other risk factorsTo this point we have dataframes with information needed to fill the summary table for different risk factors. In response to the pandemic the CORD 19 dataset https www. gov research pubtator annotations we also used BeFree http ibi. com allen institute for ai CORD 19 research challenge Entity Annotation Aggregation and Indexing of CORD 19 Articles2. To tackle the challenges we have organized a collaborative team including scientists from Insilicom Inc. org nmonath befree src master. code for getting ids https www. Note that these setences are all from the column Text. We defined the list of extended keywords based on those used by the PMC COVID 19 Initiative https www. The manually verified data can be used as benchmark data for evaluating future studies on this type of problems 3. com gdsttian utils code for search tools https www. One of the articles was displayed as follows. using PubTator https www. All codes for data aggregation and indexing were given as follows code for data aggregation https www. io scispacy annotated entities Second we used extended keywords to query articles relevant to a paticular topic Third we used synonyms to further increase the coverage of the retrieved relevant articles Fourth we used regular expressions to extract specific information for filling certain columns of the tables Fifth we parsed the relevant sentences to obtain typed dependency graphs which were used to compute the shortest pathes between relevant keywords such as chemical names and COVID 19 related terms. All codes for annotations are available through the following links code for acquiring existing PubTator annotations https www. Does the sentence describe the risk factor relationship beween the risk factor term and the disease term or severity fatality 2. Insilicom specializes in providing innovative technologies to help scientists effectively use Big Data to accelerate their research and development efforts. Keywords for Retrieving Articles Related to the Summary Table Defining extended keyword lists for risk factors severity terms and mortality terms Extracting relevant informationWe will first take age as an example and later generalize to other risk factorsWith age related papers we select those papers with patterns indicating numerical outcome of the studies for example containing OR AOR HR AHR RR and RH. gov research pubtator. These articles were queried using a list of keywords. We import the python packages and the tools we developed for the process. In the above dataframe the column Text stores the paragraph with a matching pattern The column Ratio stores all the numerical results of the corresponding ratio pattern. gov research pubtator web interface to retrieve the annotations. Does the sentence contain numerical result for such relationship 3. Getting the shortest paths for all the risk factorsshort_path. com gdsttian data indexing time code for index by words https www. The entities annotated by PubTator https www. py python entities_additional_annotation. In order to use BeFree http ibi. com allen institute for ai CORD 19 research challenge discussion 150921 of the CORD 19 challenge https www. Round 2 https www. To tackle such problem we formulated it as building machine learning models to perform classification tasks. Here we are displaying our manually curated summary tables using the results of our pipeline IntroductionThe COVID 19 pandemic has caused nearly 8 million confirmed infected patients and more than 430 thousand deathes worldwide. com allen institute for ai CORD 19 research challenge when they are available. Building machine learning models to answer specific questions Sentence Parsing Getting the shortest paths for risk factors Developing a Cleaned Dataset with Annotated Entity Types Processing the CORD 19 DatasetTo process the CORD 19 Dataset http https www. py python entities_retrieve_tiabs_from_pubtator. entities dictionary entity relation dictionary mapping sent id to numeric id mapping word to a list of numeric sent id dictionary of all sentences with unique id packages load dataset for search and display Defining extended keyword quries for risk factors Collecting the query name as a list for future usage. com gdsttian entities get pubtator annotation code for posting titles abd abstracts to PubTator for annotations https www. com gdsttian entities process pubtator annotation code for adding BeFree and scispacy annotations https www. Entity AnnotationEntity annotation is very helpful for extracting relevant information. html BeFree http ibi. After parsing the sentence on local machine we stored the files as json files. Extracting information on covid 19 risk factors and constructing benchmark data for building machine learning models Summary Tables of Studies Addressing 24 Different Risk FactorsWe developed a pipeline and a set of approaches to create the summary tables as specified in task 8 using the CORD 19 Dataset https www. PubTator https www. es befree and scispacy https allenai. It recently developed the Biomedical Knowledge Discovery Engine BioKDE https biokde. Creating the Summary Tables Retrieving COVID 19 Related Articles Keywords for Retrieving Articles Related to the Summary Table Extracting relevant infromation Generating the Summary Tables3. Transfer dictionary to a dataframe Adding column Sentence to store the sentences with pattern ratio keywords Modifying the dataframe Save dataframes as csv files dfn. py python data_indexing_time. They will also be used in the future for building predictive models for the corresponding information extraction tasks Finally we have manually verified the summary tables before submitting to obtain a manually curated dataset which can be used in future studies as benchmark data. scispacy https allenai. For example whether a sentence should be an entry in the table can be determined by answering the following questions 1. com allen institute for ai CORD 19 research challenge updated on June 9. For those without pre calculated annotations we used the PubTator https www. Defining extended keyword list for risk factors Defining extended keyword lists for severity terms and mortality terms Getting papers related with age searching over titles and abstracts published in 2020 Get the subset of Covid 19 related papers The following pattern is looking for pattern ratio keywords numbers Search over full text to get papers with pattern ratios such as OR AOR HR AHR RR RH and save these to a dictionary if any word in combined synonyms list is in abstract then we store the paper print rate if any word in combined synonyms list is in body text then we store the paper print rate Transfering dictionary to a dataframe If there are more than one sentences matching the pattern then store it in another column Sentence2 Combining column Setence and Sentence2 Here we use df_dic to store the dataframe. which also contain numerical results in the ratio pattern. ", "id": "bitmman/cord-19-round-2-task-8-risk-factors", "size": "15470", "language": "python", "html_url": "https://www.kaggle.com/code/bitmman/cord-19-round-2-task-8-risk-factors", "git_url": "https://www.kaggle.com/code/bitmman/cord-19-round-2-task-8-risk-factors", "script": "__init__ display interactive ipywidgets get_odds mining_search_tool defaultdict collections intersection utils Graph() shortest_path interact add_edge pandas widgets tqdm dijsktra switch IPython.display ", "entities": "(('which', 'benchmark data'), 'use') (('we', 'process'), 'import') (('com gdsttian entities', 'PubTator https abstract www'), 'post') (('Entity AnnotationEntity annotation', 'very relevant information'), 'be') (('they', 'same sentence'), 'summarize') (('codes', 'PubTator annotations https existing www'), 'be') (('Query', 'summary tables'), 'play') (('com allen institute', 'expert curators'), 'ask') (('setences', 'all column'), 'note') (('tools', 'data loading article query'), 'use') (('information extraction pipeline', 'following components'), 'consist') (('then we', 'summary table'), 'be') (('we', 'notebook'), 'be') (('shortest pathes', 'further relevant sentences'), 'use') (('disease keywords', 'severity mortality 19 etc'), 'COVID') (('Here we', 'dataframe'), 'store') (('manually curated data', 'machine learning also models'), 'use') (('we', 'AOR HR AHR OR RR'), 'take') (('com allen institute', 'last June'), 'update') (('Sentence parsing', 'Stanford Parser'), 'perform') (('One', 'articles'), 'display') (('manually verified data', 'problems'), 'use') (('sequence ontologies', 'annotations'), 'list') (('sentence', 'risk factor term'), 'describe') (('we', 'titles'), 'create') (('codes', 'data aggregation https www'), 'give') (('well answers', 'highly questions'), 'work') (('pre processing', 'article process'), 'find') (('gov research pubtator', 'PubMed abstracts'), 'provide') (('research 19 global community', 'art text'), 'create') (('scientists', 'research efforts'), 'specialize') (('we', 'Insilicom Inc.'), 'tackle') (('keys', 'summary tables python preprocess_get_ids'), 'read') (('we', 'risk factor shortest terms'), 'be') (('actions', 'high priority'), 'organize') (('dictionary', 'print intersection sent_list combined_syn csv to_node file'), 'dataframe') (('which', '19 related terms'), 'scispacy') (('disease severity fatality s', 'fatality terms'), 'load') (('we', 'column'), 'find') (('we', 'json files'), 'store') (('we', 'information query process'), 'create') (('manually verified data', 'information extraction better systems'), 'use') (('com gdsttian entities', 'PubTator annotations https www'), 'retrieve') (('Such sentences', 'generated dataframes'), 'store') (('Other information', 'model building also process'), 'extract') (('gov research pubtator we', 'Dataset https CORD 19 www'), 'API') (('we', 'PubTator https www'), 'use') (('gov research pubtator annotations', 'article'), 'parse') (('paper', 'column'), 'do') (('we', 'largest span'), 'select') (('we', 'classification tasks'), 'formulate') (('manually verified information', 'COVID'), 'be') (('we', 'publication time year'), 'limit') (('Codes', 'utility tools https www'), 'access') (('com gdsttian entities', 'annotations https BeFree www'), 'process') (('then we', 'summary table'), 'build') (('they', 'JSON single file'), 'include') (('article', 'pre processing'), 'store') (('We', 'Initiative https PMC COVID 19 www'), 'define') (('we', 'PubTator https www'), 'give') (('py data pathes', 'disease list blacklist etc'), 'folder') (('entry', 'following questions'), 'be') (('com gdsttian preprocess', 'article process https www'), 'get') (('displaying', '8 nearly million confirmed infected patients'), 'cause') (('which', 'package'), 'modify') (('we', 'consistent format'), 'institute') (('gov research pubtator', 'Genes Diseases Chemicals Species Mutation CelllineBeside PubTator https www'), 'include') (('articles', 'keywords'), 'query') (('notebook', 'following structure'), 'be') (('returned', 'articles'), 'rank') (('which', 'ratio pattern'), 'contain') (('current pipeline', 'risk factor keywords i.'), 'extract') (('i d', 'future usage'), 'send') (('We', 'learning deep models'), 'try') (('we', 'still high quality labelled data'), 'work') (('gov research pubtator we', 'BeFree http also ibi'), 'annotation') (('columns', 'certain questions'), 'consider') (('when they', 'com allen research ai CORD 19 challenge'), 'institute') (('sentence', 'such relationship'), 'contain') (('point we', 'risk different factors'), 'have') (('two', 'pipeline'), 'include') (('com gdsttian entities', 'annotations https www'), 'get') (('We', 'following purposes'), 'verify') (('pmids', 'PubTator'), 'use') (('which', 'genes disease chemicals such etc'), 'institute') (('Extracting', 'Dataset https 8 CORD 19 www'), 'develop') (('19 Related ArticlesInformation', 'relevant COVID'), 'tool') (('It', 'Biomedical Knowledge Discovery Engine BioKDE https recently biokde'), 'develop') (('that', 'http 19 www'), 'be') (('relatively we', 'machine learning model'), 'build') ", "extra": "['annotation', 'disease', 'gender', 'outcome', 'patient', 'test', 'male gender']", "label": "Perfect_files", "potential_description_queries": ["abstract", "age", "annotate", "annotation", "answer", "art", "article", "associated", "benchmark", "body", "build", "call", "cell", "challenge", "checking", "chemical", "classification", "clean", "code", "column", "combined", "community", "competition", "compute", "concept", "contain", "create", "csv", "current", "data", "dataframe", "dataset", "describe", "develop", "development", "dict", "dictionary", "disease", "display", "entity", "extend", "extract", "extraction", "factor", "file", "fill", "final", "find", "folder", "following", "format", "found", "function", "future", "gender", "generate", "generated", "graph", "help", "high", "http", "https 2 www", "id", "import", "include", "including", "increase", "index", "infected", "input", "intersection", "io", "json", "key", "kidney", "labelled", "largest", "learning", "list", "liver", "load", "local", "looking", "manual", "mapping", "matching", "model", "moment", "mortality", "most", "name", "need", "new", "next", "node", "non", "not", "notebook", "number", "numeric", "numerical", "order", "outcome", "overlap", "package", "pandemic", "path", "pattern", "perform", "pipeline", "point", "post", "pre", "print", "problem", "processing", "publication", "py", "python", "query", "question", "ratio", "reading", "relation", "relationship", "report", "research", "respiratory", "response", "result", "risk", "role", "sample", "save", "scientific", "search", "select", "selected", "sent", "sentence", "sequence", "set", "shortest", "single", "size", "src", "start", "state", "store", "structure", "subset", "summary", "system", "table", "target", "task", "team", "term", "text", "those", "through", "time", "title", "tokenization", "tool", "topic", "training", "try", "tuple", "type", "unique", "update", "value", "web", "weight", "word", "work", "year"], "potential_description_queries_len": 178, "potential_script_queries": ["defaultdict", "interact", "interactive", "tqdm"], "potential_script_queries_len": 4, "potential_entities_queries": ["article", "data", "extraction", "high", "infected", "labelled", "list", "python", "research", "single"], "potential_entities_queries_len": 10, "potential_extra_queries": ["male"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 180}
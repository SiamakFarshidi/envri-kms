{"name": "eda security master analysis ", "full_name": " h1 Security Master Analysis h1 Why Sec Master Analysis h3 What are some questions we want to answer h2 Making time series features when rows dates are missing h1 Takeaways ", "stargazers_count": 0, "forks_count": 0, "description": "Data providers usually provide a permanent ID so that you can keep track of this over time. Here I calculate the difference between the number of business days in each span and the count of valid days sorted by most missing data. Let s see if we can find any news on this company back in 2007. For example T Mobile US Inc And we can trace the lifetime of this company over multiple assetCodes. You can see this data matches with the lifetimes dataframe subset above. The company started its life as PCS. Therefore the assetName must not be point in time rather it looks like assetName is the name of the company when this dataset was created for Kaggle recently and then backfilled. Takeaways Security master issues are critical. Now let s look at whether tickers change over time. Long horizon features like say 12m momentum may not produce sufficient asset coverage to be useful becuase so much data is missing. assetCode is not consistent across time the same economic entity can and in many cases does have a different assetCode assetCode is not a permanent identifier. Because of this overlapping data there is no way to be sure about how to link assets over time. However assetName continues to look like a consistent choice over time for a perm ID. When we look at the amount of data in these spans it is even more surprising. The rules state Each asset is identified by an assetCode note that a single company may have multiple assetCodes. Is either assetCode or assetName unique So there are a number of companies that have more than 1 assetCode over their lifetime. The fact that an asset is missing data is not informative in itself it is an artifact of the data collection and delivery process. Missing time series data does not show up as NaN on the trading calendar rather the rows are just missing. the rolling average of 20 days spans the missing period of 2007 03 20 and is a non fixed frequency. You have to be very careful with time based features because of missing data. N was merged with TMUS. It is possible that a company changed its ticker and it s name on the same day and therefore we would not be able to catch this but let s assume this doesn t happen. This is not provided here although in fact both Intrinio and Reuters provide this in the for sale version of the data used in this competition. What is the nature of missing data What does it mean when data is missing Let s explore and see. A security master refers to reference data about the lifetime of a particular asset tracking ticker changes name changes etc over time. assetCode object a unique id of an assetSo is it unique or not and can we join time series features always over time on assetCode What about assetName Is that unique or do names change over time assetName category the name that corresponds to a group of assetCodes. These may be Unknown if the corresponding assetCode does not have any rows in the news data. Let s compare the asset lifetimes with the amout of data in those lifetime. This implies that you cannot use NLP on the headline field in any way to join or infer asset clustering. This is hard to verify without proper commercial security master data but I don t think that the actual name of this company in 2007 was T Mobile it was something like Metro PCS. As we saw above it is not possible to do this 100 without error because we don t know the permanent identifier we must make a tradeoff between the error of using assetCode or assetName. Given that assetCode will never overlap on time and therefore allows using time as an index I choose that here. What about in this dataset YES We can conclude that since no assetCode has ever been linked to more than assetName that assetName could be a good choice for a permanent identifier. This is unfortunate becuase you may hypothesize that news impact is a bigger driver of return variance during the early part of an asset s life due to lack of analyst coverage lack of participation by quants etc. In finance raw information is typically uninteresting and uninformative and you need to do substantial feature engineering and create either or both of time series and cross sectional features. For example ticker VNDA. T Mobile acquired MetroPCS on May 1 2013 google search when did t mobile acquire MetroPCS. What about the other way around Is assetName a unique identifier In the real world companies change their names all the time a hilarious example of this is here https www. So even though we asked for a 20 day window as long as there is at least 1 data point we will get a windowed average. O didn t exist during those times we just don t have data. As such to make time series features you have to be careful with pandas rolling calculations and roll on calendar days not naively on the count of rows. It took me awhile to get this to work as pandas complains a lot on multi idexes this issue https github. com pandas dev pandas issues 15584 helped a lot. However here is a major gotcha dual class stock. To make a rolling feature it was my initial inclination to try something like Let s see what we got Look at the time index. What are some questions we want to answer Is assetCode a unique and permanent identifier If you group by assetCode and make time series features are you assured to be referencing the same instrument In the real world the ticker symbol is not guaranteed to refer to the same company over time. The result makes sense if you look at 2009 06 26 you will see that the rolling average does not include any information from the year 2007 rather it is time aware and since there are 19 missing rows before give the 1 day windowed average. This is not exciting fancy data science but absolutely essential. http Let s define a valid has_data day for each asset if there is reported trading volume for the day. Looking across the entire dataset however things look a little better. Kaggle competitions are usually won in the third or fourth decimal place of the score so every detail matters. You are stuck with one of two bad choices link on assetCode and miss ticker changes and corporate actions or link on assetName but get bad output in the case of dual class shares. Making time series features when rows dates are missingLet s say you want to make rolling window time series feature like a moving average on volume. the result makes no sense. There are very many assets that only exist for say 50 days or less. Security Master Analysisby marketneutral Why Sec Master Analysis Before you do anything exciting in financial data science you need to understand the nature of the universe of assets you are working with and how the data is presented otherwise garbage in garbage out. Likely the most well know is Google called Alphabet Inc for its full life in this dataset another is Comcast Corp. The next best thing is to roll on calendar days freq tag D. And let s see how long an asset is alive by the the distance betwen the first reported data point and last and the number of days in that distance that actually has dataThis was shocking to me. This is much better Note that the default min_periods is 1 when you use a freq tag i. hypothesizing that days since IPO is a valid feature and use that as a factor. However it would be very odd for the Reuters News Data to not be point in time. assetName while consistent across time can refer to more than once stock at the same time and therefore cannot be used to make time series features assetName is not a unique permanent identifier. Depending on what you wish to do you may use the assetCode assetName or time as a way to join the market data to news data. N NYSE listed and then became Nasdaq listed. What s fascinating here is that you can see in the article headlines that the company is named correctly point in time as MetroPCS Communications Inc however the assetName is listed as T Mobile US Inc. In this case if you want to make long horizon time based features you need to join on assetName. One gotcha I see is that don t think that assetName is correct point in time. However in that 2556 days there are only 115 days that actually have data It s not the case that VNDA. For example you cannot calcuate a true asset age e. O has its first data point on 2007 02 23 and its last on 2016 12 22 for a span of 2556 business days. Though not very common some companies issue more than one class of stock at the same time. com long blockchain company iced tea sec stock 2018 8. However to do that without error requires that you deeply understand the nature of the asset universe. So the organizers have also backfilled today s assetName into the news history. Make environment and get data Note the D and on time. ", "id": "marketneutral/eda-security-master-analysis", "size": "9456", "language": "python", "html_url": "https://www.kaggle.com/code/marketneutral/eda-security-master-analysis", "git_url": "https://www.kaggle.com/code/marketneutral/eda-security-master-analysis", "script": "kaggle.competitions twosigmanews iplot init_notebook_mode numpy matplotlib.pyplot plotly.offline plotly.graph_objs pandas cufflinks plotly.plotly ", "entities": "(('tickers', 'time'), 'let') (('pandas', 'multi idexes'), 'take') (('Kaggle competitions', 'score'), 'win') (('we', 'time index'), 'be') (('you', 'asset universe'), 'require') (('very companies', 'same time'), 'issue') (('corresponding', 'news data'), 'be') (('however things', 'entire dataset'), 'look') (('single company', 'multiple assetCodes'), 'state') (('time hilarious example', 'this'), 'be') (('however the', 'T Mobile US Inc.'), 'be') (('typically you', 'sectional features'), 'uninteresting') (('you', 'asset clustering'), 'imply') (('rather it', 'time 19 missing 1 day'), 'make') (('data', 'lifetimes'), 'see') (('when you', 'freq tag i.'), 'be') (('So organizers', 'news also today history'), 'backfille') (('doesn', 'this'), 'be') (('T it', 'Metro PCS'), 'be') (('most Google', 'Comcast Corp.'), 'likely') (('However it', 'time'), 'be') (('ticker symbol', 'time'), 'be') (('You', 'missing data'), 'have') (('time therefore series', 'same time'), 'refer') (('features you', 'horizon long time'), 'need') (('T Mobile US we', 'multiple assetCodes'), 'Inc') (('Here I', 'most missing data'), 'calculate') (('This', 'data fancy science'), 'be') (('next best thing', 'calendar days freq tag D.'), 'be') (('It', 'actually data'), 'be') (('useful so much data', 'asset sufficient coverage'), 'feature') (('we', 'back 2007'), 'let') (('you', 'rows'), 'make') (('we', 'don just data'), 'have') (('that', 'assetCodes'), 'object') (('it', 'data collection process'), 'be') (('com pandas dev pandas issues', 'lot'), 'help') (('rolling average', '2007'), 'span') (('I', 'that'), 'give') (('you', 'asset age true e.'), 'calcuate') (('s', 'What'), 'be') (('you', 'time'), 'provide') (('rather rows', 'trading calendar'), 'show') (('window time rolling series', 'volume'), 'say') (('how data', 'otherwise garbage'), 'marketneutral') (('very many that', 'only say'), 'be') (('assetCode', 'good permanent identifier'), 'about') (('s', 'day'), 'let') (('T Mobile', 't when mobile acquire'), 'acquire') (('assetName', 'correct time'), 'be') (('we', 'assetCode'), 'be') (('Intrinio', 'competition'), 'provide') (('news impact', 'quants'), 'be') (('data as long at least 1 we', 'windowed average'), 'get') (('s', 'lifetime'), 'let') (('it', 'spans'), 'be') (('security master', 'time'), 'refer') (('that', 'lifetime'), 'be') (('You', 'class dual shares'), 'stick') (('actually dataThis', 'me'), 'let') (('same economic entity', 'assetCode different assetCode'), 'be') (('blockchain com long company', 'tea sec stock'), 'ice') (('when dataset', 'Kaggle'), 'point') (('you', 'news data'), 'use') (('IPO', 'factor'), 'hypothesize') (('data', 'time'), 'make') ", "extra": "['bag']", "label": "Perfect_files", "potential_description_queries": ["age", "answer", "article", "artifact", "asset", "average", "best", "blockchain", "calculate", "case", "category", "choice", "choose", "collection", "company", "compare", "correct", "could", "count", "create", "data", "dataframe", "dataset", "day", "default", "define", "detail", "difference", "distance", "engineering", "entity", "environment", "error", "even", "every", "explore", "fact", "feature", "field", "find", "fixed", "freq", "google", "group", "http", "id", "include", "index", "issue", "itself", "join", "least", "let", "life", "lifetime", "link", "little", "look", "lot", "major", "market", "mean", "missing", "momentum", "most", "multiple", "my", "name", "nature", "need", "next", "no", "non", "not", "number", "object", "output", "overlap", "part", "period", "place", "point", "provide", "raw", "reference", "result", "return", "roll", "science", "score", "search", "sense", "single", "something", "state", "subset", "tag", "think", "those", "ticker", "time", "track", "try", "unique", "up", "valid", "variance", "verify", "version", "volume", "while", "window", "work", "world", "year"], "potential_description_queries_len": 115, "potential_script_queries": ["iplot", "kaggle", "numpy", "plotly"], "potential_script_queries_len": 4, "potential_entities_queries": ["best", "freq", "missing", "time"], "potential_entities_queries_len": 4, "potential_extra_queries": ["bag"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 120}
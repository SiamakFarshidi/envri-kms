{"name": "kernelbecbda8662 ", "full_name": " h2 Introduction h1 1 Get your data h1 2 Explore the dataset h1 3 Define your objective and metrics h1 4 Set a baseline model h3 4 1 Create features h3 4 2 Run a simple algorithm h3 4 3 Optimize the hyper parameters of your algorithm h2 5 Improve features and model h3 5 1 Better features h3 5 2 Better Algorithms h2 6 Use Deep Learning ", "stargazers_count": 0, "forks_count": 0, "description": "Introduction In this tutorial we work on breast histology images. Use a learning algorithm you think appropriate k nearest neighbors linear or logistic regression random forests SVMs neural networks and XGboost 3. Here we use stratified cross validation the proportion of positive and negative examples is the same in all folds Let s have a look to the split size and We look at RGB histograms represent colors. and you didn t see that birth of date was in these values your algorithm is going to learn a completly dumb thing. Get your data The first step is simply to get your data Data can have any modality csv file dicom image text file mp3 record. Explore the dataset Let s explore your dataset now It is fundamental to become familiar with your data especially if you re not an expert. The machine learning scheme is quite different from the statistics scheme we evaluate a model based on its predictive performance and not on the probability to observe the data given the model. score4 train 1 2 3 4 test 5. In cross validation we split the dataset multiple times ex 80 20 or 90 10 and average the performances on the diffrent test sets. Extract features from your data. for negative images and 1 2 3 for positive images and compare the histograms. A common technique is to partition the dataset into N equal parts called folds and to split N times the dataset such that each part will be once the test set. Set a baseline model Now it s time to create our first model A good practice is to set a baseline i. Colors could be an easy way to classify these images 3. Create features The PCA shows that our simple histogram feature already permits to linearly separate a bit positive and negative images Good point 4. If m of these neighors e. Plot histograms correlations use standard data analysis techniques sur as PCA Try to evaluate the difficulty of the task you want to perform And of course have a look to related works on this dataset Maybe someone did the work for you Here we can observe that colors are quite different between positive images and negative images. The idea is to split the dataset into 2 groups the training set that we will use to calibrate the parameters of a model and the test set that we will use to evaluate the performance of the model using our metric. Optimize the hyper parameters of your learning algorithm 4. Then using your favorite programming language mainly python or R and appopriated packages pandas numpy. Optimize the hyper parameters of your algorithm 5. For instance imagine you have to predict the age of a patient based on is height weight and other values. I did the work for you images labels associated to images 0 no cancer 1 cancer How many images What is the size of the images Looking at some images images with label 0 no cancer negative image images with label 1 cancer positive image Each batch plot 50 negative images on the left and 50 positive images on the right Prepare the folds for a cross validation. A common machine learning way to create a new model is 1. g m 6 have label 1 then output p 60. Note that accuracy is not always a good measure if you have an unbalanced dataset with only 1 of positive examples predicting always 0 negative will lead to a 99 accuracy The measure is often called metric or loss. Better Algorithms 6. Here expert knowledge is welcome 2. We decide to keep 50 bins in the histogram but you can try other values up to 255 Here we visualize our features in 2D using PCA colored by the positive red negative blue class Try to replace PCA by SpectralEmbedding TSNE Here we will use the k nearest neighbors algorithm given a new image find the k e. Each time the network saw the entire dataset is called epoch. It permits to quickly have a first score to compare with when using more complex models and it also often helps a lot to organize your code and data. To measure the predictive performance using our metric we will use cross validation. It depends on what you want interested by the trade off precision recall use F1 score. Run a simple algorithm 4. This step includes Checking data issues of any sort missing values outliers unreadable files etc. In our case the objective or task is binary classification of images and our measure performance will be the accuracy percentage of good classification. score3 train 1 2 3 5 test 4. The more epochs the more the networks learn to recognize the training imagss and generalize it s performance on the test set. In our case we saw that colors of the images could be a good feature. But when possible it shows amazing performance In the code below we run quite a randomly designed neural network to see how it works. Searching bias in the dataset. On the learning curve you can observe the accuracy of the network on the training set in red and on the test set in blue. Define your objective and metrics Now that you are familiar with your data you have to define your objective and the way you will measure how you achieved it. com use case 6 invasive ductal carcinoma idc segmentation 1. Interested by the trade off true positive detection false positive detection Use ROC AUC. you can read your data. score5 predictive performance score1 score2 score3 score4 score5 5 4. Don t expect it to have very good results Also use it as a black box as this tuto doesn t aim to explain how deep learning works Training a neural network can be long so we just use 1 foldA neural network is trained by showing him the dataset multiple times. Improve features and model 5. Histogram counts the number of pixels with a certain intensity between 0 and 255 for each color red green and blue. A peak at 255 for all colors mean a lot of white Try 0 1 2. k 10 images in the training set with the most similar histograms. This function run train the model For each fold Train the model on the training data And predict the results on the test data Return all the predictions probabilities between 0 and 1 Here we use kNN model And call the function run_model Let s print the results How does the accuracy evolves with the number of neighbors Here we use features extracted from a deep neural network we achieve much better results with the same algorithm that our simple histogram features Nearest Neighbors The code to extract deep learning features a bit long to run model ResNet50 weights imagenet include_top False pooling max Logisitic Regression Random Forests We use keras library wuth tensorflow backend Special callback to see learning curves Preprocess the data center and normalize Create the model first layer convolution second layer pooling reduce the size of the image per 3 output 1 value between 0 and 1 probability to have cancer Use binary crossentropy as a loss function try to add loss to see the loss learning curve. Our goal is to classify Invasive Ductal Carcinoma IDC images vs non IDC images using a standard data science pipeline Explore your dataset Define your objective and a metric Set a baseline algorithm features model parameter optimization Improve it The dataset has been curated from Andrew Janowczyk website http www. Use Deep Learning Deep learning for images is end to end there is no need to exctract features from the image because the algorithm learns itself these features from raw data Neural networks are not easy to train especially from scratch and require a lot of data. But if we go too far the network memorized perfectly the training set very high accuracy on training which leads to poor generalization low accuracy on the test this phenomenom is called overfitting. For instance if you divide your dataset into 5 folds 1 2 3 4 5 then you will split 5 times the dataset train 2 3 4 5 test 1 evaluate performance on the test set to get score1 train 1 3 4 5 test 2. Our feature will be the concatenation of the 3 histograms red green and blue. We use the very useful scikit learn package. score2 train 1 2 4 5 test 3. Better features 5. ", "id": "alaedine/kernelbecbda8662", "size": "6152", "language": "python", "html_url": "https://www.kaggle.com/code/alaedine/kernelbecbda8662", "git_url": "https://www.kaggle.com/code/alaedine/kernelbecbda8662", "script": "Flatten sklearn.metrics __init__ PCA MetricsCheckpoint(Callback) keras.layers keras.callbacks scipy.misc mnist EarlyStopping Dropout SpectralEmbedding Sequential KNeighborsClassifier keras.datasets on_epoch_end TSNE Conv2D numpy matplotlib.pylab sklearn.decomposition sklearn.ensemble run_model sklearn.model_selection confusion_matrix RandomForestClassifier Dense sklearn.manifold ResNet50 StratifiedKFold as KFold keras.applications.resnet50 LogisticRegression preprocess_input Callback sklearn.neighbors roc_auc_score sklearn.linear_model StratifiedKFold roc_curve MaxPooling2D backend backend as K keras keras.models plot_accuracy ", "entities": "(('especially you', 'data'), 'explore') (('such part', 'dataset'), 'be') (('we', 'cross validation'), 'use') (('dataset', 'Andrew Janowczyk website'), 'be') (('feature', 'red 3 histograms green'), 'be') (('logistic regression random forests', 'neural networks'), 'think') (('algorithm', 'completly dumb thing'), 'see') (('we', 'breast histology images'), 'introduction') (('batch', 'cross validation'), 'do') (('model', 'loss learning curve'), 'run') (('false positive detection', 'ROC AUC'), 'Use') (('Good', 'already linearly bit positive images'), 'feature') (('Here we', 'k e.'), 'decide') (('foldA neural just 1 network', 'dataset multiple times'), 'expect') (('We', 'colors'), 'use') (('we', 'model'), 'be') (('it', 'code'), 'permit') (('score1', 'test'), 'split') (('features', 'data'), 'use') (('Histogram', 'color red green'), 'count') (('you', 'patient'), 'imagine') (('data simply Data', 'modality csv file dicom image text file mp3 record'), 'get') (('you', 'precision recall use F1 trade score'), 'depend') (('good practice', 'baseline i.'), 'set') (('colors', 'quite positive images'), 'use') (('test we', 'metric'), 'be') (('how it', 'randomly designed neural network'), 'show') (('we', 'test diffrent sets'), 'split') (('how you', 'it'), 'have') (('step', 'unreadable files'), 'include') (('colors', 'images'), 'see') (('learning common machine way', 'new model'), 'be') (('We', 'package'), 'use') (('measure', '99 accuracy'), 'lead') (('peak', 'white Try'), 'mean') (('measure performance', 'accuracy good classification'), 'be') (('Colors', '3'), 'be') (('you', 'blue'), 'observe') (('phenomenom', 'test'), 'memorize') (('it', 'test set'), 'learn') ", "extra": "['patient', 'test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "age", "algorithm", "associated", "average", "backend", "baseline", "batch", "become", "binary", "bit", "box", "breast", "call", "cancer", "case", "center", "classification", "classify", "code", "color", "colored", "compare", "convolution", "correlations", "could", "course", "create", "crossentropy", "csv", "curve", "data", "dataset", "date", "define", "detection", "dicom", "end", "equal", "evaluate", "ex", "explore", "extract", "feature", "file", "find", "fold", "function", "generalization", "green", "height", "high", "him", "histogram", "http", "idea", "image", "imagenet", "instance", "intensity", "itself", "knowledge", "label", "language", "layer", "lead", "learn", "learning", "left", "library", "linear", "look", "lot", "max", "mean", "measure", "metric", "missing", "model", "most", "multiple", "nearest", "need", "negative", "network", "neural", "new", "no", "non", "normalize", "not", "number", "objective", "optimization", "organize", "output", "parameter", "part", "patient", "peak", "per", "percentage", "perform", "performance", "pipeline", "plot", "point", "pooling", "positive", "practice", "precision", "predict", "print", "probability", "python", "random", "raw", "re", "read", "recall", "reduce", "regression", "replace", "right", "run", "science", "scikit", "score", "scratch", "second", "segmentation", "separate", "set", "similar", "size", "sort", "split", "standard", "step", "task", "technique", "tensorflow", "test", "text", "think", "time", "train", "training", "try", "tutorial", "up", "validation", "value", "visualize", "website", "weight", "work"], "potential_description_queries_len": 157, "potential_script_queries": ["mnist", "numpy"], "potential_script_queries_len": 2, "potential_entities_queries": ["csv", "file", "learning", "neural", "random", "regression"], "potential_entities_queries_len": 6, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 158}
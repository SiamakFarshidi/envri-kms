{"name": "0 123 lb pytorch unet run on google cloud ", "full_name": " h1 UNET Pytorch implementation ", "stargazers_count": 0, "forks_count": 0, "description": "up_3 conv_block in_channels 384 out_channels 256 self. confidences 0. The 2D convolution uses 3x3 filters with stride 1 and padding 1. middle_t conv_t_block in_channels 512 out_channels 256 self. up_2 out 192x128x128 128x128x128 out self. cat down2 out 1 128x128x128 concat 64x128x128 192x128x128 out self. UNET Pytorch implementationThis notebook contains a custom UNET segmentation model that I implemented from scratch using pytorch applied to the RSNA pneumonia challenge. max_pool2d down2 kernel_size 2 stride 2 128x128x128 128x64x64 down3 self. imshow dataset_train 3 1 0 cmap mpl. I created a public dataset called pytorch unet pneumonia output where I put the final submission file and some outputs obtained from the run on Google Cloud. down_1 conv_block in_channels 1 out_channels 64 self. append target pIds. size 512x16x16 256x32x32 out torch. jet print dataset_train 3 1. down_2 out 64x128x128 128x128x128 out F. cat down4 out 1 512x32x32 concat 256x32x32 768x32x32 out self. imshow box_mask 5 20 50 100 shape 256 cmap mpl. up_2_t out output_size down1. up_2 conv_block in_channels 192 out_channels 128 self. shape print parse_boxes dataset_train 3 1 define function that creates prediction strings as expected in submission predicted_boxes confidences parse_boxes dataset_train 3 1 print predicted_boxes confidences print prediction_string predicted_boxes confidences define iou function pr box_mask 50 60 100 150 shape 256 gt box_mask 30 40 100 140 shape 256 plt. up_5 conv_block in_channels 768 out_channels 512 self. size 256x64x64 64x128x128 out torch. up_5_t conv_t_block in_channels 512 out_channels 256 self. up_5_t out output_size down4. imshow box_mask box_t shape 256 cmap mpl. up_1 out 96x256x256 1x256x256 return out print model architecture Create the loss function Define the 2D Sigmoid Binary Cross Entropy loss function BCEWithLogitsLoss TBD add weights for unbalanced class NOTE Rather than using weights I also intended to try implement focal loss see RetinaNet Define auxiliary metric functions define function that creates a square mask for a box from its coordinates plt. com ternaus TernausNet but adapted to a single channel input and without using transfer learning. size 128x128x128 32x256x256 out torch. sample frac 1 does the shuffling get test set patient IDs create dictionary of patientId list of boxes define a MinMaxScaler function for the images round at closest integer and transform to integer define a warping image mask function define the data generator class initialize variables get the corresponding pId load dicom file as numpy array check if image is square calculate network image shape check if image_shape is an integer resize image IMPORTANT skimage resize function rescales the output from 0 to 1 and pytorch doesn t like this One solution would be using torchvision rescale function but need to differentiate img and target transforms Here I use skimage resize and then rescale the output again from 0 to 255 recale image from 0 to 255 image warping augmentation add trailing channel dimension apply rotation augmentation generate random angle apply transforms to image create target mask if patient ID has associated target boxes if image contains pneumonia loop through boxes extract box coordinates rescale box coordinates create a mask of 1s 255 is used because pytorch will rescale to 0 1 inside the box correct in case of overlapping boxes shouldn t happen add trailing channel dimension apply rotation augmentation apply transforms to target manual model parameters resize factor to reduce image size new_image_shape original_image_shape rescale_factor I used 25 on GCP recalculate minimum box area TBD add normalization of images into transforms define transformation create datasets define the dataloaders with the previous dataset Check if train images have been properly loaded Display some examples picking an image with pneumonia 0 is the channel index here there s just one channel Check if test images have been properly loaded 0 is the channel index here there s just one channel Define the nn convolutional block Define the nn transposed convolutional block the actual model function is defined here NOTE the comments are meant to help understand check the input output sizes of the tensor and they assume an input image size of 256x256 but the model can accept larger smaller sizes tho I haven t debugged it yet 1x256x256 64x256x256 64x256x256 64x128x128 64x128x128 128x128x128 128x128x128 128x64x64 128x64x64 256x64x64 256x64x64 256x32x32 256x32x32 512x32x32 512x32x32 512x16x16 512x16x16 512x16x16 512x16x16 512x8x8 512x8x8 512x8x8 512x8x8 256x16x16 512x16x16 concat 256x16x16 768x16x16 768x16x16 512x16x16 512x16x16 256x32x32 512x32x32 concat 256x32x32 768x32x32 768x32x32 512x32x32 512x32x32 128x64x64 256x64x64 concat 128x64x64 384x64x64 384x64x64 256x64x64 256x64x64 64x128x128 128x128x128 concat 64x128x128 192x128x128 192x128x128 128x128x128 128x128x128 32x256x256 64x256x256 concat 32x256x256 96x256x256 96x256x256 1x256x256 class PneumoniaUNET nn. cat down3 out 1 256x64x64 concat 128x64x64 384x64x64 out self. down_4 conv_block in_channels 256 out_channels 512 self. The following code pertains to the unet model proper. up_4 out 768x32x32 512x32x32 out self. imshow box_mask box_p shape 256 cmap mpl. down_3 out 128x64x64 256x64x64 out F. cat down5 out 1 512x16x16 concat 256x16x16 768x16x16 out self. up_4 conv_block in_channels 768 out_channels 512 self. down_4 out 256x32x32 512x32x32 out F. 3 for box_t in target_boxes plt. size 512x8x8 256x16x16 out torch. down_3 conv_block in_channels 128 out_channels 256 self. up_3_t conv_t_block in_channels 256 out_channels 64 self. max_pool2d down1 kernel_size 2 stride 2 64x256x256 64x128x128 down2 self. 75 sort boxes according to their confidence from largest to smallest iterate over thresholds with a first loop we measure true and false positives initiate number of true positives initiate number of false positives iterate over predicted boxes coordinates generate boolean mask iterate over ground truth boxes coordinates generate boolean mask calculate IoU if IoU is above the threshold we got one more true positive and one less false positive proceed to the next predicted box with a second loop we measure false negatives initiate number of false negatives iterate over ground truth boxes coordinates generate boolean mask iterate over predicted boxes coordinates generate boolean mask calculate IoU proceed to the next ground truth box TBD this algo must be checked against the official Kaggle evaluation method which is still not clear. max_pool2d down3 kernel_size 2 stride 2 256x64x64 256x32x32 down4 self. read train dataset read test dataset calculate minimum box area as benchmark for CNN model arbitrary value for minimum box area in the CNN model shuffle and create patient ID list then split into train and validation sets. Feedback questions are most welcome Below I import the preprocessed labels data that I generated in a previous eda kernel https www. __init__ self. 3 print IoU pr gt define precision function print precision 3 1 1 define function that calculates the average precision of an image if both predicted and target boxes are empty precision is NaN and doesn t count towards the batch average if we have predicted boxes but no target boxes precision is 0 if we have target boxes but no predicted boxes precision is 0 if we have both predicted and target boxes proceed to calculate image average precision define list of thresholds for IoU 0. up_2_t conv_t_block in_channels 128 out_channels 32 self. The second function conv_t_block does the upsampling for the upscaling half of the unet. size 512x32x32 128x64x64 out torch. The activation function is a leaky ReLU with alpha 0. up_5 out 768x16x16 512x16x16 out self. up_3 out 384x64x64 256x64x64 out self. 123 submission file in the data attached to this kernel. However you can find the LB 0. jet define function that extracts confidence and coordinates of boxes from a prediction mask extract 2d array select pixels above threshold and mark them as positives 1 in an array of equal size as the input prediction mask label regions iterate over regions and extract box coordinates retrieve x y height and width and add to prediction string add control over box size eliminate if too small plt. The following code prepares the training data in a useful format for the unet model. down_1 x 1x256x256 64x256x256 out F. NOTE I have not attempted yet to optimize these hyperparameters. Module def __init__ self super PneumoniaUNET self. max_pool2d down5 kernel_size 2 stride 2 512x16x16 512x8x8 out self. up_3_t out output_size down2. up_4_t out output_size down3. up_1 conv_block in_channels 96 out_channels 1 def forward self x down1 self. middle out 512x8x8 512x8x8 out self. down_5 out 512x16x16 512x16x16 out F. com giuliasavorgnan start here beginner intro to lung opacity s1. append pId average_precision_batch targets pIds pId_boxes_dict rescale_factor shape 256 define the training function set model to train model iterate over batches break loop after num_steps batches useful for debugging Convert torch tensor to Variable compute output compute loss compute gradient and do optimizer step update loss running average Evaluate summaries only once in a while extract data from torch Variable move to cpu compute average precision on this batch log results log epoch summary set model to evaluation mode compute metrics over the dataset break loop after num_steps batches useful for debugging Convert torch tensor to Variable compute model output compute loss of batch extract data from torch Variable move to cpu compute individual precisions of batch images compute mean of all metrics in summary reload weights from restore_file if specified define the optimizer reduce the learning rate at each epoch Run one epoch train model for a whole epoc one full pass over the training set Evaluate for one epoch on validation set Save best weights based on best_val_loss and best_val_prec set model to evaluation mode Convert torch tensor to Variable compute output train and evaluate the model define an instance of the model define the loss function define initial learning rate will be reduced over epochs Train the model visualize training loss history pick model with best precision create predictions for the validation set to compare against ground truth extracting individual coordinates create a rectangle patch get current axis and draw rectangle add confidence value in annotation text rescale and extract box coordinates create a rectangle patch get current axis and draw rectangle grid search to cross validate the best threshold for the boxes check the results on the validation set print every 100 0 is the channel index here there s just one channel create submission predictions for the test set. The cnn architecture was inspired to this model https github. max_pool2d down4 kernel_size 2 stride 2 512x32x32 512x16x16 down5 self. middle_t out output_size down5. down_2 conv_block in_channels 64 out_channels 128 self. up_4_t conv_t_block in_channels 512 out_channels 128 self. down_5 conv_block in_channels 512 out_channels 512 self. 9 predicted_boxes 20 20 60 70 110 110 50 70 target_boxes 25 25 60 70 100 100 50 70 200 200 30 50 for box_p in predicted_boxes plt. In an attempt to control the number of false positive boxes I calculate the distribution of the boxes area and manually select a lower limit for the unet model. The basic block conv_block of the unet model consists of a 2D convolution batch normalization activation sequence. Unfortunately it cannot be run on Kaggle using a batch_size of 25 images as in the original setup I ran on Google Cloud GPU out of memory. cat down1 out 1 64x256x256 concat 32x256x256 96x256x256 out self. The model was trained for 10 epochs 5 hours on Google Cloud using 8 CPUs and 1 NVIDIA TESLA P100 GPU specs PyTorch 0. middle conv_block in_channels 512 out_channels 512 self. 3 print average_precision_image predicted_boxes confidences target_boxes define function that calculates the average precision of a batch of images iterate over batch prediction masks and relative patient IDs retrieve target boxes from dictionary quicker than from mask itself rescale coordinates of target boxes extract prediction boxes and confidences targets pIds for i in range 5 img target pId dataset_train i targets. ", "id": "giuliasavorgnan/0-123-lb-pytorch-unet-run-on-google-cloud", "size": "1821", "language": "python", "html_url": "https://www.kaggle.com/code/giuliasavorgnan/0-123-lb-pytorch-unet-run-on-google-cloud", "git_url": "https://www.kaggle.com/code/giuliasavorgnan/0-123-lb-pytorch-unet-run-on-google-cloud", "script": "torch.utils.data rescale_intensity __init__ skimage.transform box_mask torch torch.autograd draw_boxes imgMinMaxScaler predict parse_boxes elastic_transform train DataLoader matplotlib.patches forward gaussian_filter numpy __getitem__ conv_block(nn.Module) skimage.exposure evaluate torch.utils.data.dataset torchvision precision PneumoniaDataset(torchDataset) get_boxes_per_patient scipy.ndimage.interpolation nn save_checkpoint RunningAverage() matplotlib.pyplot pandas rescale_box_coordinates get_prediction_string_per_pId Dataset __len__ BCEWithLogitsLoss2d(nn.Module) average_precision_batch resize conv_t_block(nn.Module) train_and_evaluate Variable Dataset as torchDataset scipy.ndimage.filters torch.nn.functional average_precision_image matplotlib update PneumoniaUNET(nn.Module) map_coordinates IoU __call__ prediction_string Rectangle ", "entities": "(('box_mask box_p', 'cmap 256 mpl'), 'imshow') (('256x32x32', '768x32x32 self'), 'down4') (('2D convolution', '1 1'), 'use') (('target boxes', 'IoU 0'), 'IoU') (('I', 'memory'), 'run') (('pytorch unet pneumonia where I', 'Google Cloud'), 'create') (('cnn architecture', 'model https github'), 'inspire') (('I', 'RSNA pneumonia challenge'), 'Pytorch') (('NOTE I', 'yet hyperparameters'), 'attempt') (('activation function', 'leaky alpha'), 'be') (('input prediction mask label regions', 'too small plt'), 'retrieve') (('cat', '1 out 128x128x128 concat'), 'down2') (('following code', 'unet model'), 'prepare') (('second function', 'unet'), 'do') (('channel 100 0 here just one channel', 'test set'), 'target') (('prediction_string predicted_boxes', 'iou function'), 'dataset_train') (('pId dataset_train i', 'img range 5 target'), 'confidence') (('cat', '1 256x64x64 concat'), 'down3') (('that', 'plt'), 'up_1') (('block basic conv_block', '2D convolution batch normalization activation sequence'), 'consist') (('which', 'Kaggle evaluation official method'), 'initiate') (('I', 'unet model'), 'calculate') (('model', '8 CPUs'), 'train') (('I', 'eda kernel https previous www'), 'be') (('1x256x256 256x32x32 128x64x64 yet 128x128x128 512x16x16 512x16x16 512x8x8 512x8x8 256x16x16 256x16x16 512x16x16 512x16x16 512x32x32 256x64x64', 'haven it'), 'frac') ", "extra": "['annotation', 'patient', 'test', 'lung']", "label": "Perfect_files", "potential_description_queries": ["256x256", "annotation", "append", "apply", "architecture", "area", "array", "associated", "augmentation", "average", "basic", "batch", "batch_size", "benchmark", "best", "block", "boolean", "box", "calculate", "case", "cat", "channel", "check", "cnn", "code", "compare", "compute", "confidence", "control", "convolution", "convolutional", "correct", "count", "create", "current", "custom", "data", "dataset", "def", "define", "dicom", "dictionary", "dimension", "distribution", "draw", "eda", "empty", "epoch", "equal", "evaluate", "evaluation", "every", "expected", "extract", "factor", "file", "final", "find", "focal", "following", "format", "forward", "frac", "function", "generate", "generated", "generator", "gradient", "grid", "ground", "gt", "half", "height", "help", "history", "image", "img", "implement", "import", "imshow", "index", "individual", "initialize", "input", "instance", "integer", "iou", "itself", "kernel", "label", "largest", "leaky", "learning", "list", "load", "log", "loop", "lower", "lung", "manual", "mask", "mean", "measure", "method", "metric", "middle", "minimum", "mode", "model", "most", "move", "need", "network", "next", "nn", "no", "normalization", "not", "notebook", "number", "numpy", "official", "opacity", "optimize", "optimizer", "out", "output", "padding", "patch", "patient", "pneumonia", "positive", "precision", "prediction", "print", "public", "pytorch", "random", "range", "read", "reduce", "relative", "rescale", "resize", "return", "run", "running", "sample", "scratch", "search", "second", "segmentation", "select", "set", "setup", "shape", "shuffle", "single", "size", "skimage", "solution", "sort", "split", "square", "start", "step", "stride", "string", "submission", "summary", "target", "tensor", "test", "text", "threshold", "through", "torch", "torchvision", "train", "training", "transfer", "transform", "transformation", "try", "update", "upsampling", "validate", "validation", "value", "visualize", "while", "width"], "potential_description_queries_len": 192, "potential_script_queries": ["evaluate", "matplotlib", "ndimage", "numpy", "predict", "torch", "train"], "potential_script_queries_len": 7, "potential_entities_queries": ["batch", "evaluation", "label", "normalization", "out", "prediction"], "potential_entities_queries_len": 6, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 193}
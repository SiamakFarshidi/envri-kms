{"name": "vinbigdata detectron2 train ", "full_name": " h1 VinBigData detectron2 train h1 Table of Contents h1 Dataset preparation h1 Installation h1 Training method implementations h2 Data preparation h1 Customizing detectron2 trainer h2 Mapper for augmentation h2 Evaluator h2 Loss evaluation hook h2 LR scheduling h1 Loading Data h1 Data Visualization h1 Training h1 Visualize loss curve competition metric AP40 h1 Visualization of augmentation by Mapper h3 If this kernel helps you please upvote to keep me motivated Thanks h1 Next step h2 Discussions ", "stargazers_count": 0, "forks_count": 0, "description": "com corochann vinbigdata 2 class classifier complete pipeline kernel explains how to train 2 class classifier model for the prediction and submisssion for this competition. Below code is to visualize the same data 4 times. See installation https detectron2. com c vinbigdata chest xray abnormalities detection discussion 220295 Suggests how to predict more smaller sized high aspect ratio bonding boxes. Ref detectron2 docs Dataloader https detectron2. pop annotations None dataset_dict. This is the inverse of data loading logic in datasets coco. com c vinbigdata chest xray abnormalities detection discussion 219221 Investigation of test dataset annotation distribution. com facebookresearch detectron2 blob 22b70a8078eb09da38d0fefa130d0f537562bebc tools visualize_data. This can be done by adding Hook which calculates the loss to the trainer. com c vinbigdata chest xray abnormalities detection discussion 207955. read_csv imgdir test_meta. get_image 1 pass aug_kwargs to cfg Let training initialize from model zoo pick a good LR Small value Frequent save need a lot of storage. dimension of precision TxRxKxAxM IoU dimension of recall TxKxAxM stats 2 _summarize 1 iouThr. roi_batch_size_per_image 128 faster and good enough for this toy dataset default 512 eval_period 20 aug_kwargs HorizontalFlip p 0. inspired from Detectron https github. In practice loading all the taining image arrays are too heavy to be loaded on memory so these are loaded inside DataLoader on demand This is done by mapper class in detectron2 as I will expain later. pop sem_seg_file_name None return dataset_dict h w it will be modified by code below aug_input T. com corochann vinbigdata detectron2 prediction kernel explains how to use trained model for the prediction and submisssion for this competition. best most iou find the proposal box that covers the best covered gt box record the iou coverage of this gt box mark the proposal box and the gt box as used append recorded iou coverage level thresholds torch. com corochann vinbigdata detectron2 prediction too UPDATE 2021 1 24 I added more advanced usage to customize detectron2 especially How to define use mapper to add your customized augmentation. These models are summarized in MODEL_ZOO. You just need to wrap above training scripts by main method and use launch method provided by detectron2. You can change which one to use by setting cfg. bbox_original int row x_min int row y_min int row x_max int row y_max test_meta pd. 5 args parse Read data Read in the data CSV files alias sample_submission pd. put_scalars validation_loss mean_loss is called to put this validation loss to the storage which will be saved to metrics. 15 rotate_limit 10 p 0. This leads to a different definition of small medium large. com facebookresearch detectron2 Detectron2 is Facebook AI Research s next generation software system that implements state of the art object detection algorithms. It is a ground up rewrite of the previous version Detectron and it originates from maskrcnn benchmark. Here I modified COCOEvaluator implementation to calculate AP with IoU 0. com 1381301 66535560 d3422200 eace 11e9 9123 5535d469db19. This is because model s evaluation is done in model. html I implemented MyMapper which uses augmentations implemented in detectron2 and AlbumentationsMapper which uses albumentations library augmentations. This dataset_dicts contains the metadata for actual data fed into the neural network. Since mapper is used inside DataLoader we can check its behavior by constucting DataLoader and visualize the data processed by the DataLoader. It is nice to start with however I want to customize the training behavior more to improve the model s performance. NOTE this config means the number of classes but a few popular unofficial tutorials incorrect uses num_classes 1 here. Visualization of augmentation by MapperLet s check the behavior of Mapper method. Resize 800 800 it will be modified by code below if not self. import matplotlib. It affects to the score a lot Preferable radiologist s id in the test dataset https www. 95 but we need AP with IoU 0. We can make own Trainer class MyTrainer here for this purpose and override methods to provide customized behavior. There are really many That s all I found that the competition data is not so many 15000 for all images 4000 images after filtering No finding images. 0 is used in this kaggle docker image. com facebookresearch detectron2 blob master configs COCO Detection faster_rcnn_R_50_FPN_3x. Famouns dataset s evaluator is already implemented in detectron2. Please refer official example train_net. 5 to be consistent with the annotation format. It is loaded beforehand of the training on memory so it should contain all the metadata image filepath etc to construct training dataset but should not contain heavy data. width width of the image. detectron2 is one of the famous pytorch object detection library I will introduce how to use this library to train models provided by this library with this competition s data https github. height height of the image. LR_SCHEDULER_NAME as you can see from the docs. com corochann preprocessing image original size lossless png on kaggle fails due to disk limit Please upvote the dataset as well Installationdetectron2 is not pre installed in this kaggle docker so let s install it. transforms with MyMapper class it provides basic augmentations. Data VisualizationIt s also very easy to visualize prepared training dataset with detectron2. put_scalars timetest 11 from detectron2. read_csv datadir sample_submission. Define Hook to calculate validation loss plotting training validation loss curve. augmentations aug_input image aug_input. Therefore we subtract 0. I insert LossEvalHook before evalutor to work well. is_train dataset_dict. com apofeniaco training on detectron2 with a validation set and plot loss on it to avoid overfitting 6449418fbf4e Now all the preparation has done MyTrainer overwraps build_evaluator method of DefaultTrainer provided by detectron2 to support validation dataset evaluation. com c vinbigdata chest xray abnormalities detection discussion 219672 The 1 step pipeline which does not use any 2 class classifier approach is proposed. We can analyze plot them to check how the training proceeded. json jsonl format during training. image_id id of the image index is used here. Loss evaluation hookWe implemented Evaluator and now we can calculate competition metric however validation loss is not calculated inside Evaluator. However our predictions are floating point coordinates. draw_dataset_dict per_image. image category_id np. html build_lr_scheduler supports only 2 types of LR scheduling WarmupMultiStepLR default WarmupCosineLR. 4 Use the COCO default keypoint OKS sigmas unless overrides are specified COCOAPI requires every detection and every gt to have keypoints so we just take the first entry from both Copying inference_on_dataset from evaluator. csv To get number of data. We can follow installation instruction https github. com drive 16jcaJoc6bCFAQ96jDe2HwtXj7BMD_ m5 scrollTo QHnVupBBn9eR Colab Notebook or version 7 of this kernel https www. Here I will just use the dataset VinBigData Chest X ray Resized PNG 256x256 https www. 40 and replaced to show this value instead of AP with IoU 0. Use validation data during training. Training method implementationsBasically we don t need to implement neural network part detectron2 already implements famous architectures and provides its pre trained weights. In my experiment Calcification seems to be the most difficult class to predict. array obj category_id for obj in dataset_dict annotations dtype np. We remove the bbox field to let mask AP use mask area. Copy so the caller can do whatever with results unmap the category ids for COCO cocoapi does not handle empty results very well Saving generated box proposals to file. com facebookresearch detectron2 blob master tools train_net. Load 1 image to get image size. I will demonstrate these augmentations later so you can skip reading the code and please just jump to next. float32 compute recall for each iou threshold ar 2 np. 5 ShiftScaleRotate scale_limit 0. This annotator does not find anything skip. Then I noticed that we can use many augmentations in albumentations so I implemented AlbumentationsMapper to support it. py L222 L252 noqa precision has dims iou recall cls area range max dets area range index 0 all area ranges max dets index 1 typically 100 per image tabulate it use RLE to encode the masks because they are too large and takes memory since this evaluator stores outputs of the entire dataset counts is an array encoded by mask_util as a byte stream. It does not take long time to train less than a day so this competition may be a good choice for beginners who want to learn object detection If this kernel helps you please upvote to keep me motivated Thanks Next step VinBigData detectron2 prediction https www. HACKING overwrite iouThrs to calc ious 0. Define Evaluator and calculating competition metric AP40. Note that current implementation is not efficient in the sense that Evaluator s evaluation and LossEvalHook s loss calculation run separately even if both need a model forward calculation for same validation data. io en latest _modules detectron2 solver build. Note that both detectron2. evaluation import COCOEvaluator PascalVOCDetectionEvaluator return PascalVOCDetectionEvaluator dataset_name not working return COCOEvaluator dataset_name bbox False output_dir output_folder flags General Data config all_train or valid20 original or wbf Training config images per batch this corresponds to total batch size WarmupMultiStepLR default or WarmupCosineLR Overwrite by param_dict flags_dict debug True outdir results debug imgdir_name vinbigdata chest xray resized png 256x256 split_mode valid20 iter 100 debug small value should be set. md we need to know CUDA and pytorch version to install correct detectron2. I also uploaded the original sized png images vinbigdata chest xray original png https www. com facebookresearch Detectron blob a6a835f5b8208c45d0dce217ce9bbda915f44df7 detectron datasets json_dataset_evaluator. https user images. Now the methods are ready. AugInput image transforms self. maxDets 2 Infering it from predictions should be better Test set json files do not contain annotations evaluation must be performed using the COCO evaluation server. com facebookresearch detectron2 blob master INSTALL. To calculate validation loss we need to call model with the training mode. out visualizer. com facebookresearch detectron2 blob master MODEL_ZOO. 5 RandomBrightnessContrast p 0. pop sem_seg_file_name None return dataset_dict h w Copyright c Facebook Inc. Below LossEvalHook calculates validation loss in _do_loss_eval method and self. Predicted box_proposals are in XYXY_ABS mode. the standard metrics Compute per category AP from https github. pyplot as plt Ref https github. To define custom dataset we need to create list of dict dataset_dicts where each dict contains following file_name file name of the image. Here implemented VinbigdataEvaluator is constructed we can also use COCOEvaluator here. py L255 noqa Record max overlap value for each gt box Return vector of overlap values all small medium large 96 128 128 256 256 512 512 inf sort predictions in descending order TODO maybe remove this and make it explicit in the documentation guard against no boxes find which proposal box maximally covers each gt box and get the iou amount of coverage for each gt box find which gt box is best covered i. trapz recalls thresholds When evaluating mask AP if the results contain bbox cocoapi will use the box area as the area of the instance instead of the mask area. com xhlulu vinbigdata chest xray resized png 256x256 to skip the preprocessing and focus on modeling part. 95 1e 5 step dtype torch. eval mode and it outputs bounding box prediction but does not output loss. We can finetune these pre trained architectures. You can check that augmentation is applied and every time the image looks different. png UPDATE 2021 1 11 I published prediction kernel please check https www. UPDATE 2021 2 18 Added links to relevant useful discussions in Next step topic. We can construct train_loader purely from cfg without instantiating trainer since it s class method. Thankfully utf 8 works out which is also what the pycocotools _mask. Visualize loss curve competition metric AP40As I explained the calculated metrics are saved in metrics. Mapper for augmentation Mapper class is used inside pytorch DataLoader. Python3 s json writer which always produces strings cannot serialize a bytestream unless you decode it. I will tune these parameters through the competition to improve model s performance. TrainingIt s actually very easy to use multiple gpus for training. Our Evaluator calculaes AP by class and it is easy to check which class is diffucult to train. Loading DataThis Flags class is to manage experiments. com corochann vinbigdata detectron2 train scriptVersionId 51628272 for the simple usage of detectron2 how to train custom dataset. VinBigData 2 class classifier complete pipeline https www. XYXY_ABS is used here meaning that absolute value of xmin ymin xmax ymax annotation is used in the bbox. Its content is saved to metric. yaml for this kernel. put_scalar validation_loss mean_loss return losses How loss is calculated on train_loop self. print anom_ind cv2_imshow out. 1 step training prediction https www. It provides Visualizer class we can use it to draw an image with bounding box as following. What anchor size aspect ratio should be used https www. EvaluatorTo evaluate validation dataset to calculate competition metric we need Evaluator. transforms albumentations augmentations properly handles bounding box. com albumentations team albumentations pixel level transforms and Spatial level transforms https github. The defined Trainer class has class method build_train_loader. Trainer has attribute storage and calculated metrics are summarized. In this competition we need object detection model I will choose R50 FPN https github. How many augmentations can be used in albumentations You can see official github page all Pixel level transforms https github. You can refer the Detectron2 Beginner s Tutorial https colab. Default build_lr_schduler method docs https detectron2. plotly models setup For debug. category_id class label id for each bounding box with shape n_boxes get_vinbigdata_dicts is for train dataset preparation and get_vinbigdata_dicts_test is for test dataset preparation. Data preparation detectron2 provides high level API for training custom dataset. COCOEvaluator only calculates AP with IoU from 0. Ref Training on Detectron2 with a Validation set and plot loss on it to avoid overfitting https medium. record image_id index objs record annotations objs utils configs T. print row print row class_name class_name row class_name It is No finding Use this No finding class with the bbox covering all image area. main scripts starts from here. Table of Contents Dataset preparation dataset Installation installation Training method implementations train_method Customizing detectron2 trainer custom_trainer Advanced topic skip it first time Mapper for augmentation mapper Evaluator evaluator Loss evaluation hook loss_hook Loading Data load_data Data Visualization data_vis Training training Visualize loss curve competition metric AP40 vis_loss Visualization of augmentation by Mapper vis_aug Next step next_step Dataset preparationPreprocessing x ray image format dicom into normal png image format is already done by xhlulu in the below discussion Multiple preprocessed datasets 256 512 1024px PNG and JPG modified and original ratio https www. io en latest tutorials data_loading. int64 Remove unnecessary field. It is responsible for converting dataset_dicts into actual data fed into the neural network and we can insert augmentation process in this Mapper class. build_hooks This method defines how to construct hooks. In COCO annotations keypoints coordinates are pixel indices. Customizing detectron2 trainer This section is advanced I recommend to jump to Training scripts section for the first time of reading. build_train_loader build_test_loader These class methods deine how to construct DataLoader for training data validation data respectively. DiscussionsThese discussions are useful to further utilize this training notebook to conduct deeper experiment. com albumentations team albumentations spatial level transforms with BBoxes checked can be used. build_evaluator This class method defines how to construct Evaluator. com corochann vinbigdata chest xray original png notebook https www. For example many kinds of AP Average Precision is calculted in COCOEvaluator. LR schedulingTo further customize learning rate scheduling you may override build_lr_scheduler class method to construct any pytorch LRScheduler. DefaultTrainer is used in the example which provides the starting point to train your model with custom dataset. Here AlbumentationMapper is passed to construct DataLoader to insert customized augmentation process. VinBigData detectron2 trainThis competition is object detaction task to find a class and location of thoracic abnormalities from chest x ray image radiographs. 5 Visualize data. py L79 L88 For visualization. Thus bounding box is adjusted when the image is scaled rotated etc At first I was using detectron2. annotation This is the ground truth annotation data for object detection which contains following bbox bounding box pixel location with shape n_boxes 4 bbox_mode BoxMode. ", "id": "corochann/vinbigdata-detectron2-train", "size": "14047", "language": "python", "html_url": "https://www.kaggle.com/code/corochann/vinbigdata-detectron2-train", "git_url": "https://www.kaggle.com/code/corochann/vinbigdata-detectron2-train", "script": "albumentations LossEvalHook(HookBase) build_detection_test_loader COCOEvaluator DatasetCatalog BoxMode detectron2.utils.visualizer detection_utils detectron2.evaluation.evaluator _derive_coco_results collections pycocotools.cocoeval plotly.graph_objs detectron2.data.samplers field get_vinbigdata_dicts plotly.express build_hooks _summarizeDets typing sklearn.model_selection log_every_n_seconds _tasks_from_predictions KFold _do_loss_eval detectron2.evaluation launch save_yaml Union distutils.util create_small_table detectron2.data __call__ MetadataCatalog convert_to_coco_json get_vinbigdata_dicts_test detectron2.utils.logger COCOeval detectron2.data.datasets.coco reset detectron2.structures dataclasses load_yaml seaborn numpy detectron2.config tabulate detectron2.utils.comm detectron2 _evaluate_box_proposals CfgNode as CN tools IPython.core.display model_zoo tqdm.notebook _get_loss pandas build_test_loader HookBase MyMapper get_cfg VinbigdataEvaluator(DatasetEvaluator) detectron2.utils.file_io build_evaluator update detectron2.evaluation.fast_eval_api AlbumentationsMapper plotly.figure_factory TrainingSampler HTML preprocessing pycocotools.mask display pairwise_iou plotly.offline Visualizer detectron2.data.transforms OrderedDict _summarize Flags build_detection_train_loader _evaluate_predictions_on_coco MyTrainer(DefaultTrainer) PascalVOCDetectionEvaluator plotly.io detection_utils as utils build_train_loader setup_logger scipy detectron2.engine.hooks after_step __init__ dataclass COCOeval_opt PathManager lightgbm _eval_box_proposals Optional DefaultTrainer Any Path Dict Boxes pathlib evaluate detectron2.engine detectron2.config.config _summarizeKps plotly COCO sklearn instances_to_coco_json matplotlib.pyplot vin_summarize DatasetEvaluator DefaultPredictor _eval_predictions strtobool CfgNode tqdm subplots catboost xgboost pycocotools.coco process ", "entities": "(('so s', 'it'), 'corochann') (('we', 'also COCOEvaluator'), 'implement') (('many kinds', 'COCOEvaluator'), 'calculte') (('later you', 'just next'), 'demonstrate') (('TrainingIt', 'training'), 's') (('albumentations augmentations', 'properly box'), 'transform') (('I', 'performance'), 'tune') (('it', 'trainer'), 'construct') (('dataset_dicts', 'neural network'), 'contain') (('mask AP', 'mask area'), 'remove') (('which', 'bbox_mode n_boxes 4 BoxMode'), 'annotation') (('you', 'Thanks'), 'take') (('models', 'MODEL_ZOO'), 'summarize') (('category ids', 'box very well generated proposals'), 'copy') (('Facebook AI generation software next that', 'object detection algorithms'), 'be') (('you', 'it'), 'serialize') (('we', 'Mapper class'), 'be') (('Trainer defined class', 'class method'), 'have') (('t', 'pre trained weights'), 'method') (('We', 'trained architectures'), 'finetune') (('Calcification', 'experiment'), 'seem') (('we', 'box'), 'provide') (('which', 'albumentations library augmentations'), 'implement') (('This', 'datasets coco'), 'be') (('Frequent save', 'storage'), 'pass') (('that', 'gt iou coverage level thresholds used append recorded torch'), 'find') (('competition we', 'Evaluator'), 'need') (('detectron2 solver', '_ io latest modules'), 'build') (('We', 'override customized behavior'), 'make') (('Data preparation detectron2', 'custom dataset'), 'provide') (('competition data', 'finding images'), 'be') (('print row print row class_name class_name row It', 'image area'), 'class_name') (('which', 'custom dataset'), 'use') (('TxKxAxM 2 _', '1 iouThr'), 'stat') (('com albumentations team albumentations pixel level Spatial level', 'https github'), 'transform') (('get_vinbigdata_dicts_test', 'dataset test preparation'), 'd') (('it', 'loss'), 'output') (('it', 'heavy data'), 'load') (('I', 'evalutor'), 'insert') (('calculated metrics', 'metrics'), 'metric') (('COCOEvaluator', '0'), 'calculate') (('it', 'basic augmentations'), 'transform') (('Below code', 'same data'), 'be') (('This', 'small medium large'), 'lead') (('I', 'data https github'), 'be') (('Mapper class', 'pytorch DataLoader'), 'use') (('I', 'png images vinbigdata chest png https also original sized xray original www'), 'upload') (('I', 'R50 FPN https github'), 'need') (('I', 'reading'), 'customize') (('Famouns evaluator', 'already detectron2'), 'implement') (('record index objs record annotations', 'utils configs'), 'image_id') (('ymin xmax ymax annotation', 'bbox'), 'use') (('Pixel level', 'https github'), 'use') (('com xhlulu vinbigdata chest xray', 'part'), 'resize') (('com corochann vinbigdata detectron2 prediction kernel', 'competition'), 'explain') (('it', 'maskrcnn benchmark'), 'be') (('so I', 'it'), 'notice') (('evaluator stores outputs', 'byte stream'), 'dim') (('LossEvalHook', '_ do_loss_eval method'), 'calculate') (('dataset_dict it', 'aug_input T.'), 'sem_seg_file_name') (('class', 'class'), 'calculaes') (('I', 'detectron2'), 'be') (('You', 'detectron2'), 'need') (('It', 'Preferable test dataset https lot i www'), 'affect') (('You', 'Tutorial https Detectron2 colab'), 'refer') (('method', 'how hooks'), 'define') (('Now preparation', 'validation dataset evaluation'), 'train') (('800 800 it', 'code'), 'Resize') (('However predictions', 'point coordinates'), 'float') (('level spatial transforms', 'BBoxes checked'), 'use') (('annotations evaluation', 'COCO evaluation server'), 'maxdet') (('Define Evaluator', 'AP40'), 'metric') (('tutorials a few popular unofficial incorrect', 'num_classes'), 'mean') (('I', 'detectron2'), 'adjust') (('Read 5 args data', 'sample_submission pd'), 'parse') (('Here I', 'IoU'), 'modify') (('1024px 256 512 PNG', 'below discussion'), 'dataset') (('LR learning schedulingTo further customize you', 'pytorch'), 'rate') (('you', 'docs'), 'LR_SCHEDULER_NAME') (('We', 'installation instruction https github'), 'follow') (('bbox cocoapi', 'instance'), 'recalls') (('1381301 66535560 d3422200', '9123 5535d469db19'), 'com') (('Visualization', 'Mapper method'), 'check') (('com corochann class classifier complete pipeline vinbigdata 2 kernel', 'competition'), 'explain') (('gt box', 'gt box find'), 'overlap') (('how training', 'them'), 'analyze') (('split_mode valid20 iter 100 debug small value', 'png'), 'return') (('however I', 'more performance'), 'want') (('md we', 'pytorch correct detectron2'), 'need') (('we', 'training mode'), 'need') (('loss separately even both', 'validation same data'), 'note') (('we', 'DataLoader'), 'check') (('put_scalar validation_loss mean_loss return How loss', 'train_loop self'), 'loss') (('class build_train_loader build_test_loader methods', 'data validation data'), 'deine') (('we', 'evaluator'), 'Use') (('where dict', 'image'), 'define') (('calculated metrics', 'attribute storage'), 'have') (('html build_lr_scheduler', 'scheduling WarmupMultiStepLR default LR WarmupCosineLR'), 'support') (('Here I', 'just dataset'), 'use') (('Predicted box_proposals', 'XYXY_ABS mode'), 'be') (('2021 11 I', 'https www'), 'UPDATE') (('Here AlbumentationMapper', 'augmentation customized process'), 'pass') (('d', 'image index'), 'image_id') (('validation however loss', 'Evaluator'), 'evaluation') (('which', 'metrics'), 'call') (('DiscussionsThese discussions', 'deeper experiment'), 'be') (('Data VisualizationIt', 'detectron2'), 's') (('which', 'class classifier 2 approach'), 'discussion') (('VinBigData competition', 'chest ray image radiographs'), 'detectron2') (('You', 'cfg'), 'change') (('evaluation', 'model'), 'be') (('com Detectron blob detectron', 'json_dataset_evaluator'), 'facebookresearch') (('which', 'trainer'), 'do') (('Loading', 'experiments'), 'be') (('com c vinbigdata chest xray abnormalities detection discussion', 'aspect ratio bonding 220295 how more smaller sized high boxes'), 'suggest') (('too 2021 1 I', 'customized augmentation'), 'UPDATE') (('class method', 'how Evaluator'), 'define') ", "extra": "['annotation', 'test']", "label": "Perfect_files", "potential_description_queries": ["256x256", "absolute", "advanced", "analyze", "annotation", "annotator", "append", "approach", "area", "array", "art", "attribute", "augmentation", "basic", "batch", "bbox", "behavior", "best", "blob", "bounding", "box", "calc", "calculate", "calculation", "call", "category", "cfg", "check", "chest", "choice", "choose", "classifier", "code", "competition", "compute", "config", "contain", "content", "correct", "create", "csv", "current", "curve", "custom", "data", "dataset", "day", "decode", "default", "define", "demand", "detection", "detectron2", "dicom", "dict", "dimension", "disk", "draw", "drive", "empty", "en", "encode", "eval", "evaluate", "evaluation", "evaluator", "evalutor", "even", "every", "experiment", "explained", "faster", "field", "file", "find", "float32", "following", "format", "forward", "found", "generated", "generation", "ground", "gt", "handle", "height", "high", "hook", "id", "image", "implement", "implementation", "import", "improve", "index", "initialize", "insert", "installation instruction https github", "instance", "int", "int64", "io", "iou", "iter", "json", "kaggle", "kernel", "label", "launch", "learn", "learning", "let", "level", "library", "list", "lot", "main", "manage", "mask", "max", "meaning", "memory", "metadata", "method", "metric", "mode", "model", "most", "multiple", "my", "name", "need", "network", "neural", "next", "no", "normal", "not", "notebook", "num_classes", "number", "object", "official", "order", "out", "output", "overfitting", "overlap", "page", "parse", "part", "per", "pipeline", "pixel", "plot", "plotly", "plotting", "plt", "png images vinbigdata chest png https also original sized xray original www", "png", "point", "practice", "pre", "precision", "predict", "prediction", "preprocessing", "print", "provide", "purpose", "py", "pyplot", "pytorch", "range", "ratio", "reading", "recall", "recommend", "record", "remove", "return", "row", "run", "sample_submission", "save", "scaled", "score", "section", "sense", "serialize", "set", "setup", "shape", "size", "sort", "spatial", "standard", "start", "state", "step", "storage", "subtract", "support", "system", "tabulate", "task", "team", "test", "threshold", "through", "time", "topic", "total", "train", "trainer", "training", "tune", "up", "usage", "user", "validation", "value", "vector", "version", "vinbigdata", "visualize", "who", "width", "work", "xhlulu", "yaml", "zoo"], "potential_description_queries_len": 232, "potential_script_queries": ["catboost", "core", "detectron2", "display", "evaluation", "launch", "lightgbm", "numpy", "pathlib", "preprocessing", "reset", "scipy", "seaborn", "sklearn", "strtobool", "tqdm", "update", "xgboost"], "potential_script_queries_len": 18, "potential_entities_queries": ["blob", "chest", "correct", "default", "detectron2", "even", "generation", "image", "io", "iter", "level", "lot", "pipeline", "png", "print", "record", "row", "team", "validation", "xhlulu"], "potential_entities_queries_len": 20, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 244}
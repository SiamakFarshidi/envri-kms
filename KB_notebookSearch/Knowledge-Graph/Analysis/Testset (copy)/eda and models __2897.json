{"name": "eda and models ", "full_name": " h2 General information h2 Functions used in this kernel h2 Data loading and overview h2 Data Exploration h2 Feature engineering h2 Prepare data for modelling h2 LGBM h2 Blending ", "stargazers_count": 0, "forks_count": 0, "description": "id_03 has 88 of missing values and 98 of values are either missing or equal to 0. 22 of values in id_11 are equal to 100and 76 are missing. Now let s have a look at transaction data. 04 max_depth 5 subsample 0. At first I ll explore the data and try to find valuable insights maybe I ll do some feature engineering and then it wil be time to build models. org images files slideshow abstract01. A very important idea it seems that train and test transaction dates don t overlap so it would be prudent to use time based split for validation. id_01 has an interesting distribution it has 77 unique non positive values with skeweness to 0. So if someone wants to normalize all variables it would be necessary to separate such variables which seem to be already normalized. Not all transactions belong to identities which are available. sort_values TransactionDT test prediction result_dict_lgb prediction result_dict_xgb prediction sub isFraud pd. 85 objective binary logistic eval_metric auc silent True nthread 1 tree_method gpu_hist result_dict_xgb train_model_classification X X X_test X_test y y params xgb_params folds folds model_type xgb eval_metric auc plot_feature_importance False verbose 500 early_stopping_rounds 200 n_estimators 5000 averaging rank test test. Let s have a closer look at them. csv index False test test. We have several features showing some kind of found status and several binary columns. General informationIn this kernel I work with IEEE Fraud Detection competition. Maybe it would be possible to use additional transactions to generate new features. There is no logic in them simply aggregations on top features. to_csv submission_xgb. Data ExplorationLet s start with identity information. id_01 id_11 are continuous variables id_12 id_38 are categorical and the last two columns are obviously also categorical. com dimartinot Cleaning infinite values to NaN categorical_feature cat_cols xgb_params eta 0. EEE CIS works across a variety of AI and machine learning areas including deep neural networks fuzzy systems evolutionary computation and swarm intelligence. jpg Work in progress Importing libraries Functions used in this kernelThey are in the hidden cell below. Prepare data for modelling LGBM Blending using ideas from this kernel https www. Train and test data have similar number of rowsMost of columns have missing data which is normal in real world. Here we can see some information about client s device. com notslush altair visualization 2018 stackoverflow survey Keep track of unique IDs Cache will stay outside and to set up scoring parameters out of fold predictions on train data averaged predictions on train data list of scores on folds split and train on folds feature importance to set up scoring parameters out of fold predictions on train data averaged predictions on train data out of fold predictions on train data averaged predictions on train data list of scores on folds split and train on folds feature importance setting up altair let s combine the data and work with the whole dataset by https www. Data loading and overviewData is separated into two datasets information about the identity of the customer and transaction information. This was already noted in abother kernel https www. merge sub test on TransactionID prediction sub. There are a lot of continuous variables and some categorical. It is important to be careful here some of info could be for old devices and may be absent from test data. sort_values TransactionDT test prediction result_dict_xgb prediction sub isFraud pd. So we have two medium sized datasets with a lot of columns. Also there are columns with one unique value or all missing. Today they re partnering with the world s leading payment service company Vesta Corporation seeking the best solutions for fraud prevention industry and now you are invited to join the challenge. com robikscube ieee fraud detection first look and edaSo card6 is type of card card4 is credit card company Feature engineeringLet s create some aggregations. We have a binary classification problem with a heavy imbalance which is an inherent property of such problems. Some of features seem to be normalized. ", "id": "artgor/eda-and-models", "size": "2897", "language": "python", "html_url": "https://www.kaggle.com/code/artgor/eda-and-models", "git_url": "https://www.kaggle.com/code/artgor/eda-and-models", "script": "sklearn.metrics v5 product lightgbm tqdm_notebook eval_auc SVR itertools render CatBoostRegressor seaborn numpy numba CatBoostClassifier GroupKFold altair fast_auc group_mean_log_mae wrapped linear_model networkx sklearn.model_selection TimeSeriesSplit sklearn LabelEncoder KFold metrics prepare_altair train_model_regression matplotlib.pyplot jit add_autoincrement train_model_classification clean_inf_nan pandas StandardScaler tqdm reduce_mem_usage mean_absolute_error GridSearchCV sklearn.preprocessing catboost sklearn.svm StratifiedKFold RepeatedKFold xgboost train_test_split IPython.display NuSVR HTML altair.vega ", "entities": "(('s', 'https www'), 'visualization') (('This', 'kernel https already abother www'), 'note') (('which', 'inherent such problems'), 'have') (('it', 'validation'), 'idea') (('General I', 'IEEE Fraud Detection competition'), 'informationin') (('id_03', '0'), 'have') (('We', 'found status'), 'have') (('Maybe it', 'new features'), 'be') (('which', 'such variables'), 'so') (('Data ExplorationLet', 'identity information'), 'start') (('credit card company Feature engineeringLet', 'aggregations'), 'look') (('then it', 'models'), 'explore') (('22', '100and'), 'be') (('here some', 'test data'), 'be') (('it', '0'), 'have') (('now you', 'challenge'), 'partner') (('which', 'identities'), 'belong') (('which', 'real world'), 'have') (('EEE CIS', 'deep neural networks'), 'work') (('Here we', 'device'), 'see') (('Data loading', 'customer information'), 'separate') (('Now s', 'transaction data'), 'let') (('So we', 'columns'), 'have') (('model_type xgb eval_metric auc', 'rank test 200 n_estimators 5000 test'), 'silent') (('kernelThey', 'hidden cell'), 'work') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["altair", "auc", "best", "binary", "build", "categorical", "cell", "classification", "client", "combine", "company", "computation", "could", "create", "credit", "csv", "customer", "data", "dataset", "detection", "distribution", "engineering", "equal", "explore", "feature", "find", "fold", "found", "generate", "idea", "identity", "imbalance", "importance", "including", "index", "industry", "info", "join", "kernel", "learning", "let", "list", "look", "lot", "max_depth", "merge", "missing", "modelling", "neural", "new", "no", "non", "normal", "normalize", "number", "objective", "out", "overlap", "positive", "prediction", "problem", "property", "rank", "re", "scoring", "separate", "service", "set", "several", "similar", "split", "stackoverflow", "start", "sub", "survey", "test", "time", "track", "train", "transaction", "try", "type", "unique", "up", "value", "visualization", "work", "world", "xgb"], "potential_description_queries_len": 89, "potential_script_queries": ["catboost", "jit", "lightgbm", "networkx", "numba", "numpy", "product", "render", "seaborn", "sklearn", "tqdm", "xgboost"], "potential_script_queries_len": 12, "potential_entities_queries": ["neural", "xgb"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 100}
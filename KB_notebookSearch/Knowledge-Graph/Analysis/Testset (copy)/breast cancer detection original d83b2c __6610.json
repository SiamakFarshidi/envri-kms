{"name": "breast cancer detection original d83b2c ", "full_name": " h1 The training part starts from here on h2 Below is the model trained using data augmentation h1 XifengGuo h1 The Capsule Network starts from here on h2 Capsule Layer h2 The entire capsule network h2 More sophisticated model h2 Comparision between the models h3 However I am willing to add some more analysis and visualization in a sooner time h2 Sensitivity between the three models h2 Specificity between the three models h2 Precision h2 F measure h1 End Remarks ", "stargazers_count": 0, "forks_count": 0, "description": "We will save it in output. scale preds so that the class probas of each sample sum to 1 manual computation of crossentropy epochs 50 In cases if you try and are not getting the satisfactory accuracy compared to other models then it s advisable to train it for longer period of time by increasing the number of epochs. Code Conclusion We have total of 277524 image filesNext Step is that we will check whether the dimentions of all the images are same or different Code Conclusion We can see that the dimentions of images are not equal therefore we would make it all equal to work bettter with our network. The entire capsule network More sophisticated modelWith 2 capsule layersIt was observed that the model after certain epochs starts attaining the nan loss. Capsule Layer This is the custom layer of capsule network. Now we will split our data into training set and testing set. plot val_acc1 color orange plt. Now we will plot the confusion matrix XifengGuo The Capsule Network starts from here on. param input_shape data shape 3d width height channels param n_class number of classes param routings number of routing iterations return Two Keras Models the first one used for training and the second one for evaluation. Doctors often do the biopsy or a scan if they detect signs of IDC. Therefore we will load only that. softmax_cross_entropy_with_logits expects logits Keras expects probabilities. add MaxPooling2D pool_size 2 2 epochs 50 In cases if you try and are not getting the satisfactory accuracy compared to other models then it s advisable to train it for longer period of time by increasing the number of epochs. Model x out_caps decoder masked noise layers. While somewhat unstable nature was shown by augmented model. For training masked Mask digitcaps Mask using the capsule with maximal length. One of the major problems is that women often neglect the symptoms which could cause more adverse effects on them thus lowering the survival chances. Data Extraction and Visualization Code Conclusion We can see that images are very small though they are cropped images its hard for human eye to understand them without using some high costly machines. Code Conclusion There are only png extentions which are present in alphabets therefore it means that we have only one image extention files with. softmax because K. Therefore automation of detection of breast cancer using Histopathology images could reduce cost and time as well as improve the accuracy of the test. define our own softmax function instead of K. When y_true i contains not just one 1 this loss should work too. IMPORT FILES Data Exploration In data exploration we will first check the name of the files. com paultimothymooney predict idc in breast cancer histology imagesWe also need a validation set inorder to check overfitting. Model x y noise decoder masked_noised_y return train_model eval_model manipulate_model def margin_loss y_true y_pred Margin loss for Eq. x Reshape 1 128 x we use a margin loss batch_size 64 comment this line and uncomment the above line if you want the batch size of 64 the squashing function. Now lets look at the color ranges that our images have Code Conclusion From the above image we can conclude that brighter region is more than the darken region in our image. Now we have our three sets of train valid and test. 5 the norm will be zoomed in while original norm is less than 0. com wp content uploads 2018 01 AI_Mammographie. The augmentor for CapsNet is called datagen_caps. This is an active research field lot of research papers and articles are present online one that I like is https www. Also it trained in less no. Input shape n_class masked_by_y Mask digitcaps y The true label is used to mask the output of capsule layer. read_csv to check the name of the directory inside which we have our files we extract only png files adds support for opening manipulating and saving many different image file formats adds progress bar for the loops going through all the images will take up lot of memory so therefore we will check until we get three different dimentions. Comparision between the models Graph of all four models validation accuracy and loss. The training part starts from here on. Model x y out_caps decoder masked_by_y eval_model models. x layers. Through below 2 cells you can print the accuracy and loss of the model. of epochs and the remained stable for the rest of the epochs. also no augmentation. We need to now preprocess our image file. The following are the functions and parameters that are further required for construction of Capsule Network. This shows the power of automation and how it could help in the detection of breast cancer. We will go for spliting testing set into validation set. eval_model can also be used for training. We can do two things either split test set further into valid set or split train se into valid set. We will now do undersampling to treat our data for class imbalances. Below two cells can plot the confusion matrix for the model2 capsule network. used for computer vision tasks such as reading image from file changing color channels etc for plotting various graph images etc. L y_true K. argmax Y_test i 0 tn 1. About 80 of all breast cancers are invasive ductal carcinomas. The Code inspiration for undersampling is taken from a notebook https www. We change pixels range from 0 255 to 0 1. Conv2D filters 256 kernel_size 9 strides 1 padding valid activation relu name conv1 x primarycaps PrimaryCap conv1 dim_capsule 8 n_channels 32 kernel_size 9 strides 2 padding valid digitcaps CapsuleLayer num_capsule n_class dim_capsule 16 routings routings name digitcaps primarycaps out_caps Length name capsnet digitcaps y layers. In developed countries the survival rate is although high but it is an area of concern in the developing countries where the 5 year survival rates are poor. In India there are about one million cases every year and the five year survival of stage IV breast cancer is about 10. In the next step we will OneHot encode our data to better work with neural networks. For prediction train_model models. param y_true None n_classes param y_pred None num_capsule return a scalar loss value. And the transfer learning model s accuracy saturated at around 80. Add digitcaps noise masked_noised_y Mask noised_digitcaps y manipulate_model models. x Conv2D 64 3 3 activation relu x x AveragePooling2D 2 2 x x Conv2D 128 3 3 activation relu x x Conv2D 128 3 3 activation relu x x Reshape 1 128 x capsule Capsule 64 8 3 True primarycaps This is more than one capsule layer This is more than one capsule layer This is more than one capsule layer output Lambda lambda z K. BENCHMARK MODEL A simple CNN model Now we will plot the confusion matrix Below is the model trained using data augmentation. 1 2 3 4 5 6 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 plt. linear algebra data processing CSV file I O e. 5 in stead of 1 in hinton s paper. 5 and be zoomed out while original norm is greater than 0. Image Argumentation We will now add image argumentation to our data so that it may be set for wider range of domainWe will also rescale our image pixels from range of 0 255. if 1 the norm of vector will be zoomed out. Therefore it is very important to detect the signs as early as possible. plot val_acc1 color orange 1 2 3 4 5 6 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 plt. Sensitivity between the three models. argmax Y_test i 1 tp 1 Senstivity of models confusion_bench_s cnf_matrix_bench 1 1 tp 100 tp 0 tn 0 for i in range 0 len Y_test Number of postive cases if np. Data Processing We will first shuffle are images to remove any patterns if present and then load them. function to view an image reads an image displays an image to plot histogram of pixel values present in an image VS intensities to open and write csv files Allows the use of display for DataFrames to shuffle the data to hot encode the output labels to hot encode the data For performing undersampling Constructor of the class to perform undersampling resamples the dataset resamples the dataset For Plotting the distribution of classes plt. if no true label mask by the max length of capsules. Breast Cancer Detection https blogs. However I am willing to add some more analysis and visualization in a sooner time. add BatchNormalization import tensorflow as tf the squashing function. plot val_acc1 color orange tp 0 for i in range 0 len Y_test Number of positive cases if np. Mainly used for prediction compute lengths of capsules true label provided no true label provided Transform matrix None 10 16 from utils import combine_images from capsulelayers import CapsuleLayer PrimaryCap Length Mask def CapsNet input_shape n_class routings A Capsule Network on MNIST. Input shape n_class 16 noised_digitcaps layers. We have a large dataset and we will work with neural networks therefore for better debugging we will use only a part of data considering limited RAM and non GPU processor this will not cost us much as we would also be using under sampling methods and image argumentation to deal with class imbalances and moderate data. It had performed well on the train data validation data and the test data as well as seen by the confusion matrix. 68 million new cases and 522 000 deaths. argmax Y_test i 1 tp 1 for i in range 0 len Y_test number of negative cases if np. csv and displays it Class1 represents IDC and Class0 represents IDC Code Conclusion We can see that we have an unbalanced class and which is a common problem when we have medical data therefore this is one another problem that we have to deal with later. We would encode our output data which is present as Class1 and Class0 to 1 and 0. Invasive ductal carcinoma IDC is the most common form of breast cancer. add 256 5 5 input_shape 50 50 3 custom_model. Next step is we need to extract the class names in which each files belong from its file names. square z 2 capsule we use a margin loss epochs 50 In cases if you try and are not getting the satisfactory accuracy compared to other models then it s advisable to train it for longer period of time by increasing the number of epochs. End Training with data augmentation train or test init the model weights with provided one as long as weights are given will run testing For Image argumentaton the squashing function. Input shape input_shape conv1 layers. 9 y_pred 0. Hence we applied the below call back in order to terminate as soon as it starts attaining nan loss. In 2012 it resulted in 1. Specificity between the three models. plot train_acc1 color red plt. sum L 1 unpacking the data compile the model Begin Training with data augmentation shift up to 2 pixel for MNIST Training with data augmentation. jpg Domain Background Breast Cancer is the most common type of cancer in woman worldwide accounting for 20 of all cases. We will now create our benchmark model. Further I am willing to make this a more complex hence better model that may consists of more than just two capsule layers. I have by default added the data augmentation. xticks y_pos objects hot encoding them create iterators for effective looping Plotting the confusion matrix for checking the accuracy of the model For Image argumentaton true label is provided with shape None n_classes i. Precision F measure End RemarksIt was observed that the CapsNet performed better than all of the models. softmax can not specify axis. The cost of testing for breast cancer sets one back with 5000 which is a very big amount for poor families and also manual identification of presence and extent of breast cancer by a pathologist is critical. Below code reads the data from output. gov pmc articles PMC5453426 as they used deep learning approach to study on histology images and achieved the sensitivity of 95 which is greater than many pathologists 90. ", "id": "adityashrivastava/breast-cancer-detection-original-d83b2c", "size": "6610", "language": "python", "html_url": "https://www.kaggle.com/code/adityashrivastava/breast-cancer-detection-original-d83b2c", "git_url": "https://www.kaggle.com/code/adityashrivastava/breast-cancer-detection-original-d83b2c", "script": "Flatten sklearn.metrics shuffle #to shuffle the data CapsuleLayer cv2 #used for computer vision tasks such Dropout tensorflow.keras.models build AveragePooling2D and saving many different image file formats manipulate_latent optimizers sklearn.model_selection confusion_matrix Image Activation imblearn.under_sampling tensorflow.keras.backend tensorflow.keras customentropy backend as K CapsNet train_test_split SVG keras.preprocessing.image tensorflow.keras.layers Mask(layers.Layer) PrimaryCap Layer callbacks numpy plot_confusion_matrix Input model_to_dot view_images get_config plot_log softmax test ImageDataGenerator margin_loss hist_plot keras.utils tensorflow pandas BatchNormalization Capsule(layers.Layer) Model _to_tensor ImageDataGenerator  #For Image argumentaton keras.models to_categorical #to hot encode the output labels tensorflow.keras.utils Reshape manipulating train Mask compute_output_shape RandomUnderSampler #For performing undersampling shuffle Conv2D Capsule(Layer) PIL display # Allows the use of display() for DataFrames train_generator Image #adds support for opening MaxPooling2D backend Length(layers.Layer) tqdm #adds progress bar for the loops IPython.display sklearn.utils __init__ glob keras.layers GlobalAveragePooling2D Sequential models capsulelayers combine_images initializers CapsuleLayer(layers.Layer) keras.backend Length utils matplotlib.pyplot call Dense Lambda activations tqdm to_categorical to_categorical #to hot encode the data 0 images squash plot_model regularizers layers keras 1 images ", "entities": "(('However I', 'sooner time'), 'be') (('it', 'bettter network'), 'Conclusion') (('We', 'train split valid set'), 'do') (('sum', 'data augmentation'), 'begin') (('we', 'three different dimentions'), 'add') (('y_pred None num_capsule', 'loss scalar value'), 'param') (('capsule More sophisticated modelWith 2 layersIt', 'nan loss'), 'observe') (('original norm', '0'), '5') (('year survival where 5 rates', 'developing countries'), 'be') (('which', '1'), 'encode') (('we', 'image extention only one files'), 'Conclusion') (('Input n_class Mask true label', 'capsule layer'), 'shape') (('I', 'data augmentation'), 'add') (('we', 'files'), 'Exploration') (('We', 'class imbalances'), 'undersample') (('Now we', 'training'), 'split') (('as soon it', 'nan loss'), 'apply') (('IV breast cancer', 'one year about million year five stage'), 'be') (('two cells', 'model2 capsule network'), 'plot') (('brighter region', 'image'), 'range') (('param', 'second evaluation'), 'return') (('out_caps Length name capsnet', 'y layers'), 'filter') (('transfer learning accuracy', 'around 80'), 'saturate') (('CapsNet', 'models'), 'measure') (('we', 'image class imbalances'), 'have') (('Now we', 'train'), 'have') (('more adverse effects', 'survival thus chances'), 'be') (('We', '255 0'), 'change') (('more complex hence better that', 'just two capsule layers'), 'be') (('augmentor', 'CapsNet'), 'call') (('they', 'IDC'), 'do') (('I', 'research field research active papers'), 'be') (('you', 'model'), 'print') (('We', 'image now file'), 'need') (('idc', 'overfitting'), 'predict') (('that', 'Capsule Network'), 'be') (('dataset', 'classes plt'), 'read') (('which', 'pathologist'), 'set') (('Therefore automation', 'test'), 'reduce') (('we', 'one that'), 'represent') (('which', 'many pathologists'), 'article') (('as long weights', 'squashing function'), 'run') (('Capsule This', 'custom capsule network'), 'Layer') (('Therefore it', 'very signs'), 'be') (('Keras', 'probabilities'), 'expect') (('them', 'None'), 'provide') (('Code inspiration', 'notebook https www'), 'take') (('Below', 'data augmentation'), 'model') (('then it', 'epochs'), 'capsule') (('capsule more than one This', 'AveragePooling2D'), 'Conv2D') (('ductal carcinoma Invasive IDC', 'breast most common cancer'), 'be') (('Capsule Network', 'confusion matrix'), 'plot') (('it', '0'), 'argumentation') (('then it', 'epochs'), 'add') (('About 80', 'breast cancers'), 'be') (('norm', 'vector'), 'zoom') (('eval_model', 'also training'), 'use') (('files', 'file names'), 'be') (('then it', 'epochs'), 'pred') (('1 loss', 'just one'), 'contain') (('how it', 'breast cancer'), 'show') (('first shuffle', 'then them'), 'Processing') (('very they', 'high costly machines'), 'Extraction') (('out_caps', 'noise masked layers'), 'Model') (('Add', 'noise masked_noised_y'), 'digitcap') (('It', 'test confusion as well matrix'), 'perform') (('above you', '64 squashing function'), 'x') (('We', 'validation set'), 'go') (('somewhat unstable nature', 'augmented model'), 'show') (('we', 'better neural networks'), 'OneHot') (('jpg Domain Background Breast Cancer', 'cases'), 'be') (('y out_caps', 'eval_model masked_by_y models'), 'model') ", "extra": "['biopsy', 'test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "active", "approach", "area", "argumentaton", "augmentation", "batch", "batch_size", "benchmark", "biopsy", "breast", "call", "cancer", "cause", "check", "checking", "code", "color", "comment", "compile", "computation", "compute", "computer", "confusion", "content", "cost", "could", "create", "crossentropy", "csv", "custom", "data", "dataset", "decoder", "def", "default", "define", "detect", "detection", "directory", "display", "distribution", "encode", "encoding", "equal", "every", "extent", "extract", "eye", "field", "file", "following", "form", "function", "graph", "height", "help", "high", "histogram", "hot", "human", "image", "import", "improve", "init", "label", "layer", "learning", "len", "length", "line", "linear", "load", "look", "lot", "major", "manipulating", "manual", "margin", "mask", "masked", "matrix", "max", "measure", "medical", "memory", "model", "most", "name", "nature", "need", "negative", "network", "neural", "new", "next", "no", "noise", "non", "norm", "not", "notebook", "number", "open", "opening", "order", "out", "output", "padding", "part", "pathologist", "perform", "performing", "period", "pixel", "plot", "plotting", "png", "positive", "power", "predict", "prediction", "present", "print", "problem", "processing", "range", "reading", "reduce", "region", "remove", "rescale", "research", "rest", "return", "run", "sample", "sampling", "save", "saving", "scale", "scan", "second", "set", "shape", "shift", "shuffle", "size", "softmax", "split", "square", "stage", "step", "sum", "support", "survival", "tensorflow", "test", "testing", "tf", "through", "time", "total", "train", "training", "transfer", "try", "type", "under", "undersampling", "until", "up", "valid", "validation", "vector", "view", "vision", "visualization", "while", "width", "work", "write", "year", "zoomed"], "potential_description_queries_len": 184, "potential_script_queries": ["backend", "build", "computer", "cv2", "display", "file", "glob", "image", "numpy", "output", "preprocessing", "shuffle", "support", "test", "tqdm", "undersampling"], "potential_script_queries_len": 16, "potential_entities_queries": ["breast", "field", "masked", "name", "research", "survival", "year"], "potential_entities_queries_len": 7, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 188}
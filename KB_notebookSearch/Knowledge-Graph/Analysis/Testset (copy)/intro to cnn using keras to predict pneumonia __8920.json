{"name": "intro to cnn using keras to predict pneumonia ", "full_name": " h1 The purpose of this exercise is to see how accurate of a Neural Network we can create to classify X Ray scans from patients with pneumonia h1 Let s start by Importing the required libraries h2 Let s set up the training and testing folders h2 Let s take a look at some of the pictures h1 Alright I don t know about you but I am no X Ray reading wizard but these don t look too off to me h1 Soooo h1 Have you ever wondered HOW and WHAT a computer sees h1 CONVOLUTIONAL NEURAL NETWORKS TO THE RESCUE h1 There you go all caught up No need to be scared If this looks intimidating don t worry it is pretty easy to implement h1 Convolutional Neural Networks are easy to build and run because of the deep learning libraries such as Keras h1 Now we are going to fit the model to our training dataset and we will keep out testing dataset seperate h1 This summary is a great way for us to see how our CNN is being set up h1 PHEW So we just built a CNN that can predict penumonia from X Ray scans WOOOOO h1 Let s take a look at the Confusion matrix and the Classification Report h1 Now let s see how accuracy changed over our training and Validation Set and also how our Loss function changed h1 What this means ", "stargazers_count": 0, "forks_count": 0, "description": "gif Convolutional Neural Networks are easy to build and run because of the deep learning libraries such as Keras Keras is a high level deep learning library. I will be working with some more bio medical imaging dataset just to get more practice and probably create some web applications online for atleast one of them forlinear algebra for plotting things Keras Libraries train Normal pic Load the images Let s plt these images let s build the CNN model 2nd Convolution 2nd Pooling layer Flatten the layer Fully Connected Layers Compile the Neural network Fitting the CNN to the images The function ImageDataGenerator augments your image by iterating through image as your CNN is getting ready to process that image Image normalization. com media l396ZJAsqbN5VX3O0 giphy. The most commonly used one is ReLU. This section was inspired by this post https medium. Rays of lights reflected off an object hit your retina. The purpose of this exercise is to see how accurate of a Neural Network we can create to classify X Ray scans from patients with pneumonia. Computers learn see in not such a different way from us. The purpose of this data set is to prevent our model from Overfitting. No need to be scared. However other than that I can t tell anything else. The second FC has only 1 unit becuase it needs to predict if someone has pneumonia. The above pictures are being generated randomly from the dataset. The coresponding numbers in both matrices are multiplied and and added to yield a single number describing that input space. com max 800 1 vbfPq HvBCkAcZhiSTZybg. com max 800 1 EuSjHyyDRPAQUdKCKLTgIQ. There is no need for a doctor or a health care provider to ponder these images to gauge things. png Two of the most commonly associated words with CNN are stride and padding STRIDE Stride just means the amount a filter moves during a covolution operation. I don t know about you but I am no X Ray reading wizard but these don t look too off to me. The way we mammals and almost any other animal with two eyes and a developed brain sees is something as follows 1. This can be seen in the following animation https cdn images 1. The Network takes an input image and uses a filter or kernel to create a feature map describing the image. This process is repeated all over the image. display when you call Keras. confusion_matrix validation_generator. com max 800 1 VVvdh BUKFh2pwDD0kPeRA 2x. Optimization functions are far too complex for me to get into in this post. The sensory input is transported to your brain. PADDING Padding is just zero value pixels that surround the input image. Using TensorFlow backend. There are two ways we can resolve this problem 1. com max 1600 1 cot55wd6gdoJlovlCw0AAQ. The next step of our process involves further reducing the dimensionality of the data which will lower the computation power required for training this model. Also recall that your family was there to teach you what things are. After each convolution I will add a Pooling layer using max pooling. com max 800 0 iqNdZWyNeCr5tCkc. This is not a shot at doctors or their jobs The task of reading these is incredibly menial and repititive. If this looks intimidating don t worry it is pretty easy to implement. So a stride of 1 means that the filter will slide 1 pixel after each covolution operation as shown in this animation. You know something is an umbrella because you look at it and someone told you that this specific object is called an umbrella. It runs on top of more low level libraries such as Tensorflow which is why you will usually see that message. Let s take a look at some of the pictures. When we compile this CNN we will use the Adam optimization fuction which optimizes how fast our model learns the correct classification of the image. gif https cdn images 1. Your brain then stores that association and you don t have to be taught this again. gif Let s start by Importing the required libraries Our data is located in three folders 1. After the second convolutional layer we will add 2 Fully Connected layers which will take out feature map of an image and make predictions about it. gif This is a 2 D representation of calculations happening in 3 dimensions. org an intuitive guide to convolutional neural networks 260c2de0a050 The gifs animations are from this post https towardsdatascience. png We use different filters to pass over our inputs and take all the feature maps put them together as the final output of the convolutional layer. This is achieved by using a Pooling Layer. A convolution does this by multiplying two matrices and yielding a third smaller matrix. We then pass the output of this layer through a non linear activation function. com media 3ov9jG4eqz9k3XXsU8 giphy. classes y_pred Accuracy Loss. Overfitting is when your model gets a little too comofortable with the training data and can t handle data it hasn t see. com media l0MYtoPNAQ0YCgNVe giphy. They will however need to look and analyze thousands upon thousands of images before they can generalize and say that a yellow umbrella falls under the same category as a black umbrella. train contains the training data images for teaching our model. com applied deep learning part 4 convolutional neural networks 584bc134c1e2 There you go. com media ChzfTLSi47FYc giphy. I am going to build a CNN that has 2 Convolution layers. png https cdn images 1. Now let s see how accuracy changed over our training and Validation Set and also how our Loss function changed What this means The world of medical imaging is ripe for a revolution in terms of deploying CNN based technologies. There are slight differences in the pictures but let s see if we can t create a Convolutional Neural Network which can create a more objective measure of quantifying and classifying these differences. This significantly reduces the training time and preserves significant information. com media l3q2UyW34cT2rcgko giphy. gif Have you ever wondered HOW and WHAT a computer sees The answer to that lies in mammilian physiology. test this contains the data that we use to test the model once it has learned the relationships between the images and their label Pneumonia Not Pneumonia Let s set up the training and testing folders. This protects the loss of any valuable information since the feature map is ever shrinking. Go to Med school and learn the skills that are necessary to read these figures and make educated guesses as to what they mean. There are some obvious differences in the rib cage shape of the patient who has pneumonia vs someone who is normal. Not go 250 000 in debt and train a Convolutional Nerual Network to tell me the differnces. The most commonly used one is max pooling which takes the maximum value in the window created by a filter. This is because what they see are not pictures but numerical representaions of pixels describing these pictures. This is what is actually happening Source https cdn images 1. Those are two things that AI technologies are great at. gif Let s take a look at the Confusion matrix and the Classification Report. Now we are going to fit the model to our training dataset and we will keep out testing dataset seperate This summary is a great way for us to see how our CNN is being set up PHEW So we just built a CNN that can predict penumonia from X Ray scans WOOOOO https media. So while we see things in pictures a computer sees this https cdn images 1. The brain after interpreting the input tells you what it sees. gif CONVOLUTIONAL NEURAL NETWORKS TO THE RESCUEA Convolutional Neural Network is a special type of an Artificial Intelligence implementation which uses a special mathematical matrix manipulation called the convolution operation to process data from the images. val contains images which we will use to validate our model. In the convolution operation we take a filter usually 2x2 or 3x3 matrix and slide it over the image matrix. https cdn images 1. ", "id": "sanwal092/intro-to-cnn-using-keras-to-predict-pneumonia", "size": "8920", "language": "python", "html_url": "https://www.kaggle.com/code/sanwal092/intro-to-cnn-using-keras-to-predict-pneumonia", "git_url": "https://www.kaggle.com/code/sanwal092/intro-to-cnn-using-keras-to-predict-pneumonia", "script": "Flatten sklearn.metrics keras.preprocessing.image confusion_matrix ImageDataGenerator Conv2D keras.layers load_img Image numpy matplotlib.pyplot MaxPooling2D Dense classification_report PIL keras.models Sequential ", "entities": "(('png We', 'convolutional layer'), 'use') (('I', 't anything'), 'tell') (('task', 'these'), 'be') (('who', 'someone'), 'be') (('association', 'don this'), 'store') (('how fast model', 'image'), 'use') (('This', 'significant information'), 'reduce') (('computer', 'https cdn images'), 'see') (('sensory input', 'brain'), 'transport') (('I', 'max pooling'), 'add') (('which', 'it'), 'add') (('s', 'training folders'), 'test') (('it', 'what'), 'tell') (('Rays', 'retina'), 'reflect') (('process', 'all image'), 'repeat') (('two we', 'problem'), 'be') (('we', 'pneumonia'), 'be') (('feature map', 'valuable information'), 'protect') (('just amount', 'filter covolution operation'), 'png') (('which', 'model'), 'involve') (('they', 'what'), 'go') (('don t', 'too off me'), 'know') (('we', 'brain developed 1'), 'be') (('far too me', 'post'), 'be') (('Computers', 'us'), 'learn') (('This', '3 dimensions'), 'gif') (('max which', 'filter'), 'be') (('convolution', 'third smaller matrix'), 'do') (('which', 'differences'), 'be') (('This', 'animation https cdn following images'), 'see') (('that', 'Convolution 2 layers'), 'go') (('gifs 260c2de0a050 animations', 'post https towardsdatascience'), 'org') (('data', 'three folders'), 'let') (('AI technologies', 'two that'), 'be') (('that', 'X Ray scans WOOOOO https media'), 'go') (('purpose', 'Overfitting'), 'be') (('We', 'non activation linear function'), 'pass') (('train', 'model'), 'contain') (('CNN', 'image Image normalization'), 'work') (('filter', 'animation'), 'mean') (('yellow umbrella', 'black umbrella'), 'need') (('we', 'image matrix'), 'take') (('This', 'Pooling Layer'), 'achieve') (('above pictures', 'randomly dataset'), 'generate') (('things', 'there you'), 'recall') (('it', 'don t'), 'worry') (('it', 't see'), 'be') (('deep learning libraries', 'Keras such Keras'), 'be') (('s', 'Confusion matrix'), 'let') (('we', 'model'), 'contain') (('see', 'pictures'), 'be') (('There you', 'deep learning part 4 convolutional neural networks'), 'apply') (('coresponding numbers', 'input space'), 'be') (('Network', 'image'), 'take') (('section', 'post https medium'), 'inspire') (('value just zero that', 'input image'), 'be') (('specific object', 'you'), 'know') (('s', 'pictures'), 'let') (('world', 'CNN based technologies'), 'let') (('ever HOW computer', 'mammilian physiology'), 'wonder') (('what', 'Source https cdn actually images'), 'be') (('which', 'images'), 'be') (('why you', 'usually message'), 'run') (('doctor', 'things'), 'be') (('someone', 'pneumonia'), 'have') ", "extra": "['patient', 'test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "analyze", "animal", "animation", "answer", "associated", "association", "brain", "build", "call", "care", "category", "classification", "classify", "compile", "computation", "computer", "convolution", "convolutional", "correct", "create", "data", "dataset", "dimensionality", "display", "doctor", "exercise", "family", "feature", "filter", "final", "fit", "following", "function", "generated", "handle", "high", "image", "implementation", "input", "kernel", "label", "layer", "learn", "learning", "let", "level", "linear", "little", "look", "lower", "map", "matrix", "max", "maximum", "measure", "medical", "model", "most", "need", "network", "neural", "next", "no", "non", "not", "number", "numerical", "object", "objective", "operation", "optimization", "out", "output", "padding", "part", "patient", "pixel", "plotting", "plt", "pneumonia", "png", "pooling", "post", "power", "practice", "predict", "prevent", "problem", "provider", "purpose", "read", "reading", "recall", "representation", "run", "school", "second", "section", "set", "shape", "single", "slide", "something", "special", "start", "step", "stride", "summary", "task", "test", "testing", "through", "time", "train", "training", "type", "under", "unit", "up", "val", "validate", "value", "web", "while", "who", "window", "world"], "potential_description_queries_len": 128, "potential_script_queries": ["numpy", "preprocessing"], "potential_script_queries_len": 2, "potential_entities_queries": ["following", "linear", "part"], "potential_entities_queries_len": 3, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 130}
{"name": "reshampling credit card data ", "full_name": " h1 Data Understanding h1 Data Reshampling h1 Logistic Regression Model h1 Model Evaluation h3 Please Upvote this kernel if it is useful for you ", "stargazers_count": 0, "forks_count": 0, "description": "Information given in data is sesitive so i think data has been preprocessed with technique such as PCA or Factor Analysis So we need not to put extra effort on Data Cleaning and Wrangling. There is no missing value Dataset is highly imbalanced only 0. Out of 284807 only 492 observations are detected Fraud so this data is highly imbalanced we will use different sampling technique to increase accuracy. Data UnderstandingThere is 284807 observation of 31 variable. Class is target variable where as others are predictor variable. 17 obseravations are detected as Fraud We can see there are only less variable which are weakly correalted with class May be this is because data is already reduced to lower domension using PCA and other Feature engineering method and these varables are explaining significant variance in data Data ReshamplingHere i am reshampling data using SMOTE method because dataset is imbalaned. Logistic Regression Model Model Evaluation Model is validated we can see accuracy at both train and test set is almost sam which means model is not overfitting ROC AUC score is also enough good 0. Please Upvote this kernel if it is useful for you. ", "id": "ravichaubey1506/reshampling-credit-card-data", "size": "1205", "language": "python", "html_url": "https://www.kaggle.com/code/ravichaubey1506/reshampling-credit-card-data", "git_url": "https://www.kaggle.com/code/ravichaubey1506/reshampling-credit-card-data", "script": "LogisticRegression SMOTETomek sklearn metrics sklearn.model_selection seaborn numpy matplotlib.pyplot sklearn.linear_model imblearn.combine pandas train_test_split train_test_split as tts ", "entities": "(('ROC AUC score', 'model'), 'validate') (('highly we', 'accuracy'), 'detect') (('dataset', 'SMOTE method'), 'detect') (('kernel it', 'you'), 'Upvote') (('Factor So we', 'Data Cleaning'), 'be') (('Data UnderstandingThere', '284807 31 variable'), 'be') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "data", "dataset", "detected", "effort", "engineering", "increase", "kernel", "lower", "method", "missing", "model", "need", "no", "not", "observation", "overfitting", "predictor", "sampling", "score", "set", "target", "technique", "test", "think", "train", "value", "variable", "variance"], "potential_description_queries_len": 29, "potential_script_queries": ["numpy", "seaborn", "sklearn"], "potential_script_queries_len": 3, "potential_entities_queries": [], "potential_entities_queries_len": 0, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 32}
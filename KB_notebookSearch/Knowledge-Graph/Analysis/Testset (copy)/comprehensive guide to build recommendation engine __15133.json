{"name": "comprehensive guide to build recommendation engine ", "full_name": " h1 Introduction h1 1 Association Rule Learning h2 1 1 Data Preprocessing h3 1 1 2 Business Problem h3 1 1 3 Dataset Story h3 1 1 4 Variables h3 1 1 5 LIBRARIES h3 1 1 6 Load and Check Data h3 1 1 7 Outlier Observations h2 1 2 Preparing ARL Data Structure Invoice Product Matrix h2 1 3 Association Rules h2 1 4 Making Product Suggestions to Users at the Shopping Cart Stage h4 Some Notes h1 2 Content Based Filtering h3 Euclidean Distance h3 Cosine Similarity h2 2 1 Generating TF IDF Matrix h3 2 1 1 Libraries h4 2 1 2 CountVectorizer h4 2 1 3 tf idf h2 2 2 Creating Cosine Similarity Matrix h2 2 3 Making Suggestions Based on Similarities h2 2 4 Functionalize All Code of Content Based Filtering h1 3 Collaborative Filtering h2 3 1 Item Based Collaborative Filtering h3 3 1 2 Data Preprocessing h3 3 1 2 Creating the User Movie Df h3 3 1 3 Making Item Based Movie Suggestions h2 3 2 User Based Collaborative Filtering h3 3 2 1 Data Preprocessing h3 3 2 2 Determining The Movies Watched By The User To Make A Suggestion h3 3 2 3 Accessing Data and Ids of Other Users Watching the Same Movies h3 3 2 4 Identifying Users with the Most Similar Behaviors to the User to Suggest h3 3 2 5 Calculating the Weighted Average Recommendation Score h2 3 3 Matrix Factorization h4 What are these factors in this data h4 Some Notes h3 3 3 1 Data Preprocessing h3 3 3 2 Modelling h3 3 3 3 Model Tuning h3 3 3 4 Final Model and Prediction h1 4 References ", "stargazers_count": 0, "forks_count": 0, "description": "1 Data Preprocessing 22 3. 1 Generating TF IDF MatrixRecommendation System Based on Movie Overviews 2. 2 Preparing ARL Data Structure Invoice Product Matrix 9 1. 0 moving user_movie_count in the columns 40 treshold in common movies how many people watch the same movies with James he watched 50 movies there is one person watching the same movies let s bring users id watching the same movies We set all user in the columns but it doesn t look good therefore we will make them tidy making above matrix tidy Users with 65 percent or more correlation with James lets merge our new table with ratings taking out James from the table We have a problem here. 3 Model Tuning 34 3. We will assume the latent variables. We can do this with unstack function we could have used pivot funct instead of it. Content Based Filtering Represent texts mathematically vectoring texts Count Vector word count TF IDFIn this content based section we will go through these steps below. agg weighted_rating mean recommendation_df recommendation_df. I know what to suggest with product X but if the person has already bought this product it is necessary to make a correction accordingly. Our aim is to suggest products to users in the product purchasing process by applying association analysis to the online retail II dataset. Which one should we consider I need to make a weighting based on rating and correlation. columns userId movie_count users_same_movies user_movie_count user_movie_count movie_count 20 userId final_df pd. You can make the dataset smaller with this below code. We will find the most similar finders Top Users We have a problem here. Association Rules We will subtract the probabilities of all possible products being together. These hidden factors are also present in movies. 4 Final Model and Prediction 35 1. 4 Variables InvoiceNo Invoice number. names user_id_1 user_id_2 corr_df corr_df. It is designed to identify strong rules that have been identified in databases using various measures of interest. 137658 people watched at least on movie common movies count 191 user_movie_count indicates how many movies each user watched notnull gives us binary output 1 or 0 if we don t do that the ratings count like 3. 3 Association Rules 10 1. Decomposes the user item matrix into 2 less dimensional matrices. The data we created in accordance with the data structure of the surprise library predictions Let s guess blade runner 541 for userid 1 Let s guess Whispers 356 for userid 1. Calculating the Weighted Average Recommendation Score We will create a single score by simultaneously considering the impact of the users most similar to James correlation and the rating. fit_transform dataframe overview cosine_sim cosine_similarity tfidf_matrix tfidf_matrix return cosine_sim cosine_sim calculate_cosine_sim df content_based_recommender The Dark Knight Rises cosine_sim df movie counts rating count of each movies we don t want all ratings therefore we add trashold. 4 Identifying Users with the Most Similar Behaviors to the User to Suggest 29 3. Empty observations are filled with the weights found. User Based Collaborative FilteringSuggestions are made based on user similarities. There are many ratings given to a movie. csv top_users_ratings top_users. Should I do this replacement 10 times like 100 times So this is a hyperparameter for me that needs to be optimized by the user. It s an optimization it s actually a gradient descent work. isin users_same_movies random_user_df movies_watched corr_df final_df. concat movies_watched_df movies_watched_df. Initially random p and q values and the values in the rating matrix are tried to be estimated. Step 1 Preparing the Data Set Step 2 Determining the Movies Watched by the User to Suggest Step 3 Accessing Data and Ids of Other Users Watching the Same Movies Step 4 Identifying Users with the Most Similar Behaviors to the User to Suggest Step 5 Calculating the Weighted Average Recommendation Score 3. There are two levels in data. 1 Generating TF IDF Matrix 13 2. Data Preprocessing We have already defined user movie matrix above as named user_movie_df. Someone has high corr but rating is 1. For instance there are movies that show the same liking structure as The Lord of The Rings movie. Users and movies are considered to have scores for latent features. Seconly If there is a product in the columns we will convert it to 1. If there is a product in the columns we expect 1 if not 0. One is corr other one is rating. Frac is in ration of percentage you desire. Let s turn all these codes into a single function named create_invoice_product_df. 4 Functionalize All Code of Content Based Filtering 3. Determining The Movies Watched By The User To Make A Suggestion 3. IntroductionRecommender systems are a big part of our lives recommending products and movies that we want to buy or watch. We do not want to recommend weighted_score below 3. 7 Outlier Observations 8 1. 2 Modelling 33 3. 1 Data Preprocessing 2 1. StockCode Product code. 3 Dataset Story The data set named Online Retail II is a UK based online sale. 5 Calculating the Weighted Average Recommendation Score 30 3. We will only work on Germany let s filter. reset_index movies_to_be_recommend recommendation_df recommendation_df weighted_rating 3. drop_duplicates corr_df pd. 6 Load and Check Data 1. Creating the TF IDF Matrix2. 2 Business Problem 3 1. merge movie movieId title user_based_recommender pip install surprise We reduce the dataset to these four movies in terms of both followability and performance. 6 Load and Check Data 7 1. Accessing Data and Ids of Other Users Watching the Same MoviesAs we can see above there are lots of people watched at least one movie in common but we need to put a threshold here. Preparing ARL Data Structure Invoice Product Matrix 3. 1 Data Preprocessing 32 3. It doesn t look good let s make id True in create_invoice_product_df for better looking matrix Let s define a function for checking StockCode number Let s check first stockcode s name 10002 1. STEP 1 TF t Frequency of occurrence of a t term in the relevant document Total number of terms in the document term frequency Step 2 IDF t 1 log_e Total number of documents 1 number of documents with t term 1 inverse document frequency Step 3 TF IDF TF t IDF t Step 4 L2 normalization to TF IDF values 2. The reason why James watches the movie the genre of the film the director or actors of the film the duration of the film the language in which the film was shot. In this notebook We will discuss three types of recommender system 1 Association rule learning ARL 2 content based and 3 collaborative filtering approaches. It assumes that the transition from two matrices to the user item matrix occurs with latent factors. There are 8071 movies we can t recommend all these movies. Which one should we consider Calculation of weighted_rating there are 8071 movies list of movies to recommend james def user_based_recommender import pickle import pandas as pd random_user int pd. Estimation is made for null observations based on the available p and q. Collaborative Filtering 20 3. 0 with James another person has low corr but high rating. 3 Accessing Data and Ids of Other Users Watching the Same Movies 28 3. 01 In real life scenarios this minimum support value is very low. 1 Data Preprocessing 1. columns random_user_df. There must be an intermediate control mechanism. fillna tfidf_matrix tfidf. 3 Making Suggestions Based on Similarities 18 2. csv return movies_to_be_recommend. Association Rule Learning Association rule learning is a rule based machine learning approach for finding significant connections between variables in large databases. There is a fine line you should consider 2. reset_index user_movie_count. read_csv kaggle input movielens 20m dataset movie. UnitPrice Product price in GBP CustomerID Unique customer number Country The country where the customer lives. Common movies count 50 3. Association Rule Learning ARL 1 1. 01 we don t want to get below 0. 2 Creating the User Movie Df 3. max_rows None \u00e7\u0131kt\u0131n\u0131n tek bir sat\u0131rda olmas\u0131n\u0131 sa\u011flar. reset_index drop True top_users top_users. Matrix factorization assume There are some latent factors when users like a movie. InvoiceDate Invoice date and time. In this notebook we will explain how to build a recommender system with these three methods. index random_user movies_watched random_user_df. For instace let s look at the example below. read_csv kaggle input movielens 20m dataset rating. Description Product name Quantity Number of products. For example if 5 is called 3 in one iteration the next one is called 4 then 5 is called. 1 Item Based Collaborative Filtering 21 3. Cosine SimilarityEuclidean Distance It finds the distance between two vectors. com mvahit https www. If the word is in it it will count 1 or more othewise 0. Latent factors Or latent features Latent factors or variables. Thus p and q values are filled as a result of a certain iteration. Recommender systems have been around for decades but have recently come into the spotlight. sort_values by corr ascending False top_users. There is also information that most of its customers are wholesalers. sample 1 random_state 45. Factor matrices User latent factors movie latent factors are actually two separate matrices. 2 Creating Cosine Similarity Matrix 17 2. The product catalog of this company includes souvenirs. 7 Outlier Observations 1. rename columns user_id_2 userId inplace True rating pd. Netflix Amazon and other businesses employ recommendation algorithms to assist their clients in locating appropriate items or movies. At the database level the userid should be checked. If the person has not bought that product after checking it is necessary to recommend that product. We guessed for the movie she didn t watc here it is our parameters for the model epoch and learning rate Let s guess blade runner 541 for userid 1 Another example Cries and Whispers 356 for user id1. 1 Data Preprocessing 26 3. Aborted operation if it starts with C. promotion can be considered as products. Cosine SimilarityA metric focused on the similarity of two vectors. 3 Matrix Factorization To fill in the blanks the weights of the latent features that are assumed to exist for users and movles are found over the existing data and predictions are made for non existent observations with these weights. The ouput indicates Invoice 536527 has these above items. 3 Making Item Based Movie Suggestions 24 3. ALS Spark ALS for big data. EXAMPLE Description NINE DRAWER OFFICE TIDY SET 2 TEA TOWELS I LOVE LONDON SPACEBOY BABY GIFT SET Invoice 536370 0 1 0 536852 1 0 1 536974 0 0 0 537065 1 0 0 537463 0 0 1 applymap will itinirate all cells in the dataframe. We will aggregate data from James and other users. 3 tf idf 16 2. In each iteration erroneous estimations are arranged and the values in the rating matrix are tried to be approached. The unique number of each transaction namely the invoice. 3 tf idf There are normalized numeric representations. Let s make it more clear. sum user_movie_count user_movie_count. com in vahitkeskin https www. It will not bring under 10000 taking out rare movies from dataframe all ratings we have 462 movies now let s pivot it columns count and title count are equal Another Example random selection of movies script of all codes user_movie_df create_user_movie_df this function helps to find the movie names Let s define a random user the output random user id we selected the random_user s movie here Taking out all NaN if you want to see all the movies that watched by random user execute this Let s check if random user watch 2001 A Space Odyssey 1968 how many movies he watched James movies Number of people who watched at least one movie in common with James. 3 Model Based Collaborative Filtering Matrix Factorization 31 3. We want to see the description products in the columns. tolist movies_watched_df user_movie_df movies_watched user_movie_count movies_watched_df. 2 Business ProblemTo suggest products to customers who have reached the basket stage. Preparation of the Working Script Euclidean Distance d p q sqrt sum_ i 1 infty x_i \u00dcr\u00fcn i\u00e7eriklerinin benzerlikleri \u00fczerinden tavsiyeler geli\u015ftirilir. 2 Preparing ARL Data Structure Invoice Product Matrix In this section we will create a matrix of invoice and products as in the example below. 3 Making Suggestions Based on SimilaritiesCosine similarities of The American President movie and other movies. We will convert all words to the matrix. These are called latent factors features in machine learning. 2 Data Preprocessing We have 20000797 rows 6 columns we don t want to use all of them. We will use this data instead of making all the data process again. In this case it should be done at category level When the person adds a product to the cart what I will suggest should already be clear. 65 user_id_2 corr. The weights of the latent factors are found on the filled observations. 2 Creating the User Movie Df 23 3. 2 User Based Collaborative Filtering 25 3. It takes sample from orginal data. These weights scores are first found on the existing data and then the empty sections are filled according to these weights. Some Notes Matrix Factorization vs SVD is not the same SVD Singular Value Decomposition is a size reduction method. How many times will I update the weight With this question what will my learning speed be There is a learning rate that represents the speed of these updates. 1 Data Preprocessing 3. Creating the Cosine Similarity Matrix3. Firstly we will assign 0 to NaN values. creating the user movie dataframe The surprise library requires between which numbers it will be. 4 Making Product Suggestions to Users at the Shopping Cart Stage 11 1. And we want to see whether there are products at the intersections of the matrix or not. 1 Item Based Collaborative Filtering Suggestions are made on item similarity. Identifying Users with the Most Similar Behaviors to the User to Suggest We will perform 3 steps 1. Content Based Filtering 12 2. 3 Making Item Based Movie SuggestionsLet s put all the codes in a single script 3. It is assumed that the rating matrix is formed by the product of two factor matrices dot product. org wiki Association_rule_learning pip install mlxtend libraries pd. Making Suggestions Based on Similarities4. 2 Creating Cosine Similarity Matrix 2. reset_index top_users corr_df corr_df user_id_1 random_user corr_df corr 0. Only difference ALS make some changes on p and q values. There is one more problem this above table. showing the index number of the films generates index capturing the index of the title Calculating similarity scores by title the top 10 movies except itself the movie we chose Example Example def calculate_cosine_sim dataframe tfidf TfidfVectorizer stop_words english dataframe overview dataframe overview. apply would only itinirate in row or columns minumum support value 0. DataFrame corr_df columns corr corr_df. Unique number for each product. add FORMULA OF MATRIX FAC. let s take some sample from this data. 4 Functionalize All Code of Content Based Filtering 19 1. Collaborative Filtering Item Based Collaborative Filtering User Based Collaborative Filtering Model Based Collaborative Filtering 3. antecedent support probability of the first product consequent support probability of the second product and others support probability of two products or more appearing together confidence when product x is bought the probability of purchasing product y lift when x is taken the probability of getting y increases by this much lift 1. merge rating userId movieId rating how inner top_users_ratings weighted_rating top_users_ratings corr top_users_ratings rating top_users_ratings top_users_ratings top_users_ratings userId random_user recommendation_df top_users_ratings. These systems forecast the most probable product that customers would buy and it is interesting to them. We have four sentences. References https github. We will use groupby for this problem. If we apply this method for all the data all NaN values are going to be filled by the predicted values 4. What are these factors in this data Comedy horror adventure action thriller youth having a specific actor director. ADD TABLES PICTURE r_ 11 p_ 11 q_ 11 p_ 12 q_ 21 All p and q are found iteratively over the existing values and then used. 2 CountVectorizer 15 2. Making Product Suggestions to Users at the Shopping Cart Stage 1. Store s sales between 01 12 2009 09 12 2011. It expresses how many of the products on the invoices have been sold. 2 Determining The Movies Watched By The User To Make A Suggestion 27 3. 5 Libraries 6 1. References 36 1. 3 Model TuningThere is the problem of how long I will do the process of changing the values. 4 Variables 5 1. While you are liking the movie there are some factors that you are not aware of. values random_user_df user_movie_df user_movie_df. 4 Final Model and PredictionUser_id1 didn t give any rate for Cries and Whispers but we predicted that userid1 would give 4. 3 Dataset Story 4 1. We will create the correlation df. 2 CountVectorizerIn the Count operation the number of times each word occurs in each document is counted. sort_values weighted_rating ascending False movie pd. com blogs what are recommendation systems machine learning https en. 4 Making Product Suggestions to Users at the Shopping Cart StageExample Product Id 22492If want to see two product suggection Some Notes For example if I had 10 000 products I wouldn t be interested in all of them. 1 Libraries 14 2. The functions of a recommender system are to suggest things to the user based on a variety of criteria. ", "id": "kemalgunay/comprehensive-guide-to-build-recommendation-engine", "size": "15133", "language": "python", "html_url": "https://www.kaggle.com/code/kemalgunay/comprehensive-guide-to-build-recommendation-engine", "git_url": "https://www.kaggle.com/code/kemalgunay/comprehensive-guide-to-build-recommendation-engine", "script": "calculate_cosine_sim arl_recommender surprise.model_selection train_test_split content_based_recommender accuracy TfidfVectorizer apriori user_based_recommender sklearn.metrics.pairwise cross_validate retail_data_prep Reader replace_with_thresholds sklearn.feature_extraction.text create_user_movie_df create_invoice_product_df association_rules item_based_recommender check_id check_df CountVectorizer cosine_similarity pandas Dataset SVD outlier_thresholds mlxtend.frequent_patterns GridSearchCV surprise check_film ", "entities": "(('We', 'ARL 2 content'), 'discuss') (('We', 'columns'), 'want') (('also most', 'customers'), 'be') (('it', 'correction'), 'know') (('we', 'them'), 'datum') (('ALS', 'p values'), 'make') (('Invoice', 'items'), 'indicate') (('s', 'single function'), 'let') (('person', 'low corr'), 'have') (('who', 'common James'), 'bring') (('when x', 'much lift'), 'support') (('s', 'user 1 356 id1'), 'be') (('Data We', 'user movie already matrix'), 'preprocesse') (('we', 'that'), 'be') (('how long I', 'values'), 'be') (('s', 'first name'), 'doesn') (('that', 'weights'), 'find') (('then empty sections', 'weights'), 'find') (('We', 'James'), 'aggregate') (('Comedy horror adventure action thriller youth', 'actor specific director'), 'be') (('fine you', '2'), 'be') (('We', 'data'), 'use') (('index random_user', 'random_user_df'), 'movies_watched') (('s', 'only Germany'), 'work') (('userid1', '4'), 'give') (('suggest', 'what'), 'do') (('it', 'user movie dataframe'), 'create') (('Matrix factorization', 'latent when movie'), 'assume') (('film', 'which'), 'reason') (('common we', 'threshold'), 'be') (('we', 'movie'), 'generate') (('that', 'user'), 'do') (('ADD TABLES PICTURE q 11 _ 11 11 _ 12 21 p', 'iteratively existing values'), 'r') (('We', 'James most similar correlation'), 'create') (('userid', 'database level'), 'check') (('support minimum value', 'life real scenarios'), '01') (('Cosine SimilarityA metric', 'two vectors'), 'focus') (('dataset', 'code'), 'make') (('person', 'product'), 'be') (('Empty observations', 'weights'), 'fill') (('don ratings', '3'), 'watch') (('we', '1'), 'convert') (('Identifying 4 Users', 'Average Recommendation 5 Weighted Score'), 'step') (('we', 'example'), 'prepare') (('read_csv kaggle input', 'm 20 dataset movie'), 'movielen') (('learning that', 'updates'), 'update') (('merge pip install movie movieId We', 'followability'), 'surprise') (('SVD Singular Value same Decomposition', 'SVD'), 'be') (('latent factors', 'machine learning'), 'call') (('1 s', '356 userid'), 'let') (('org wiki Association_rule_learning pip install', 'libraries'), 'mlxtend') (('weights', 'filled observations'), 'find') (('Estimation', 'available p'), 'make') (('SET 536370 1 1 536974 0 537065 1 0 0 537463 0 0 1 applymap', 'dataframe'), 'description') (('we', 'pd random_user int pd'), 'consider') (('therefore we', 'trashold'), 'return') (('Users', 'latent features'), 'consider') (('Item Based Collaborative Filtering 1 Suggestions', 'item similarity'), 'make') (('who', 'basket stage'), 'suggest') (('rule learning', 'large databases'), 'be') (('values', 'user_movie_df user_movie_df'), 'random_user_df') (('Unique customer number where customer', 'UnitPrice Product GBP'), 'price') (('Initially random p values', 'rating matrix'), 'try') (('we', 'three methods'), 'explain') (('we', 'matrix'), 'want') (('We', '3'), 'want') (('apply', 'support only row minumum value'), 'itinirate') (('occurs', 'document'), 'count') (('transition', 'latent factors'), 'assume') (('values', 'rating matrix'), 'arrange') (('you', 'percentage'), 'be') (('then 5', 'one iteration'), 'call') (('We', 'problem'), 'treshold') (('it', 'them'), 'forecast') (('hidden factors', 'also movies'), 'be') (('that', 'Rings movie'), 'be') (('you', 'movie'), 'be') (('we', 'instead it'), 'do') (('NaN values', 'predicted values'), 'apply') (('Top We', 'problem'), 'find') (('I', 'rating'), 'consider') (('functions', 'criteria'), 'be') (('Netflix Amazon', 'appropriate items'), 'employ') (('read_csv kaggle input', 'm dataset 20 rating'), 'movielen') (('that', 'interest'), 'design') (('how many', 'invoices'), 'express') (('movies_watched_df tolist user_movie_df', 'user_movie_count movies_watched_df'), 'movies_watched') (('we', '1'), '0') (('content based we', 'steps'), 'vectore') (('Association Rules We', 'possible products'), 'subtract') (('User Based Collaborative FilteringSuggestions', 'user similarities'), 'make') (('Thus p values', 'certain iteration'), 'fill') (('it', '1 othewise'), 'count') (('aim', 'retail II online dataset'), 'be') (('Recommender systems', 'recently spotlight'), 'be') (('merge rating', 'movieId how inner top_users_ratings weighted_rating'), 'rate') (('I', 'them'), '4') (('s', 'example'), 'let') (('We', '3 steps'), 'perform') (('rating matrix', 'factor matrices dot two product'), 'assume') (('Latent factors', 'Latent factors'), 'feature') (('product catalog', 'souvenirs'), 'include') (('8071 we', 't movies'), 'be') (('Cosine SimilarityEuclidean It', 'two vectors'), 'Distance') ", "extra": "", "label": "No_extra_files", "potential_description_queries": ["agg", "aggregate", "apply", "approach", "assign", "association", "binary", "build", "case", "category", "check", "checking", "company", "confidence", "consider", "content", "control", "convert", "corr", "correction", "correlation", "could", "count", "country", "create", "csv", "customer", "data", "database", "dataframe", "dataset", "date", "def", "define", "description", "df", "difference", "distance", "document", "dot", "drop", "duration", "empty", "epoch", "equal", "execute", "factor", "fill", "find", "forecast", "found", "frequency", "funct", "function", "gradient", "groupby", "high", "https github", "hyperparameter", "id", "import", "index", "inner", "input", "instance", "int", "item", "iteration", "itself", "kaggle", "language", "learning", "least", "let", "level", "library", "life", "line", "list", "look", "looking", "matrix", "mean", "merge", "method", "metric", "minimum", "mlxtend", "model", "most", "movie", "my", "name", "need", "new", "next", "non", "normalization", "normalized", "not", "notebook", "null", "number", "numeric", "operation", "optimization", "out", "output", "overview", "part", "pd", "people", "percent", "percentage", "perform", "person", "pickle", "present", "price", "probability", "problem", "product", "question", "random", "rare", "rating", "reason", "recommend", "recommendation", "recommender", "reduce", "replacement", "result", "return", "row", "runner", "sample", "score", "script", "second", "section", "selected", "selection", "separate", "set", "similar", "similarity", "single", "size", "speed", "sqrt", "structure", "subtract", "sum", "support", "surprise", "system", "table", "term", "tf", "tfidf", "threshold", "through", "title", "transaction", "turn", "under", "unique", "update", "user", "value", "weight", "who", "word", "work"], "potential_description_queries_len": 175, "potential_script_queries": ["accuracy", "apriori"], "potential_script_queries_len": 2, "potential_entities_queries": ["dataset", "empty", "int", "minimum", "movie", "random", "similar"], "potential_entities_queries_len": 7, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 177}
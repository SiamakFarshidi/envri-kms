{"name": "fork of hubmap submission experts raster i o ve ", "full_name": " h1 Introduction h1 Training Tricks h2 Disclamer h2 Color spaces augmentation trick h2 Multi scale input tiles h2 Pseudo labelling h2 Short training pipeline h1 Inference h2 Inference in a nutshell h2 Parameters h2 Models h1 Detailed Description of our Inference Approach h2 Data Preprocessing h3 Loading and Downsampling Whole Slide Images h3 Separate Slices between FFPE and Fresh Frozen h2 Making Predictions h3 Padding h3 Dividing the Image into Tiles h3 Generating the Segmentation Mask h3 Saving the Segmentation Mask h2 Generating Final Predictions h1 Submission h1 Insights ", "stargazers_count": 0, "forks_count": 0, "description": "Final submissions are ensembles of models trained with and without Color Space Augmenatations and Cutmix in order to increase the robustness. Color spaces augmentation trick For the training we found and decided to use various Color Space Augmentations in combination with custom stochastic kernel this is one of the most important things that allowed our models to stay robust and segment glomeruli despite the data source type of the images FFPE fresh frozen even others and color related variations. In order to handle the WSI images size we used memmap to load the images and also used temporary saving of processed patches to perform the ensembling. 068 2ec3f1bb9 33462 692 0. COLOR_RGB2HSV cv2. png Tiles with both augmentations image. COLOR_RGB2BGR cv2. 069 afa5e8098 21632 577 0. Ensembling predictions with different padding dimensions allows us to avoid bad predictions due to glomeruli located on edges of the tiles. COLOR_BGR2LAB cv2. COLOR_RGB2Luv cv2. 068 cb2d976f4 13378 435 0. png This methodology demonstrated its effectiveness and power during both stages of the competition but mostly with the first set of the data maybe due to the different test sets since we dont know yet results on the private test data. Eventually we need a DataLoader to feed data to our model. Inference in a nutshell We make an inference on the bigger patch size than was used for training. COLOR_RGB2LUV cv2. The first line with needs to be removed for that function to work. Imports TODO remove PARAMETERS Printing parameters Data processing Input data directory Reduce the original images by x times check 1024 Size of tiles on which inference is done 256 x 256 on all tiles Models MODELS_FRESH_FROZEN f. png attachment 0e0ed513 8f0e 459a 8f93 61152ceeafac. Additionally we used only non empty tiles of the bigger reduction rates to balance more the training dataset. pth for i in range 4 MODELS_PATHS MODELS_FRESH_FROZEN MODELS_FFPE Tiles selection https www. 33 that wasn t used because of the inference time constraints. The median perimeter was similarly correlated respectively 0. COLOR_RGB2YUV In the batch sampling part if self. load facebookresearch semi supervised ImageNet1K models resnext50_32x4d_ssl aspp with customized dilatations aspp with customized dilatations m torch. COLOR_RGB2HLS cv2. Image names from public and private test sets are retrieved from the sample_submission. That approach was giving us very good results on the public leaderboard and on cross validation before the change of test data but unfortunately for some reason we could not see that improvement afterwards. We copy our group finding code for information. COLOR_BGR2HSV cv2. 069 b9a3865fc 15859 483 0. 068 8242609fa 32320 683 0. png attachment 9408f479 08ca 46fa 8d25 2f090fdbeadf. Obvious visual differences can be noticed in both types of WSI the structure of FFPE tissues is better preserved than fresh frozen ones. COLOR_BGR2Luv cv2. Then the mask is reconstructed based on these tiles computed with different padding parameters. Loading and Downsampling Whole Slide ImagesThe main issue with WSI is that they are very big. Eventually the obtained mask is binarized and converted into RLE format. ParametersHere are the parameters that we use for inference. Then we generate masks for each image in the test set. At that moment the mask is already upsampled to match the original image. SubmissionHere is the final part of this kernel dealing with the actual submission of a CSV file containing generated masks. 071 aa05346ff 48216 1064 0. random 1 len cspaces cspace random. After loading the image using the load_image function above we apply the _tile_resize_save function below. 059 2f6ecfcdf 34158 708 0. The second version using a two pass segmentation is described in a separate notebook. Dealing with such big images is not convenient we found that we should downsample data for better performance. We also share the code as we implemented this idea. And finally we generate a submission. IntroductionThis kernel contains the inference code of the submission_experts team for the 2021 HuBMAP competition version 1. We added zero padding to make the dimensions of the image dividable by the tile size. First the make_predictions function generates mask tiles using the aforementioned get_mask_tiles function. com bguberfain memory aware rle encoding watch out for the bug This simplified method requires first and last pixel to be zero. 070 3589adb90 27831 624 0. ModelsThe models that we can use for inference are defined below. We also used classical TTA based on transformations of the D4 group but we were limited by the kernel inference time. pth for i in range 4 MODELS_FFPE f. 069 54f2eec69 32392 684 0. csv file that is provided. The following _get_group function allowed to get the group of a given image 0 if the slice has been fresh frozen and and 1 if it has been formalin fixed paraffin embedded. This also gave us significant boost both in CV and LB. 65 \u03bcm whereas FFPE tissue images had a physical spacing of 0. COLOR_RGB2XYZ cv2. All these functions are combined in make_one_prediction that aims at saving segmentation mask tiles based on an image and a given set of padding parameters. Save tiles in HDD memory First generate mask tiles Then reconstruct mask from tiles Eventually convert to rle https www. The _generate_masks function outputs a zero padded mask. For example improvement is from 0. The RLE conversion is done using the following rle_encode_less_memory function obtained from https www. Saving the Segmentation MaskThe segmentation mask is then saved as tiles containing scores it is not binarized yet. rand 3 3 K stoch. 89 Dice depending on the fold. com bguberfain memory aware rle encoding https www. Detailed Description of our Inference ApproachIn this section we describe our approach version 1. Then we select tiles on which we will make predictions based on their color saturations. 069 aaa6a05cc 13466 436 0. InferenceIn this section we describe how we make predictions. COLOR_BGR2LUV cv2. PaddingAs images are very big we must divide them into tiles. If PUBLIC_ONLY True then we only make the prediction for public test data. 065 c68fe75ea 34348 720 0. The goal of the competition was to provide with automated glomeruli segmentation models for WSI of human kidneys. 067 4ef6695ce 22636 574 0. png Tiles with Color Space augmentation image. Additionally we observed interesting behaviour such as robust segmentation even of some suspicious glomeruli in the d48 sample from public test set. 072 57512b7f1 11356 400 0. input models 256 cutmixup color nostoch model_ i. Generating the Segmentation MaskThe segmentation mask is then generated. 65 in the standard pipeline up to 0. exp K K elif random. Training Tricks DisclamerWe used NO hand labelling and manual annotation since in our vision it is not consistent with the initial goal and objective of the competition. 067 e79de561c 33504 704 0. We also initially wanted to find to which group fresh frozen vs FFPE they belonged to but as we said before we finally did not follow that approach. import cv2cspaces cv2. Locally we used smaller step of 0. The next step is logically to remove that padding. On the images below one could see how the naturally looked tiles are transformed being augmented with this method. 5xtile_size in both X and Y directions to cut the patches from test images. einsum ijk kl ijl img stoch This method also allowed to obtain much more focused predictions we observed very high soft dice metrics even without proper binarization threshold. Generating Final PredictionsFinal predictions are generated as follows. 071 b2dc8411c 24430 594 0. But it still demonstrated higher CV when models were trained independently for each group. Then we must reconstruct the image from resampled tiles that we saved. csv file containing all our predictions. Therefore we initially tried to apply different models with respect to the type of WSI that we were processing. Before the data update the best one was of 1024 and after 512 while the training is performed on 256x256. sqrt K stoch stoch K img np. Tiles with CutMix augmentation image. For that purpose we apply the following _reconstruct_img function. This DataLoader is based on the HuBMAPTestDataset class below. InsightsThanks to our predictions we could compute some metrics about glomeruli. 069 26dc41664 28316 649 0. These predictions are upsampled to match the original image. 071 095bf7a1f 29992 651 0. We obtained that information from the metadata of TIFF images. Making PredictionsIn this section we describe how we make predictions. After discussion we decided not to follow that approach in our final submissions. Some additional insights are provided at the end of the notebook. This information was crucial before the data update and allowed us to get different models that worked for each of the groups. png attachment a124c589 2fe5 46c4 93e2 d2f5257806d8. Data PreprocessingData preprocessing consists in downsampling images. The median area perimeter\u00b2 describing how complex the shape of the glomeruli were has been found to be correlated to the weight 0. You can see normal tiles with the cutmix augs color spaced without cutmix and color spaced with cutmix. Separate Slices between FFPE and Fresh FrozenAs both types of slices have different properties we found beneficial to apply a different model for FFPE slices and Fresh Frozen slices. Pseudo labellingPublic test set pseudo labeled with own models and included in the training procedure Short training pipelineUnet with resnext50_32x4d resnext101_32x16d efficientnet b7 b5 backbones ASPP and FPN modules complex loss combination of FocalLoss DiceLoss SymmetricLovasz OneCycleLR Heavy Augmentations CutMix ColorSpaced augs 5 fold patient based CV. The _generate_masks function is based on the Model_pred iterator like class that is used to generate predictions. In particular we were interested in the median area per patient the median perimeter per patient and the median ratio area perimeter\u00b2 per patient. COLOR_BGR2Lab cv2. All put together the result is the following load_resize function. It is not yet binarized. Segmentation mask tiles are generated for all possible sets of padding parameters using on the following get_mask_tiles function. choice cspaces img cv2. cvtColor img cspace if self. 071 1e2425f28 8768 356 0. However these findings must be confirmed on more patients as they are based on a very small sample of people that is not necessarily representative of the general population. 063 We found that the median area of glomeruli was negatively correlated to the weight correlation coefficient of 0. com iafoss 256x256 images Saturation blancking threshold Threshold for the minimum number of pixels Inference Make predictions only on public LB Overlap between tiles during prediction X axis Overlap between tiles during prediction Y axis Reduction for two types of models Threshold for positive predictions Number of bins when saving mask tiles Final prediction Size of saved mask tiles m torch. COLOR_BGR2HLS cv2. COLOR_BGR2YUV cv2. Here is how we load an image using NumPy MemMap. We used overlapping step of 0. We import them as follows. We use a TTA approach with four transformations from D4 we finally did not use rotations even though our code allows us to do it. In this competition these WSI can be divided into two categories those containing fresh frozen FFPE tissues and those containing formalin fixed paraffin embedded tissues. 046 d488c759a 9560 388 0. Dividing the Image into TilesThe following _split_image function allows us to divide images into tiles. Such approach naturally increases the training dataset and enriches variation of glomeruli size and its proportion in the considered tile of fixed size. Here are the values we obtained based on the GT for images in the training set and based on our predictions for images in the test set. load facebookresearch semi supervised ImageNet1K models resnet50_swsl aspp with customized dilatations Import models Get tile Reduce if needed Save tile Return dimension after reduction Tiles are deleted when read X overlap padding Y overlap padding Check that width is OK Check that height is OK Generate tmp directory if needed Remove black or gray images based on saturation check Iterator like wrapper that returns predicted masks List of models Dataloader Half precision Reduction on reduced image Prepare input Make predictions Upsample to initial shape Quantize probablities to save memory Output predictions Add padding to make the image dividable into tiles Split image into tiles using the reshape transpose trick Final shape nb_x nb_y TILE_SZ TILE_SZ 3 Select tiles for running the model Make tiles dataset Generate masks Reshape tiled masks into a single mask and crop padding A little bit of cleaning. Very important point that we wanted to highlight that we were able to split all test images into two groups with respect to the ffpe ff type using the PhysicalSizeY from the tiff. sum 0 keepdims True if random. Multi scale input tilesWe used multiple image reduction rates 3 4 5 6 and 8 in order to create the tiles from original images. The aforementioned DataLoader is generated using the following _make_tiles_dataloader function. COLOR_RGB2LAB cv2. However by some reasons we did not discover which this stopped working after the data update at least for the public LB. id median area \u00b5m\u00b2 median perimeter \u00b5m median area perimeter\u00b2 0486052bb 5610 309 0. COLOR_BGR2XYZ cv2. COLOR_RGB2Lab cv2. We found indeed that fresh frozen tissue images had a physical spacing of 0. COLOR_BGR2RGB cv2. com bguberfain memory aware rle encoding. ", "id": "vladimirgroza/fork-of-hubmap-submission-experts-raster-i-o-ve", "size": "13614", "language": "python", "html_url": "https://www.kaggle.com/code/vladimirgroza/fork-of-hubmap-submission-experts-raster-i-o-ve", "git_url": "https://www.kaggle.com/code/vladimirgroza/fork-of-hubmap-submission-experts-raster-i-o-ve", "script": "torch.utils.data __init__ _select_tiles UneXt101(nn.Module) _get_group make_predictions FPN(nn.Module) rle_encode_less_memory torchvision.models.resnet segmentation_models_pytorch _reshape_depad_mask UneXt50(nn.Module) Unet50(nn.Module) DataLoader PixelShuffle_ICNR _init_weight _split_image forward UnetBlock(nn.Module) torch.nn _save_mask_tiles HuBMAPTestDataset(Dataset) numpy __getitem__ _reconstruct_img load_resize get_mask_tiles _make_tiles_dataloader ConvLayer # TODO: remove _ASPPModule(nn.Module) PIL load_image ASPP(nn.Module) _tile_resize_save Model_pred _generate_masks fastai.vision.all Image matplotlib.pyplot ResNet tqdm.notebook pandas Bottleneck Dataset __len__ tqdm _get_nored_pads torch.nn.functional img2tensor read_tiff _add_padding __iter__ make_one_prediction ", "entities": "(('WSI', 'formalin fixed paraffin embedded tissues'), 'divide') (('models', 'fresh even others'), 'trick') (('This', 'CV'), 'give') (('Eventually we', 'model'), 'need') (('Image names', 'sample_submission'), 'retrieve') (('we', 'FFPE slices'), 'slice') (('tissue indeed fresh frozen images', '0'), 'find') (('load', 'NumPy MemMap'), 'be') (('Inference', 'prediction mask tiles m Final saved torch'), 'iafoss') (('we', '_ tile_resize_save function'), 'apply') (('it', 'scores'), 'save') (('they', 'WSI'), 'Slide') (('particular we', 'ratio median patient'), 'be') (('mask', 'already original image'), 'be') (('we', '_ reconstruct_img following function'), 'apply') (('Additionally we', 'training more dataset'), 'use') (('goal', 'human kidneys'), 'be') (('SubmissionHere', 'generated masks'), 'be') (('Eventually obtained mask', 'RLE format'), 'binarize') (('dimensions', 'tile size'), 'add') (('FFPE tissue 65 images', '0'), '\u03bcm') (('put', 'together result'), 'be') (('PUBLIC_ONLY then we', 'test public data'), 'make') (('training', '256x256'), 'update') (('we', 'test private data'), 'demonstrate') (('additional insights', 'notebook'), 'provide') (('Generate masks Reshape', 'cleaning'), 'supervise') (('we', 'tiff'), 'point') (('scale', 'original images'), 'use') (('that', 'padding given parameters'), 'combine') (('next step', 'logically padding'), 'be') (('we', 'kernel inference time'), 'use') (('simplified method', 'first pixel'), 'aware') (('predictions', 'original image'), 'be') (('Generating', 'Segmentation MaskThe segmentation mask'), 'generate') (('fresh it', 'given image'), 'allow') (('we', 'test set'), 'be') (('how we', 'predictions'), 'make') (('we', 'idea'), 'share') (('we', 'binarization even proper threshold'), 'stoch') (('how we', 'predictions'), 'inferencein') (('ColorSpaced CutMix augs', '5 patient based CV'), 'set') (('how shape', 'weight'), 'describe') (('we', 'ensembling'), 'use') (('we', 'that'), 'try') (('function', 'work'), 'line') (('that', 'predictions'), 'base') (('we', 'that'), 'reconstruct') (('that', 'groups'), 'be') (('mask First tiles', 'rle https Eventually www'), 'save') (('aforementioned DataLoader', '_ make_tiles_dataloader following function'), 'generate') (('group', 'information'), 'copy') (('Segmentation mask tiles', 'get_mask_tiles function'), 'generate') (('us', 'tiles'), 'allow') (('inference', 'tiles'), 'remove') (('Then we', 'test set'), 'generate') (('Additionally we', 'test public set'), 'observe') (('Then mask', 'padding different parameters'), 'reconstruct') (('make_predictions First function', 'get_mask_tiles aforementioned function'), 'generate') (('we', 'better performance'), 'be') (('very we', 'tiles'), 'divide') (('us', 'it'), 'use') (('wasn t', 'inference time constraints'), '33') (('structure', 'better fresh frozen ones'), 'notice') (('median area', '0'), '063') (('we', 'color saturations'), 'select') (('DataLoader', 'HuBMAPTestDataset class'), 'base') (('You', 'cutmix'), 'see') (('Final submissions', 'robustness'), 'be') (('second version', 'separate notebook'), 'describe') (('_ generate_masks function', 'zero padded mask'), 'output') (('RLE conversion', 'https www'), 'do') (('that', 'necessarily general population'), 'confirm') (('we', 'inference'), 'define') (('we', 'glomeruli'), 'InsightsThanks') (('We', 'TIFF images'), 'obtain') (('when models', 'independently group'), 'demonstrate') (('we', 'inference'), 'be') (('section we', 'approach version'), 'description') (('load facebookresearch semi', 'dilatations m customized torch'), 'supervise') (('IntroductionThis kernel', 'HuBMAP competition 2021 version'), 'contain') (('we', 'improvement'), 'give') (('how naturally looked tiles', 'method'), 'see') (('this', 'at least public LB'), 'discover') (('it', 'competition'), 'use') (('inference', 'training'), 'inference') (('we', 'final submissions'), 'decide') (('Such approach', 'fixed size'), 'increase') (('we', 'finally approach'), 'want') ", "extra": "['annotation', 'patient', 'test', 'procedure']", "label": "Perfect_files", "potential_description_queries": ["256x256", "annotation", "apply", "approach", "area", "augmentation", "balance", "batch", "best", "bit", "check", "choice", "code", "coefficient", "color", "combined", "competition", "compute", "conversion", "convert", "copy", "correlation", "could", "create", "crop", "csv", "custom", "cut", "cutmix", "data", "dataset", "describe", "dice", "dimension", "directory", "downsample", "efficientnet", "empty", "encoding", "end", "even", "exp", "feed", "ff", "file", "final", "find", "fixed", "fold", "following", "found", "function", "general", "generate", "generated", "glomeruli", "gray", "group", "hand", "handle", "height", "high", "highlight", "human", "id", "image", "img", "import", "improvement", "increase", "inference", "initially", "input", "issue", "kernel", "labeled", "leaderboard", "least", "len", "line", "little", "load", "main", "manual", "mask", "match", "median", "memory", "metadata", "method", "minimum", "model", "moment", "most", "multiple", "need", "next", "non", "normal", "not", "number", "objective", "order", "out", "overlap", "padding", "part", "patch", "patient", "people", "per", "perform", "pipeline", "pixel", "png", "point", "positive", "power", "precision", "prediction", "preprocessing", "procedure", "processing", "provide", "public", "purpose", "rand", "random", "range", "ratio", "read", "reason", "reconstruct", "remove", "reshape", "result", "rle", "robust", "running", "sample", "sampling", "save", "saving", "scale", "second", "section", "segment", "segmentation", "select", "selection", "semi", "separate", "set", "shape", "single", "size", "slice", "soft", "source", "split", "sqrt", "standard", "step", "structure", "submission", "sum", "supervised", "team", "test", "those", "threshold", "tile", "time", "tissue", "training", "transpose", "type", "up", "update", "validation", "variation", "version", "vision", "weight", "while", "width", "wrapper"], "potential_description_queries_len": 187, "potential_script_queries": ["forward", "nn", "numpy", "torch", "tqdm"], "potential_script_queries_len": 5, "potential_entities_queries": ["even", "following", "inference", "mask", "patient", "segmentation", "tissue"], "potential_entities_queries_len": 7, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 191}
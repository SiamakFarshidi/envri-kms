{"name": "keras u net for nuclei segmentation ", "full_name": " h1 Part 0 Intro h1 Part 1 Data Input h2 Visualize masks on the training data h1 Part 2 Build model h1 Part 3 Run model h1 Part 4 Evaluate output h2 Visualize predictions on the validation data h2 Visualize predictions on the test data h1 Part 5 Submit results h2 Visualize upscaled predictions on the test data ", "stargazers_count": 0, "forks_count": 0, "description": "com weiji14 yet another keras u net data augmentation and many others I added the visualization of the input and result images. py Fixed code to enable non flat loss plots on keras model. com rakhlin fast run length encoding python Apply Run Length Encoding on our Y_hat_upscaled note that for each test_image we can have multiple entries of encoded pixels Create submission DataFrame Have a look at our submission pandas dataframe. Part 1 Data Input Visualize masks on the training data Part 2 Build model Part 3 Run model Part 4 Evaluate output Visualize predictions on the validation data Visualize predictions on the test data Part 5 Submit results Visualize upscaled predictions on the test data Set number of GPUs defaults to 1 if one GPU or one CPU. com questions 41342098 keras load checkpoint weights hdf5 generated by multiple gpus get second last layer in multi_gpu_model i. get_layer model_1 Reload the model Predict on val Threshold predictions Define IoU metric as a regular function to manually check result calcualte average iou of validation images the result from tensorflow seems too high. I just evaluate whether a pixel is marked as nuclei or not correctly. To simplify the problem all the individual nuclei masks of an input image are merged to one flatten mask image. home user kaggle dsbowl changes our python working directory to the top directory of our kaggle files see what s in the input folder where data is in path to training data file folder path to test data file folder Get training data take only 3 channels bands Get training data labels loop through each individual nuclei for an image and combine them together need to add an extra dimension so mask. 2 n 16 32 64 128 256 size of filter kernel kernel initializer encoder do not run max pooling on the last encoding downsampling step decoder Custom IoU metric Custom loss function Set some model compile parameters Compile our model For more GPUs Runtime data augmentation Image data generator distortion options use constant Train data provide the same seed and keyword arguments to the fit and flow methods Test data no data augmentation but we create a generator anyway combine generators into one which yields image and masks Runtime custom callbacks https github. fit_generator Finally train the model increase epoch on your own machine Save the model weights to a hdf5 file Refer to https stackoverflow. train image illustrate the details for some images Get test data Use model to predict test labels Upsample Y_hat back to the original X_test size height and width loop through test_ids in the test_path read original test image directly from path upscale Y_hat image according to original test image append upscaled image to Y_hat_upsampled Run length encoding stolen from https www. shape img_height img_width 1 Illustrate the train images and masks train image Design our model architecture here the n th deep channel s exponent i. Part 0 IntroThis notebook takes a lot of inspiration from https www. com keegil keras u net starter lb 0 277 https www. com deepsense ai intel ai webinar neural networks blob master live_loss_plot. Set height y axis length and width x axis length to train model on Default to 256 266 use None None if you do not want to resize imgs Import all the necessary libraries Used for imshow function Used for resize function Used for Run Length Encoding RLE to create final submission Set seed values Have a look at our data folder defaults to kaggle in kaggle kernels different if on own system e. ", "id": "dingli/keras-u-net-for-nuclei-segmentation", "size": "754", "language": "python", "html_url": "https://www.kaggle.com/code/dingli/keras-u-net-for-nuclei-segmentation", "git_url": "https://www.kaggle.com/code/dingli/keras-u-net-for-nuclei-segmentation", "script": "Flatten keras.preprocessing.image __init__ keras.layers keras.callbacks LeakyReLU train_test_split GlobalAveragePooling2D keras_model mean_iou EarlyStopping Dropout skimage.morphology matplotlib.ticker keras.layers.advanced_activations on_epoch_end translate_metric Conv2D AveragePooling2D get_X_data numpy multi_gpu_model label                  #Used for Run-Length-Encoding RLE to create final submission Input Conv2DTranspose bce_dice_loss ModelCheckpoint sklearn.model_selection ImageDataGenerator clear_output cal_iou matplotlib.pyplot Activation Dense keras.utils tensorflow pandas Lambda GlobalMaxPooling2D dice_coef get_train_test_augmented BatchNormalization plot_model FormatStrFormatter Callback load_model on_train_begin rle_encoding Model concatenate MaxPooling2D get_Y_data prob_to_rles backend backend as K keras add PlotLosses(Callback) keras.models IPython.display keras.layers.merge ZeroPadding2D ", "entities": "(('fit_generator', 'https stackoverflow'), 'train') (('submission Set seed final values', 'system own e.'), 'Set') (('com keras checkpoint weights 41342098 hdf5', 'multi_gpu_model i.'), 'question') (('Set number', 'one GPU'), 'mask') (('many I', 'input'), 'com') (('IntroThis 0 notebook', 'https www'), 'part') (('nuclei individual masks', 'mask one flatten image'), 'merge') (('Get', 'together extra dimension'), 'change') (('here n', 'deep channel'), 'shape') (('just pixel', 'nuclei'), 'evaluate') (('DataFrame', 'submission pandas dataframe'), 'run') (('train image', 'https www'), 'illustrate') (('metric', 'tensorflow'), 'model_1') (('which', 'image'), '2') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["append", "architecture", "augmentation", "average", "blob", "channel", "check", "checkpoint", "code", "combine", "compile", "create", "custom", "data", "decoder", "dimension", "directly", "directory", "distortion", "enable", "encoder", "encoding", "epoch", "evaluate", "file", "filter", "final", "fit", "flat", "flow", "folder", "function", "generated", "generator", "height", "image", "imshow", "increase", "individual", "input", "iou", "kaggle", "kernel", "layer", "length", "load", "look", "loop", "lot", "mask", "max", "metric", "model", "multiple", "need", "neural", "no", "non", "not", "notebook", "nuclei", "number", "output", "path", "pixel", "pooling", "predict", "problem", "provide", "py", "python", "read", "resize", "result", "run", "second", "shape", "size", "step", "submission", "system", "tensorflow", "test", "through", "train", "training", "user", "val", "validation", "visualization", "width"], "potential_description_queries_len": 91, "potential_script_queries": ["backend", "concatenate", "final", "label", "numpy", "preprocessing", "tensorflow"], "potential_script_queries_len": 7, "potential_entities_queries": ["final"], "potential_entities_queries_len": 1, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 96}
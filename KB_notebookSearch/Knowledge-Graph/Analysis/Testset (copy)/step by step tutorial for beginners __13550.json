{"name": "step by step tutorial for beginners ", "full_name": " h1 Table of Contents h1 A Thank You Note h1 Article on medium publication h1 What would be the workflow h1 Problem Identification h1 What data do we have h1 Exploratory data analysis h1 Feature engineering h1 Creating a Model h1 Model Evaluation h1 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "2nd approach to treat the Age feature Sex Creating Family Size variable using SibSp Parch SibSp Parch Ticket Tickets are of 2 types here. represents the economic status. We can create more features using this Cabin variable. AdaBoost classifier Adaboost begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases. The idea behind SVM is to find a maximum marginal hyperplane MMH that best divides the dataset into classes. png Title Sex_Female Fare PClass seems to be common features preferred for classification. SibSP This variable refers to number of siblings spouse onboard. map lambda s 1 if s 1 else 0 combdata SmallF combdata Fsize. Variable source is a kind of tag which indicates data source in combined data PassengerID Drop PassengerID Pclass Name Extract Salutation from Name variable Name Create 5 major categories analyze the survival rate inspect the correlation between Title and Survived Create dummy variable Fare Check the number of missing value Only 1 value is missing so we will fill the same with median Use the numpy fuction log1p which applies log 1 x to all elements of the column combdata Fare np. Approximately 62 of Pclass 1 passenger survived followed by 47 of Pclass2. Feature engineering FE. png What we need to do to process following variables PassengerID No action required PClass Have only 3 numerical values. I tried various ML algorithms but I found the voting method most useful based on the variables I had. distplot combdata Fare fit norm bin Fare into five intervals with equal amount of people inspect the correlation between Fare bin and Survived Index of NaN age rows missing_index list combdata Age combdata Age. get_dummies combdata columns Sex Create a variable representing family size from SibSp and Parch Analyze the correlation between Family and Survived Create new feature of family size combdata Single combdata Fsize. png One important aspect of machine learning is to ensure that the variables show almost the same trend across train test data. map lambda s 1 if s 2 else 0 combdata MedF combdata Fsize. In my previous versions I have used ALL In approach using all variables with feature engineering for prediction. Problem Identification Prob 20Ident. Fill the age with median age of similar rows according to Sex Pclass Parch SibSP or use a quick machine learning algorithm to predict the age values based on Age Title Fare SibSPI used both of them to test which one works better. Please refer to versions 25 or earlier to review the same. We are trying following to develop a baseline 1. inspect the correlation between Ticket and Survived Let s look at the number of people for each type of tickets check the correlation again Create dummy variables Cabin Replace the missing Cabin number by the type of cabin unknown U Let s plot the survival probability by Cabin Drop the variables we don t need Import the required libraries You may want to drop some variables to avoid dummy variable trap test. png attachment Prob 20Ident. com content uploads 2016 04 blog twenty one business icebergs sink business 280416. com rp1611 model ensembles for survival prediction a3ecc9f7c2ae and access the blog. As we all know that Learning the model parameters and testing it on the same data is a big mistake. Extra Trees Classifier 6. It would help me improve. Ticket This variable has alphanumeric value which might not be related to Survival directly but we can use this variable to create some additional features. Adaboost Best score RFC Parameters tunning Best score Gradient boosting Best score Best score Feature importance Concatenate all classifier results Use voting classifier to combine the prediction power of all models Predict and export the results. Build the model on the training set and evaluate it on the test set d. jpg Let s import necessary libraries bring in the datasets in Python environment first. Exploratory data analysis analysis. com blog 2018 05 improve model performance cross validation in python r Now we have the training and test datasets available and we can start training the model. Embarked C Cherbourg Q Queenstown S SouthamptonLet s explore the variable with Survival rate. iloc i filled_age else combdata Age. Example Let s start with finding the number of missing values. jpg So it is a classification problem and you are expected to predict Survived as 1 and Died as 0. You will look for people with similar experience type of work department etc and then will use the median salary of such a group. an estimator regressor or classifier 2. SibSP 1 and SibSP 2 shows higher chances of survival. The sub sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap True default. com rf image_large Pub p9 AJC 2018 07 12 Images newsEngin. 22048809_071418 titanic_Titanic Image 7 2. Let s extract the first digit and compare it with survival probability. What data do we have Data. Different hyper parameters can result in different model with varying performance accuracy. Based on value counts and average survival we can put all other ticket categories into a new category 4. map lambda s 1 if 3 5 else 0 Analyze the Survival Probability by Fsize SibSp Drop the variable Parch Drop the variable Ticket Extracting the ticket prefix. Multi layer Perceptron classifier 5. Special thanks to Yassine. png Evaluating multiple models using GridSearch optimization method. For example if my salary information is missing you can t simply replace the missing value with median salary of my whole organization. A search consists of 1. Fare Let s check the distribution first. It helps you to understand the performance of your model and fight with overfitting. Hyper parameters are key parameters that are not directly learnt within the estimators. You can click this clink https medium. The guided approach explained here will help you to understand how you should design and approach Data Science problems. png Import the basic python libraries Read the datasets We have 891 observations 12 columns. We will build couple of base models and then will use Grid Search method to optimize the parameters. png attachment model. If you compare the output you will see that missing value percentages do not vary much across train test datasets. png Best Practice The most important part of any project is correct problem identification. Gradient Boosting Classifier 10. iloc i Parch combdata Pclass combdata. Write down things like what are you expected to do what data you might need or let s say what all algorithms you plan to use. Parch Parch indicates number of parents children aboard the Titanic. Article on medium publicationI also wrote an article on medium on the same topic. I will give you one example here. I will be trying the classic LESS IS MORE approach. As we do variable analysis try to replicate wherever applicable the code for test data and see if there is any major difference in data distribution. drop labels source Sex_male Fsize LargeF SibSp_8 Parch_9 T_WEP Cabin_T Emb_Q axis 1 inplace True You may want to drop some variables to avoid dummy variable trap X_train train. Frankly speaking no one cares. Note that Parch 3 and Parch 1 shows higher survival probabilities. Here we are combining the predictions from models that we built and predict based on votes. png attachment Good 20Bye. Name Not relevant from analysis modeling perspective. 2 Splits are chosen completely at random from the range of values in the sample at each split. Support Vector Classifier 4. The general approach is as follows 1. If not it would lead to overfitting because model is representing a relationship which is not applicable in the test dataset. Understand the problem first and draft a rough strategy on a piece of paper to start with. Most of these tickets belong to category 1 2 3 S P C. Gradient Boosting Gradient boosting is one of the most powerful techniques for building predictive models. While Title Age feature represents the Age category of passengers the features like Fare PClass Cabin etc. Save the evaluation score 3. Type 1 has only number and Type 2 is a combination of some code followed by the number. Based on findings we can conclude that Age Gender features representing social economic status were primary factors affecting the survival of passenger. It is not an actual classifier but a wrapper for set of different ones that are trained and valuated in parallel in order to exploit the different peculiarities of each algorithm. Though there are many ways to do the same analysis I have used the codes which I found more efficient and helpful. If you liked this notebook and found this notebook helpful Please upvote and leave a comment Good 20Bye. AdaBoost Classifier Model Evaluation model. png attachment analysis. png Cross Validation is one of the most powerful tool in Data Scientist s tool box. 687 missing values in train 327 missing values in test data which needs to be treated. K Nearest Neighbour 2. Such a model would have learned everything about the training data and would give result in a near perfect test score as it has already seen the data. For each unique group a. Sex Create dummy variables Age Missing value treatment followed by creating dummy variables SibSP Drop the variable Parch Drop the variable as most of the values are 0 Ticket Create dummy variables post feature engineering Fare Missing value treatment followed by log normalization Cabin Create dummy variables post feature engineering Embarked Create dummy variables PassengerID Pclass Name Title Fare Age There are 2 ways of handling the missing age values. Name Can be used to create new variable Title by extracting the salutation from name. Additional analysis Let s create few additional charts to see how different variables are related. Use the remaining groups as training data set c. SVM generates optimal hyperplane in an iterative manner which is used to minimize the error. Embarked represents port of embarkation. Cabin Embarked Creating a Model Cross Validation Strategy CV. Conclusion Conclusion. Table of Contents A Thank You Note. Random Forest Classifier Similar to Extra Tree Classifier a Random Forest is a meta estimator that fits a number of decision tree classifiers on various sub samples of the dataset and uses averaging to improve the predictive accuracy and control over fitting. jpg The insight below connects back to Ladies and Kids First scene of the movie. drop labels Survived Sex_male Fsize LargeF SibSp_8 Parch_9 T_WEP Cabin_T Emb_Q axis 1 Cross validate model with Kfold stratified cross val Modeling differents algorithms. a method for searching or sampling candidates 4. Once we have the datasets in Python environment we can slice dice the data to understand what we have and what is missing. Problem Identification What data do we have Exploratory data analysis Data preparation including feature engineering Developing a model Model evaluation Conclusions That s all you need to solve a data science problem. We have to pass these as arguments. jpg Based on data above female passengers had better chances of survival than male passengers Age Age. We have 417 observations 11 columns no response Survived column. Logistic Regression 7. a cross validation scheme and5. In boosting each new tree is a fit on a modified version of the original data set. We will use it as it is. index for i in missing_index median_age combdata Age. Cabin Alphanumeric variable. This will help you to stay on track. Let s look at the distribution. As the analysis output below suggests Emabrked C shows high probabilities of survival. Support Vector Machines SVM builds a hyperplane in multidimensional space to separate different classes. This might be a representation of class compartment. Before you jump to How to do this part like typical Data Scientists understand What Why part. Decision Trees 8. See the mix of variable types. median if not np. To avoid it it is common practice when performing a supervised machine learning experiment to hold out part of the available data as a test set X_test y_test. It shows that a good number of babies young kids survived. Use the groupby univariate bivariate analysis method to compare the distribution across Train Test data PassengerId Not relevant from modeling perspective so we will drop this variable later Pclass Pclass is categorical variable. Instead of directly replacing the missing values with the median value of complete data the script looks for nearby data which is similar in terms of Sex Pclass Parch and SibSp and then takes the median values of those observations. Kee one group as a hold out or test data set b. Summarize the performance of the model using the sample of model evaluation scoresYou can access following link and read about Cross Validation in detail. To find out what paparmeters are resulting in best score we can use Grid Search method and use the optimum set of hyper parameters to build and select a good model. So here is the workflow. png attachment Conclusion. Random Forest 9. iloc i SibSp combdata Parch combdata. Sex Create dummy variables combdata pd. We will do this during feature engineering process. The same model would fail terribly when tested on unseen data. iloc i median_age This is somewhat arbitrary. What would be the workflow I will keep it simple crisp rather than using buzz words useless data science frameworks. Let s plot feature importance by various algorithms Voting Classifier Voting is one of the simplest method of combining the predictions from multiple machine learning models. This section of code is for missing value treatment for age. This situation is called overfitting. log1p combdata Fare Check the new distribution sns. The idea is just to show you the path try your own ways and share the same with others. Wherever whenever required I have given due credit to my fellow Kagglers which they deserve for their hard work. com datadriveninvestor k fold cross validation 6b8518070833https www. iloc i Sex combdata SibSp combdata. Linear Discriminant Analysis 3. Boosting is a method of converting weak learners into strong learners by building an additive model in a forward stage wise fashion. We need to transform this variable using log function and make it more normally distributed. One of the code will be markdown to avoid confusion. The Fare variable is right skewed. Split the dataset into k groups2. We will drop this feature later after creating a new variable as Title. How ET differes from RF 1 When choosing variables at a split samples are drawn from the entire training set instead of a bootstrap sample of the training set. ExtraTrees Classifier ET is a meta estimator that fits a number of randomized decision trees on various sub samples of the dataset and then uses averaging method to improve the predictive accuracy and control over fitting. Sex Based on analysis below female had better chances of survival. median filled_age combdata Age combdata Sex combdata. Check missing values in train data set Check missing values in train data set Fill empty and NaNs values with NaN Analyze the count of survivors by Pclass Analyze the Survival Probability by Pclass Count the number of passengers by gender Analyze survival count by gender Analyze the Survival Probability by Gender Let s explore the distribution of age by response variable Survived We can also say that the older the passenger the lesser the chance of survival Analyze the count of survivors by SibSP Analyze probability of survival by SibSP Analyze the count of survivors by Parch Analyze the Survival Probability by Parch for some statistics Get the fitted parameters used by the function Now plot the distribution Let s check the unique values Analyze the count of survivors by Embarked variable Analyze the Survival Probability by Embarked Age Pclass Survival Age Embarked Sex Pclass Relation among Pclass Gender Survival Rate Relation among SibSP Gender Survival Rate Relation among Parch Gender Survival Rate Let s combining train test for quick feature engineering. Now the Titanic challenge hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing age sex or passenger s class on the boat. There are several classification you can select. Please leave comments feedback. isnan filled_age combdata Age. ", "id": "rp1611/step-by-step-tutorial-for-beginners", "size": "13550", "language": "python", "html_url": "https://www.kaggle.com/code/rp1611/step-by-step-tutorial-for-beginners", "git_url": "https://www.kaggle.com/code/rp1611/step-by-step-tutorial-for-beginners", "script": "cross_val_score sklearn.tree sklearn.discriminant_analysis AdaBoostClassifier sklearn.neural_network KNeighborsClassifier DecisionTreeClassifier collections seaborn numpy RandomForestRegressor learning_curve GradientBoostingRegressor scipy.stats ExtraTreesClassifier GradientBoostingClassifier VotingClassifier sklearn.ensemble sklearn.model_selection RandomForestClassifier LinearDiscriminantAnalysis matplotlib.pyplot skew #for some statistics stats pandas norm LogisticRegression Counter scipy GridSearchCV sklearn.neighbors SVC sklearn.linear_model StratifiedKFold sklearn.svm MLPClassifier ", "entities": "(('You', 'X_train train'), 'Fsize') (('which', 'column combdata Fare np'), 'be') (('value missing percentages', 'train test much datasets'), 'compare') (('This', 'class compartment'), 'be') (('you', 'data science problem'), 'identification') (('we', 'model'), 'improve') (('meta that', 'fitting'), 'be') (('PClass', 'only 3 numerical values'), 'png') (('Embarked C Cherbourg Q Queenstown SouthamptonLet s', 'Survival rate'), 'S') (('you', 'whole organization'), 'replace') (('Approximately 62', 'Pclass2'), 'survive') (('score Feature classifier Best importance results', 'results'), 'Parameters') (('that', 'algorithm'), 'be') (('com datadriveninvestor k', 'cross validation 6b8518070833https www'), 'fold') (('most', 'Cabin variables post feature variables Pclass Name Title Fare age Create dummy Embarked Create dummy 2 missing values'), 'create') (('we', 'votes'), 'combine') (('directly we', 'additional features'), 'have') (('We', 'Survived column'), 'have') (('which', 'observations'), 'look') (('which', 'test dataset'), 'lead') (('such subsequent classifiers', 'more difficult cases'), 'begin') (('you', 'algorithms'), 'write') (('Emabrked below C', 'survival'), 'suggest') (('Article', 'same topic'), 'write') (('which', 'test 327 missing data'), 'value') (('how different variables', 'few additional charts'), 'let') (('map lambda', 'Parch Ticket ticket variable prefix'), 's') (('that', 'classes'), 'be') (('they', 'hard work'), 'give') (('Gradient Boosting Gradient boosting', 'predictive models'), 'be') (('We', 'baseline'), 'try') (('s', 'missing values'), 'let') (('how you', 'Data Science problems'), 'explain') (('SibSP variable', 'siblings'), 'refer') (('I', 'which'), 'be') (('png Best most important part', 'project'), 'practice') (('We', 'feature engineering process'), 'do') (('classification you', '0'), 'jpg') (('scoresYou', 'detail'), 'access') (('Parch', 'survival 3 1 higher probabilities'), 'note') (('Parch Parch', 'Titanic'), 'indicate') (('We', 'Cabin variable'), 'create') (('Sex', 'survival'), 'have') (('We', 'parameters'), 'build') (('Title Age feature', 'Fare PClass Cabin etc'), 'represent') (('We', '891 observations'), 'Import') (('goal', 'boat'), 'be') (('Most', 'S P 1 2 3 C.'), 'belong') (('I', 'MORE approach'), 'try') (('we', 'good model'), 'use') (('it', 'X_test y_test'), 'be') (('you', 'overfitting'), 'help') (('Boosting', 'forward stage wise fashion'), 'be') (('young kids', 'babies'), 'show') (('This', 'i'), 'iloc') (('Support Vector Machines SVM', 'different classes'), 'build') (('1 only number', 'number'), 'have') (('s', 'feature quick engineering'), 'check') (('key that', 'directly estimators'), 'be') (('which', 'error'), 'generate') (('Age Gender', 'passenger'), 'conclude') (('I', 'prediction'), 'use') (('Learning', 'same data'), 'know') (('One', 'confusion'), 'be') (('what', 'what'), 'slice') (('training data', 'remaining groups'), 'use') (('distplot combdata Fare', 'missing_index list combdata Age combdata Age'), 'fit') (('variable analysis', 'data major distribution'), 'try') (('just path', 'others'), 'be') (('1 When choosing', 'training set'), 'differe') (('jpg', 'passengers Age male Age'), 'have') (('variables', 'train test data'), 'be') (('meta that', 'fitting'), 'Similar') (('SibSP', 'survival'), 'show') (('I', 'most variables'), 'try') (('Name', 'name'), 'use') (('Cross validate 1 model', 'val Modeling differents algorithms'), 'label') (('samples', 'True default'), 'be') (('png Cross Validation', 'Data tool box'), 'be') (('required You', 'trap dummy variable test'), 'inspect') (('I', 'buzz data science simple rather words useless frameworks'), 'be') (('average we', 'new category'), 'put') (('notebook', 'helpful comment'), 'like') (('same model', 'terribly when unseen data'), 'fail') (('png Title Sex_Female Fare PClass', 'common classification'), 'seem') (('Pclass later Pclass', 'variable'), 'use') (('Data typical Scientists', 'What'), 'jump') (('hyper Different parameters', 'performance varying accuracy'), 'result') (('We', 'Title'), 'drop') (('SibSp Parch SibSp Parch Ticket Tickets', '2 types'), 'feature') (('s', 'Python environment'), 'let') (('Voting Classifier Voting', 'machine learning multiple models'), 'let') (('section', 'age'), 'be') (('2 Splits', 'split'), 'choose') (('one', 'them'), 'fill') (('log1p combdata Fare', 'distribution new sns'), 'check') (('it', 'already data'), 'learn') (('it', 'log function'), 'need') (('s', 'survival probability'), 'let') (('get_dummies combdata Sex', 'family size combdata Single combdata Create new Fsize'), 'column') (('You', 'group'), 'look') ", "extra": "['gender', 'organization', 'test']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "age", "algorithm", "alphanumeric", "analyze", "approach", "article", "average", "baseline", "basic", "best", "bin", "blog", "boosting", "build", "cabin", "categorical", "category", "challenge", "check", "children", "classification", "classifier", "code", "column", "combine", "combined", "comment", "compare", "competition", "content", "control", "correct", "correlation", "count", "create", "credit", "data", "dataset", "decision", "develop", "dice", "difference", "digit", "directly", "distplot", "distribution", "drop", "dummy", "empty", "engineering", "ensure", "environment", "equal", "estimator", "evaluate", "evaluation", "everything", "expected", "experience", "experiment", "explained", "explore", "export", "extract", "fail", "family", "feature", "fill", "find", "fit", "fitting", "fold", "following", "forward", "found", "function", "gender", "general", "group", "groupby", "help", "high", "hyperplane", "idea", "import", "importance", "improve", "including", "index", "input", "key", "layer", "lead", "learning", "leave", "let", "link", "list", "log", "look", "major", "male", "manner", "map", "maximum", "median", "meta", "method", "might", "minimize", "missing", "model", "most", "multiple", "my", "near", "need", "new", "no", "norm", "normalization", "not", "notebook", "number", "numerical", "numpy", "optimization", "optimize", "order", "out", "output", "overfitting", "parallel", "part", "passenger", "path", "people", "performance", "performing", "plot", "png", "post", "power", "practice", "predict", "prediction", "probability", "problem", "project", "python", "random", "range", "read", "relationship", "replace", "replacement", "representation", "response", "result", "review", "right", "salary", "sample", "sampling", "scene", "science", "score", "script", "search", "section", "select", "separate", "set", "several", "sex", "similar", "situation", "size", "slice", "source", "space", "split", "stage", "start", "strategy", "sub", "supervised", "survival", "survived", "tag", "test", "testing", "those", "ticket", "tool", "train", "training", "transform", "treatment", "tree", "trend", "try", "type", "unique", "val", "validate", "validation", "value", "variable", "version", "wise", "work", "workflow", "wrapper"], "potential_description_queries_len": 215, "potential_script_queries": ["numpy", "scipy", "seaborn", "skew"], "potential_script_queries_len": 4, "potential_entities_queries": ["classifier", "dummy", "feature", "learning", "major", "missing", "multiple", "numerical", "science", "stage", "ticket", "validate", "variable"], "potential_entities_queries_len": 13, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 218}
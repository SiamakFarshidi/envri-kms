{"name": "enhancing oct image resolution with srgan ", "full_name": " h2 Enhancing OCT image resolution with SRGANs h4 Keywords unsupervised super resolution SRGAN VGG19 h2 I Introduction h2 II Imports and globals h2 III Data h2 IV Utility functions h3 IV A Metrics h4 1 PSNR Peak Signal to Noise ratio h4 2 SSIM Structural Similarity Index h3 IV B Loss Functions h4 Plot loss function h3 IV C Sampling saving images h2 V SRGAN VGG19 h3 V 1 Generator h3 V 2 Discriminator h3 V 3 VGG19 Feature Extractor h2 VI Training h2 VII References and further reading ", "stargazers_count": 0, "forks_count": 0, "description": "MSE loss approaches give a high Peak Signal to Noise PSNR value but they also tend to produce overly smooth images with insufficient high frequency details. Generative Adversarial Networks GANs 1 are one of newer methods that have been applied to super resolution and in this notebook we use a Super Resolution GAN SRGAN 2 to enhance subsampled OCT scans. VGG loss is the euclidean distance between the feature maps of the generated SR image and the original HR image. The computational enhancement of image resolution is known as super resolution. Content Loss The SRGAN replaced the MSE loss with a VGG loss. A Deep Journey into Super resolution A Survey https arxiv. Code The code is based on the SRGAN paper 2 and Kailash Ahirwar s code 3. Sampling saving images V. The feature maps are the activation layers of the pre trained VGG 19 network. Perceptual Loss is a weighted sum of the content loss and adversarial loss. In this exercise we use an SRGAN design which is faithful to the original SRGAN 2. 04802 3 Kailash Ahirwar. pdf install an older version of tensorflow the implementation may not work with the most recent TensorFlow release data path batch size equals to 8 due to RAM limits define the shape of low resolution image LR define the shape of high resolution image HR optimizer for discriminator generator use seed for reproducible results get min max image sizes image_list is the list of all images ransom sample a batch of images change the size do a random horizontal flip convert lists into numpy ndarrays X 1 2 to scale back from 1 1 to 0 1 use 16 residual blocks in generator input LR dimension 4x downsample of HR input for the generator pre residual block conv layer before residual blocks add 16 residual blocks post residual block conv and batch norm layer after residual blocks take the sum of pre residual block gen1 and post residual block gen2 upsampling upsampling conv layer at the output model define hyperparameters the input is the HR shape input layer for discriminator 8 convolutional layers with batch normalization fully connected layer last fully connected layer for classification input layer for high resolution images input layer for low resolution images generate high resolution images from low resolution images extract feature maps from generated images make a discriminator non trainable discriminator will give us a probability estimation for the generated high resolution images create and compile initialize training loop normalize the images generate high resolution images from low resolution images generate a batch of true and fake labels calculate total loss of discriminator as average loss on true and fake labels sample a batch of images normalize the images extract feature maps for true high resolution images train the generator calculate the psnr calculate the ssim normalize the images comment this line to display all the images plots post training save model weights. SSIM x y 2 mu_x mu_y c_1 2 sigma_ xy c_2 over mu_x 2 mu_y 2 c_1 sigma_x 2 sigma_y 2 c_2 mu_x mu_y average value for image x y sigma_x sigma_y standard deviation for image x y sigma_ xy covariance of x and y c_1 c_2 coefficients IV B. Adversarial Loss This is calculated based on probabilities provided by Discriminator. GeneratorThere are 16 residual blocks and 2 upsampling blocks. ESRGAN Enhanced Super Resolution Generative Adversarial Networks https arxiv. Adversarial framework V 1. Both losses are defined below Pixel wise MSE loss is the mean squared error between each pixel in the original HR image and a the corresponding pixel in the generated SR image. OCT imaging is the now the standard of care in opthalmologyand there is interest in applying AI methods to enhance conventional OCT images from commercial systems. PSNR 10 log_ 10 left MAX_I 2 over MSE right MAX_I maximum possible power of a signal of image I MSE mean squared error pixel by pixel 2. Utility functionsQuantitative metrics for image quality Loss functions Plots Image processing sampling and saving images IV A. We downsample HR OCT images by 4x to synthetically create LR training data. pdf 5 Xintao Wang et al. This architecture used a pre trained VGG 19 feature extractor and gave photorealistic results on large 4x upsampled low resolution images. Discriminator V 3. The perceptual loss by contrast has a content loss component that computes pixel wise differences in feature space not pixel space and this results in an SR image that is closer to the subjective evaluation of human observers. Here the authors used a perceptual loss instead of a pixel wise Mean Squared Error MSE loss. The Generator upsamples LR images by 4x and will be trained to generate SR images. In addition standard quantitative metrics Peak Signal to Noise Ratio and Structural Similarity Index PSNR SSIM will be used to assess the results. DataLoad data process data EDA IV. PSNR Peak Signal to Noise ratioPSNR is the ratio between maximum possible power of signal and power of corrupting noise Wikipedia. org wiki Structural_similarity. The generator follows the architecture outlined in 2. References and further reading 1 Goodfellow et al. A VGG 19 network is used for feature extraction this allows us to compute the feature distance between the original and generated images sent through the feature extractor. Generative Adversarial Networks Projects https github. l_ VGG i j SR 1 over W_ i j H_ i j sum limits_ x 1 W_ i j sum limits_ y 1 H_ i j phi _ i j I HR _ x y phi _ i j G_ theta _G I LR _ x y 2 l_ VGG i j SR VGG loss phi _ i j the feature map obtained by the j th convolution after activation before the i th maxpooling layer within the VGG19 network 2. The discriminator will be trained to distinguish between HR SR images the GAN loss is backpropagated to the discriminator and the generator. The SRGAN model uses a deep neural network built with residual blocks and optimized using perceptual loss in a GAN framework. The SRGAN introduced in 2016 addressed the issue of reconstructing high resolution HR images from low resolution LR images such that fine texture detail in the reconstructed super resolution SR images was not lost. Evaluation The visual quality of generated images will be observed. It has been applied to the DIV2K CelebA and other natural image datasets and here we want to see how it performs on OCT data. Imports and globals III. SSIM Structural Similarity IndexSSIM measures the perceptual difference between two similar images see Wikipedia https en. Discriminator network 3. l SR l_X SR 10 3 l_ Gen SR l SR perceptual loss l_X SR content loss l_ Gen SR adversarial loss 1. The SRGAN is implemented as follows Training 1. This network will serve as a baseline for further experiments with upscaling choice of feature extractor etcetera. IntroductionOptical coherence tomography OCT scans of the retina are used to produce high resolution cross sectional images of the retina. VGG19 Feature Extractor VI. l_ Gen SR sum limits_ n 1 N log D_ theta _D G_ theta _G I LR l_ Gen SR generative loss D discriminator function D_ theta _D discriminator function parametrized with theta _D D_ theta _D G_ theta _G I LR probability that the reconstructed image G_ theta _G I LR is a natural HR image Plot loss function IV C. Feature extractor using the VGG19 network 4. Enhancing OCT image resolution with SRGANs Keywords unsupervised super resolution SRGAN VGG19 I. Loss FunctionsThe most important contribution of the SRGAN paper was the use of a perceptual loss function. SRGAN VGG19The SRGAN has the following code components 1. Photo Realistic Single Image Super Resolution Using a Generative Adversarial Network https arxiv. com PacktPublishing Generative Adversarial Networks Projects 4 Saeed Anwar et al. This gives us pairs of HR and LR images for the training data set. Generative Adversarial Nets https arxiv. ", "id": "shir0mani/enhancing-oct-image-resolution-with-srgan", "size": "7046", "language": "python", "html_url": "https://www.kaggle.com/code/shir0mani/enhancing-oct-image-resolution-with-srgan", "git_url": "https://www.kaggle.com/code/shir0mani/enhancing-oct-image-resolution-with-srgan", "script": "skimage.transform keras.layers keras.callbacks LeakyReLU imageio resize as imresize VGG19 build_adversarial_model Adam itertools plot_ssim imread plot_psnr Conv2D sample_images numpy compute_ssim repeat Input compute_psnr PIL build_generator residual_block asarray Image keras.applications matplotlib.pyplot Activation Dense tensorflow get_train_images pandas find_img_dims keras.optimizers resize save_images BatchNormalization UpSampling2D plot_loss Model TensorBoard Add keras keras.models build_VGG19 build_discriminator ", "entities": "(('VGG loss', 'SR generated image'), 'be') (('Enhancing', 'super resolution'), 'unsupervise') (('they', 'frequency insufficient high details'), 'give') (('issue', 'resolution SR reconstructed super images'), 'address') (('Wikipedia https', 'two similar images'), 'measure') (('SRGAN VGG19The SRGAN', 'code following components'), 'have') (('us', 'feature extractor'), 'use') (('PacktPublishing Generative Adversarial Networks', 'Saeed Anwar et 4 al'), 'com') (('how it', 'OCT data'), 'apply') (('reconstructed image', 'G _ _ I HR image Plot loss IV natural C.'), 'limit') (('coherence tomography OCT IntroductionOptical scans', 'retina'), 'use') (('that', 'human observers'), 'have') (('network', 'feature extractor etcetera'), 'serve') (('visual quality', 'generated images'), 'observe') (('Adversarial This', 'Discriminator'), 'Loss') (('j _ _ LR _ _ j SR VGG loss phi 2 i', 'VGG19 network'), 'VGG') (('Structural Similarity Index PSNR SSIM', 'results'), 'in') (('This', 'training data set'), 'give') (('Perceptual Loss', 'content weighted loss'), 'be') (('We', 'LR training synthetically data'), 'downsample') (('I MSE', 'pixel'), 'leave') (('architecture', 'resolution upsampled low images'), 'use') (('plots', 'training save model weights'), 'install') (('Here authors', 'perceptual loss'), 'use') (('which', 'original SRGAN'), 'use') (('upsamples LR images', 'SR images'), 'train') (('we', 'OCT 2 subsampled scans'), 'be') (('PSNR Peak Signal', 'noise Wikipedia'), 'be') (('OCT imaging', 'commercial systems'), 'be') (('code', 'SRGAN paper'), 'Code') (('GAN loss', 'discriminator'), 'train') (('Generative Adversarial Networks', 'https github'), 'Projects') (('Content SRGAN', 'VGG loss'), 'Loss') (('generator', '2'), 'follow') (('SRGAN model', 'GAN framework'), 'use') (('Loss most important contribution', 'loss perceptual function'), 'be') (('feature maps', 'activation trained VGG 19 network'), 'be') (('losses', 'SR corresponding generated image'), 'define') (('computational enhancement', 'super resolution'), 'know') ", "extra": "", "label": "No_extra_files", "potential_description_queries": ["architecture", "average", "baseline", "batch", "block", "calculate", "care", "choice", "classification", "code", "comment", "compile", "compute", "content", "contrast", "conv", "convert", "convolution", "convolutional", "covariance", "create", "data", "define", "detail", "difference", "dimension", "display", "distance", "downsample", "enhance", "error", "estimation", "evaluation", "exercise", "extract", "extraction", "feature", "flip", "following", "framework", "frequency", "function", "generate", "generated", "generator", "high", "human", "image", "implementation", "initialize", "input", "interest", "issue", "layer", "left", "line", "list", "log", "loop", "map", "max", "maximum", "mean", "min", "model", "most", "network", "neural", "noise", "non", "norm", "normalization", "normalize", "not", "notebook", "numpy", "optimizer", "output", "path", "pdf", "pixel", "post", "power", "pre", "probability", "processing", "psnr", "random", "ratio", "reading", "residual", "resolution", "retina", "right", "sample", "sampling", "save", "saving", "scale", "sent", "shape", "signal", "similar", "size", "smooth", "space", "squared", "ssim", "standard", "sum", "tensorflow", "through", "total", "train", "training", "upsampling", "value", "version", "wise", "work", "xy"], "potential_description_queries_len": 121, "potential_script_queries": ["asarray", "imageio", "imread", "imresize", "resize", "skimage"], "potential_script_queries_len": 6, "potential_entities_queries": ["following", "high", "model", "save", "training"], "potential_entities_queries_len": 5, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 126}
{"name": "build your first ann using keras on bank customer ", "full_name": " h2 Sampling SubSampling h3 Categorical Encoding h2 Modelling ", "stargazers_count": 0, "forks_count": 0, "description": "com kaggle docker python For example here s several helpful packages to load linear algebra data processing CSV file I O e. input directory For example running this by clicking run or pressing Shift Enter will list all files under the input directory You can write up to 20GB to the current directory kaggle working that gets preserved as output when you create a version using Save Run All You can also write temporary files to kaggle temp but they won t be saved outside of the current session take sample of df0 as per 1 Encoding month with month numbers Encode education Encode P_outcome onhot all remaining columns look at data train test split num of input features Define Model compile model evaluate the model. Sampling SubSampling we have to balance the dataset according to output classes Categorical Encoding Label Encoding One Hot Encoding Modelling Thank you. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python Docker image https github. If you like my Notebook Please Upvote it It gives immense motivation to move forward with Data Science Journey. read_csv Input data files are available in the read only. ", "id": "rxsraghavagrawal/build-your-first-ann-using-keras-on-bank-customer", "size": "286", "language": "python", "html_url": "https://www.kaggle.com/code/rxsraghavagrawal/build-your-first-ann-using-keras-on-bank-customer", "git_url": "https://www.kaggle.com/code/rxsraghavagrawal/build-your-first-ann-using-keras-on-bank-customer", "script": "sklearn.model_selection numpy matplotlib.pyplot tensorflow.keras.layers Dense pandas train_test_split tensorflow.keras Sequential ", "entities": "(('It', 'kaggle python Docker image https github'), 'come') (('It', 'Data Science forward Journey'), 'like') (('Categorical Encoding Label Hot Encoding One Modelling', 'you'), 'SubSampling') (('read_csv Input data files', 'read'), 'be') (('Encode P_outcome remaining columns', 'model'), 'list') ", "extra": "['outcome', 'test']", "label": "Perfect_files", "potential_description_queries": ["balance", "compile", "create", "current", "data", "dataset", "directory", "education", "environment", "evaluate", "file", "forward", "image", "input", "kaggle", "linear", "list", "load", "look", "model", "month", "motivation", "move", "my", "num", "output", "per", "processing", "python", "read", "run", "running", "sample", "session", "several", "split", "test", "train", "under", "up", "version", "write"], "potential_description_queries_len": 42, "potential_script_queries": ["numpy", "sklearn"], "potential_script_queries_len": 2, "potential_entities_queries": ["forward", "python"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 44}
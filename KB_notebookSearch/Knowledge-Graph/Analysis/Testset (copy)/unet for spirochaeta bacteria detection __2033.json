{"name": "unet for spirochaeta bacteria detection ", "full_name": " h1 About h3 About the model s performance h1 Snippets to read and slice images into batches of 256x256x3 RGB images h1 Define loss functions h1 Define Unet Model h1 Calculate classes percentage for balancing h1 Split into training and testing set h1 One hot encoding the labels h1 Start training the model h1 Conclusion h2 Optimization options ", "stargazers_count": 0, "forks_count": 0, "description": "We also use only 2000 samples. One hot encoding the labelsFor training Start training the modelSince the instance only has 13GB I will not apply any augmentation and train the model only on 300 data points at once ConclusionThe model learns. com longmakesstuff UnetPlusPlus Calculate classes percentage for balancingSince background s absolute frequency is very dominant. The data was collected processed and annotated by myself with help of my Professor Dr. Use the whole dataset Require a computer with about 64GB RAM or an implementation with Python generator Image too small Width small Height small Reading raw images Sanity check Slicing images into 256 x 256 Check output Some hyper parameters I have to use only 2000 images because the kaggle s cloud instance does not have enough RAM. nguyen2306 at protonmail. Optimization options Augmentation that a lots. With a proper computer and much optimization the final model can be used to analyze live video of bacteria. Define loss functionsWe make use of sum of three major loss functions for segmentation crossentropy intersection over union and F1. com longmakesstuff UnetPlusPlus About the model s performanceTraining on kaggle is quite constrainted since I only have about 16GB RAM so this script only demonstrates a prototype of what UNet and UNetPlusPlus can be used for. Snippets to read and slice images into batches of 256x256x3 RGB imagesYou can use following cell if you want to obtain the data in optimal form. Define Unet ModelThe implementation can also be found at https github. We need some balancing for the model to learn properly. If you have any question don t hesitate to contact me at long. com watch v 9 J3L1Fvv60Also we do not do any further statistical analysis of model s performance in this notebook. The output are the two variables images and masks. The video can be found at the following link https www. Images are normalized into interval 0. The implementation can also be found at https github. Split into training and testing setNo validation set for this setting. AboutThis is a code demonstration for reproducibility purpose of my Bachelor thesis. ", "id": "longnguyen2306/unet-for-spirochaeta-bacteria-detection", "size": "2033", "language": "python", "html_url": "https://www.kaggle.com/code/longnguyen2306/unet-for-spirochaeta-bacteria-detection", "git_url": "https://www.kaggle.com/code/longnguyen2306/unet-for-spirochaeta-bacteria-detection", "script": "__init__ weighted_loss log_iou tensorflow.keras.optimizers LeakyReLU tensorflow.keras.layers Dropout Adam Conv2D log_dice numpy Input Conv2DTranspose loss iou compile conv2d loss_function tensorflow tensorflow.keras.backend conv2dtranspose do fit tqdm BatchNormalization dice concatenate MaxPooling2D UNetPP SlidingWindow ", "entities": "(('com UnetPlusPlus Calculate classes percentage', 'balancingSince absolute frequency'), 'longmakesstuff') (('implementation', 'https also github'), 'find') (('data', 'Professor'), 'collect') (('much final model', 'bacteria'), 'use') (('ConclusionThe once model', 'learns'), 'encode') (('cloud instance', 'enough RAM'), 'use') (('video', 'link https following www'), 'find') (('UNet', 'what'), 'longmakesstuff') (('some', 'model'), 'need') (('Define Unet ModelThe implementation', 'https also github'), 'find') (('don t', 'me'), 'have') (('we', 'notebook'), 'do') (('AboutThis', 'Bachelor thesis'), 'be') (('you', 'optimal form'), 'use') ", "extra": "['test']", "label": "Perfect_files", "potential_description_queries": ["absolute", "analyze", "apply", "augmentation", "background", "cell", "check", "cloud", "code", "computer", "contact", "crossentropy", "data", "dataset", "demonstration", "encoding", "final", "following", "found", "frequency", "generator", "help", "hot", "implementation", "instance", "intersection", "interval", "kaggle", "learn", "link", "major", "model", "my", "need", "normalized", "not", "optimization", "output", "percentage", "performance", "prototype", "purpose", "question", "raw", "read", "reproducibility", "script", "segmentation", "set", "slice", "sum", "testing", "train", "training", "validation", "video"], "potential_description_queries_len": 56, "potential_script_queries": ["compile", "concatenate", "dice", "fit", "iou", "numpy", "tensorflow", "tqdm"], "potential_script_queries_len": 8, "potential_entities_queries": ["final"], "potential_entities_queries_len": 1, "potential_extra_queries": ["test"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 65}
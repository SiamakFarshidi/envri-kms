{"name": "very contradictory eda ", "full_name": " h2 con tra dic tion \u02cck\u0252ntr\u0259\u02c8d\u026ak\u0283\u0259n h1 Welcome h1 Random exploration h1 Annotation Artifacts Yes sir h1 The defeat of Napoleon h1 About the author h1 Resources ", "stargazers_count": 0, "forks_count": 0, "description": "Let s go Random explorationLet s start by looking at the raw data. The battle of Waterloo It depends on our personal judgement on some historic event. The great example of this paradox is The Battle of Borodino which has very diverse set of opinions expressed by different historians Some claim it is a victory for the French Others say it is a victory for the Russians The third group exists saying it was a Pyrrhic victory as it ultimately cost Napoleon his armySo the other important question arises How could one define the crossing line between natual language understanding and having a certain probably biased opinion on some facts One would also note the sentences in these strange samples are of a very different length. Sentences of the different length are more likely to either contradict or entail3. Would The defeat of Napoleon be an entailement if the premise would explicitly say about Waterloo being referred as a battle e. How people reproached me for it And yet could you stuff my pipe No it s just a representation is it not So if I had written on my picture This is a pipe I d have been lying Ren\u00e9 Magritte WelcomeWelcome to a Very Contradictory EDA This notebook is inspired by a quote by Kaggle Grandmaster Agnis Liukis https www. This leads to a conclusion that humans judge on the meaning of the sentence pairs given prior knowledge and context. com alijs1 To stand out and get some real advantage it is necessary to do something different find something that others didn t notice. Bauerstein and give a positive answer. In this case those are just random surnames which are different and are thus contradictionary. D Day is the name of the Normandy landings operation during World War II on June 6 1944. Given this sentence pair without prior knowledge which is a premise and hypothesis Would you choose premise and hypothesis the same way as in the dataset Would you label these pairs differently depending on that assignment Case 1 neutral Premise Yes sir. We should account for no prior knowledge of Agatha Cristie and in this case Bauersten is just a random surname so the pair is neutral. png con tra dic tion \u02cck\u0252ntr\u0259\u02c8d\u026ak\u0283\u0259n the fact of something being the complete opposite of something else or very different from something else so that one of them must be wrong Cambrigde dictionary a difference between two statements beliefs or ideas about something that means they cannot both be true Longman dictionary The famous pipe. Given the knowledge that Mary Westmacott is Agatha Cristie s pseudonym we should say it is an entailement. One might argue the last statement as sometimes a person has two names. Melatonin is a hormone made by the pineal gland. Is Bauerstein a doctor Given you have just read Agatha Cristie s novel The Mysterious Affair at Styles you may recall Dr. Let s check this idea by introducing additional feature word count ratio Now let s check the samples with hypothesis being at least twice as long as the premise https storage. In case longer sentence is a premise as in Case 2 the pair is more likely to be entailed just because shorter hypothesis has fewer chances to be contradictory. 02324 Draw the density plot Plot formatting. lv kaggle napoleon_vs_agatha_cristie. So the purpose of this EDA is to find something interesting and not so straightforward about this dataset. On the other hand the pair is not Agatha Cristie s Bauerstein vs Agatha Cristie s Alfred Inglethorp so we should treat those names without any connection to the original novel. Annotation Artifacts Yes sir Despite having very similar meaning the resulting label is different depending on sentence order Why is this happening Word count. I spend a few hours every day to write a single post about a single concept. Thank you Resources1. In certain cases one could interprete the very same pairs of sentences differently given different knowledge and context. Sentences of the same length are more likely to be neutral2. The defeat of NapoleonLet s continue by filtering out samples with premises consisting of just one word The following pairs are great examples of what could go wrong with the model training for Natural Language Inference some of these sentences require very specific domain knowledge Dr Bauerstein and Alfred Inglethorp are fictional characters in Agatha Christie s detective novel The Mysterious Affair at Styles. png Let s recall the sample about Waterloo again. In case hypothesis is longer than a premise it has higher entropy containing more information which in turns increases chances of a contradiction4. Given the knowledge that there are thousands of people with the very same name Agatha Christie the pair might be neutral. Hypothesis I will take care of that right away Sir. Thus Waterloo might be a battle but primarily it is a geographic name thus the pair is neutral. Should our model be aware of the Agatha Cristie and Napoleon https storage. png The one about proximity to Jerusalem is of particular interest Let s check out all the samples with the same premise Recalling the labels 0 entailment 1 neutral 2 contradictionIsn t three miles away from Jerusalem still being close to it I would rather label this pair as entailement however training set says it is neutral. lv kaggle Regiment Charles Ewart. In case longer sentence is a hypothesis as in Case 1 we could assume the pair is more likely to be contradictory or at least neutral because longer sentence have more chances to contain information that contradicts a premise. com feed hashtag keywords datasciencedj If this work gives you joy or maybe even inspiration please consider contributing to my Patreon account https www. We will check that assumption on a training set by introducing anothe feature word count ratio Let s check what part of a training has hypotheses longer than premises Now let s check how this correlates to the label our assumption is that contradiction will prevail About the authorThis notebook is published under the Data Science DJ initiative with the goal of giving you distilled pieces of valuable information short and concise easy to comprehend. It helps your body know when it s time to sleep and wake up. With that we will formulate our own set of hypotheseses based on word count in respective sentences 1. Despite being commonly referred as Waterloo battle direct meaning of this word is the municipality not the famous Napoleon s combat. Clearly we have found some pattern samples with short premises are most contradictory to look at. Instead of the common approach taking head of the dataset we will take random samples This gives us a chance to find some non topmost samples in training and test set that might be interesting to investigate deeper Let s inspect one of the sentence pairs consisting of Yes sir and I will take care of that right away Sir. Longer sentence naturally conveys more information than a shorter one 1. Saint Paul de Vence is a commune in the Alpes Maritimes department in the Provence Alpes C\u00f4te d Azur region of Southeastern France. For example how would you label the pair Agatha Cristie and Mary Westmacott the latter is one of her pseudonyms Following the logic of Alfred Inglethorp vs Bauerstein as the names are different we should say it is contradictionary. Waterloo is a municipality in Belgium from which the famous Waterloo battle took its name. Hypothesis Yes sir. Are Alfred Inglethorp and Bauerstein the same person Obviously they are not given you are familiar with Agatha Cristie s The Mysterious Affair at Styles. In case hypothesis is shorter than a premise it has lower entropy and have more chances to be a summary either neutral or entailement word overlap is measured by the percentage of tokens from the question that appear in the evidence. You can find them by Joining my Telegram channel https t. Is Waterloo is the defeat of Napoleon It depends on how one understands the word Waterloo. me datasciencedj Following my LinkedIn tag https www. Case 2 entailed Premise I will take care of that right away Sir. ", "id": "dmitryyemelyanov/very-contradictory-eda", "size": "8688", "language": "python", "html_url": "https://www.kaggle.com/code/dmitryyemelyanov/very-contradictory-eda", "git_url": "https://www.kaggle.com/code/dmitryyemelyanov/very-contradictory-eda", "script": "scipy dist_plot seaborn numpy matplotlib.pyplot stats get_word_count_ratio pandas get_word_count ", "entities": "(('just random which', 'case'), 'be') (('just random pair', 'case'), 'account') (('It', 'historic event'), 'battle') (('which', 'contradiction4'), 'be') (('you', 'Styles'), 'be') (('we', 'respective sentences'), 'formulate') (('others', 'that'), 'com') (('Dr Bauerstein', 'Mysterious Styles'), 'continue') (('Why this', 'Word count'), 'Artifacts') (('s', 'Waterloo'), 'let') (('Agatha pair', 'very same name'), 'be') (('Waterloo famous battle', 'name'), 'be') (('So purpose', 'interesting so dataset'), 'be') (('I', 'right away Sir'), 'take') (('One', 'very different length'), 'be') (('D Day', 'June'), 'be') (('it', 'knowledge'), 'say') (('Alfred so we', 'original novel'), 'be') (('explicitly Waterloo', 'battle e.'), 'be') (('contradiction', 'valuable information'), 'check') (('that', 'evidence'), 'be') (('Hypothesis I', 'right away Sir'), 'take') (('Melatonin', 'pineal gland'), 'be') (('Plot', 'density plot'), 'draw') (('municipality', 'word'), 'be') (('notebook', 'Kaggle Grandmaster Agnis Liukis https www'), 'reproach') (('s', 'raw data'), 'let') (('Obviously they', 'Styles'), 'be') (('that', 'premise'), 'assume') (('more just shorter hypothesis', 'fewer chances'), 'be') (('Saint Paul de Vence', 'Southeastern France'), 'be') (('hypothesis', 'premise https at least twice as long storage'), 'let') (('maybe even inspiration', 'Patreon account https www'), 'datasciencedj') (('it', 'rather pair'), 'png') (('it', 'Bauerstein'), 'label') (('Longer sentence', 'shorter one 1'), 'convey') (('you', 'assignment differently Case'), 'choose') (('I', 'right away Sir'), 'entail') (('sometimes person', 'two names'), 'argue') (('pattern samples', 'short premises'), 'find') (('Sentences', 'more contradict'), 'be') (('model', 'Napoleon https Agatha Cristie storage'), 'be') (('they', 'something'), '\u02cck\u0252ntr\u0259\u02c8d\u026ak\u0283\u0259n') (('Sentences', 'same length'), 'be') (('You', 'Telegram channel https t.'), 'find') (('one', 'differently different knowledge'), 'interprete') (('I', 'single concept'), 'spend') (('humans', 'prior knowledge'), 'lead') (('how one', 'word'), 'be') ", "extra": "['annotation', 'test']", "label": "Perfect_files", "potential_description_queries": ["account", "advantage", "appear", "approach", "assignment", "body", "care", "case", "channel", "check", "choose", "close", "conclusion", "connection", "consider", "contain", "cost", "could", "count", "dataset", "day", "define", "dictionary", "difference", "doctor", "domain", "entropy", "even", "every", "fact", "feature", "feed", "find", "following", "found", "group", "hand", "head", "idea", "interest", "kaggle", "knowledge", "label", "language", "latter", "least", "length", "let", "line", "look", "looking", "lower", "meaning", "might", "model", "most", "my", "name", "no", "non", "not", "notebook", "operation", "opinion", "order", "out", "overlap", "pair", "part", "pattern", "people", "percentage", "person", "picture", "plot", "png", "positive", "post", "purpose", "question", "quote", "random", "ratio", "raw", "read", "recall", "region", "representation", "right", "sample", "sentence", "set", "short", "similar", "single", "something", "start", "stuff", "summary", "tag", "test", "those", "time", "training", "under", "understanding", "word", "work", "write"], "potential_description_queries_len": 109, "potential_script_queries": ["numpy", "scipy", "seaborn"], "potential_script_queries_len": 3, "potential_entities_queries": ["channel", "least"], "potential_entities_queries_len": 2, "potential_extra_queries": [], "potential_extra_queries_len": 0, "all_components_potential_queries_len": 112}
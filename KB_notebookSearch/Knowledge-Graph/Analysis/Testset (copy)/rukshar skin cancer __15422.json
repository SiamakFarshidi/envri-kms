{"name": "rukshar skin cancer ", "full_name": " h1 Automated Classification of Skin Lesions h1 Making Dictionary of images and labels h1 Data Processing h1 Data Imputation h1 Data Visualization h1 Image Data Preparation for Training h1 Train Test Split h1 Normalization h1 Label Encoding h1 Creating a Validation Dataset h2 Data Augmentation h1 Model Building h2 CNN h2 Setting Optimizer and Annealer h2 Metrics of Performance h2 Callbacks Learning Rate Adapter Early Stopping Checkpointing h1 Model Training and Evaluation h3 Loading a Saved Model if any h3 Training from Scratch h2 Filter Visualization h2 Feature Map Visualization h1 Conclusion h2 Statement of Purpose h3 Acknowledgements ", "stargazers_count": 0, "forks_count": 0, "description": "Basal cell carcinoma 5. Dermatofibroma We detect 7 different classes of skin cancer using NN and analyse the result to see how the model can be useful in practical scenario. Now lets check the presence of null values againOur data imputation step is complete. Statement of Purpose The purpose of this notebook is to experiment with image datasets classification task visualizations and DNNs from existing literature and to showcase what I ve learned from other resources regarding the mentioned topics Acknowledgements https www. e the area size pooled each time more the pooling dimension is high more the downsampling is important. The optimizer iteratively improves parameters filters kernel values weights and bias of neurons to reduce loss. Root Mean Square Propagation RMSProp that also maintains per parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight e. Using this intuition we can see that the filters detect gradients from light to dark. We have to choose the pooling size i. Model Building Before writing down the code for the class of neural network let s describe the features of our NN. Checkpointing is used alongside early stopping to save the best model weights for later use. However high LR causes oscillations in loss reductions and the optimizer can fall into a local minima. Confocal Reflectance confocal microscopy is an in vivo imaging technique with a resolution at near cellular level and some facial benign with a grey world assumption of all training set images in Lab color space beforeand after manual histogram changes. That would be a better representation of data. Dropout is a regularization method where a proportion of nodes in the layer are randomly ignored thus forcing the network to learn features in a distributed way. We plot 16 2 dimensional feature map images in a 4x4 setting. We group the age values according to the skin disease type determine the median of each group and fill the null values with the median value corresponding to that data points skin disease type. The idea of visualizing a feature map for a specific input image would be to understand what features of the input are detected or preserved in the feature maps. 3 meaning most samples are examined by dermatologists. The higher the LR the bigger are the steps and the quicker is the convergence. The LR is the step by which the optimizer walks through the loss landscape. We create additional columns for later reference path to image file cell_type which contains the short name of lesion type categorical column cell_type_idx the lesion type is categorized from 0 to 6 Data ImputationIn this step we check for Missing values and impute the missing dataThere are some age data missing. So the age column has 57 null values. Choose colormap of your taste Add title and labels with custom font sizes Checking the image size distribution Perform one hot encoding on the labels Reshape image in 3 dimensions height 75px width 100px canal 3 With data augmentation to prevent overfitting set input mean to 0 over the dataset set each sample mean to 0 divide inputs by std of the dataset divide each input by its std apply ZCA whitening randomly rotate images in the range degrees 0 to 180 Randomly zoom image randomly shift images horizontally fraction of total width randomly shift images vertically fraction of total height randomly flip images randomly flip images explanation of some of the class arguments conv_layer_no how many conv. com multi class metrics made simple part i precision and recall 9250280bddc2 Callbacks Learning Rate Adapter Early Stopping Checkpointingfor faster optimizer convergence and reaching global minimum of the loss function an annealing method of the learning rate LR is used. Follow up If nevi monitored by digital dermatoscopy did not show any changes during 3 follow up visits or 1. Data AugmentationIn order to avoid overfitting problem we artificially expand our HAM 10000 dataset by introducing transformations to produce the variations in the dataApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. zip and HAM10000_images_part2. Metrics of PerformanceIn order to measure how our model performs we use the following metrics Accuracy Validation Loss Precission Recall F1 ScoreTo learn more about multi class precision recall and f1 score the following article is a good read https towardsdatascience. input skin cancer mnist ham10000 Merging images from both folders HAM10000_images_part1. com sid321axn step wise approach cnn model 77 0344 accuracy used for converting labels to one hot encoding convert to one hot encoding. filter info in a dictionary format it also prints some info about the model layer name layer number used later for feature maps and filter shapes of the format kernel size channel filter no. Histopathology Histo Histopathologic diagnoses of excised lesions have beenperformed by specialized dermatopathologists. natural language and computer vision problems. Let s see how many rows don t have age data. The next largest category is follow up 37 meaning Melanocytic Nevi being further checked upon to ensure its benignity. CNNKeras Sequential API is used where we add one layer at a time starting from the input. So let s check out the median value of age per skin disease typeDifferent median ages for different skin diseases. Consensus For typical benign cases without histopathology or followup biologists provide an expert consensus rating of authors PT and HK. Label EncodingFor multiclass classification the labels of 7 different classes of skin cancer types ranging from 0 to 6 need to be converted to one hot vectors. Now lets visualize agewise distribution of skin cancer typesIt seems that skin cancer types 0 1 3 and 5 which are Melanocytic nevi dermatofibroma Basal cell carcinoma and Vascular lesions are not much prevalant below the age of 20 years Image Data Preparation for TrainingIn this step images will be loaded into the column named image using the image path and the image folder. By applying just a couple of these transformations we can create a very robust model. Each filter transforms a part of the image defined by the kernel size using the kernel filter. These are used to reduce computational cost and to some extent also reduce overfitting. Here 75x100 is the image dimension and 1 is batch size. For multiclass classifications 2 classes this model uses categorical_crossentropy loss func. The expectation would be that the feature maps close to the input detect small or fine grained detail whereas feature maps close to the output of the model capture more general features. The rectifier activation function is used to add non linearity to the network. The Flatten layer is use to convert the final feature maps into a one single 1D vector. Chosen methods of data augmentation Randomly rotate some training images by 10 degrees Randomly Zoom by 10 some training images Randomly shift images horizontally by 10 of the width Randomly shift images vertically by 10 of the height Once our model is ready we fit the augmented training dataset. So decreasing learning rate can help training to reach the global minimum of the loss function. Data VisualizationIn this we will explore different features of the dataset through visualizationsPlot to see distribution of 7 different classes of cell typeIts seems from the above plot that in this dataset more than 50 percent cells are of type Melanecytic nevi. To keep the advantage of the fast computation time with a high LR LR is dynamically reduced every X steps epochs if validation accuracy doesn t improve. Some popular augmentations are grayscales horizontal flips vertical flips random crops color jitters translations rotations and much more. epoch plots confusion matrix and other metric scoresNot only training stabilizes to a plateau after training for at least 80 epochs but also the oscillations of curves become less due to our adaptive learning rate mechanism that reduces LR after some epochs Filter VisualizationBefore visualizing the filters let s create a method to load and save filter names shapes filter dataRunning the example creates a figure with six rows of three images or 18 images one row for each filter and one column for each channelThe dark squares indicate small or inhibitory weights and the light squares represent large or excitatory weights. Additionally we perform EDA visualize model metrics loss accuracy recall precision f1 score filters and feature maps for an input image. of filters and dropout rate dense_layer_no how many dense layers you want dense_layer_desc description of each dense layer namely no. layer visualize some feature maps. They applied the consensus label only if both authors independently gave the same unequivocal benign diagnosis. Model Training and Evaluation Loading a Saved Model if any Training from ScratchNow that our model class has been defined we can feed our data into the model for training and observe the performance through loss accuracy vs. Adaptive Gradient Algorithm AdaGrad maintains a per parameter learning rate that improves performance on problems with sparse gradients e. Plotting the distribution of localization field The most compromised regions of skin cancer are back 22 lower extremity 21 trunk 14 However no one part of the body dominates the chart. ConclusionIn this notebook we process skin disease dataset and feed it into a customizable neural network CNN with early stopping and checkpointing mechanism. relu is the rectifier activation function max 0 x. Benign keratosis like lesions 4. Feature Map VisualizationThe activation maps called feature maps capture the result of applying the filters to input such as the input image or another feature map. To get the feature maps we input a processed image taken from x_train x_valid x_test in the newly defined sub model and the result will be a feature map with dimensions 1 75 100 no. The CNN can isolate features that are useful everywhere from these transformed images feature maps. layer the img parameter representing input image must be of a preprocessed form with dimensions 75 100 3 the input shape to the original model specify subplot and turn of axis plot filter channel in grayscale show the figure this method traverses each conv. This means it s better to fill the missing age values using median belonging to that datapoint s median value. This technique also improves generalization and reduces the overfitting. Now check the distribution of AgeFrom the given data people in below 30 are at lower risk of getting skin diseases as compared with people whose age is above 35. We can see that the result of applying the filters in a convolutional layer is a lot of versions of the an image with different features highlighted. layer of a model and create feature map images for an input image layer number for conv. Since there are above 10k images it ll take some time to process all of them into the dataframeWe can see image column has been added in its color format codeLet s check out a sample of 5 images from each cancer typeLet s separate the features from the target variable Train Test SplitThe data is into training and testing with a 80 20 ratio NormalizationThe x_train x_test data are normalized by substracting mean values and then dividing by standard deviations. The next 2 largest numbers of cell types are Melanoma and Benign keratosis like lesions Plotting of Technical Validation field ground truth which is dx_type to see the distribution of its 4 categories which are listed below 1. Loss function is the error rate between the oberved labels and the predicted ones and measures how poorly a model performs on data with known labels. layers for each conv. With the ReduceLROnPlateau function from Keras. Combining convolutional and pooling layers CNN are able to combine local features and learn more global features of the image. In the last layer Dense 10 activation softmax the net outputs distribution of probability of each class. plot first few filters layer name you can find layer names model_filters model_filters dictionary containing filter weights x number of filters to plot y number of channels for each filter to plot layer output parameter output layer is the layer chosen for output method to visualize feature map from a particular conv. The first is the convolutional Conv2D layer a set of learnable filters. It looks at the 2 neighboring pixels and picks the maximal value. This kernel includes Data imputation Exploratory Data Analysis Data Processing for training splitting data into training testing and validation sets normalization and augmentation Model building Model training and evaluation Visualization of filters Making Dictionary of images and labelsIn this step I have made the image path dictionary by joining the folder path from base directory base_skin_dir and merge the images in jpg format from both the folders HAM10000_images_part1. of filters of that conv. how quickly it is changing. zip Data ProcessingIn this step we have read the csv by joining the path of image folder which is the base folder where all the images are placed named base_skin_dir. This layer simply acts as a downsampling filter. Melanocytic nevi 2. At first we define a method to create a model from the previously trained model where the output is the layer output feature maps we wish to visualize. Automated Classification of Skin Lesions Automated classification of skin lesions using images is a challenging task owing to the fine grained variability in the appearance of skin lesions. layers save layer number for conv. Creating a Validation DatasetDuring training we want to observe how the model performs on unseen data. People in their 40s seem to be at the greatest risk. The second important layer in CNN is the pooling MaxPool2D layer. Normalizing the data generally speeds up learning and leads to faster convergence. Lets see the distribution of males and femalesBoth men and women seem to get affected by skin diseases nearly equally with men being infected somewhat more. zip into one dictionary This dictionary is useful for displaying more human friendly labels later on Creating New Columns for better readability Now lets see the sample of tile_df to look on newly made columns it MUST be integer Good old loop. Only nevi but no other benign diagnoses were labeled with this type of ground truth because dermatologists usually do not monitor dermatofibromas seborrheic keratoses or vascular lesions. The original dimension of the images are 450 x 600 x3 which TensorFlow can t handle and so the images are resized to 100 x 75. Majority of technical validation is of the type Histopathology 53. Filters can be seen as a transformation of the image. As we go deeper into the network we get to explore more general features of image data. Setting Optimizer and AnnealerAfter adding layers to the model we need a score function a loss function and an optimisation algorithm. of neurons and dropout rate patience how many epochs should the model run if there is no improvement in the metrics example of format for conv_layer_desc and dense_layer_desc are given in the default initialization below how many epochs to run the model before stopping due to accuracy not improving define architecture of the model CNN architechture is In Conv2D relu 2 MaxPool2D Dropout 2 Flatten Dense Dropout Out first layer Define the optimizer Compile the model Set a learning rate annealer simple early stopping create the callback list for Keras model Fit the model summarize history for accuracy summarize history for loss Function to plot confusion matrix Predict the values from the validation dataset Convert predictions classes to one hot vectors Convert validation observations to one hot vectors compute the confusion matrix plot the confusion matrix i uploaded the pretrained model here loading the saved model the output is a dictionary whose format layer_name filter_shape filter_data adding this to conv. layers you want conv_layer_desc descriptoion of each conv. So we create another dataset from the training data called validation data. Vascular lesions 7. Additionally early stopping mechanism will allow the model to stop training if there s no improvement after certain number of epochs to save time and prevent overfitting. It s suffice to say the skin diseases are spread throughout the body. 5 years biologists accepted this as evidence of biologic benignity. callbacks the LR is halved if accuracy fails to improve after 3 epochs. The kernel filter matrix is applied on the whole image. Classification of skin diseases here involves utilizing the HAM10000 Human Against Machine with 10000 training images dataset. Actinic keratoses 6. This means the algorithm does well on online and non stationary problems e. Adam optimizer a popular optimizer achieving satisfactory results fast combines advantages of 2 other extensions of stochastic gradient descent. because this is needed when visualizing feature maps for an input image filter shape 3 3 channel filter_number 3x3 filter size normalize filter values to 0 1 so we can visualize them this method plots x number of filters with y number of channels in each row get the filter plot each channel separately specify subplot and turn of axis plot filter channel in grayscale show the figure shows layer info name filter shape of all layers of input model save conv. For example some highlight lines other focus on the background or the foreground. It combines all the found local features of the previous convolutional layers. It consists of 10015 dermatoscopic images which are released as a training set for academic machine learning purposes It has 7 different classes of skin cancer which are listed below 1. Lesions with this type of groundtruth were usually photographed for educational reasons and did not needfurther follow up or biopsy for confirmation. This flattening step is needed so that you can make use of fully connected layers after some convolutional maxpool layers. For this purpose the training set is divided in two parts a small fraction 10 became the validation set on which the model is evaluated and the rest 90 is used to train the model. ", "id": "mdruksharalam/rukshar-skin-cancer", "size": "15422", "language": "python", "html_url": "https://www.kaggle.com/code/mdruksharalam/rukshar-skin-cancer", "git_url": "https://www.kaggle.com/code/mdruksharalam/rukshar-skin-cancer", "script": "Flatten sklearn.metrics keras.preprocessing.image glob __init__ tensorflow.keras.metrics visualize_all_conv_feature_maps keras.layers keras.callbacks label_binarize train_test_split build_model EarlyStopping Dropout Sequential MaxPool2D to_categorical # convert to one-hot-encoding Adam show_all_layer_info keras.utils.np_utils Conv2D fit_model seaborn numpy plot_confusion_matrix create_model ReduceLROnPlateau PIL plot_confusion_matrix_util plot_model_history to_categorical # used for converting labels to one-hot-encoding ModelCheckpoint confusion_matrix ImageDataGenerator sklearn.model_selection plot_filter_w_channel Image matplotlib.pyplot Dense pandas classification_report keras.optimizers evaluate_model load_filters BatchNormalization visualize_feature_map Model missingno Custom_NN sklearn.preprocessing backend backend as K keras keras.models load_saved_model keras.layers.normalization ", "entities": "(('dermatologists', 'dermatofibromas seborrheic usually keratoses'), 'label') (('you', 'maxpool convolutional layers'), 'need') (('model', 'categorical_crossentropy loss func'), 'use') (('percent more than 50 cells', 'type Melanecytic nevi'), 'VisualizationIn') (('vertically fraction', 'how many conv'), 'colormap') (('Checkpointing', 'later use'), 'use') (('most samples', 'dermatologists'), 'mean') (('Filters', 'image'), 'see') (('features', 'feature maps'), 'be') (('base where images', 'image folder'), 'ProcessingIn') (('layer output feature we', 'previously trained model'), 'define') (('back 22 lower extremity 21 trunk However one part', 'chart'), 'plot') (('feature maps', 'model capture'), 'be') (('I', 'topics Acknowledgements https mentioned www'), 'Statement') (('X steps validation accuracy dynamically doesn', 'LR high LR'), 'reduce') (('Melanocytic 37 Nevi', 'further benignity'), 'follow') (('NormalizationThe x_test data', 'then standard deviations'), 'be') (('model', 'overfitting'), 'allow') (('horizontal vertical flips', 'crops color jitters translations rotations'), 'be') (('training 10000 images', 'Machine'), 'involve') (('It', 'previous convolutional layers'), 'combine') (('optimizer', 'gradient stochastic descent'), 'combine') (('technique', 'overfitting'), 'improve') (('nevi', 'visits'), 'follow') (('annealing method', 'learning rate LR'), 'make') (('which', '1'), 'consist') (('regularization where proportion', 'distributed way'), 'be') (('We', '4x4 setting'), 'plot') (('how model', 'unseen data'), 'create') (('notebook we', 'mechanism'), 'conclusionin') (('how model', 'practical scenario'), 'detect') (('activation rectifier function', 'network'), 'use') (('filters', 'dark'), 'see') (('we', 'image data'), 'get') (('you', 'conv'), 'layer') (('age', '35'), 'be') (('Consensus', 'authors'), 'provide') (('dropout how many dense you', 'dense layer'), 'dense_layer_no') (('that', 'data augmentation techniques'), 'order') (('predicted how poorly model', 'known labels'), 'be') (('method', 'conv'), 'be') (('layer names model_filters model_filters', 'particular conv'), 'plot') (('That', 'better data'), 'be') (('classification', 'skin lesions'), 'be') (('Combining', 'image'), 'be') (('first', 'Conv2D convolutional learnable filters'), 'be') (('layer', 'downsampling simply filter'), 'act') (('optimizer', 'loss landscape'), 'be') (('figure', 'input model save conv'), 'need') (('Majority', 'type'), 'be') (('Lesions', 'needfurther confirmation'), 'photograph') (('that', 'images feature everywhere transformed maps'), 'isolate') (('s', 'NN'), 'Building') (('confocal microscopy', 'histogram manual changes'), 'be') (('second important layer', 'CNN'), 'be') (('light squares', 'large weights'), 'training') (('we', 'training augmented dataset'), 'rotate') (('nearly equally men', 'skin diseases'), 'see') (('90', 'model'), 'become') (('image path', 'HAM10000_images_part1'), 'include') (('learning So decreasing rate', 'loss function'), 'help') (('These', 'also overfitting'), 'use') (('that', 'gradients sparse e.'), 'maintain') (('data', 'generally faster convergence'), 'speed') (('result', 'feature dimensions'), 'no') (('data imputation againOur step', 'null values'), 'check') (('we', 'loss accuracy'), 'Loading') (('it', 'newly made columns'), 'zip') (('step images', 'image path'), 'seem') (('which', '1'), 'be') (('years 5 biologists', 'biologic benignity'), 'accept') (('Flatten layer', '1D one single vector'), 'be') (('algorithm', 'problems well online stationary e.'), 'mean') (('result', 'different features'), 'see') (('so images', '100 75'), 'be') (('that', 'weight e.'), 'rmsprop') (('People', 'greatest risk'), 'seem') (('don t', 'age data'), 'let') (('we', 'very robust model'), 'create') (('So s', 'skin different diseases'), 'let') (('f1 following article', 'class precision multi recall'), 'be') (('multiclass labels', 'one hot vectors'), 'need') (('only authors', 'independently same unequivocal benign diagnosis'), 'apply') (('kernel filter matrix', 'whole image'), 'apply') (('optimizer', 'loss'), 'improve') (('accuracy', '3 epochs'), 'callback') (('where we', 'input'), 'use') (('optimizer', 'local minima'), 'cause') (('it', 'median value'), 'mean') (('It', 'maximal value'), 'look') (('format layer_name filter_shape filter_data', 'conv'), 'run') (('we', 'loss function'), 'set') (('Histopathology Histo Histopathologic diagnoses', 'specialized dermatopathologists'), 'beenperforme') (('age data', 'missing dataThere'), 'create') (('We', 'data points skin disease type'), 'group') (('Additionally we', 'feature input image'), 'perform') (('So we', 'training data'), 'create') (('skin diseases', 'body'), 's') (('it', 'filter format kernel size channel filter'), 'print') (('filter', 'kernel filter'), 'transform') ", "extra": "['biopsy', 'biopsy of the greater curvature', 'disease', 'test', 'diagnosis']", "label": "Perfect_files", "potential_description_queries": ["accuracy", "advantage", "age", "algorithm", "appearance", "apply", "approach", "architecture", "area", "array", "article", "augmentation", "average", "background", "batch", "become", "best", "biopsy", "body", "cancer", "categorical", "category", "cell", "channel", "check", "choose", "classification", "close", "cnn", "code", "color", "column", "combine", "computation", "compute", "computer", "confusion", "convergence", "convert", "convolutional", "cost", "create", "csv", "custom", "data", "dataset", "default", "define", "describe", "description", "detail", "detect", "detected", "dictionary", "dimension", "directory", "disease", "distributed", "distribution", "encoding", "ensure", "epoch", "error", "evaluation", "every", "evidence", "expand", "experiment", "explore", "extent", "f1", "faster", "feature", "feed", "field", "figure", "file", "fill", "filter", "final", "find", "fit", "flip", "folder", "following", "form", "format", "found", "function", "general", "generalization", "gradient", "grayscale", "ground", "group", "handle", "height", "help", "high", "highlight", "histogram", "history", "hot", "human", "idea", "image", "img", "improve", "improvement", "impute", "indicate", "infected", "info", "input", "integer", "intuition", "kernel", "label", "labeled", "language", "largest", "layer", "learn", "learning", "least", "let", "level", "light", "list", "load", "local", "look", "lot", "lower", "manual", "map", "matrix", "max", "mean", "meaning", "measure", "median", "men", "merge", "method", "metric", "minimum", "missing", "mnist", "model", "most", "name", "near", "need", "network", "neural", "next", "no", "non", "normalization", "normalize", "normalized", "not", "notebook", "null", "number", "optimizer", "order", "out", "output", "overfitting", "parameter", "part", "path", "people", "per", "percent", "perform", "performance", "plot", "pooling", "precision", "pretrained", "prevent", "probability", "problem", "provide", "purpose", "random", "range", "rating", "ratio", "read", "recall", "reduce", "reference", "regularization", "representation", "resolution", "rest", "result", "risk", "robust", "rotate", "row", "run", "sample", "save", "score", "second", "separate", "set", "shape", "shift", "short", "single", "six", "size", "skin", "softmax", "space", "sparse", "splitting", "spread", "standard", "std", "step", "sub", "subplot", "summarize", "target", "task", "technique", "testing", "through", "time", "title", "total", "train", "training", "transformation", "turn", "type", "up", "validation", "value", "variability", "variable", "vertical", "vision", "visualize", "vivo", "weight", "while", "width", "wise", "world", "zip", "zoom"], "potential_description_queries_len": 259, "potential_script_queries": ["backend", "glob", "missingno", "numpy", "preprocessing", "seaborn"], "potential_script_queries_len": 6, "potential_entities_queries": ["augmentation", "color", "disease", "feature", "following", "high", "input", "lower", "model", "precision", "save", "size", "sparse", "validation"], "potential_entities_queries_len": 14, "potential_extra_queries": ["diagnosis"], "potential_extra_queries_len": 1, "all_components_potential_queries_len": 263}
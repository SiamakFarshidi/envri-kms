{"name": "face expression recognition with deep learning ", "full_name": " h1 Introduction h1 Quick data visualization h1 Setup the data generators h1 Setup our Convolutional Neural Network CNN h1 Train the model h1 Analyze the results ", "stargazers_count": 0, "forks_count": 0, "description": "The following image summarizes how it works http deeplearning. One solution consists in early stopping the training of the model. Here this is simply due to the presence of dropout which is only applied during the training phase and not during the validation phase. The original data consisted in arrays with a greyscale value for each pixel. Keras has a very useful class to automatically feed data from a directory ImageDataGenerator. There are different types of filters and each one will be able to retrieve different image features https ujwlkarn. Now let s define the architecture of our CNN We define our CNN with the following global architecture 4 convolutional layers 2 fully connected layersThe convolutional layers will extract relevant features from the images and the fully connected layers will focus on using these features to classify well our images. Train the modelEverything is set up let s train our model now Our best model managed to obtain a validation accuracy of approximately 65 which is quite good given the fact that our target class has 7 possible values At each epoch Keras checks if our model performed better than during the previous epochs. Some hidden layers that will allow the NN to learn complex interactions within the data. An output layer that will give the final result for instance a class prediction. Each of them contain the following operations A convolution operator extracts features from the input image using sliding matrices to preserve the spatial relations between the pixels. com 2016 08 screen shot 2016 08 05 at 11 03 00 pm. Convolutional Neural Networks also have Convolutional layers that apply sliding functions to group of pixels that are next to each other. All those outputs were saved into the history variable. This means that our model starts to overfit our training dataset after too much iterations. The function flow_from_directory specifies how the generator should import the images path image size colors etc. We chose the Adam optimizer as it is one of the most computationally effective. Quick data visualizationFirst let s see how our images look like Can you guess which images are related to which expressions This task is quite easy for a human but it may be a bit challenging for a predictive algorithm because the images have a low resolution the faces are not in the same position some images have text written on them some people hide part of their faces with their handsHowever all this diversity of images will contribute to make a more generalizable model. com jrishabh96 Facial Expression RecognitionLet s focus on how our convolution layers work. ai images wiki perceptron_node. Now it s time to try our model in a real situation We will use flask to serve our model in order to perform real time predictions with a webcam input. The size of the input layer depends on the size of the input data. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The training loss is slightly higher than the validation loss for the first epochs which can be surprising. The size of this layer depends on the type of output we want to produce e. We chose softmax as our last activation function as it is commonly used for multi label classification. io assets cnn maxpool. gif The green matrix corresponds to the raw image values. The image expressions in our training dataset are pretty balanced except for the disgust category. Finally we can plot the confusion matrix in order to see how our model classified the images Our model is very good for predicting happy and surprised faces. Indeed we are more used to see higher validation losses than training losses in machine learning. Setup our Convolutional Neural Network CNN We chose to use a Convolutional Neural Network in order to tackle this face recognition problem. It can also perform data augmentation while getting the images randomly rotating the image zooming etc. Indeed this type of Neural Network NN is good for extracting the features of images and is widely used for image analysis subjects like image classification. This will allow us to load directly the weights of our model without having to re train it if we want to use it. net profile Martin_Musiol publication 308414212 figure fig1 AS 409040078295040 1474534162122 A general model of a deep neural network It consists of an input layer some here two. Our metric will be the accuracy which is also quite informative for classification tasks on balanced datasets. The orange sliding matrix is called a filter or kernel. However it predicts quite poorly feared faces because it confuses them with sad faces. jpeg We also use some common techniques for each layer Batch normalization improves the performance and stability of NNs by providing inputs with zero mean and unit variance. Other functions like tanh or sigmoid could also be used but ReLU has been found to perform better in most situations. Pooling is used to reduce the dimensionality of each features while retaining the most important information. Like for the convolutional step we apply a sliding function on our data. png A NN is composed of several layers of nodes https www. Using them slightly increased the training duration of the model. We could also use some different dropout values and performing data augmentation. png w 342 h 562 We apply the ReLU function to introduce non linearity in our CNN. Each image corresponds to a facial expression in one of seven categories 0 Angry 1 Disgust 2 Fear 3 Happy 4 Sad 5 Surprise 6 Neutral. display some images for every different expression size of the image 48 48 pixels input path for the images count number of train images for each expression number of images to feed into the NN for every batch number of possible label values Initialising the CNN 1 Convolution 2nd Convolution layer 3rd Convolution layer 4th Convolution layer Flattening Fully connected layer 1st layer Fully connected layer 2nd layer number of epochs to train the NN serialize model structure to JSON plot the evolution of Loss and Acuracy on the train and validation sets show the confusion matrix of our predictions compute predictions compute confusion matrix plot normalized confusion matrix. We chose the categorical cross entropy as our loss function as it is quite relevant for classification tasks. The dataset contains approximately 36K images. This architecture was inspired by the following work on the subject https github. With more research and more resources this model could certainly be improved but the goal of this study was primarily to focus on obtaining a fairly good model compared to what has been done in this field. IntroductionThe data comes from the past Kaggle challenge Challenges in Representation Learning Facial Expression Recognition Challenge https www. into a file Analyze the resultsWe got outputs at each step of the training phase. This means that every neuron of one layer is connected to every neurons of the next layer. If it is the case the new best model weights are saved into a file. That is why the validation loss does not decrease a lot after. We will explain this in more details after. Those methods were tested on this dataset but they did not significantly increase the validation accuracy although they reduced the overfitting effect. Now that our CNN is defined we can compile it with a few more parameters. We can use it to plot the evolution of the loss and accuracy on both the train and validation datasets The validation accuracy starts to stabilize at the end of the 50 epochs between 60 and 65 accuracy. Each node gets weighted input data passes it into an activation function and outputs the result of the function https skymind. The max function usually performs better. Therefore those structures have a better understanding of patterns that we can observe in images. We also have to save the structure of our CNN layers etc. Setup the data generatorsDeep learning models are trained by being fed with batches of data. This method is often used as a way to artificially get more data when the dataset has a small size. how many classes do we want to predict Classic NNs are usually composed of several fully connected layers. Dropout reduces overfitting by randomly not updating the weights of some nodes. A Neural Network with a lot of hidden layers is called a Deep Neural Network. png An input layer that will get the data. We converted this data into raw images and splitted them in multiple folders images nbsp nbsp nbsp nbsp train nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp angry nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp disgust nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp fear nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp happy nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp neutral nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp sad nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp surprise nbsp nbsp nbsp nbsp validation nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp angry nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp disgust nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp fear nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp happy nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp neutral nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp sad nbsp nbsp nbsp nbsp nbsp nbsp nbsp nbsp surprise 80 of our images are contained inside the train folder and the last 20 are inside the validation folder. edu wiki images 6 6c Convolution_schematic. com c challenges in representation learning facial expression recognition challengeThe data consists of 48x48 pixel grayscale images of faces. This helps prevent the NN from relying on one node in the layer too much. Quick reminder of what a NN is A Neural Network is a learning framework that consists in multiple layers of artificial neurons nodes. This filter slides over the image by one pixel at each step stride. During each step we multiply the filter with the corresponding elements of the base matrix. We can see that the training loss is becoming much smaller than the validation loss after the 20th epochs. Different functions can be applied max sum mean. ", "id": "jonathanoheix/face-expression-recognition-with-deep-learning", "size": "9878", "language": "python", "html_url": "https://www.kaggle.com/code/jonathanoheix/face-expression-recognition-with-deep-learning", "git_url": "https://www.kaggle.com/code/jonathanoheix/face-expression-recognition-with-deep-learning", "script": "Flatten sklearn.metrics keras.preprocessing.image keras.layers keras.callbacks GlobalAveragePooling2D Dropout Sequential Adam Conv2D seaborn numpy plot_confusion_matrix Input img_to_array ModelCheckpoint confusion_matrix ImageDataGenerator load_img matplotlib.pyplot Activation Dense keras.optimizers BatchNormalization Model MaxPooling2D keras.models ", "entities": "(('automatically face', 'image'), 'register') (('which', 'first epochs'), 'be') (('we', 'e.'), 'depend') (('we', 'usually several fully connected layers'), 'want') (('NN', 'data'), 'layer') (('training loss', '20th epochs'), 'see') (('images', 'etc'), 'perform') (('when dataset', 'small size'), 'use') (('We', 'more details'), 'explain') (('we', 'it'), 'allow') (('Batch normalization', 'unit zero mean variance'), 'use') (('original data', 'pixel'), 'consist') (('Using', 'model'), 'increase') (('it', 'most computationally effective'), 'choose') (('dataset', 'K approximately 36 images'), 'contain') (('Neural learning that', 'neurons artificial nodes'), 'be') (('Keras', 'directory ImageDataGenerator'), 'have') (('Convolutional Neural We', 'face recognition problem'), 'setup') (('Dropout', 'nodes'), 'reduce') (('We', 'webcam input'), 's') (('confusion matrix plot', 'confusion matrix'), 'display') (('png input that', 'data'), 'layer') (('that', 'other'), 'have') (('we', 'images'), 'have') (('which', 'balanced datasets'), 'be') (('filter', 'step stride'), 'slide') (('it', 'label commonly multi classification'), 'choose') (('green matrix', 'image raw values'), 'gif') (('Indeed we', 'machine learning'), 'be') (('We', 'data augmentation'), 'use') (('it', 'sad faces'), 'predict') (('input data', 'function https skymind'), 'weight') (('One solution', 'model'), 'consist') (('it', 'classification quite tasks'), 'choose') (('image', 'seven categories'), 'correspond') (('We', 'CNN layers'), 'have') (('what', 'field'), 'improve') (('diversity', 'more generalizable model'), 'let') (('model', 'too much iterations'), 'mean') (('layersThe 2 fully connected convolutional layers', 'well images'), 'let') (('It', 'input layer'), 'figure') (('h 342 We', 'CNN'), 'png') (('architecture', 'https subject github'), 'inspire') (('we', 'a few more parameters'), 'compile') (('which', 'validation phase'), 'be') (('model', 'very happy faces'), 'plot') (('last 20', 'validation folder'), 'convert') (('how it', 'http'), 'summarize') (('resultsWe', 'training phase'), 'get') (('validation accuracy', '60 accuracy'), 'use') (('we', 'data'), 'apply') (('convolution operator', 'pixels'), 'contain') (('learning models', 'data'), 'generatorsdeep') (('data', 'Learning Facial Expression Recognition Challenge https www'), 'come') (('Neural Network', 'hidden layers'), 'call') (('they', 'overfitting effect'), 'test') (('model new best weights', 'file'), 'save') (('Pooling', 'most important information'), 'use') (('This', 'layer'), 'help') (('model', 'better previous epochs'), 'set') (('expression recognition challengeThe facial data', 'faces'), 'challenge') (('Indeed type', 'image classification'), 'be') (('one', 'https'), 'be') (('size', 'input data'), 'depend') (('outputs', 'history variable'), 'save') (('also ReLU', 'better most situations'), 'use') (('we', 'base matrix'), 'multiply') (('png NN', 'nodes https www'), 'compose') (('output that', 'class prediction'), 'layer') (('image expressions', 'disgust pretty category'), 'be') (('2016 08 screen', '2016 08 05 11 03 00 pm'), 'com') (('neuron', 'next layer'), 'mean') (('flow_from_directory how generator', 'images path image size colors'), 'specify') ", "extra": "['test']"}
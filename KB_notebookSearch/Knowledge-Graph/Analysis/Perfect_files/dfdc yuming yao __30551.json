{"name": "dfdc yuming yao ", "full_name": " h1 1 Introduction h1 2 Related Work h2 Load Data h1 3 Problem Formulation h1 Initialize BlazeFace h1 Initialize Yolo h1 Initialize MTCNN h1 Initialize MobilenetFace h1 Ability to Detect Face h1 Accuracy Comparison h1 Cropped Images h1 BlazeFace h1 MTCNN h1 Mobilenet h1 YOLO h1 Extra Comparisons h1 4 Methods h1 5 Experiments and Results h1 MesoNet h1 Resnext Model h1 Xception h1 6 Conclusion and Future Works h1 7 Bibliography ", "stargazers_count": 0, "forks_count": 0, "description": "Bug in PyTorch If we found any faces prepare them for the model. For the training of the model mentioned above we use packages such as numpy pandas matplotlib. For example Generative Adversarial Networks GAN models can produce super realistic images languages and even videos. In the training data whether the video is forged by deepfake is determined by the string REAL or FAKE in the label column. In this case the researchers decided to find a method of deepfake detection to protect people from this huge danger. The proposal of the Deep Residual Network ResNet is a milestone event in the history of CNN images. Ivanenko Combining Deep Learning and Super Resolution Algorithms for Deep Fake Detection 2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering EIConRus St. are analyzing the following methods two convolutional neural network CNN architectures namely Meso 4 and MesoInception 4 Convolutional LSTM network the former extracts frame level features the latter performs sequence processing and sends the dense layer and finally determines whether the video is real or fake. Resize to the model s required input size. Finally combined with the residual network the final ResNext is obtained. Further other researchers can add other parts to this work to enhance the recognition effect. After the picture passes through the P Net many prediction windows will be left. We show the effect of our work by drawing the ROC curve. We changed the model chose the pre trained Rest and Xception and we got the best results on Rest. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python Docker image https github. NOTE When running on the CPU the batch size must be fixed or else memory usage will blow up. Test time augmentation horizontal flips. used the Resnet model for training and prediction and at the same time using Resnetx and Xception pre trained models to perform predictions. Unlike Inception v4 ResNext does not require manual design of complex Inception structural details but each branch uses the same topology. LabelEncoder is a function in the scikit learn package. 1109 CSCloud EdgeCom49738. The three cascaded networks are P Net for quickly generating candidate windows R Net for filtering and selecting high precision candidate windows and O Net for generating final bounding boxes and face key points. After the features are input to the three convolutional layers of the result the network uses a face classifier to determine whether the region is a face and uses border regression and a face key point. Compared with a single machine learning and deep learning model deep ensemble learning shows better results in deepfake detection. x i x i 255. Public test set This data set is completely rejected and the Kaggle platform calculates the public ranking. Changing faces is never perfect. Therefore it is very necessary to do some work to identify these fake content generated by algorithms through technical means which is a crucial part of solving the problems caused by deepfake described above. The difference is that what we do has the following characteristics. It is divided into 50 files for easy access and download. Both YOLO training and detection are performed in a separate network. In studying the problem of image classification the basis of convolution will follow the logistic regression layer. Although ResNet wins by depth there are tricks in its architecture which makes the depth of the network play a role. Sung DeepfakeStack A Deep Ensemble based Learning Technique for Deepfake Detection 2020 7th IEEE International Conference on Cyber Security and Cloud Computing CSCloud 2020 6th IEEE International Conference on Edge Computing and Scalable Cloud EdgeCom New York NY USA 2020 pp. Our work is also based on deep learning. MethodsIn this part we will introduce the related algorithms used in this work mainly Resnet Xception and ResNext. Video data analysis 3. The basic structure is a more complicated convolutional neural network. After uploading this fake video to this website it caused a lot of discomfort. On the other hand this problem is considered to be more complex and requires other connections beyond vision 1. When you submit the competition from the output file of the submitted notebook containing the competition data set your code will rerun in the background and when the retest is completed the score will be posted on the public leaderboard. Then we used 4 face detection methods and compared its running time. 98 which is a good data. Problem FormulationIn this work the data set we selected is a competition on Kaggle Deepfake Detection Challenge DFDC which is the data set provided by the Deepfake synthetic face detection competition. Compared with the 1x1x32 feature of P Net using full convolution output R Net uses a 128 fully connected layer after the last convolution layer which retains more image features and the accuracy performance is also better than P Net. The full name of P Net is Proposal Network and its basic structure is a fully convolutional network. In the case of uncomplicated data distribution both it can solve problems and increase the speed of network reasoning which makes BlazeFace efficient and lightweight Initialize YoloYOLO its full name is You Only Look Once which basically summarizes the characteristics of YOLO completely that is only one CNN operation is required. Compared with R Net there is one more convolutional layer. In order to balance performance and accuracy MTCNN avoids the huge performance consumption caused by traditional ideas such as sliding window plus classifier first use a small model to generate a certain possibility of target area candidate frame then use more complex models for fine classification and higher precision area box regression and let this step be executed recursively this idea forms a three layer network namely P Net R Net and O Net to achieve fast and efficient face detection. The change is mainly reflected in ResNet directly using stride 2 convolution for downsampling and replacing the fully connected layer with the global average pool layer. This work is to protect people s personal rights safeguard the people s legitimate interests and maintain the stable development of society which is extremely beneficial. Compared with ordinary networks ResNet adds a short circuit mechanism between every two layers which forms residual learning. When the network is deeper it performs residual learning between three layers three layer volume The product cores are 1x1 3x3 and 1x1. There are two strategies 1 Use zero padding to increase the dimension. It can not only ensure the accuracy of detection but also the fast reasoning speed can reach the sub millisecond level in the general mobile phone CPU. Compared with the first layer of P Net a fully connected layer is added so the input data will be more stringent. Private test set This data set is private outside the Kaggle platform and is used to calculate private rankings. Corresponds to an input channel so depthwise convolution is a depth level operation. Experiments and Results MesoNet\u73b0\u5728\u6211\u4eec\u4f7f\u7528MesoNet\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3 \u5728\u8fd9\u4e4b\u524d\u6211\u4eec\u505a\u4e86\u6570\u636e\u96c6\u7684\u4e00\u4e9b\u5206\u6790 \u53d1\u73b0\u8fd9\u5e76\u4e0d\u662f\u4e00\u4e2a\u5747\u8861\u7684\u6570\u636e\u96c6 \u4e3a\u6b64\u6211\u4eec\u91c7\u7528\u4e86\u4e0b\u91c7\u6837\u7684\u65b9\u5f0f\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u5904\u7406 \u901a\u8fc7K 5\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65b9\u5f0f\u8fdb\u884c \u5e76\u901a\u8fc7log_loss\u4f5c\u4e3a\u8bad\u7ec3\u7ed3\u679c\u8bc4\u4f30\u7684\u6807\u51c6 \u51c6\u786e\u7387\u5728\u6d4b\u8bd5\u96c6\u4e0a\u5927\u7ea6\u670960 \u4ee5\u4e0a\u7684\u6b63\u786e\u7387 \u6211\u4eec\u53d1\u73b0\u81ea\u5df1\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u6548\u679c\u5e76\u4e0d\u51fa\u8272 \u6211\u60f3\u8fd9\u4e0e\u6211\u4eec\u6570\u636e\u96c6\u7684\u4f7f\u7528\u4e0d\u591f\u79d1\u5b66\u6709\u5173 \u4e3a\u6b64\u6211\u4eec\u5c1d\u8bd5\u4e86\u5176\u4ed6\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u9884\u6d4b \u901a\u8fc7\u5b9e\u9a8c\u53ef\u4ee5\u8868\u660e \u76f8\u5bf9\u6bd4MesoNet Xception\u548cResnext Resnext\u7684\u8868\u73b0\u7ed3\u679c\u662f\u6700\u597d\u7684 \u5728\u8fd9\u4e4b\u524d\u6211\u4eec\u4e5f\u5df2\u7ecf\u4ecb\u7ecd\u4e86Resnext\u548cXception\u7684\u7f51\u7edc \u4e0b\u9762\u6211\u4eec\u4f1a\u901a\u8fc7\u5bf9\u8fd9\u4e24\u4e2a\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u9884\u6d4b \u5e76\u901a\u8fc7AUC\u8fdb\u884c\u8bc4\u4f30 Resnext ModelWhen using regression models and machine learning models all the survey data are numerical values to make it easier to get good results. Compared with Inception V3 in terms of classification performance Xception has a smaller lead on ImageNet but is much ahead of JFT in terms of parameters and speed Xception has fewer parameters than Inception but is faster. At that time DeepFake made its first appearance in the adult exchange community of the American social news website Reddit and it caused a lot of shock. Derakhshani Eyebrow Recognition for Identifying Deepfake Videos 2020 International Conference of the Biometrics Special Interest Group BIOSIG Darmstadt Germany 2020 pp. The use of exchanged face resolution mismatches and affine transformations leads to the existence of fake images a CNN is trained to capture these features and match. The level 1 model is trained based on the predictions made by the basic model of out of sample data. Load DataFirst we need to declare the path of training and test samples and metadata files this is just a small part of it more training data we will show later View the number of samples in the test and training set Load metadataAnalyze the number of true and false videos in the training set and describe them with pie charts and histograms respectivelyIn this histogram we find that only 19 of the samples are real videosThe training samples have two resolutions 1080x1920 and 1920x1080. The difference between the effect of O Net and R Net is that this layer of structure will recognize the area of the face through more supervision and will regress the facial feature points of the person and finally output five facial feature points. Usually the solution approach uses visible artifacts which is common in most deepfakes. The above described depthwise separable convolution which is the basic component of MobileNet but batchnorm will be added to the real application and the ReLU activation function will be used. TODO not sure yet if this helps or not Preprocess the images. Depthwise convolution is different from standard convolution. you have to enable this manually calculate the fpr and tpr for all thresholds of the classification method I plt Remove original output layer new updated Find the faces for N frames in the video. The Xception architecture has 36 convolutional layers which form the basis of the feature extraction of the network. For a stacked layer structure several layers stacked when the input is x the learned feature is recorded as H x and now I hope it can learn the residual F x H x x so the original learning feature is F x x. Optionally a fully connected layer can be inserted before the logistic regression layer. It is found that Inception V4 is better than ResNeXt in more environments. Initialize MTCNNMTCNN Multi task convolutional neural network is a multi task neural network model for face detection tasks proposed by Shenzhen Research Institute of Chinese Academy of Sciences in 2016. Using high level libraries such as Keras or TensorFlow Slim only requires 30 to 40 lines of code which is different from architectures such as VGG 16 but is much more complicated to define than architectures such as Inception V2 or V3. Of course this is only one of many bad influences and there are many evil or illegal ways to use these fake content in propaganda political campaigns cyber crime blackmail etc. The basic unit of MobileNet is depthwise separable convolution. The idea of grouped convolution is derived from Inception. P Net is a region suggestion network for the face region. com kaggle docker python For example here s several helpful packages to load linear algebra data processing CSV file I O e. First let s look at some related work directly based on machine learning and deep learning. It is not clear whether the private test will be the same release. The official has provided 50 small data sets after segmentation. IntroductionThe continuous development of science and technology enables deep learning DL models to be applied to a variety of applications. Training set This data set contains target labels which can be downloaded outside of Kaggle for competitors to build their models. YOLO model training is divided into two steps one is pre training using data to train the first 20 convolutional layers of the YOLO network 1 average pooling layer 1 fully connected layer. In principle DeepFake uses one of the most well known deep learning algorithms GANs. First look at Resnet. Of course you can also build a deeper network. This makes the architecture very easy to define and modify. At this time a downsamp is generally required. It achieved 5 first results in ILSVRC and COCO 2015. This is a very efficient and lightweight face detector. In fact this structure has been used in the Inception model before. ResNeXt does have fewer hyperparameters than Inception V4 but it does not seem to be very reasonable to directly abolish Inception s characteristics of including different receptive fields. We send all the prediction windows to R Net. O Net is called Output Network. In order to improve the image accuracy when training the detection model the input image resolution is resized to 448x448. In general YOLO has the characteristics of fast speed low background false detection rate and strong versatility. This model mainly uses three cascaded networks and uses the idea of candidate box plus the classifier is to perform fast and efficient face detection. This part will eventually output a lot of face areas that may have faces and input these areas into R Net for further processing. For standard convolution the convolution kernel is used on all input channels while depthwise convolution uses different convolution kernels for each input channel that is a convolution kernel. The difference is that YOLO does not use the inception module but uses 1x1 convolutional layer here 1x1 convolutional layer exists for cross channel information integration 3x3 convolutional layer simple replacement. read_csv Input data files are available in the read only. In 3 they focused on the problem of detecting fake faces by matching falsely replaced face components specifically by matching the eyebrow region to detect fake phenomena. The most used research on this type of problem is directly based on machine learning and deep learning for recognition and detection but recently integrated learning has been proposed to further improve the recognition accuracy. It does not completely assign each channel to an independent convolution kernel or the entire Feature Map. In principle it can turn the protagonist of the video into anyone. Ability to Detect Face Accuracy ComparisonBlue BlazeFaceRed MobilenetGreen MTCNNPurple YOLO Cropped Images BlazeFace MTCNN Mobilenet YOLO Extra Comparisons 4. Because the output of P Net is only a possible face area with a certain degree of credibility in this network the input will be refined and selected and most of the wrong input will be discarded and again use the border regression and facial key point locator to carry out the border regression and key point positioning of the face area and finally outputs a more credible face area for O Net. For example when processing Fake or Real data we replace them with 0 and 1 and then analyze. Therefore the biometrics of the exchange components may be more preferable than marking forged images. Obvious distortions and blurring of the surrounding facial areas usually expose them. Due to its large size it must be accessed through the GCS bucket. Initialize BlazeFaceFirst look at BlazeFace. It is worth noting that the number of feature maps in the hidden layer is relatively small and it is 1 4 of the number of output feature maps. The convolution machine is a compromise between ordinary convolution and depth separable convolution that is the number of channels of the Feature Map generated by each branch is n n 1. 0 can get good results. Then analyze the residual unit ResNet uses two residual units shallow network and deep network. The second is Xception which is another improvement to Inception v3 proposed by Google after Inception. If it is allowed to continue the consequences will be disastrous. BlazeFace only cascades 2 scale features for face detection and each point uses only two anchors under 16x16 features and each point uses 6 anchors under 8x8 features. For short circuit connection when the input and output dimensions are the same the input can be directly added to the output. pyplot glob cv2 torch and tensorflow in python. Xception\u4ee5\u4e0a\u4e09\u79cd\u7b97\u6cd5\u5c31\u662f\u672c\u6b21\u5de5\u4f5c\u4e2d\u7528\u5230\u7684\u7b97\u6cd5 \u6211\u4eec\u4f7f\u7528AUC ROC Area Under Curve \u6765\u8861\u91cf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8d28\u91cf\u7684\u6307\u6807 AUC ROC\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u5e38\u7528\u7684\u4e00\u4e2a\u5206\u7c7b\u5668\u8bc4\u4ef7\u6307\u6807 \u5176\u89c4\u5219\u7528\u4e00\u53e5\u8bdd\u6982\u62ec\u5c31\u662f \u4e00\u4e2a\u6b63\u4f8b \u4e00\u4e2a\u8d1f\u4f8b \u9884\u6d4b\u4e3a\u6b63\u7684\u6982\u7387\u503c\u6bd4\u9884\u6d4b\u4e3a\u8d1f\u7684\u6982\u7387\u503c\u8fd8\u8981\u5927\u7684\u53ef\u80fd\u6027 \u6211\u4eec\u901a\u8fc7\u7ed8\u5236ROC\u66f2\u7ebf\u6765\u4f53\u73b0\u6211\u4eec\u7684\u5de5\u4f5c\u6548\u679c ROC\u66f2\u7ebf\u4e0b\u9762\u7684\u9762\u79ef\u5c31\u662fAUC\u7684\u503c \u5177\u4f53\u56fe\u793a\u4f1a\u5728\u4e0b\u4e00\u90e8\u5206\u8be6\u7ec6\u7ed9\u51fa \u5bf9\u4e8e\u4e0a\u9762\u63d0\u5230\u7684\u6a21\u578b\u7684\u8bad\u7ec3 \u6211\u4eec\u4f7f\u7528\u4e86python\u4e2d\u7684numpy pandas matplotlib. The ResNet network is based on the VGG19 network modified on the basis of it and added a residual unit through a short circuit mechanism. The full name of R Net is Refine Network. The accuracy of DeepfakeStack can reach 99. The area under the ROC curve is the value of AUC. This is why the first data sets containing generated fake videos appeared. The current work is based on machine learning deep learning and deep integrated learning to identify and detect deepfakes. YOLO solves object detection as a regression problem. At the end of the network structure there is also a larger 256 fully connected layer which retains more image features and at the same time performs face discrimination and human face area border regression and face feature positioning and finally output the coordinates of the upper left corner and the lower right corner of the face area and the five feature points of the face area. Public verification set The submitted file output generation will be based on a small set of 400 videos id included in this public verification set. Unlike Inception which requires manual design of each branch the topology of each branch of ResNeXt is the same. Reddit officially banned the face changing video produced and uploaded by Deepfakes for inappropriate content and infringed on the privacy of others. Echizen MesoNet a Compact Facial Video Forgery Detection Network 2018 IEEE International Workshop on Information Forensics and Security WIFS Hong Kong Hong Kong 2018 pp. In short the Xception architecture is a linear stack of deeply separable convolutional layers with residual connections. Its first appearance at the end of 2017 caused a sensation. O Net has more characteristic input and more complex network structure and also has better performance. In order to find a solution to this problem relevant researchers have actively explored relevant research strategies and made many attempts. That is to say the data not used for training the basic model is provided to the basic model to make predictions and these predictions and the expected output provide input and output pairs of the training data set used to fit the meta model. pyplot glob cv2 torch tensorflow\u7b49package 6. The pointwise convolution is actually an ordinary convolution but it uses a 1x1 convolution kernel. Petersburg and Moscow Russia 2020 pp. The architecture of DeepfakeStack includes two or more basic learners called level 0 models and a meta learner called level 1 model which combines the predictions of these level 0 models. In fact ResNet solved the deep CNN model. In the next work we will try to do some work similar to the DeepfakeStack deep integration learning algorithm to achieve better recognition results and find the optimal integration strategy. It is a more complex convolutional network with more input features. The structure of Xception is based on ResNet but the convolutional layer is replaced with Separable Convolution. I did this intentionally because the model can t get most of the private validation set right based on LB Find the faces for N frames in the video. Here are the main columns filename the file name of the video label whether the video is real or fake original if the video of the training set is fake the original video is listed here split this is always equal to training. backend as K This is not a bug. Depth level separable convolution is actually a factorized convolutions which can be decomposed into two smaller operations depthwise convolution and pointwise convolution. In this work we use LabelEncoder to implement the above conversion process. The above three algorithms are the algorithms used in this work. 65 and the AUC can reach 1. The essence of ResNeXt is Group Convolution which controls the number of groups by variable cardinality. When the residual is 0 the stacked layer only does the identity mapping at this time at least the network performance will not decrease in fact the residual will not be 0 which will also make the stacked layer learn new features based on the input features for better performance. Initialize MobilenetFaceMobileNet which is a small and efficient CNN model proposed by Google has a compromise between accuracy and latency. There is also grouped convolution. Only look at one face per frame. One of its most influential applications DeepFake is very advanced. calculate the fpr and tpr for all thresholds of the classification method I plt. When training and testing the number of frames of each video is 297 299 and 298 299 of which 299 is the most frequent. With the continuous improvement of the deepfake algorithm one can expect that the altered image artifacts will disappear. Because of this situation we need a way to digitize text to preprocess the training data. Because regression and machine learning are both based on mathematical function methods when categorical data appears in the data set we want to analyze the data at this time is not ideal because we cannot process them mathematically. input directory For example running this by clicking run or pressing Shift Enter will list all files under the input directory You can write up to 20GB to the current directory kaggle working that gets preserved as output when you create a version using Save Run All You can also write temporary files to kaggle temp but they won t be saved outside of the current session \u52a0\u8f7d\u8bad\u7ec3\u89c6\u9891\u7684\u6587\u4ef6\u540d \u52a0\u8f7d\u6d4b\u8bd5\u89c6\u9891\u7684\u6587\u4ef6\u540d Equal aspect ratio ensures that pie is drawn as a circle. Make a prediction then take the average. Obviously from the perspective of frame resolution this challenge will require a lot of resources. com c deepfake detection challenge 1. Then a framework for using deep learning methods to detect these deepfake videos is proposed a convolutional neural network architecture is trained on the face database extracted from the FaceForensics and DeepFakeDetection datasets. You can use the pooling with strde 2 so that no parameters will be added 2 Use a new mapping projection shortcut Generally a 1x1 convolution is used which will increase the parameters and increase the amount of calculation. Because traditional image forensics technology is usually not suitable for video and compression will seriously reduce the quality of the data. It performs very well in face detection tasks in close up frontal scenes. AUC ROC is a commonly used evaluation index for classifiers in machine learning. Another difference from Inception v4 is that ResNeXt first performs 1 1 convolution and then performs unit addition. In the end we found that BlazeFace has the fastest detection speed and the Resnetx model AUC can reach 0. Therefore it is necessary to combine other technologies to study and solve the deepfake problem. The input of the predictor is the data set provided by the DFDC challenge and the Resnext and Xception neural network algorithms are used to detect real and fake faces. Why it can have such high performance One is the design of the backbone network which uses the depthwise convolution of the large receptive field and 1x1 convolution kernel to speed up the features and uses the nested single blaze method to increase the expression of the model ability the second is because of the design of the detection regression. But when the dimensions are inconsistent corresponding to double the dimensions this cannot be added directly. Another is ResNext which is a combination of ResNet and Inception. Finally we chose the shortest use time FaceBlaze was used to extract faces and then we used a ResNet model similar to CNN for training and verification but our method did not perform well. First identify the false content and then we can better prevent warn and punish. Obviously we need further research to combat deepfake. Resize the training image resolution to 224x224 then use the first 20 convolutional layer network parameters obtained in step 1 to initialize the network parameters of the first 20 convolutional layers of the YOLO model and then use the VOC 20 type of annotation data for YOLO model training. Use residual learning to solve the degradation problem. An important design principle of ResNet is when the size of the feature map is reduced by half the number of feature maps doubles which maintains the complexity of the network layer. The specific diagram will be given in detail in the next part. The reason for this is that residual learning is easier than direct learning of original features. Such artifacts provide good accuracy for deepfakes to a large extent especially for relatively older fakes. We intercept a certain frame or a few frames in each video as input for training and detection as shown in the following figureNext we show the photos in the training setIn the selection of extraction methods we have chosen four face extraction methods BlazeFace MTCNN MobileNet and YOLO. Based on training meta learners on top of pre trained basic learners and provide an interface to adapt meta learners according to the predictions of basic learners and show how the integrated technology performs classification tasks. proposed an automatic and efficient method for detecting face tampering in videos based on DeepFake and Face2Face which can generate fake videos that cannot be distinguished by the human eyes. In general its core is the use of decomposable depthwise separable convolution which can not only reduce the computational complexity of the model but also greatly reduce the model size. First we need to create a variable encoder_x for encoding and then when the program is executed these Fake and Real category data are converted into values 0 and 1. The locator is used to make the initial proposal of the face area. What I want to do this time is to detect the fake faces generated by deepfake. DeepfakeStack 5 is a deep ensemble learning technology that combines a series of the latest classification models based on deep learning and creates an improved combined classifier. In addition to directly using identity mapping for short circuit connections of course projection shortcuts can be used. The problem of difficulty in training 14 years of VGG has only 19 layers and 15 years of ResNet has as many as 152 layers which is not an order of magnitude in network depth. Next let s look at the work that has made some research progress in this area. The complete training set exceeds 470GB. For the image pyramid constructed in the previous step an FCN is used to perform preliminary feature extraction and frame calibration and perform the Bounding Box Regression adjustment window and NMS to filter most of the windows. The most successful method is based on blinking eyes mismatched color profiles and facial distortion artifacts. Inception V4 performs splicing and then performs 1 1 convolution. We keep the aspect ratio intact and add zero padding if necessary. Grouped convolution is a compromise between the depth of the ordinary convolution kernel and the separable convolution. This trick is Residual Learning. Collect training image size View the first frame of the first 10 videos Sample size distribution \u8bfb\u53d6\u89c6\u9891 \u83b7\u53d6\u6807\u7b7e \u83b7\u53d6\u7b2c\u4e00\u5e27 u3000\u5c55\u793a\u7b2c\u4e00\u5e27\u89c6\u9891 \u63d0\u53d6\u8138\u90e8\u56fe\u7247 That constant describe pieces for 16 9 images fast less accurate slower more accurate 9 16 respectively Face Detection The value below are both the number of frames Frame rate Resolution Width Resolution Height Total number of frames Duration unit s import keras. It contains videos of similar format and nature to the training and public verification test sets but real organic videos with or without deepfakes. YOLO did not show the process of obtaining the region proposal. Its basic structure is a convolutional neural network. zip on the Kaggle data page. This is one of the earlier work done in deepfake detection. There are 4 data sets related to this competition. Based on a single end to end network complete the input from the original image to the output of the object position and category. Conclusion and Future WorksIn the whole work we first tried to segment the video data set and divide the data set into pictures. In addition the model has been tested on various interpretable artificial intelligence technologies such as LRP and LIME to provide a clear visualization of the salient areas of the image focused by the model 4. The running speed of ResNeXt of similar structure should be better than Inception V4 because the design of the branch of the same topology of ResNeXt is more in line with GPU hardware design principles. This is a user named Deepfakes in a community who grafted the face of Wonder Woman Gal Gadot to the heroine of an adult movie and uploaded the video to the website. We use AUC ROC Area Under Curve to measure the quality of machine learning models. We do it on the original video data set. It was at that time that offensive deepfakes and defensive detection methods began to compete. This network will filter out a large number of candidate frames with poor results and finally perform Bounding Box Regression and NMS on the selected candidate boxes to further optimize the prediction results. For depthwise separable convolution it first uses depthwise convolution to convolve different input channels separately and then uses pointwise convolution to combine the above outputs so that the overall effect is similar to a standard convolution but it will greatly reduce the calculation quantity and model parameter quantity. For example the so called deep forgeries made by GANs Generative Adversarial Networks manipulating audio or video clips are too close to real content to be distinguished from real images in human perception. A comparison of several ways of extracting faces such as MTCNN BlazeFace YOLO etc. Since the main task of the algorithm is the detection of positive faces in most cases the anchor with a ratio of 1. Therefore this paper follows the method of deep learning and proposes two networks both with fewer layers to focus on the mesoscopic properties of the image 2. The YOLO network draws on the GoogLeNet classification network structure. Kazi Explainable Deep Fake Detection Using Visual Interpretability Methods 2020 3rd International Conference on Information and Computer Technologies ICICT San Jose CA USA 2020 pp. Use the same convolution kernel. The above work has achieved quite good results but deepfake is also making progress. Here is another introduction to the training set. Its rules are summarized in one sentence a positive example a negative example the probability that the prediction is positive is greater than the probability that the prediction is negative. The 36 convolutional layers are constructed into 14 modules all of which have linear residual connections around them except for the first and last modules. Related WorkSince the development of deepfake even the detection of deepfake has long become a hot research topic. In general ResNeXt proposes a strategy of separable convolution between the depth of the ordinary convolution kernel grouped convolution which achieves a balance between the two strategies by controlling the number of groups base. The output of this layer is used as the final network model output. Yuming Yao 2032754Dataset https www. For 18 layer and 34 layer ResNet it performs residual learning between two layers. ", "id": "fangxina/dfdc-yuming-yao", "size": "30551", "language": "python", "html_url": "https://www.kaggle.com/code/fangxina/dfdc-yuming-yao", "git_url": "https://www.kaggle.com/code/fangxina/dfdc-yuming-yao", "script": "albumentations sklearn.metrics tqdm_notebook get_mtcnn_face Pooling(nn.Module) make_square_image tensorflow.keras.models get_blazeface_face torch.nn gather_info face_extract_1 MyResNeXt(models.resnet.ResNet) process_file get_frame sklearn.model_selection func mtcnn InceptionLayer schedule load_mobilenetv2_224_075_detector BlazeFace annotate_image get_boxes_points train_test_split isotropically_resize_image ZeroPadding2D tensorflow.keras.applications.mobilenet_v2 scale_boxes FaceExtractor tensorflow.keras.layers = tf.compat.v1.GraphDef MTCNN FCN(torch.nn.Module) Head(torch.nn.Module) seaborn numpy tqdm_notebook as tqdm FaceDetector() Input read_img transpose_shots larger_range Normalize LabelEncoder VideoReader tqdm.notebook tensorflow pandas keras.optimizers log_loss sigmoid Model matplotlib.animation keras.callbacks read_video_1 shuffle get_yolo_face forward Conv2D get_original_filename get_label predict_on_video_set ArtistAnimation detect visualize_frame get_mobilenet_face MobileNetV2 get_path predict_on_video check_answers pytorchcv.model_provider define_model LearningRateScheduler FuncAnimation torchvision.transforms __init__ get_model keras.layers blazeface Sequential union_suppression ThreadPoolExecutor crop_image concurrent.futures get_blaze_boxes keras.backend matplotlib.pyplot Dense Lambda correct_precentile prediction_pipline tqdm torch.nn.functional sklearn.preprocessing keras torchvision.models non_max_suppression ", "entities": "(('Inception V4', 'then 1 1 convolution'), 'perform') (('how integrated technology', 'classification tasks'), 'base') (('Inception V4', 'more environments'), 'find') (('Kaggle completely platform', 'public ranking'), 'set') (('it', 'consequences'), 'be') (('projection shortcuts', 'course'), 'use') (('It', 'convolution independent kernel'), 'assign') (('34 it', 'two layers'), 'for') (('It', 'ILSVRC'), 'achieve') (('faces', 'model'), 'bug') (('Such artifacts', 'especially relatively older fakes'), 'provide') (('Of course this', 'propaganda political campaigns'), 'be') (('data why first sets', 'generated fake videos'), 'be') (('batchnorm', 'real application'), 'describe') (('input image resolution', '448x448'), 'resize') (('Group which', 'variable cardinality'), 'be') (('that', 'human eyes'), 'propose') (('Initialize MTCNNMTCNN Multi neural task convolutional network', '2016'), 'be') (('second', 'detection regression'), 'have') (('YOLO training', 'separate network'), 'perform') (('region', 'border regression'), 'be') (('full name', 'P Net'), 'be') (('I', 'classification method'), 'calculate') (('picture', 'prediction P Net many windows'), 'leave') (('they', 'fake phenomena'), 'focus') (('Of course you', 'also deeper network'), 'build') (('we', 'training data'), 'need') (('model', 'face fast detection'), 'use') (('input data', 'P Net'), 'add') (('full name', 'R Net'), 'be') (('convolutional layer', 'Separable Convolution'), 'base') (('area', 'AUC'), 'be') (('value', 'Resolution Width Height frames Duration import Total keras'), 'collect') (('FCN', 'windows'), 'use') (('point', '8x8 features'), 'cascade') (('which', 'most deepfakes'), 'use') (('network', 'prediction further results'), 'filter') (('learning deep deep ensemble learning', 'deepfake detection'), 'show') (('ResNet', 'CNN deep model'), 'solve') (('which', 'ResNet'), 'be') (('challenge', 'resources'), 'require') (('Generative Adversarial Networks GAN models', 'images super realistic languages'), 'produce') (('videosThe training real samples', 'two resolutions'), 'need') (('it', 'different receptive fields'), 'have') (('layer product three cores', 'three layers'), 'perform') (('most successful method', 'color profiles'), 'base') (('pyplot', 'python'), 'glob') (('LabelEncoder', 'package'), 'be') (('we', 'them'), 'want') (('which', 'groups base'), 'propose') (('Here introduction', 'training set'), 'be') (('here 1x1 convolutional layer', 'channel information cross integration 3x3 convolutional layer simple replacement'), 'be') (('specific diagram', 'next part'), 'give') (('0 meta 1 which', 'level 0 models'), 'include') (('neural network convolutional architecture', 'FaceForensics datasets'), 'propose') (('numerical it', 'good results'), 'Experiments') (('P Net', 'region suggestion face region'), 'be') (('relevant researchers', 'many attempts'), 'explore') (('competitors', 'models'), 'set') (('level 1 model', 'sample data'), 'train') (('reasoning also fast speed', 'mobile phone general CPU'), 'ensure') (('deepfake', 'also progress'), 'achieve') (('BlazeFace', 'Resnetx 0'), 'find') (('which', 'network'), 'have') (('principle DeepFake', 'algorithms most well known deep learning GANs'), 'use') (('pie', 'circle'), 'list') (('main task', '1'), 'be') (('we', 'integration optimal strategy'), 'try') (('which', 'Inception'), 'be') (('also stacked layer', 'better performance'), 'be') (('DeepFake', 'most influential applications'), 'one') (('CNN only one operation', 'YOLO'), 'solve') (('output', 'network model final output'), 'use') (('actually factorized which', 'convolution'), 'be') (('also larger 256 fully connected which', 'feature face five area'), 'be') (('learning 5 deep ensemble that', 'improved combined classifier'), 'be') (('AUC ROC\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u5e38\u7528\u7684\u4e00\u4e2a\u5206\u7c7b\u5668\u8bc4\u4ef7\u6307\u6807', '\u4e00\u4e2a\u6b63\u4f8b \u4e00\u4e2a\u8d1f\u4f8b \u9884\u6d4b\u4e3a\u6b63\u7684\u6982\u7387\u503c\u6bd4\u9884\u6d4b\u4e3a\u8d1f\u7684\u6982\u7387\u503c\u8fd8\u8981\u5927\u7684\u53ef\u80fd\u6027 \u6211\u4eec\u901a\u8fc7\u7ed8\u5236ROC\u66f2\u7ebf\u6765\u4f53\u73b0\u6211\u4eec\u7684\u5de5\u4f5c\u6548\u679c \u5bf9\u4e8e\u4e0a\u9762\u63d0\u5230\u7684\u6a21\u578b\u7684\u8bad\u7ec3 pandas ROC\u66f2\u7ebf\u4e0b\u9762\u7684\u9762\u79ef\u5c31\u662fAUC\u7684\u503c \u5177\u4f53\u56fe\u793a\u4f1a\u5728\u4e0b\u4e00\u90e8\u5206\u8be6\u7ec6\u7ed9\u51fa \u6211\u4eec\u4f7f\u7528\u4e86python\u4e2d\u7684numpy matplotlib'), 'Area') (('structure', 'Inception model'), 'use') (('we', 'Rest'), 'change') (('change', 'pool global average layer'), 'reflect') (('299', '298 299 which'), 'be') (('which', 'network layer'), 'be') (('Obviously we', 'deepfake'), 'need') (('usually video', 'data'), 'reduce') (('We', 'zero padding'), 'keep') (('want', 'deepfake'), 'be') (('problem', 'vision'), 'consider') (('it', 'anyone'), 'turn') (('accuracy', '99'), 'reach') (('which', 'calculation'), 'use') (('model', 'model'), 'test') (('accuracy performance', 'P also Net'), 'use') (('basic unit', 'separable convolution'), 'be') (('separable that', 'branch'), 'be') (('Therefore biometrics', 'more forged images'), 'be') (('ResNet network', 'circuit short mechanism'), 'base') (('it', 'shock'), 'make') (('pyplot', 'cv2 torch tensorflow\u7b49package'), 'glob') (('basis', 'regression logistic layer'), 'follow') (('image altered artifacts', 'deepfake algorithm'), 'expect') (('official', 'segmentation'), 'provide') (('which', 'data face detection Deepfake synthetic competition'), 'FormulationIn') (('which', 'residual learning'), 'add') (('ResNet', 'two residual units'), 'analyze') (('MethodsIn part we', 'work'), 'introduce') (('CNN', 'features'), 'lead') (('input', 'directly output'), 'for') (('We', 'ROC curve'), 'show') (('offensive deepfakes', 'time'), 'be') (('relatively it', 'output feature maps'), 'be') (('so called deep forgeries', 'human perception'), 'be') (('i', 'verification public set'), 'set') (('branch', 'same topology'), 'require') (('Obvious distortions', 'usually them'), 'expose') (('Therefore paper', 'image'), 'follow') (('AUC ROC', 'machine learning'), 'be') (('downsamp', 'time'), 'require') (('depth', 'role'), 'be') (('which', 'network depth'), 'have') (('whole we', 'pictures'), 'conclusion') (('YOLO', 'regression problem'), 'solve') (('all', 'first modules'), 'construct') (('prediction', 'probability'), 'summarize') (('Initialize BlazeFaceFirst', 'BlazeFace'), 'look') (('It', 'easy access'), 'divide') (('We', 'R Net'), 'send') (('that', 'input channel'), 'use') (('method', 'training'), 'choose') (('which', 'model also greatly size'), 'be') (('Grouped convolution', 'convolution ordinary kernel'), 'be') (('Further other researchers', 'recognition effect'), 'add') (('F H learning residual so original feature', 'H x'), 'stack') (('who', 'website'), 'be') (('Xception short architecture', 'residual connections'), 'be') (('Reddit', 'others'), 'ban') (('it', 'GCS bucket'), 'access') (('yet this', 'images'), 'sure') (('It', 'close frontal scenes'), 'perform') (('residual learning', 'original features'), 'be') (('Related development', 'even deepfake'), 'WorkSince') (('layer', 'feature finally five facial points'), 'be') (('video', 'label column'), 'determine') (('Depthwise convolution', 'standard convolution'), 'be') (('which', 'Inception such V2'), 'require') (('we', 'face extraction four methods'), 'intercept') (('which', 'deepfake'), 'be') (('that', 'further processing'), 'output') (('topology', 'ResNeXt'), 'be') (('Net', 'network more complex also better performance'), 'have') (('Derakhshani Eyebrow Recognition', 'Biometrics Special Interest Group BIOSIG Darmstadt Germany'), 'pp') (('final ResNext', 'Finally residual network'), 'obtain') (('score', 'public leaderboard'), 'rerun') (('actually ordinary it', 'convolution 1x1 kernel'), 'be') (('first appearance', 'sensation'), 'cause') (('current work', 'deep integrated deepfakes'), 'base') (('ResNeXt', 'unit then addition'), 'be') (('category Fake data', 'values'), 'need') (('we', 'pandas such numpy matplotlib'), 'use') (('idea', 'Inception'), 'derive') (('locator', 'face area'), 'use') (('which', 'society'), 'be') (('above three algorithms', 'work'), 'be') (('t', 'video'), 'do') (('here this', 'always training'), 'be') (('researchers', 'huge danger'), 'decide') (('memory usage', 'When CPU'), 'fix') (('YOLO model training', 'pooling YOLO network 1 average layer'), 'divide') (('it', 'discomfort'), 'cause') (('we', '0'), 'replace') (('This', 'deepfake detection'), 'be') (('which', 'accuracy'), 'have') (('Private test', 'private rankings'), 'set') (('YOLO network', 'GoogLeNet classification network structure'), 'draw') (('recursively idea', 'P Net R face namely fast detection'), 'avoid') (('recently integrated learning', 'recognition further accuracy'), 'base') (('most', 'O Net'), 'refine') (('data set', 'neural network Resnext real faces'), 'be') (('this', 'inconsistent dimensions'), 'be') (('proposal', 'CNN images'), 'be') (('predictions', 'meta model'), 'be') (('it', 'calculation greatly quantity'), 'use') (('we', 'conversion above process'), 'use') (('then we', 'better warn'), 'identify') (('depthwise convolution', 'input channel'), 'correspond') (('read_csv Input data files', 'read'), 'be') (('It', 'verification test public real organic deepfakes'), 'contain') (('Optionally fully connected layer', 'regression logistic layer'), 'insert') (('It', 'kaggle python Docker image https github'), 'come') (('First s', 'machine directly learning'), 'let') (('design', 'GPU hardware design principles'), 'be') (('Ability', 'Face Accuracy ComparisonBlue'), 'BlazeFaceRed') (('three cascaded networks', 'key points'), 'be') (('that', 'area'), 'let') (('finally video', 'dense layer'), 'analyze') (('We', 'machine learning models'), 'use') (('Therefore it', 'deepfake problem'), 'be') (('do', 'following characteristics'), 'be') (('It', 'input more complex convolutional more features'), 'be') (('DL deep learning models', 'applications'), 'enable') (('YOLO', 'region proposal'), 'show') (('new updated', 'video'), 'have') (('Then we', 'running time'), 'use') ", "extra": "['annotation', 'biopsy of the greater curvature', 'test']"}
{"name": "student performance prediction complete analysis ", "full_name": " h1 Hi there h1 The first step towards the solution is identifying which data sources will be relevant to the problem h1 Part 1 Feature Engineering h1 Assessments h1 VLE h1 StudentInfo h1 Compiling all relevant tables h1 Part 2 EDA h1 The fact that the goal feature is categorical makes it not possible for us to include it in a correlation matrix but we can see a tendency of correlation between the grading features weighted grade pass rate and exam score h1 With a Pass count much higher than the other labels we must pay attention to the performance metrics fot the models and analyse the least represented cases more closely h1 On the pairplot we can detect two outliers One with an average click number way above average and another one with a sole occurrence of an amount of previous attempts In order to keep our data as consistent as possible these cases will be removed h1 Part 3 Modeling h1 Given the high correlation between weighted grade and pass rate the models will be fit to 3 types of inputs One with both features and one with each one of them removed from the dataset h1 Model 1 Logistic Regression h1 Model 2 LDA h1 Model 3 Random Forest h1 Model 4 Neural Network Classifier h1 We have sucessfully developed models for the prediction of the student performance but how can we choose one ", "stargazers_count": 0, "forks_count": 0, "description": "From this data we can infer how in touch a student was with their subjects whether they studied it on a solid basis and how they used the content. With this in mind the construction of a metric to track study commitment becomes impractical Here we can track the average time after the start of the course the student took to use the materials and the average amount of clicks per material General average per student per module Removing the cases where the student has withdrawn their registration to the module The final dataframe only has information relevant to the problem 1 contains both 2 just pass_rate e 3 just weighted_grade For the neural network training the outputs needed to be codified and in order to avoid the ordinalization of the classes I chose to classify the distintion cases toghether with thw pass cases. The first step towards the solution is identifying which data sources will be relevant to the problem. com kaggle docker python For example here s several helpful packages to load linear algebra data processing CSV file I O e. You could choose between making a clustering model in order to profile the students or make a forecasting model to predict whether a student would pass or fail their modules. input directory For example running this by clicking run or pressing Shift Enter will list all files under the input directory You can write up to 20GB to the current directory kaggle working that gets preserved as output when you create a version using Save Run All You can also write temporary files to kaggle temp but they won t be saved outside of the current session Here we have the total amount of assessments by module Function to determine whether a student passed a given assessment Creating the stud_ass dataframe to join infos about the assessment weights and their respective grades Final assessment average per student per module Pass rate per student per module Final exam scores Only 1121 from the 6364 entries have the reference week for the materials the week in which they would be used in course. The other is a pass rate created on the premise that a student must get at least 40 score on an assessment to pass it calculating the percentage of assessments the student sucessfully passed. PNG attachment schema. If you are curious too fork this notebook and give it a try too Thanks for reading my kernel and keep learning This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python Docker image https github. uk open_dataset to find a more complete description of the data used here. We also will split final exams from the other assessments given their status and participation in the final evaluation is different from the other assessments. The other models could be used in headhunting programs developed to select students who are very likely to graduate with distinction and offering them scholarships jobs etc. uk open_dataset to illustrate the data structure of the set. Altough I created a lot of features I wonder how many other features could be created for this problem and how would they improve model performance. In order to include the assessments we will build 2 features One of them is the final grade given by the score and the weight of each assessment. Here we have a schema from https analyse. PNG As you can see there are many different types of data involved but since we want to make predictions about student performance it would be interesting to have A measurement of the students commitment to the course throughout the period A measurement of their performance during the period Their final grades as they are a huge part of the final grade compositionGoing to the indicated website we can see that this info is contained under the following tables studentInfo studentAssessment assessments studentVle vleThese tables will be our data sources for the model building process Part 1 Feature EngineeringHere we will discuss how we used the given data in order to create features that made sense in order to build the model AssessmentsThe performance in each assessement is a good indicator of the students knowledge of the course and as it composes the grade for the final evaluation it s interesting to make it a feature in the final model. But as there are many different courses each with a different structure it s unfeasible to create a feature for each assessment. In order to keep our data as consistent as possible these cases will be removed Part 3 ModelingFor the modeling step we will use the following techniques and models Cross validation paired with classification reports and confusion matrices to evaluate model performance Logistic Regression Linear Discriminant Analysis Random Forest Neural Network Classifier Given the high correlation between weighted_grade and pass_rate the models will be fit to 3 types of inputs One with both features and one with each one of them removed from the dataset Model 1 Logistic Regression Model 2 LDA Model 3 Random Forest Model 4 Neural Network Classifier We have sucessfully developed models for the prediction of the student performance but how can we choose one First of all the models in which both weighted_grade and pass_rate were included overall performed better than their omitted counterparts suggesting that our hypotheses was wrong The neural network classifiers had difficulties predicting the cases of failure but overall had a better performance tha the other models probably due to the removal of one class. Hi there This is my first complete project developed from beggining to end with all steps usually followed throughout the development of a machine learning and data science project. I chose the prediction modeling problem and the data given was the same as given here. read_csv Input data files are available in the read only. You can also go to https analyse. I originally developed this as part of an interview process and I ll be adapting the notebook I created for that to this environment. VLEThe datasets referring to the VLE Virtual Learning Environment contain the interaction feed of the students with the content available for reference throughout the duration of the period. StudentInfoThe studentInfo table contains various info about the students but the relevant ones for this analysis are The amount of times the student has already tried to finish the module The students final resultThe last one is our interest variable as we build our prediction model Compiling all relevant tables Part 2 EDAWe start the exploratory data analysis by checking the dataframe integrity The fact that the goal feature is categorical makes it not possible for us to include it in a correlation matrix but we can see a tendency of correlation between the grading features weighted_grade pass_rate and exam_score With a Pass count much higher than the other labels we must pay attention to the performance metrics fot the models and analyse the least represented cases more closely On the pairplot we can detect two outliers One with an average click number way above average and another one with a sole occurrence of an amount of previous attempts. If you enjoy this work or if it was useful to you please upvote Thanks The project started by deciding which problem we were going to solve. ", "id": "devassaxd/student-performance-prediction-complete-analysis", "size": "5676", "language": "python", "html_url": "https://www.kaggle.com/code/devassaxd/student-performance-prediction-complete-analysis", "git_url": "https://www.kaggle.com/code/devassaxd/student-performance-prediction-complete-analysis", "script": "sklearn.metrics sklearn.discriminant_analysis tensorflow.keras.layers tensorflow.keras.callbacks EarlyStopping Dropout Sequential tensorflow.keras.models MinMaxScaler categories pass_fail seaborn numpy sklearn.ensemble confusion_matrix sklearn.model_selection RandomForestClassifier LinearDiscriminantAnalysis matplotlib.pyplot Dense pandas classification_report LogisticRegression sklearn.linear_model sklearn.preprocessing train_test_split ", "entities": "(('student', 'assessments'), 'be') (('student', 'modules'), 'choose') (('data sources', 'problem'), 'identify') (('it', 'final model'), 'PNG') (('there This', 'data science machine learning project'), 'hi') (('who', 'jobs'), 'use') (('how they', 'content'), 'infer') (('datasets', 'period'), 'contain') (('data', 'problem'), 'choose') (('uk', 'data'), 'open_dataset') (('it', 'assessment'), 's') (('I', 'thw pass toghether cases'), 'become') (('we', 'problem'), 'upvote') (('We', 'other assessments'), 'split') (('how they', 'model performance'), 'create') (('read_csv Input data files', 'read'), 'be') (('One', 'assessment'), 'be') (('they', 'course'), 'list') (('I', 'environment'), 'develop') (('It', 'kaggle python Docker image https github'), 'notebook') (('overall', 'one class'), 'remove') (('we', 'previous attempts'), 'be') (('uk', 'set'), 'open_dataset') (('Here we', 'https analyse'), 'have') ", "extra": "[]"}
{"name": "nlp on student writing eda ", "full_name": " h1 Feedback Prize Evaluating Student Writing h1 Introduction to the competition h1 Lenght of the discourse text and predictionstring h1 Length and frequency and relative position per discourse type h1 Investigation the gaps between Annotations text not used as discourse text h1 Are there many really bad essays large percentage of text not classified h1 Color printing essays including the gaps h1 Most used words per Discourse Type h1 Making n grams for each discourse type h1 NER Introduction ", "stargazers_count": 0, "forks_count": 0, "description": "See discussion topic https www. Virtual writing tutors and automated writing systems can leverage these algorithms while teachers may use them to reduce grading time. com c feedback prize 2021 discussion 298193 Color printing essays including the gapsI saw a very pretty way to do this in the Notebook made by Sanskar Hasija https www. News World Report ranked GSU as one of the most innovative universities in the nation. Please upvote his notebook When comparing the discourse_end of the last discourse in each essay we see that the discourse_end is sometimes larger than the essay_len. This cannot be right but I will assume that those are last pieces of text in the essay indeed. Concluding Statement a concluding statement that restates the claimsLet s look at the full text of one essay first. Although the gaps in the example above are small we do have huge gaps in a number of essays. Therefore I will go through the essays to find the real ends. In this case the title is not part of any discourse. This function should also work for the single words just run it with n_grams 1. We also know that a Lead is missing in around 40 of the essays. com robikscube student writing competition twitch. Are there many really bad essays large percentage of text not classified Yes we do have those. I also took out some extra words that were all over the place in the figures for each discourse_type. Later on I decided that making one function for all n_grams was the way to go. I took out stopwords converted all text to lowercase but left in the punctuation. What s surprising to me is that a Lead is missing in about 40 of the essays Lead 1 is found in almost 60 of the essays. Regarding the one with gap_end_length 7348 I found out that this student just copied and pasted the same texts multiple times in his her essay. I am basically using the loop found in Chris Deotte s great notebook https www. More specifically you will automatically segment texts and classify argumentative and rhetorical elements in essays written by 6th 12th grade students. loc which is easier to read you have to be careful with resetting the index if necessary loop over dataframe with all full texts now a list with length the total number of words in an essay is initialised with all values being O now loop over dataframe with all discourses of this particular essay make a list with the position numbers in predictionstring converted into integer now the entities lists gets filled with real values the first word of each discourse gets prefix Beginning the other ones get prefix I. Below I make a function that adds all gaps in an essay as rows with discourse type Nothing. query this code chunk is copied from Rob Mulla initialize column set the first one discourse start 1 previous end is always 1 loop over rest gap if difference is not 1 within an essay minus 2 as the previous end is always 1 and the previous start always 1 gap if the first discourse of an new essay does not start at 0 is there any text after the last discourse of an essay display an example how many pieces of tekst are not used as discourses filter outliers index new row as there is no i 1 for first row add gap at end code from https www. These are Lead an introduction that begins with a statistic a quotation a description or some other device to grab the reader s attention and point toward the thesis Position an opinion or conclusion on the main question Claim a claim that supports the position Counterclaim a claim that refutes another claim or gives an opposing reason to the position Rebuttal a claim that refutes a counterclaim Evidence ideas or examples that support claims counterclaims or rebuttals. We see that Evidence1 Position1 and Claim1 are almost always there in an essay. Some have around 90 of text not classified as one of the discourse types. As we can see not necessarily all text of an essay is part of a discourse. Feedback Prize Evaluating Student WritingGeorgia State University GSU is an undergraduate and graduate urban public research institution in Atlanta. Below you can see a histogram of the length of all gaps with the outliers taken out all gaps longer than 300 characters. The predictionstring corresponds to the index of the words in the essay and the predicted discourse type for this sequence of words should be correct. Most used words per Discourse TypeInitially I did a manual effort to find out which single words were used most often. NER IntroductionFirst I am ging to convert the words in all train discourses into NER labels. The length of 19 words seems correct to me and the length of the predictionstring also really seems to be 18. Most students also had at least one Concluding Statement. There can be partial matches if the correct discourse type is predicted but on a longer or shorter sequence of words than specified in the Ground Truth. The graph only plots discourse_type_nums which are found in at least 3 of the essays. Investigation the gaps between Annotations text not used as discourse_text Just taking the last discourse_end in train is not entirely correct as a last piece of text may not have been used as a discourse. GSU awards more bachelor s degrees to African Americans than any other non profit college or university in the country. Evidence is the longest discount type on average. This enables me to make a function that uses the code made by Sanskar Hasija to color print an essay including the gaps. com cdeotte pytorch bigbird ner cv 0 615 Please upvote his notebook but tried to make it a little easier to understand. Please stay tuned The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell add columns add thousands separator if you are interested in other discourse_types you can add them to the list in df. You ll have access to the largest dataset of student writing ever released in order to test your skills in natural language processing a fast growing area of data science. com odins0n feedback prize eda but adjusted to df_essay get stopwords from nltk library put dataframe of Top 10 words in dict for all discourse types https www. One thing to notice is that however is used a lot in Rebuttal. Making n_grams for each discourse typeAfter the manual effort above I was not fully pleased with the result and decided that I wanted to make a function to compose Top 10 n_grams per discount type by using CountVectorizer. If successful you ll make it easier for students to receive feedback on their writing and increase opportunities to improve writing outcomes. First we have to make a dataframe with all full texts of the essays in a dataframe. Length and frequency and relative position per discourse_typeIs there a correlation between the length of a discourse and the class discourse_type Yes there is. Is this always correct No I find 468 discourses where this goes wrong by one word Let s check the first one. Something to keep in mind. The code is nice but did not print the gaps yet. Below I have also made a function that prints the results in this dataframe as subplots. When looking at the frequencies of occurence we see that Counterclaim and Rebuttal are relatively rareWe do have the field discourse_type_num. GSU and The Learning Agency Lab an independent nonprofit based in Arizona are focused on developing science of learning based tools and programs for social good. Below you can see the distributions of the discourse types of the first and last discourses identified. The open sourced algorithms you come up with will allow any educational organization to better help young writers develop. The train dataset gives us the following human annotations that are extracted from this essay. After this effort I was not sure how useful this is. If you are still interested in my manual effort for the single words you can unhide the code in the cell below. Lenght of the discourse_text and predictionstringFirst I would like to check if the discourse_text and the predictionstring always have the same number of words as they should. This function return one dataframe with 70 rows the top 10 most used n grams for each discourse type. Below I am also plotting the trigrams using both functions in one go. Introduction to the competitionBasically we have a bunch of essays written by kids in the age range of about 12 18 years old in which we have to find word sequences that can be classified as one of 7 discourse types. com raghavendrakotala fine tunned on roberta base as ner problem 0 533 please be aware that since I used df. com odins0n feedback prize eda. Below you can see a plot with the average positions of the discourse start and end. Kaggle gives us the following field descriptions id ID code for essay response discourse_id ID code for discourse element discourse_start character position where discourse element begins in the essay response discourse_end character position where discourse element ends in the essay response discourse_text text of discourse element discourse_type classification of discourse element discourse_type_num enumerated class label of discourse element predictionstring the word indices of the training sample as required for predictionsThe Ground Truth here is a combination of the discourse type and the prediction string. I am also interested in the relative positions of discourse types with the essays. until I remebered that Rob Mulla already did that in the excellent EDA https www. In this competition you ll identify elements in student writing. Below you can see that if there is a Lead it s almost always the first discourse identified in an essay Lead 2 is very rare anyway. ", "id": "erikbruin/nlp-on-student-writing-eda", "size": "8399", "language": "python", "html_url": "https://www.kaggle.com/code/erikbruin/nlp-on-student-writing-eda", "git_url": "https://www.kaggle.com/code/erikbruin/nlp-on-student-writing-eda", "script": "get_n_grams glob CountVectorizer matplotlib.style nltk.corpus stopwords numpy matplotlib.pyplot sklearn.feature_extraction.text add_gap_rows tqdm.notebook pandas plot_ngram FuncFormatter print_colored_essay tqdm matplotlib.ticker ", "entities": "(('that', 'discourse_type'), 'take') (('how many pieces', 'https www'), 'copy') (('that', 'one essay'), 'look') (('News World Report', 'nation'), 'rank') (('More specifically you', 'grade 6th 12th students'), 'segment') (('only which', 'essays'), 'plot') (('I', 'essays'), 'be') (('almost always first discourse', 'essay'), 'see') (('Therefore I', 'real ends'), 'go') (('discourse_end', 'sometimes essay_len'), 'see') (('you', 'df'), 'stay') (('you', 'cell'), 'be') (('0 533 I', 'df'), 'tun') (('necessarily text', 'discourse'), 'be') (('GSU', 'social good'), 'focus') (('function', 'n_grams'), 'work') (('Below you', 'first discourses'), 'see') (('I', 'Chris notebook https great www'), 'use') (('stopwords', 'types https discourse www'), 'com') (('that', 'subplots'), 'make') (('also Lead', 'essays'), 'know') (('Counterclaim', 'discourse_type_num'), 'see') (('student', 'multiple times essay'), 'find') (('First we', 'dataframe'), 'have') (('com feedback Color prize 2021 298193 printing essays', 'Sanskar Hasija https www'), 'discussion') (('those', 'essay'), 'be') (('code', 'gaps'), 'be') (('Below I', 'one go'), 'plot') (('Below you', 'discourse start'), 'see') (('teachers', 'grading time'), 'leverage') (('discourse_text text', 'here discourse type'), 'give') (('Rob Mulla', 'EDA https excellent www'), 'remebere') (('making', 'n_grams'), 'decide') (('function', 'CountVectorizer'), 'make') (('that', 'claims counterclaims'), 'be') (('they', 'words'), 'like') (('single words', 'manual effort'), 'use') (('how this', 'effort'), 'be') (('that', 'gaps'), 'enable') (('that', 'essay'), 'give') (('I', 'punctuation'), 'take') (('NER I', 'NER labels'), 'IntroductionFirst') (('s', 'first one'), 'be') (('discourse partial correct type', 'Ground Truth'), 'be') (('you', 'student writing'), 'identify') (('Most students', 'Concluding also at least one Statement'), 'have') (('Lead', 'essays'), 'be') (('corresponds', 'words'), 'be') (('it', 'notebook'), 'cv') (('function', 'discourse type'), 'return') (('outliers', 'longer 300 characters'), 'see') (('length', 'predictionstring'), 'seem') (('first word', 'I.'), 'have') (('Evidence1 Position1', 'almost always there essay'), 'see') (('title', 'discourse'), 'be') (('One thing', 'however lot Rebuttal'), 'be') (('that', 'discourse type'), 'make') (('You', 'data science'), 'have') (('entirely last piece', 'discourse'), 'be') (('we', 'those'), 'be') (('that', '7 discourse types'), 'introduction') (('students', 'writing outcomes'), 'make') (('Some', 'discourse types'), 'have') (('Feedback Evaluating Student WritingGeorgia State University GSU', 'research undergraduate urban public Atlanta'), 'Prize') (('above we', 'essays'), 'have') ", "extra": "['annotation', 'organization', 'outcome', 'test']"}
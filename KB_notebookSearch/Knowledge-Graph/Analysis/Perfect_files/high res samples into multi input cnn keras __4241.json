{"name": "high res samples into multi input cnn keras ", "full_name": " h1 High res samples into multi input CNN h1 Image preparation h1 Train our future input branch h1 Build the core model h1 Make predictions using our newly trained model h3 If you found this notebook helpful please give it an upvote It is always greatly appreciated ", "stargazers_count": 0, "forks_count": 0, "description": "Make predictions using our newly trained modelTime to predict on new data We use the function to retrieve random samples from the original full size images and simply feed it to the model. Now time to build the model. High res samples into multi input CNNThis notebook will go through the steps required to take some high resolution samples from an image and feed them into a multi input CNN. Time to use our custom generator which loads 3 samples into the branches. We need to use it both for our training data and validation data. We use 100 images from the training set. The activation layer for our output is set to softmax with 6 units representing the gradient from 0 to 5. Generate paths to the input files and a list with corresponding groundtruthWe re quickly shuffling the data and split the dataframe in two in order to keep a validation set. Version notes V7 Stacked images randonly sampled and feed them into a ResNet50 score 0. Train our future input branchWe build a fairly basic CNN that will be trained using random 256x256pixel samples and the gleason score. The gleason score will be calculcated from the corresponding masks for each image. We have an input_branch function that will generate the 3 input branches with our pretrained weights before merging them together. Due to the random sampling we will do 3 passes on each image to increase our chances of finding the cancerous zones and keep the mean of all grades. It ensures there is actually some kind of content in the returned sample and give the associated groundtruth. The model will never see the entire image and only three 256x256 pixels samples. Build the core modelBelow we have our custom generator which will use the function to generate original scale 256x256 images from random samples. Be careful if you decide to add data augmentation into your custom generator as your performance on the validation set will be biased. In future version we will try to optimise the sampling strategy. If it finds the folder it will load test. If you found this notebook helpful please give it an upvote. 15 V9 Apply to the model 3 times over each image at prediction time score 0. This version brings so minor changes to try to fix that. 32 V11 Take the mean from the predicted isup score over 5 runs instead of the max over 3 runs score 0. csv and apply predictions before saving the submission file. The 3 input branches have their weight mostly frozen as they have already been trained using the gleason score. 34 V12 Now train the input branches first before training a model with 3 input branches with the input branches mostly frozen. We create a custom generator that will randomly take samples from each full scale image. This approach assumes that there is more value to learn from high resolution local areas in an image than a resized version of the entire image. In previous versions of this notebook I tried to stack the three samples together and feed as one input into a ResNet50 but the model never learnt. One last check to ensure that the predict_submission function works as intended. The architecture itself will need some additional tuning later. V14 Reduce the number of epochs in order to run in less than 6 hours and submit the notebook. The passes parameter will decide how many times we attempt to predict on a given image. Image preparationJust to double check. We know generate images with 3 images with 3 channels each. To finish we add a condition that will check that the test images are available when running the notebook in submission mode. In this case add a parameter to your custom generator to activate the augmentation. It could also be set to linear if we approached this as a regression problem. We can check that the function works by displaying the random samples that will be used as inputs. 0 V8 Randomly samples 3 images at full resolution and feed them into a multi input CNN score 0. V13 It appeared that the model training was sometimes unstable as seen in V12 s log. It is always greatly appreciated remove all image file that don t have a mask file check that the sample is not empty and use the standard deviation to make sure there is something happening in the sample check that the sample is not empty and use the standard deviation to make sure there is something happening in the sample. To do so we will use a custom generator which will prepare the images live as we build the batches during training. ", "id": "frlemarchand/high-res-samples-into-multi-input-cnn-keras", "size": "4241", "language": "python", "html_url": "https://www.kaggle.com/code/frlemarchand/high-res-samples-into-multi-input-cnn-keras", "git_url": "https://www.kaggle.com/code/frlemarchand/high-res-samples-into-multi-input-cnn-keras", "script": "Flatten sklearn.utils sklearn.metrics randint Reshape cohen_kappa_score tensorflow.keras.layers get_single_sample get_random_samples GlobalAveragePooling2D VGG16 random tensorflow.keras.preprocessing.image tensorflow.keras.callbacks predict_submission EarlyStopping Dropout Sequential tensorflow.keras.models keras.losses shuffle Conv2D mean_squared_error numpy tensorflow.keras.applications input_branch shutil custom_single_image_generator Input ReduceLROnPlateau branch ModelCheckpoint InputLayer ImageDataGenerator copyfile matplotlib.pyplot Activation Dense tensorflow ResNet50 pandas tensorflow.keras tqdm move BatchNormalization Callback Model layers MaxPooling2D keras custom_generator ", "entities": "(('V14', 'notebook'), 'reduce') (('that', 'random 256x256pixel samples'), 'train') (('gleason score', 'image'), 'calculcate') (('version', 'that'), 'bring') (('mostly they', 'gleason already score'), 'have') (('approach', 'entire image'), 'assume') (('We', 'model'), 'make') (('It', 'associated groundtruth'), 'ensure') (('which', 'random samples'), 'have') (('model', 'ResNet50'), 'learn') (('we', 'sampling strategy'), 'try') (('that', 'them'), 'have') (('Randomly', 'input CNN multi score'), 'sample') (('architecture', 'additional tuning'), 'need') (('15 V9', 'prediction time score'), 'Apply') (('sample', 'sample'), 'appreciate') (('which', 'branches'), 'time') (('model', 'entire image'), 'see') (('how many times we', 'given image'), 'decide') (('model training', 'sometimes log'), 'V13') (('We', 'training both data'), 'need') (('we', 'grades'), 'do') (('V7 Stacked images', 'ResNet50 score'), 'note') (('performance', 'validation set'), 'be') (('notebook', 'upvote'), 'give') (('that', 'scale full image'), 'create') (('We', '3 channels'), 'know') (('notebook', 'input multi CNN'), 'sample') (('input 3 branches', 'input branches'), 'train') (('also we', 'regression problem'), 'set') (('32 V11', 'runs instead over 3 score'), 'take') (('activation layer', '5'), 'set') (('groundtruthWe', 'validation set'), 'shuffle') (('test images', 'submission mode'), 'add') (('we', 'training'), 'use') (('that', 'inputs'), 'check') (('it', 'test'), 'load') ", "extra": "['test']"}
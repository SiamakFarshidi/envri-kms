{"name": "02 decimerplus efficientnetv2 transformer ", "full_name": " h1 Bristol Myers Squibb Molecular Translation h2 Image Captioning End to End Pipeline EfficientNetV2 h1 TABLE OF CONTENTS h3 0 xa0 xa0 xa0 xa0IMPORTS h3 1 xa0 xa0 xa0 xa0BACKGROUND INFORMATION h3 2 xa0 xa0 xa0 xa0SETUP h3 3 xa0 xa0 xa0 xa0HELPER FUNCTIONS h3 4 xa0 xa0 xa0 xa0PREPARE THE DATASET h3 5 xa0 xa0 xa0 xa0MODEL PREPARATION h3 6 xa0 xa0 xa0 xa0DATASET CREATION h3 7 xa0 xa0 xa0 xa0CUSTOM MODEL TRAINING h3 8 xa0 xa0 xa0 xa0INFER ON TEST DATA h1 0 xa0 xa0IMPORTS xa0 xa0 xa0 xa0 h1 1 xa0 xa0BACKGROUND INFORMATION xa0 xa0 xa0 xa0 h1 2 xa0 xa0SETUP xa0 xa0 xa0 xa0 n h3 2 1 ACCELERATOR DETECTION h1 The name you gave to the TPU to use h1 or you can also specify the grpc path directly h1 TPU WORKER grpc xxx xxx xxx xxx 8470 h1 The zone you chose when you created the TPU to use on GCP h1 The name of the GCP project where you created the TPU to use on GCP h3 2 2 COMPETITION DATA ACCESS h3 2 3 LEVERAGING MIXED PRECISION h3 2 4 LEVERAGING XLA OPTIMIZATIONS h3 2 5 BASIC DATA DEFINITIONS INITIALIZATIONS h3 2 6 INITIAL DATAFRAME INSTANTIATION h3 2 7 USER INPUT VARIABLES h1 n 3 xa0 xa0HELPER FUNCTION CLASSESS xa0 xa0 xa0 xa0 n h3 3 1 GENERAL HELPER FUNCTIONS h1 4 xa0 xa0PREPARE THE DATASET xa0 xa0 xa0 xa0 h3 4 1 READ TFRECORD FILES CREATE THE RAW DATASET S h3 4 2 WHAT TO DO IF YOU DON T KNOW THE FEATURE DESCRIPTIONS OF THE DATASET h1 See an example h3 4 3 PARSE THE RAW DATASET S h3 4 4 WORKING WITH TF DATA DATASET OBJECTS h1 5 xa0 xa0MODEL PREPERATION xa0 xa0 xa0 xa0 h3 5 1 UNDERSTANDING THE MODELS ENCODER h3 5 2 UNDERSTANDING THE MODELS TRANSFORMER h3 5 2 0 TRANSFORMER HYPERPARAMETERS h3 5 2 1 TRANSFORMER POSITIAL ENCODING h3 5 2 2 TRANSFORMER MASKING h3 5 2 3 TRANSFORMER SCALED DOT PRODUCT ATTENTION h3 5 2 4 TRANSFORMER MULTI HEAD ATTENTION h3 5 2 5 TRANSFORMER POINT WISE FEED FORWARD NEURAL NETWORK h3 5 2 6 TRANSFORMER ENCODER DECODER NETWORK ARCHITECTURE OVERVIEW h3 5 2 7 TRANSFORMER ENCODER h3 5 2 8 TRANSFORMER DECODER LAYER COMPONENT h3 5 2 9 TRANSFORMER ENCODER COMPONENT h3 5 2 10 TRANSFORMER DECODER COMPONENT h3 5 2 11 TRANSFORMER PUT IT ALL TOGETHER h3 5 3 CREATE A LEARNING RATE SCHEDULER h3 5 4 WRAP THE CONFIGURATION DETAILS IN A CLASS OBJECT FOR EASY ACCESS h3 5 5 HOW TPU IMPACTS MODELS METRICS AND OPTIMIZERS h3 5 6 LOSS CLASSES AND REDUCTION h3 5 7 DISTRIBUTE THE DATASETS ACROSS REPLICAS h3 5 8 DISTRIBUTED COMPUTATION OPTIMIZING LOOPS h1 6 xa0 xa0MODEL TRAINING xa0 xa0 xa0 xa0 h3 6 1 INDIVIDUAL TRAIN STEP h3 6 2 INDIVIDUAL VAL STEP h3 6 3 INITIALIZE LOGGER h3 6 4 CUSTOM TRAIN LOOP h3 6 4 1 \u7b5b\u9009\u51fatokenS\u957f\u5ea6\u4e0d\u8d85\u8fc747\u7684\u5206\u5b50 \u4e14\u5747\u5728\u8bcd\u5178\u4e2d h3 6 4 2 decimer\u4ee3\u7801\u751f\u6210\u56fe\u7247\u7edf\u8ba1\u7ed3\u679c h3 6 4 3 \u539f\u59cb\u56fe\u7247\u7edf\u8ba1\u7ed3\u679c\u53ca\u53ef\u89c6\u5316 h3 6 4 3 \u53ef\u89c6\u5316\u7ed3\u679c h3 6 4 2 \u9884\u6d4b\u8f93\u51fa h2 6 4 1 small is good h2 6 4 2 large is good h2 6 4 1 heat h2 6 5 JUST IN CASE SAVE h3 6 5 JUST IN CASE SAVE h3 6 6 VIEW PREDICTIONS DISTRIBUTION OF LEVENSHTEIN DISTANCE FOR VAL DATASET h3 6 7 smiles and inchi lsd h1 7 xa0 xa0INFER ON TEST DATA xa0 xa0 xa0 xa0 h3 7 1 INDIVIDUAL TEST STEP AND DISTRIBUTED h3 7 2 RAW INFERENCE LOOP h3 7 3 TEST PRED POST PROCESSING h3 7 4 SAVE SUBMISSION CSV ", "stargazers_count": 0, "forks_count": 0, "description": "DataFrame df_final image_id 0 df_final w 0 df_final h 0 df_final lsd 0 df pd. name def download_to_kaggle bucket_name destination_directory file_name Takes the data from your GCS Bucket and puts it into the working directory of your Kaggle notebook os. We say an operation is numerically unstable in float16 or bfloat16 if running it in one of those dtypes causes the model to have worse evaluation accuracy or other metrics compared to running the operation in float32. Warmup is commonly used in learning rate schedule where we start training a model with a much smaller learning rate and increase it during the first few epochs steps until the initial learning rate is used. TFRecordDataset filenames num_parallel_reads N_PARALLEL dataset dataset. In other words the mask indicates which entries should not be used. Define a parsing function by using tf. N encoder layersThe input is put through an embedding which is summed with the positional encoding. Dense 72 name logit_dense2 activation sigmoid logit 2 591 logit self. nbsp REFERENCES Guide Use TPUs Doc TPUClusterResolver2. Chem import AllChem from rdkit. where ls END_TOKEN 0 0 print p_s pred_s lbls_s LDS image_ids val_dist_ds iter strategy. nbsp REFERENCE TF Tutorial Transformer Model for Language Understanding TF Tutorial Image Captioning TF Tutorial Neural Machine Translation w Attention5. . apply sin to even indices in the array 2i angle_rads_row get_angles tf. You define the operations for example forward pass compute loss values and gradients etc. append pre_smiles_ecfp pre_ecfp tf. Unless using a high level API like model. index_word x for x in p l_s. legend Confidence RECALL plt. loc ind lsd row LDS_ALL print df_final. 1 READ TFRECORD FILES CREATE THE RAW DATASET S Here we will leverage tf. These are effectively a list of tensors of length num_attention_heads where the corresponding shapes are batch_size 1 key_dim batch_size 1 key_dim batch_size 1 value_dim Then the query and key tensors are dot producted and scaled see previous section. numpy m1 Chem. Without them I wouldn t have been able to make this Awesome Notebook For Best Practices in Distributed Computing The Amazing Mark Wijkhuizen s TPU Training Notebook For This CompetitionTABLE OF CONTENTS 0 nbsp nbsp nbsp nbsp IMPORTS 1 nbsp nbsp nbsp nbsp BACKGROUND INFORMATION 2 nbsp nbsp nbsp nbsp SETUP 3 nbsp nbsp nbsp nbsp HELPER FUNCTIONS 4 nbsp nbsp nbsp nbsp PREPARE THE DATASET 5 nbsp nbsp nbsp nbsp MODEL PREPARATION 6 nbsp nbsp nbsp nbsp DATASET CREATION 7 nbsp nbsp nbsp nbsp CUSTOM MODEL TRAINING 8 nbsp nbsp nbsp nbsp INFER ON TEST DATA0 nbsp nbsp IMPORTS nbsp nbsp nbsp nbsp 10514 1 nbsp nbsp BACKGROUND INFORMATION nbsp nbsp nbsp nbsp 10514 PRIMARY TASK DESCRIPTION Given an image our goal is to generate a caption. function as shown by python tf. dist_ds strategy. join x for x in p l_s. groupby loss group. pool x x 2 72 208 img_logit self. string dist_test_ds iter strategy. shape batch_size seq_len vocab_size prediction_batch attention_weights decoder _image_logit decoder_pred_batch training False look_ahead_mask combined_mask prediction_batch attention_weights decoder _image_embedding _image_logit decoder_pred_batch training False look_ahead_mask combined_mask Update Loss Accumulator Update Accuracy Metric no teacher forcing predicted char is next transformer input Update Loss Metric def __init__ self verbose_frequency 100 print_style tight f ACC str self. 1 3 This query aligns equally with the first and second key so their values get averaged. 4 LEVERAGING XLA OPTIMIZATIONS XLA Accelerated Linear Algebra is a domain specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes. The attention output for each head is then concatenated using tf. org api_docs python tf distribute in general certain objects will have to be created inside the strategy s scope Here is the rule of thumb Anything that creates variables that will be used in a distributed way must be created inside strategy. numpy pred_s. not_equal lbls END_TOKEN tf. inchi_lsd 0 print df_1 df_1 inchi_lsd 0 inchi_lsd. groupby w h lsd. decode utf 8 selfies_df pd. nbsp NOTE The parsed images are tf. csv import pandas as pd from sklearn. shuffle shuffle_buffer_size dataset dataset. transpose and tf. Multi head attention consists of four parts Linear layers and split into heads. val_loss_cls val_acc_seq stat_logger. array pre_smiles_ecfp euclidean spatial. function def replica_fn batch tensor0. 3 TRANSFORMER SCALED DOT PRODUCT ATTENTION Scaled dot product attention is an attention mechanism where the dot products are scaled down by sqrt d_k. numpy en_l encoder_logit. The attention function used by the transformer takes three inputs Q query K key V value The equation used to calculate the attention weights is Large Attention Q K V softmax_k frac QK T sqrt d_k V The dot product attention is scaled by a factor of square root of the depth. This is done because for large values of depth the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. softmax is normalized on the last axis seq_len_k so that the scores add up to 1. Policy typically referred to as a dtype policy. n print f t t t TRUNCATED VALUE v. The tensors are then interpolated by these probabilities then concatenated back to a single tensor. This should give you enough information to define the feature description. tfrec key lambda x int x. csv index False import os os. What is most impressive about these methods is a single end to end model can be defined to predict a caption given a photo instead of requiring sophisticated data preparation or a pipeline of specifically designed models. For example consider that Q and K have a mean of 0 and variance of 1. csv target jaccard_all listBins 0 0. There are N encoder layers in the transformer. apply lambda x x 2 1 if len df_1 df_1 image_id. where l END_TOKEN 0 0 l_s. ParseFromString serialized_example. An example of iterating over a distributed dataset is python for dist_batch in dist_ds dist_step dist_batch Every step in the loop which calls strategy. At this time we only want to use the raw no pretraining headless features with no pooling. NVIDIA GPUs can run operations in float16 faster than in float32 TPUs can run operations bfloat16 faster than in float32 Therefore these lower precision dtypes should be used whenever possible on those devices. grid print pre_smiles_ecfp print 1 if i 0. values 0 selfies_label_1 df df image_id_all image_id selfies_labels_all. TEST DATA DIRECTORY PATH IS n t TEST_DATA_DIR Set Mixed Precision Global Policy To use mixed precision in Keras you need to create a tf. The input sequennce image embedding sequence in our case is passed through N encoder layers that generates an output for each word token in the sequence. parse and return a dataset w the appropriate configuration Load the dataset Fake Images Fake IDs If we are training than we will want to repeat the dataset. As the softmax normalization is done on K its values decide the amount of importance given to Q The output represents the multiplication of the attention weights and the V value vector. The positional encoding vector is added to the embedding vector. run replica_fn args dist_batch where replica_fn expects a single tensor as arugment. PROJECT my tpu project tpu tf. If we utilized EfficientNetV2B7 we would have 2560 feature maps instead of the 1280 feature maps that EfficientNetV2B0 produces. MolDrawing import MolDrawing DrawingOptions Only needed if modifying defaults df pd. org api_docs python tf distribute Strategy run each replica receives a part of the batch andcalculates the loss values separately. map lambda x decode x is_test tokenized_smile num_parallel_calls N_PARALLEL return dataset def get_dataset filenames batch_size is_test False shuffle_buffer_size 1 repeat_dataset True preserve_file_order False drop_remainder True tokenized_smile True external_smile_dataset None Get a tf. append r 0 j jaccard pre_smiles_ecfp encoder_logit i jaccard_all. values 0 image_id_1 image_id 2 1 print print f image id k w i. where l END_TOKEN 0 0 p_s selfies_decoder p_s compatible True pre_smiles_ecfp simies_to_ecfps p_s l_s selfies_decoder l_s compatible True l_smiles_ecfp simies_to_ecfps l_s pre_smiles_ecfp_batch. The output of each sublayer is LayerNorm x Sublayer x. shape N_PE_POS 72 N_PE_POS 101 D_FF 1024 add extra dimensions to add the padding to the attention logits. This can be found on the GCP project dashboard page. Dataset object options tf. This will vastly reduce the running time and limit the time TPUs will sit idle waiting for data from the local VM. set_index w h df_g2 df_g1. 1 TRANSFORMER POSITIAL ENCODING Since this model doesn t contain any recurrence or convolution positional encoding is added to give the model some information about the relative position of the words in the sentence. values 0 preds_selfies df_1 df_1 image_id_all image_id preds_selfies_all. nbsp WARNING XLA can not currently compile functions where dimensions are not inferrable that is if it s not possible to infer the dimensions of all tensors without running the entire computation nbsp NOTE XLA compilation is only applied to code that is compiled into a graph in TF2 that s only a code inside tf. 5 BASIC DATA DEFINITIONS INITIALIZATIONS 2. Therefore it is impossible in general to obtain the averaged per example loss over the whole distributed batch from by simply dividing it by the number of replicas. blob destination_blob_name blob. title f IMAGE smile. train_acc_seq val_loss_seq stat_logger. In this notebook we use a fixed number of training steps so we can also use python tf. apply lambda x x 2 1 k 0 smiles_dir f. Hence square root of dk is used for scaling and not any other number because the matmul of Q and K should have a mean of 0 and variance of 1 and you get a gentler softmax. 3 INITIALIZE LOGGER INFORMATION6. decode for x in tqdm all_pred_ids 1 REQUIRED_DATASET_PAD. get_gcs_path automl efficientdet efficientnetv2 effnetv2 gs kds f58e6eb872f6e631a1a7b17a5028b74b70a853301aacf67c57cb95a3 Installs Pips text chemfp 3. TFRecordDataset to read files in parallel. numpy total N_TEST pred_df pred_df. In particular the following methods and attributes are of special interest to us Use num_parallel_reads in tf. experimental_deterministic False and use it to get a new dataset that ignores the order of elements. join list map str pre_smiles_ecfp pred_s lbls_s LDS image_ids val_dist_ds iter strategy. Here we will call this approach a learning rate schedule. reset_index print df_g2. 3 LEVERAGING MIXED PRECISION Mixed precision is the use of both 16 bit and 32 bit floating point types in a model during training to make it run faster and use less memory. We also have to discuss how to collect the returned values from strategy. seq_len_q seq_len_k shape. compute_fingerprint mol return fp pattern 00000000000000000000020040000002000000000000000000000000000000000000000000000004040000000000000400000000000000000000000100000000000000000000000000000000000000000004010000008000004000000000000000200000000000800002000002000000011000080000000000000000000040000080800002000000010000040000000000010000000000000000000000000000000000000012000000000000100000000000000000100000000000000000008011000000000000001008000000000000000000000000000000204200000080000000000000000000000002000000000000000000000000000000000000000000 p_li fpstolist pattern pattern_2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 smil O CC CC1 C C C ON C C C OC CC1 a simies_to_ecfps smil a_hex simies_to_ecfps_hex smil hex_text_1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 s_text 00400020000000000000010000000000000000000000010000820000000000000000000000800000040000000000000408000000000000000000000040000000000000000000000000000008000000000004040000000000000000000800000000000000808000000000000000000000000000408000000000000000001000080000000002000000002000000000000200000000000000000000000000004000000000000000000000000000100040000200000000100000000100000000000000000100000000000000000000000000000000200000000000000000000000001000000000000000000402000000002000000000000000200000000000000000 print hex_text_1 fpstolist s_text sel O C Branch1_1 Branch2_2 C N C C N Ring1 Branch1_1 C C C N Branch1_1 C C C C N Branch1_1 C C C Ring1 Branch2_1 ls 9 7 3 4 19 2 12 2 3 5 6 4 2 2 2 5 4 2 2 2 2 5 4 2 2 2 6 13 10 0 0 0 print ls print END_TOKEN print np. append confirence_loss listBins_1 0 confirence_loss loss_all_max listLabels_1 0 1 df loss pd. OF TRAIN VAL EXAMPLES N_EX 1 C 2 C 3 Branch1_1 4 Ring1 5 N 6 O 7 Branch1_2 8 9 10 Expl Ring1 11 Branch2_1 12 N 13 S 14 Branch1_3 15 O 16 Ring2 17 F 18 Branch2_2 19 Cl 20 Branch2_3 21 C 22 Br 23 P 24 S 25 I 26 P 27 B 28 N 29 Expl Ring2 30 0 1 2 C 3 C 4 Branch1_1 5 Ring1 6 N 7 O 8 Branch1_2 9 10 11 Expl Ring1 12 Branch2_1 13 N 14 S 15 Branch1_3 16 O 17 Ring2 18 F 19 Branch2_2 20 Cl 21 Branch2_3 22 C 23 Br 24 P 25 S 26 I 27 P 28 B 29 N 30 Expl Ring2 0 for i in range len sel print str. iterrows ind df_final df_final image_id str row image_id_all 2 1. However variables and a few computations should still be in float32 for numeric reasons so that the model trains to the same quality. RAW TFRECORD INVESTIGATION TO DETERMINE FEATURE DESCRIPTIONS COMPLETED. function Kaggle Discussion TPU Extreme Optimizations Kaggle Notebook Custom Training Loop With 100 Flowers on TPU6 nbsp nbsp MODEL TRAINING nbsp nbsp nbsp nbsp 10514 In this section we will define the training and validation routines as well as the final custom training loop that will execute everything we have worked on up until this point. ceil N_TEST OVERALL_BATCH_SIZE This is for padding our test dataset so we only have whole batches REQUIRED_DATASET_PAD OVERALL_BATCH_SIZE N_TEST OVERALL_BATCH_SIZE Modelling Information ATTN_EMB_DIM 192 print f n. trainable_variables decoder. DataFrame lbl_smile lbls_s pred_smile pred_s image_ids image_ids selfies_df. argmax prediction_batch axis 1 output_type tf. nbsp DEFINITION The term numeric stability refers to how a model s quality is affected by the use of a lower precision dtype instead of a higher precision dtype. function calls Prefixes and Their Respective Ordering Format ORDERING c h None b None t None m None s None i None h None t None m None Paths to Respective Image Directories TEST_DIR os. gather per_replica_seqs axis 0 pred_ids strategy. Datasets we will use for training and validation4. join bms_csv sample_submission_w_extra. However there are two lower precision dtypes float16 and bfloat16 each which take 16 bits of memory instead. org api_docs python tf data Dataset API we can use strategy. 02368 In gradient accumulation each replica receives several batches before the optimizer applies the graidents we divide the sum of per examples losses by the update size i. dump loss_pkl open loss_pkl. notebook import tqdm tqdm. gather _img_ids axis 0 return predictions pred_ids all_pred_arr tf. Dataset https www. val_lsd_seq pickle. get_cmap Set3 \u4f7f\u7528matplotlib\u4e2d\u7684\u989c\u8272\u76d8 plt. constant 2 dtype TARGET_DTYPE tf. 9 TRANSFORMER ENCODER COMPONENT The TransformerEncoder consists of 1. figure figsize 18 36 plt. whl Apt get Library used to easily calculate LD Built In Imports Visualization Imports efficientnet v2 efficientnet v1 Machine Learning and Data Science Imports For reference later EV2_NAME efficientnetv2 b2 EfficientNet Module Imports See EfficientNetV2 Base Config Detect hardware return appropriate distribution strategy TPU detection. string image_id features image_id Figure out the correct information to return if tokenized_smile else smile features smile w feature_dict w h feature_dict h def load_dataset filenames is_test False ordered False tokenized_smile True Read from TFRecords. MultiHeadAttention num_heads key_dim d_model self. mha2 attn2 attn2 out1 padding_mask Residual connection followed by layer normalization batch_size target_seq_len d_model batch_size target_seq_len d_model Residual connection followed by layer normalization batch_size target_seq_len d_model sample_decoder_layer_output _ _ sample_decoder_layer tf. readlines for i in range len lines ls lines i. uint8 all_pred_ids tf. 5 JUST IN CASE SAVE INFORMATION6. numpy en_log encoder_logit i en_log_a np. The normalization is done on the d_model last axis. RAW TFRECORD INVESTIGATION TO DETERMINE FEATURE DESCRIPTIONS STARTED. For optimal performance reading from multiple files at once and disregarding data order if ordered False. org api_docs python tf distribute Strategy run to perform a distributed computation on different TPU replicas each processes a part of the batch. In other words the decoder predicts the next word token by looking at the encoder output and self attending to its own output. positional_encoding positional_encoding_2d 6 12 232 self. experimental_local_results https www. If a dataset yield a single tensor you can do things like python tf. So after adding the positional encoding words feature representations will be closer to each other based on the similarity of their meaning and their position in the sentence feature vector in the d dimensional space. TPUClusterResolver tpu TPU_WORKER zone ZONE project PROJECT nbsp WARNING Although the Tensorflow documentation says it is the project name that should be provided for the argument project it is actually the Project ID that you should provide. apply lambda x get_lsd x pre_inchi x label_inchi axis 1 df_1. loc i image_id ls 0 w int ls 1 h int ls 2 lsd 0 print df_final. head target ecfps_cosine_all listBins 0 0. append j Reset the validation metrics as one epoch should not effect the next Print validation scores verbose logging step stop training when NaN loss is detected update learning rate lr_scheduler. append ecfps_cosine 0 0 r pearsonr pre_smiles_ecfp encoder_logit i pearsonr_all. Point Wise Feed Forward Neural Networks Each of these sublayers has a residual connection around it followed by a layer normalization. function def dist_run_on_dataset dist_ds for dist_batch in dist_ds dist_step dist_batch dist_process_dataset dist_ds This way all the operations conducted on the dataset are compiled into a graph which is sent to the remote TPU worker s for execution. Example messages and when iterated over it we get scalar string tensors. For example pythonfeature_description feature0 tf. chained_assignment None import matplotlib. experimental_distribute_dataset val_ds for j in range VAL_STEPS preds lbls _logit encoder_logit _val_pattern_batch _val_image_id_batch dist_val_step val_dist_ds tonimoto_list all_right_num get_levenshtein_distance_smiles preds lbls print all_right_num len lbls 100 pre_smiles_ecfp_batch for i p l in enumerate zip preds. PATHS TO CSVS print f t TRAIN CSV TRAIN_CSV_PATH print f t SS CSV SS_CSV_PATH When debug is true we use a smaller batch size and smaller model Distribution Information N_TRAIN 909353 N_VAL 100780 N_VAL 100000 N_VAL 450 N_VAL 5740 N_VAL 5704 N_TRAIN 921600 N_VAL 102400 N_VAL 5713 N_VAL 2538 N_VAL 272 N_TRAIN 10240 N_VAL 1024 Batching Information Could probably be 128 if DEBUG REPLICA_BATCH_SIZE BATCH_SIZE_DEBUG Input Image Information IMG_SHAPE 192 384 3 Autocalculate Training Validation Testing Information TEST_STEPS int np. But the embeddings do not encode the relative position of words in a sentence or in our case the localization of features as encoded by our efficientnetv2 encoder model. where l 2 0 0 LD Levenshtein. At each location in the sequence y the MultiHeadAttention runs all 8 attention heads across all other locations in the sequence returning a new vector of the same length at each location. input daily result levenshtein_distance_good_USPTO. The results of strategy. numpy total N_TEST smile arr_2_smile pred_arr for pred_arr in tqdm all_pred_arr 1 REQUIRED_DATASET_PAD. experimental_distribute_dataset val_ds LDS_ALL confidence_loss_cls_all auc_all ecfps_cosine_all pearsonr_all jaccard_all euclidean_all image_id_all smiles_all selfies_all selfies_labels_all labels_all batch_dis_all pre_smiles_ecfp_batch preds lbls _logit encoder_logit _val_pattern_batch image_id dist_val_step val_dist_ds _ batch_dis get_levenshtein_distance preds lbls image_id_all. get i if c break smile_str c return smile_str pred_df pd. In our case the name of the dataset is the name of the directory the dataset is mounted within. 5 HOW TPU IMPACTS MODELS METRICS AND OPTIMIZERSIn order to use TPU or tensorflow distribute strategy https www. sum accumulated_loss MAX_LEN BATCH_SIZE_DEBUG n n print 100 Just for printing prediction_batch _ decoder _image_pattern _smile_batch_input training True look_ahead_mask combined_mask prediction_batch _ decoder _image_embedding _image_pattern _smile_batch_input training True look_ahead_mask combined_mask Update Loss Accumulator Update Accuracy Metric backpropagation using variables gradients and loss split this into two seperate optimizers lrs etc in the future we use the batch loss accumulation to update gradients gradients tape. train_loss_seq train_loss_cls stat_logger. xxx 8470 The zone you chose when you created the TPU to use on GCP. append confirence_auc listBins_1 0 confirence_auc 1 listLabels_1 0 1 df auc pd. input daily result val_lsd_confidence_auc_4. csv df_a df df batch_dis_all 10 print len df_a df_2 df_a image_id_all. The mask is multiplied with 1e9 close to negative infinity. reshape and put through a final Dense layerInstead of one single attention head Q K and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. title title plt. Deep learning methods have demonstrated state of the art results on caption generation problems. edit_distance preds_sparse lbls_sparse normalize False print len np. size 299 299 m Chem. cast i 2 TARGET_DTYPE d_model return pos angle_rates 0 2 4. index_word x for x in ls 1 np. show print confirence_auc_list print auc_list print right_list import pandas as pd from sklearn. Parse example. Therefore for efficient utilization of Cloud TPU a program should make use of each of the EIGHT 4x2 cores. create_bucket dataset_name print Bucket created. range n_stes dist_step next dist_ds_iter dist_ds_iter iter dist_ds dist_process_dataset dist_ds_iter With the above discussions we are ready to define the routines used for training validation and prediction. csv print f n. experimental_distribute_dataset test_ds for i in tqdm range TEST_STEPS total TEST_STEPS img_batch id_batch next dist_test_ds preds pred_ids distributed_test_step img_batch id_batch all_pred_arr tf. Kaggle provides a utility library KaggleDatasets which has a utility function. mha2 enc_output1 enc_output2 out1 padding_mask enc_output1 enc_output1 enc_output2 attn2 attn_weights_block2 self. output of EfficientNetV2 The output of the decoder is the input to the linear layer and its output is returned. Because these kernels are unique to the model they can exploit model specific information for optimization. shape n tARGMAX tf. pkl wb epoch image_id_all_1 for i in range len image_id_all image_id_all_1. join destination_directory file_name blobs storage_client. py L361 when iterating over it. plot right_list plt. function def distributed_test_step _img_batch _img_ids per_replica_seqs strategy. MolFromSmiles smiles_dic image_id_1 lable_inchi Chem. append euclidean fpr tpr thredholds roc_curve pre_smiles_ecfp encoder_logit i auc_ auc fpr tpr auc_all. MultiHeadAttention num_heads key_dim d_model Feed Forward NN Layer Normalization Layers Dropout Layers enc_output. FixedLenFeature shape 1 dtype tf. function def dist_process_dataset dist_ds_iter for _ in tf. However the tuple now contains PerReplica objects wheras before that tuple contained tensors representing the image and the label id respectively. uint8 for c_idx in range 1 MAX_LEN prediction_batch hidden_batch memory_batch decoder decoder_input_batch hidden_batch memory_batch image_batch_embedding training False decoder_input_batch tf. 4 CUSTOM TRAIN LOOP INFORMATION 6. enable XLA optmizations 10 speedup when using tf. numpy 2 1 0 k k 1 image_id str w i. where l END_TOKEN 0 0 else l_s. take 2 example tf. batch_size 1 1 seq_len seq_len seq_len Used in the 1st attention block in the decoder. org api_docs python tf distribute Strategy run. get_gcs_path that will allow us to access the location of our input datasets within GCS. apply lambda x x 2 1 df_1 label_inchi df_1 image_id. Dataset as input pipeline Perform a custom training loop Correctly define loss function Gradient accumulation with TPUsMORE DETAIL ON IMAGE CAPTIONINGDescription From a Tutorial I Used As Reference Caption generation is a challenging artificial intelligence problem where a textual description must be generated for a given photograph. Scaled dot product attention. For example python tf. array LDS 0 0 len LDS 100 preds tf. metrics import roc_curve auc import plotly. The goal is to zero out these cells and large negative inputs to softmax are near zero in the output. name def upload_blob bucket_name source_file_name destination_blob_name Uploads a file to the bucket. Map the raw dataset by _parse_function. We will utilize a basic step function following a warmup phase. numpy i pattern _val_pattern_batch. We SHOULD NOT calculate the average of the per example losses on the partial batch the replica recieves. The dtype the layer s computations are done in 2. If not ordered this will ensure that we use data as soon as it streams in rather than in its original order. If we need to add on manually the smile Zip the datasets and tile the 1 channel image to 3 channels drop the old smile value Shuffling Batching prefetch next batch while training autotune prefetch buffer size Template Configuration Individual Respective Configurations test_ds get_dataset TEST_DS_CONFIG for SPLIT CONFIG in zip TRAINING VALIDATION TESTING TRAIN_DS_CONFIG VAL_DS_CONFIG TEST_DS_CONFIG TEST_DS_CONFIG TEST_DS_CONFIG plt. It ensures that the model does not treat padding as the input. 1 3 3 3 batch_size seq_len d_model batch_size seq_len d_model batch_size seq_len d_model batch_size num_heads seq_len_q depth batch_size num_heads seq_len_k depth batch_size num_heads seq_len_v depth scaled_attention. 3 PARSE THE RAW DATASET S The general recipe to parse the string tensors in the raw dataset looks something like this STEP 1. N decoder layersThe target is put through an embedding which is summed with the positional encoding. patches as patches import plotly. cut df LDS_ALL bins listBins right True labels listLabels retbins False precision 3 include_lowest True loss_all_min min df target loss_all_max max df target cut_n 100 cut_ran loss_all_max loss_all_min 100 print loss_all_max print loss_all_min print cut_ran loss_list confirence_loss_list right_list for i in range cut_n i i 1 confirence_loss loss_all_min i cut_ran if 100 i confirence_loss loss_all_min i cut_ran cut_ran 1000 confirence_loss_list. title size 20 plt. numpy 2 1 0 image_id str w i. 6 LOSS CLASSES AND REDUCTIONIn order to accurately calculate loss when leveraging a TPU we have to accumulate the losses that will be calculated across the individual replicas. newaxis d_model 2 angle_rads_col get_angles tf. These values are softmaxed to obtain attention probabilities. The scaled_dot_product_attention defined above is applied to each head broadcasted for efficiency. show print confirence_loss_list print loss_list 1 print right_list 1 import pandas as pd from sklearn. Masked Multi Head Attention with look ahead mask and padding mask 2. colab import drive drive. n def get_angles pos i d_model angle_rates tf. pythondef _parse_function example Args example A string tensor representing a tf. 1 ACCELERATOR DETECTION In order to use TPU we use TPUClusterResolver for the initialization which is necessary to connect to the remote cluster and initialize cloud TPUs. repeat if external_smile_dataset is not None dataset tf. shape batch_size num_heads seq_len_q depth attention_weights. com storage docs blobs storage_client. lstrip sel i print PAD_TOKEN print selfies_decoder selfies_encoder Cc1ccc Sc2ccc Sc3ccc C cc3 c C N c2C N cc1 def tf_load_image path img_size 192 384 3 invert False def decode_image image_data resize_to 192 384 3 sparse tensors are required to compute the Levenshtein distance preds tf. 2 nbsp nbsp SETUP nbsp nbsp nbsp nbsp 10514 2. append auc_ ecfps_cosine cosine_similarity pre_smiles_ecfp encoder_logit i ecfps_cosine_all. MolToInchi m logLevel None treatWarningAsError False return inchi df_1 pre_inchi df_1 preds_all. 6 VIEW PREDICTIONS DISTRIBUTION OF LEVENSHTEIN DISTANCE FOR VAL DATASET INFORMATION6. append lbls_s Create tf. We will use this method to collect the labels and model predictions We will need to iterate over the dataset to perform inference train on the whole distributed dataset. Let s go over two important points1. 4 WRAP THE CONFIGURATION DETAILS IN A CLASS OBJECT FOR EASY ACCESS 5. the number of examples used for one parameter update rather than by the size of a single distributed batch. There are N decoder layers in the transformer As Q receives the output from decoder s first attention block and K receives the encoder output the attention weights represent the importance given to the decoder s input based on the encoder s output. iterrows w. append p lbls_s. MolToInchi m1 logLevel None treatWarningAsError False if m None inchi Chem. where ls 10 p_s. TFRecordDataset TEST_TFREC_PATHS num_parallel_reads None feature_dict w tf. AUTOTUNE to automatically determine parallelization argument valuesThe parallel processing and prefetching are particular important when working with TPU This is because a TPU can process batches very quickly The dataset pipeline should be able to provide data for TPU efficiently otherwise the TPU will be idle. txt smiles_dic selfies_dic with open smiles_dir as file lines file. map _parse_function In the following cell we apply the above recipe to our BMS tfrecord dataset. This is incorrect. 2 RAW INFERENCE LOOP INFORMATION7. Options if not ordered options. 1 INDIVIDUAL TEST STEP AND DISTRIBUTED INFORMATION7. append pre_smiles_ecfp df pd. Finally the result tensor with the last dimension as value_dim can take an linear projection and return. This ensures that the words you want to focus on are kept as is and the irrelevant words are flushed out. Multi Head Attention with padding mask V value and K key receive the encoder output as inputs. In this case that image is of a single molecule and the description caption is the smile string for that molecule. On Kaggle this is always the case. numpy 0 0 len batch_distance. MolToInchi m logLevel None treatWarningAsError False draw Draw. numpy print sum pre_smiles_ecfp print sum 1 if i 0. int64 default_value 150 else Define a parser Decode the tf. AUTOTUNE else N_PARALLEL None dataset tf. constant 1 TARGET_DTYPE tf. This newly created raw dataset contains tf. n print n. argmax pred_output axis 1 print f nTHE CALCULATED INDIVIDUAL STEP LOSS n t loss_seq SAMPLE_LBLS i pred_output. The output of this summation is the input to the decoder layers. lev_dist log_y True val_dist_ds iter strategy. XLA provides us with an alternative mode of running models it compiles the TensorFlow graph into a sequence of computation kernels generated specifically for the given model. euclidean en_log_a pre_smiles_ecfp_a euclidean_all. head df_g df_final. 1 cp37 cp37m manylinux2014_x86_64. There is however a particularity about the loss function which we will discuss further down as well. groupby auc group. figure dpi 120 sns. 8 TRANSFORMER DECODER LAYER COMPONENT Each transformer decoder layer consists of sublayers 1. 7 DISTRIBUTE THE DATASETS ACROSS REPLICASWith an input pipeline written using the tf. FixedLenFeature shape dtype tf. nbsp NOTE For different encoder architectures we will have a different number of feature maps. 8 DISTRIBUTED COMPUTATION OPTIMIZING LOOPSFor each distributed batch which contains PerReplica objects as discussed previously produced by a distributed dataset we use strategy. shape sample_encoder_output sample_encoder img_logit training False mask None batch_size input_seq_len d_model def call self x enc_output1 enc_output2 training look_ahead_mask None padding_mask None adding embedding and position encoding. 55 else 0 for i in list en_log. batch batch_size drop_remainder drop_remainder dataset dataset. Modern accelerators can run operations faster in the 16 bit dtypes as they have specialized hardware to run 16 bit computations and 16 bit dtypes can be read from memory faster. bn1 img_logit training training x tf. concat all_pred_arr preds axis 0 all_pred_ids tf. plot loss_list 1 plt. If query key value are the same then this is self attention. extend image_id_all i df pd. 1 UNDERSTANDING THE MODELS ENCODER We will be leveraging an EfficientNetV2 https arxiv. Therefore we can see that for each replica we calculate the sum of per examples losses divided by the batch size of the whole distributed batch which will give the optimizer the correct gradients to apply. data Build TensorFlow Input Pipelines Guide Better Performance With the tf. rsplit _ 2 1 Paths to relevant CSV files containing training and submission information TRAIN_CSV_PATH os. com using learning rate schedules deep learning models python keras for a basic tutorial on learning rade schedules. csv from google. Q query receives the output from the masked multi head attention sublayer. The intuition behind this is as follows The gradients calculated on each replica will be synced across the replicas Therefore they are summed before the optimizer applies the gradients to update the model s parameters If we use the averaged per examples loss to compute the graident on each replica the final graident applied by the optimizer will correspond to the sum of these averaged per examples losses for respective replicas. for dist_batch in dist_ds strategy. 2 INDIVIDUAL VAL STEP INFORMATION6. join int_2_tok z for z in y i. val_acc 1 100 5 False df_1 print \u6e05\u6d17\u957f\u5ea6\u8d85\u8fc747 print len df_1 def smiles_to_inchi smiles m Chem. shape batch_size num_heads seq_len_q seq_len_k batch_size seq_len_q num_heads depth batch_size seq_len_q d_model batch_size seq_len_q d_model CUSTOM batch_size encoder_sequence d_model TF NATIVE INNER LAYER batch_size seq_len dff OUTPUT batch_size seq_len d_model returns batch_size input_seq_len d_model Potentially unncessary by passing dropout1 to tf. loc 1 LDS_ALL 100 right_list. head 100 df_2 df_1 df_1. Let s create a MultiHeadAttention layer to try out. decode_png The smile strings and Image IDs will just be left as byte string tensors. batch_size input_seq_len d_model batch_size input_seq_len d_model maximum_position_encoding 101 maximum_position_encoding 72 maximum_position_encoding 73 print img_embedding_batch print img_embedding_batch. 10 TRANSFORMER DECODER COMPONENT 1. Bristol Myers Squibb Molecular TranslationImage Captioning End to End Pipeline EfficientNetV2CREATED BY DARIEN SCHETTLER nbsp CREDIT TO THE FOLLOWING NOTEBOOKS I USED IN CREATING THIS KERNEL If you liked this notebook please upvote these other notebooks. shape batch_size input_seq_len d_model def call self x enc_output1 enc_output2 training look_ahead_mask None padding_mask None Residual connection followed by layer normalization batch_size target_seq_len d_model Merging connection between encoder and decoder MHA batch_size target_seq_len d_model attn2 attn_weights_block2 self. append l_s if 1 in p or 1 in l smiles_all. dec_layers i x enc_output1 enc_output2 training look_ahead_mask padding_mask x. shape batch_size target_seq_len d_model enc_output2 img_logit def call self enc_output1 enc_output2 t_tar def call self enc_output1 t_tar Modified by zjh bypass transformer encoder batch_size inp_seq_len d_model dec_output. input daily result smiles. This usually prevents breaking pretrained weights. In the cell below we will create the functions and configuration template which will later be used to create our respective datasets nbsp REFERENCE Guide tf. com c flower classification with tpus discussion 135443 for a good benchmark by Martin G\u00f6rner https www. train_loss_cls train_acc_seq stat_logger. Each timestep in query attends to the corresponding sequence in key and returns a fixed width vector. Inside the scope everything is defined in the same way it would be outside the distribution strategy. concat predictions_seq_batch decoder_input_batch axis 1 return predictions_seq_batch tf. index_word x for x in p selfies_all. pyplot as plt df pd. n else print f t t t TRUNCATED VALUE str v. reset_index drop True df_g11. decode utf 8 LDS. csv submission_e_14. concat x img_logit 1 Example enoder output print img_embedding_batch. numpy for i k v in enumerate example. plot right_list 1 plt. AUTOTUNE return dataset disable order increase speed If not ordered this will read in by automatically interleaving multiple tfrecord files. cut df LDS_ALL bins listBins right True labels listLabels retbins False precision 3 include_lowest True auc_all_min min df target auc_all_max max df target cut_n 100 cut_ran auc_all_max auc_all_min 100 auc_list confirence_auc_list right_list for i in range cut_n i i 1 confirence_auc auc_all_min i cut_ran if 100 i confirence_auc auc_all_min i cut_ran cut_ran 10000 confirence_auc_list. heatmap data df_g2 cmap plt. nbsp TIPS If you have multiple datasets attached to the notebook you should pass the name of a specific dataset to the get_gcs_path function. init_hidden_state image_batch_embedding training False decoder_input_batch tf. Recently deep learning methods have achieved state of the art results on examples of this problem. 1 GENERAL HELPER FUNCTIONS 4 nbsp nbsp PREPARE THE DATASET nbsp nbsp nbsp nbsp 10514 In this section we prepare the tf. run replica_fn args dist_batch The above code snippet is a high level concept and replica_fn doesn t necessary receive a single argument. The simplest way is to specify a list of filenames paths of TFRecord files. join TEST_DATA_DIR test_records Get the Full Paths to The Individual TFRecord Files TEST_TFREC_PATHS sorted tf. 2 COMPETITION DATA ACCESS TPUs read data must be read directly from G oogle C loud S torage GCS. pythondataset raw_dataset. int64 plt. append p_s pre_smiles_ecfp simies_to_ecfps p_s pre_smiles_ecfp_batch. SECONDARY TASK DESCRIPTIONIn this notebook we will go through step by step training models with TPUs in a custom way. LEARNING RATE SCHEDULE CREATION STARTING. The distributed datasets when working with TPU contain objects of type tensorflow. numpy print if j 0 break def simies_to_ecfps_hex smiles fptype chemfp. During training when a batch is distributed to the replicas https www. parse_single_example example feature_description return parsed_example STEP 3. Each TensorFlow operation has a precompiled GPU TPU kernel implementation that the executor dispatches to. numpy pre_smiles_ecfp_a np. 0 tensorflow python distribute values. newaxis d_model 2 SAMPLE IMAGES ENCODER_CONFIG This will be the dimension the network outputs flattened IMG_EMB_DIM 6 12 208 IMG_EMB_DIM 6 12 232 self. MolToImage m options opts plt. numpy print sum list en_log. pkl print ld_df. In our case the original dataset yields tuples of tensors A distributed batch is also a tuple of PerReplica objects and the replica_fn is actually receiving the unpacked version of a tuple of tensors as arguments. mha3 enc_output1 enc_output1 enc_output2 padding_mask attn2 attn_weights_block2 self. concat all_pred_ids tf. seq_len_q seq_len_k scale matmul_qk Calculate scaled attention logits add the mask to the scaled tensor. com tensorflow tensorflow blob v2. index_word x for x in p 1 np. append index 0 h. seq_len_q depth_v Set print options Demo inputs 4 3 4 2 This query aligns with the second key so the second value is returned. graph_objects as go import matplotlib. join bms_csv train_labels_w_extra. However on G oogle C ompute E ngine GCE you will need to do the following python The name you gave to the TPU to useTPU_WORKER my tpu name or you can also specify the grpc path directly TPU_WORKER grpc xxx. append 0 if 1 not in p and 1 not in l p_s selfies_decoder p_s compatible True smiles_all. 2 decimer\u4ee3\u7801\u751f\u6210\u56fe\u7247\u7edf\u8ba1\u7ed3\u679c 6. MultiHeadAttention if using tf MHA Residual connection followed by layer normalization returns batch_size input_seq_len d_model Point wise Feed Forward Step returns batch_size input_seq_len d_model Residual connection followed by layer normalization returns batch_size input_seq_len d_model sample_encoder_layer_output sample_encoder_layer img_logit training False mask None batch_size input_seq_len d_model WE COULD USE A CUSTOM DEFINED MHA MODEL BUT WE WILL USE TFA INSTEAD self. 4 TRANSFORMER MULTI HEAD ATTENTION This is an implementation of multi headed attention based on Attention is all you Need https arxiv. By keeping certain parts of the model in the 32 bit types for numeric stability the model will have a lower step time and train equally as well in terms of the evaluation metrics such as accuracy. expand_dims pred_ids axis 1 axis 0 def arr_2_smile arr smile_str for i in arr c int_2_tok. express as px import seaborn as sns from PIL import Image import matplotlib import plotly import PIL import cv2 df_final pd. The mask indicates where pad value 0 is present it outputs a 1 at those locations it outputs a 0 otherwise. The output of this summation is the input to the encoder layers. concat https www. Each multi head attention block gets three inputs Q query K key V value These are put through linear Dense layers and split up into multiple heads. show df_1 from rdkit import Chem from rdkit. To understand how strategy. loc 0 LDS_ALL len df 100 plt. When leveraging a TPU this is a non trivial task. numpy if z not in 0 1 2 n plt. org api_docs python tf distribute Strategy run are also distributed values just like the distributed batches it takes as inputs. function def dist_step dist_batch strategy. tensorN batch model tensor0. constant 10000 TARGET_DTYPE tf. This means that to predict the third token only the first and second tokens will be used. Concatenation of heads. The dtype of a layer s variables. uint8 predictions_seq_batch tf. json bucket_name example_zhang_kaggle_storage upload_blob bucket_name. run replica_fn args dist_batch for dist_batch in dist_ds dist_step dist_batch Here replica_fn is a function that is going to be run on each replica and it should work with tensors not with PerReplica objects. 1 3 This query aligns with a repeated key third and fourth so all associated values get averaged. map method to have parallel processing. csv selfies_df pd. In the following cell we will create a function to generate our encoder model. format source_file_name destination_blob_name def list_blobs bucket_name Lists all the blobs in the bucket. index_word x for x in l selfies_labels_all. 6 TRANSFORMER ENCODER DECODER NETWORK ARCHITECTURE OVERVIEW The transformer model follows the same general pattern as a standard sequence to sequence with attention model nmt_with_attention. org api_docs python tf function. py L361 which is a subclass of tf. append pre_smiles_ecfp confidence_loss_cls loss_cls pre_smiles_ecfp encoder_logit i confidence_loss_cls_all. decode_png which is an alias for tf. pyplot as plt from tqdm. DataFrame df confidence_loss_cls_all confidence_loss_cls_all df LDS_ALL LDS_ALL df auc_all auc_all df ecfps_cosine_all ecfps_cosine_all df pearsonr_all pearsonr_all df jaccard_all jaccard_all df euclidean_all euclidean_all df image_id_all image_id_all_1 df. sort_values by image_id. parsed_example tf. makedirs destination_directory exist_ok True full_file_path os. if epoch 2 1 or epoch EPOCHS save weights loss_pkl train_loss_seq stat_logger. com storage docs bucket storage_client. upload_from_filename source_file_name print File uploaded to. express as px from matplotlib. No parameters necessary if TPU_NAME environment variable is set. Chem import Draw from rdkit. show import pandas as pd pd. parse_single_example and the defined feature description. 0000000001 1000000 listLabels 0 1 df group pd. filterwarnings ignore val_dist_ds iter strategy. append lbls_s all_right_ratio len np. run test_step args _img_batch predictions strategy. Use num_parallel_calls in tf. The results are improvements in speed and memory usage. DataFrame df image_id_all image_id_all df batch_dis_all batch_dis_all df preds_all smiles_all df preds_selfies_all selfies_all df selfies_labels_all selfies_labels_all df. hist df_1 num_bin plt. experimental_distribute_dataset val_ds for _ in tqdm range VAL_STEPS total VAL_STEPS preds lbls _logit _val_image_id_batch dist_val_step val_dist_ds for i p l h in enumerate zip preds. On TPU GPU CPU we will use an EfficientNetV2 B2 model Basic View of EfficientNetB0 Architecture w 380x380x3 Input. Dataset from filepaths for conversion later raw_test_ds tf. with_options options dataset dataset. 5 else 0 for i in list en_log. split df_final. org api_docs python tf function or the replica function has to be annotated with tf. get_bucket bucket_name blob bucket. 7 USER INPUT VARIABLES 3 nbsp nbsp HELPER FUNCTION CLASSESS nbsp nbsp nbsp nbsp 10514 3. numpy to check the information. 3 CREATE A LEARNING RATE SCHEDULER Adapting the learning rate for your stochastic gradient descent optimization procedure can increase performance and reduce training time. mean df_g1 df_g. zip dataset external_smile_dataset dataset dataset. take 1 for i in range 272 df_1 image_id df_1 image_id_all. You will get something like pythonfeatures feature key class value int64_list value 57 feature key id value bytes_list value 338ab7bac feature key image value bytes_list value. org api_docs python tf distribute Strategy run will have a communication between the local VM in our case the Kaggle VM and the remote TPU worker s. values 0 preds_selfies df df image_id_all image_id preds_selfies_all. shape batch_size target_seq_len d_model adding embedding and position encoding. index df_final. Point Wise Feed Forward Networks Each of these sublayers has a residual connection around it followed by a layer normalization The output of each sublayer is LayerNorm x Sublayer x The normalization is done on the d_model last axis. describe display ld_df px. What Is a Replica A single Cloud TPU device consists of FOUR chips each of which has TWO TPU cores. input daily result levenshtein_distance_cleaned_JPO_all. array pre_smiles_ecfp_batch print _val_pattern_batch. For each return value we can use strategy. 1 \u7b5b\u9009\u51fatokenS\u957f\u5ea6\u4e0d\u8d85\u8fc747\u7684\u5206\u5b50 \u4e14\u5747\u5728\u8bcd\u5178\u4e2d 6. count len df_1 print df_1 inchi_lsd. numpy 100 print batch_distance. head 100 df_g2 df_g11. string which are then decoded with tf. An appropriate mask must be used in the attention step. MolFromSmiles smiles inchi 0 if m None inchi Chem. reset_index drop True pred_df pred_df. list_blobs bucket_name for blob in blobs blob. int64 feature1 tf. This is obviously not ideal. append p_s lbls_s. 00298 model to act as the Encoder CNN in our network. Dataset w the appropriate configuration Args TBD Returns TBD dataset load_dataset filenames is_test preserve_file_order tokenized_smile if repeat_dataset dataset dataset. split image_id str tokens 0 smiles str tokens 1 selfies str tokens 2 smiles_dic image_id smiles selfies_dic image_id selfies for x y z w in val_ds. apply label_smiles_to_inchi df_1 print len df_1 def get_lsd s1 s2 return Levenshtein. Positional Encoding3. positional_encoding positional_encoding_2d 6 12 208 self. 7 smiles and inchi lsd INFORMATION7 nbsp nbsp INFER ON TEST DATA nbsp nbsp nbsp nbsp 10514 In this section we will use our trained model to generate the predictions we will use to submit to the competition7. val_acc_seq val_lsd_seq stat_logger. figure figsize 20 10 dpi 80 plt. to_csv val_lsd_confidence_auc. gradient batch_loss_seq encoder. 2 TRANSFORMER MASKING Mask all the pad tokens in the batch of sequence. function def replica_fn batch model batch. numpy n n print 100 Just for printing print f n n. append confidence_loss_cls. After the split each head has a reduced dimensionality so the total computation cost is the same as a single head attention with full dimensionality. MolFromSmiles pre_smiles_selfies plt. However you can iterate the distributed dataset inside a tf. When working with TPU either strategy. DATASET OBJECTS With the above parsing methods defined we can define how to load the dataset with more options and further apply shuffling bacthing etc. Each replica is essentially a copy of the training graph that is run on each core and trains a mini batch containing 1 8th of the overall batch size Google Cloud Dataset path to training and validation images Local path to training and validation images print f. The decoder attends on the encoder s output and its own input self attention to predict the next word token. t_decoder t_tar enc_output1 enc_output2 training look_ahead_mask dec_padding_mask batch_size tar_seq_len target_vocab_size fn_out _ sample_transformer img_embedding_batch img_logit SAMPLE_LBLS training False batch_size tar_seq_len target_vocab_size print n. val_loss_seq val_loss_cls stat_logger. shape batch_size tar_seq_len d_model dec_output attention_weights self. Their matrix multiplication will have a mean of 0 and variance of dk. csv SS_CSV_PATH os. zeros 1 1 dtype tf. pandas import plotly. input googletoken gleaming glass 315115 1431ba008903. nbsp REFERENCE Tutorial TFRecord and tf. The following steps will be covered Use tf. numpy try p_s. 1 INDIVIDUAL TRAIN STEP INFORMATION6. Similarly to predict the fourth token only the first second and the third tokens will be used and so on. 5 TRANSFORMER POINT WISE FEED FORWARD NEURAL NETWORK Point wise feed forward network consists of two fully connected layers with a ReLU activation in between. imshow draw print f pre inchi inchi print f label inchi lable_inchi plt. trainable_variables Initialize batch_loss Get image embedding once Teacher forcing feeding the target as the next input predictions. experimental_distribute_dataset val_ds for _ in tqdm range VAL_STEPS total VAL_STEPS preds lbls _val_image_id_batch dist_val_step val_dist_ds lsd get_levenshtein_distance preds lbls for i p l h in enumerate zip preds. In the following cell we will demonstrate using dummy values and pretending we are distributing them how to deal with the accumulation of the loss values across replicas. numpy print f pred smiles str pre_smiles_selfies print f smilles label smiles_dic image_id_1 print print f pre selfies preds_selfies print f selfies labels 1 selfies_label_1 print f selfies label selfies_dic image_id_1 print f inchi_LSD df_1 df_1 image_id_all image_id inchi_lsd opts DrawingOptions opts. prefetch to allow later batches to be prepared while the current batch is being processed. batch_size target_seq_len d_model x block1 block2 self. extend LDS for i p l in enumerate zip preds. The optimizer should apply the gradient obtained from the averaged per examples loss over the whole distributed batch It s worth noting that each replica may infact receive different number of examples. The input to the encoder is the output of our image encoder i. The look ahead mask is used to mask the future tokens in a sequence. mount content drive force_remount True bms_train gs from_aws_0001 train_tfrecords bms_test gs from_aws_0001 val_records bms_test gs from_aws_0001 val_records_heatmap bms_test gs from_aws_0001 val_records_JPO bms_test gs from_aws_0001 val_records_UOB bms_test gs from_aws_0001 val_records_USPTO bms_test gs from_aws_0001 val_records_cleaned_good_JPO bms_test gs from_aws_0001 val_records_cleaned_JPO bms_test gs from_aws_0001 val_records_cleaned_UOB bms_test gs from_aws_0001 val_records_cleaned_USPTO bms_test gs from_aws_0001 val_records_cleaned_good_USPTO bms_test gs from_aws_0001 val_records_good_USPTO effnetv2 KaggleDatasets. n except print byte print f t t t TRUNCATED VALUE v. org api_docs python tf distribute Strategy run has to be called inside tf. Sometimes this is called learning rate annealing or adaptive learning rates. count auc_list. experimental_distribute_dataset ds dist_ds will now be distributed across all replicas. this is very similar to EfficientNetV2 Our encoder will create feature maps for each image which will in turn be passed to the decoder side of the network. append p_s if len np. txt with open path as file lines file. int32 y if shuffle_buffer_size 1 dataset dataset. This includes but is not limited to model creation optimizer metrics sometimes checkpoint restore any custom code that creates distributed variables Once a variable is created inside a strategy s scope it captures the strategy s information and you can use it outside the strategy s scope. DistributedValues https www. append index 1 df_g11 df_g1. Final linear layer. numpy print f pred smiles str pre_smiles_selfies print f smilles label smiles_dic image_id_1 print print f pre selfies preds_selfies print f selfies labels 1 selfies_label_1 print f selfies label selfies_dic image_id_1 print f LSD df df image_id_all image_id batch_dis_all opts DrawingOptions opts. shape confidence_loss_cls loss_cls _val_pattern_batch _logit print confidence_loss_cls. string feature2 tf. 7 TRANSFORMER ENCODER Each transformer encoder layer consists of sublayers 1. MolToInchi m logLevel None treatWarningAsError False return inchi def label_smiles_to_inchi id smiles smiles_dic id m Chem. distance p_s l_s if i 1000 0 print f Levenshtein Distance LD print f t p_s print f t l_s n pred_s. tensorN strategy. experimental_distribute_dataset https www. We will determine the number of steps or updates later for 1 training epoch. See the notebook on positional encoding https www. better for pretrained models peark_lr_start float The starting learning rate after warmup peak value lr_final float The final learning rate to step down to by the end of training n_epochs int The total number of epochs for the training regime Returns The learning rate float to be used for a given step if step SAMPLE_LBLS i print f nOUR PREDICTIONS n tSHAPE pred_output. express as px import seaborn as sns from PIL import Image import matplotlib import plotly import PIL import cv2 df pd. numpy _val_image_id_batch. Knowing this we are limited to using a reduction value of SUM or NONE as the default value and some of the other options will not work with TPU. something that is a tf. PerReplica https github. not_equal lbls END_TOKEN lbls 0 preds_sparse dense_to_sparse preds lbls_sparse dense_to_sparse lbls batch_distance tf. Args filenames list of strings List of paths to that point to the respective TFRecord files is_test bool optional Whether or not to include the image ID or label in the returned dataset ordered bool optional Whether to ensured ordered results or maximize parallelization tokenized_smile bool optional Whether our dataset includes the tokenized smile or we will be creating it from the caption numpy array Returns Decoded tf. Let s get started nbsp REFERENCE Tutorial Using Iterators Tutorial Iterating Inside a tf. See the demonstration above in the scaled dot product attention section. Residual connections help in avoiding the vanishing gradient problem in deep networks. DataFrame image_id x 0. input daily result val_lsd_confidence_auc_5. join x for x in l np. distance s1 s2 df_1 inchi_lsd df_1. For example python ds. For adaptive optimisers like Adam warmup also allows the optimizers to compute bettere statistics of the gradients. int64 default_value 150 feature_dict h tf. environ GOOGLE_APPLICATION_CREDENTIALS. Intuitively this method will allow a model to adjust itself less before it becomes more familiar with the dataset. zeros 1 MAX_LEN dtype tf. org tutorials text transformer positional_encoding to learn more about it. When iterating over the dataset we will still get a tuple containing two values. Dtype policies specify the dtypes layers will run in target data type bfloat16 when using TPU to improve throughput The policy specifies two important aspects of a layer 1. numpy pre_smiles_selfies df_1 df_1 image_id_all image_id preds_all. InvalidArgumentError exception is thrown nbsp REFERENCE XLA Optimizing Compiler for Machine Learning2. This layer the MHA layer first projects query key and value. csv Instantiate our tool for logging for epoch in range 1 2 to compute epoch duration create distributed versions of dataset to run on TPU with 8 computation units Update current step Update the current step Calculate training step end of epoch validation step for _ in range 2 LDS tonimoto_list all_right_num get_levenshtein_distance_smiles preds lbls LDS_ALL. colors import ListedColormap import matplotlib. expand_dims x 0 1 tf. cloud import storage storage_client storage. subplot 1 2 1 plt. numpy batch_dis_all. download_to_filename full_file_path. Otherwise you can use like pythonexample tf. values 0 selfies_label_1 df_1 df_1 image_id_all image_id selfies_labels_all. not_equal lbls PAD_TOKEN preds 0 lbls tf. 6 INITIAL DATAFRAME INSTANTIATION 2. append LD ld_df pd. get_fingerprint_type RDKit Morgan fpSize 2048 T fptype. readlines for line in lines tokens line. It is used to pad and mask future tokens in the input received by the decoder. either the entire function is compiled with XLA or an errors. org api_docs python tf distribute Strategy experimental_local_results to obtain a tuple of tensors from all replicas and we can use tf. 2 WHAT TO DO IF YOU DON T KNOW THE FEATURE DESCRIPTIONS OF THE DATASET If you are the author who created the TFRecord files you definitely know how to define the feature description to parse the raw dataset. loc 0 LDS_ALL res. Today most models use the float32 dtype which takes 32 bits of memory. fit defining something within the strategy s scope WILL NOT automatically distribute the computation. uniform BATCH_SIZE_DEBUG int MAX_LEN D_MODEL dtype TARGET_DTYPE sample_encoder_layer_output img_logit False None None sample_decoder_layer_output. ACCUMULATED LOSS n t accumulated_loss print f n n. If pulling smile from TFRecords than order does not matter since we will be shuffling the data anyway for training dataset. 2 UNDERSTANDING THE MODELS TRANSFORMER 5. DERde Will yield at the lowest feature level 6 12 208 or 72 208 def get_efficientnetv2_backbone model_name include_top False input_shape 192 384 3 pooling None weights None Catch unsupported arguments Will yield at the lowest feature level 6 12 208 or 72 208 def get_efficientnetv1_backbone model_name include_top False input_shape 192 384 3 pooling None weights None if pooling or weights or include_top raise NotImplementedError n. MolFromSmiles smiles if None mol fp fptype. Multi Head AAttention with padding mask 2. to_csv levenshtein_distance_cleaned_USPTO_all. org api_docs python tf distribute DistributedValues that is the base class for representing distributed values. See this article https machinelearningmastery. numpy pre_smiles_selfies df df image_id_all image_id preds_all. See TPU extreme optimizations https www. experimental_deterministic False N_PARALLEL tf. org api_docs python tf concat to aggregate them into a single tensor. 3 TEST PRED POST PROCESSING INFORMATION7. TFRecordDataset to read the TFRecord files. When using TPU on Kaggle you don t need to specify arguments for TPUClusterResolver 2. 11 TRANSFORMER PUT IT ALL TOGETHER Our Transformer consists of the transformer encoder transformer decoder and a final linear layer. list_blobs bucket_name for blob in blobs print blob. append l image_ids. subplot 1 2 2 plt. lev_dist log_y True def test_step _image_batch Forward pass calculate gradients Args image_batch TBD smile_batch TBD Returns tbd image_batch_embedding encoder _image_batch training False hidden_batch memory_batch decoder. 0 TRANSFORMER HYPERPARAMETERS 5. xticks num_bin plt. In the next cell we instantiate the learning rate function the loss object and the model s inside the scope nbsp REFERENCE TPUStrategy Scope Tutorial Custom Training With TPUs5. to peform just like witout using TPU. plot auc_list plt. count loss_list. The formula for calculating the positional encoding is as follows Large PE_ pos 2i sin pos 10000 2i d_ model Large PE_ pos 2i 1 cos pos 10000 2i d_ model 5. head 100 df_g1 df_g1. where p 2 0 0 except p_s. EDIT In this notebook we have the option to use gradient accumulation https arxiv. join x for x in p np. input daily result similes_test_2_heatmap_id_size. split n tokens tokens 0. index_word x for x in l 1 np. We will be using a model architecture very similar to that found within the Show Attend and Tell Research Paper https arxiv. ones REPLICA_BATCH_SIZE 1 dtype tf. Client project gleaming glass 315115 def create_bucket dataset_name Creates a new bucket. FixedLenFeature tf. take 1 for i in range 450 if len df_2 df_2. org api_docs python tf distribute Strategy experimental_distribute_dataset to turn it into a distributed dataset which produces per replica values which are objects of type PerReplica https github. where p END_TOKEN 0 0 except p_s. set_index w h df_g2 df_g2. mean df_2 print inchi_lsd\u4e0d\u4e3a0 print len df_2 df_1 for x y z w in val_ds. run will execute across the replicas we can look at an example python tf. items print f tFEATURE i 1 print f t t KEY k if k image try print int print f t t t TRUNCATED VALUE v. The output of the encoder is the input to the decoder. Dense 208 name logit_dense1 activation None self. current_step epoch 1 TRAIN_STEPS Save every other epoch starting with first epoch Save after last epoch too. It requires both methods from computer vision to understand the content of the image and a language model from the field of natural language processing to turn the understanding of the image into words in the right order. numpy i try p_s. Example TFRecordDataset Documentation Decoding PNGs Documentation4. TFRecordDataset TEST_TFREC_PATHS num_parallel_reads None raw_test_ds tf. The jit_compile API has must compile semantics i. The output of the decoder is the input to the final linear layer. toolkit mol Chem. join list map str 1 if i 0. AVERAGE LOSS BY EXAMPLE n t accumulated_loss MAX_LEN print f n n. DataFrame lbl_smile lbls_s pred_smile pred_s lev_dist LDS ld_df. drop_duplicates subset image_id_all df_1 df_3 batch_dis_all d 1 num_bin range int min df_1 int max df_1 d print df_1. AVERAGE LOSS ACROSS BATCH n t np. head 100 w h for index row in df_g1. When a TensorFlow program is run all of the operations are executed individually by the TensorFlow executor. Even if a dataset yields tuples of tensors the above code still works but replica_fn expects a single tuple of tensors as argument. The Keras mixed precision API allows you to use a mix of either float16 or bfloat16 with float32 to get the performance benefits from float16 bfloat16 and the numeric stability benefits from float32. n EPOCHS 36 TOTAL_STEPS TRAIN_STEPS EPOCHS WARM_STEPS 100 WARM_START_LR 1e 5 PEAK_START_LR 2e 3 FINAL_LR 1e 4 def lr_schedule_fn step total_steps warm_lr_start warm_steps peak_lr_start lr_final n_epochs Function to generate the learning rate for a given step based on parameters Args step int The current step for which to calculate the respective learning rate total_steps int The total number of steps for the entire training regime warm_lr_start float The starting learning rate prior to warmup warm_steps int The number of steps for which the learning rate will ramp up to the desired peak learning rate value more steps will result in less dramatic changes to existing weights. cut df target bins listBins_1 right True labels listLabels_1 retbins False precision 3 include_lowest True res df. It is a subclass of tf. numpy for i p l in enumerate zip preds. nbsp REFERENCE TF Mixed Precision Overview2. Dataset Documentation5 nbsp nbsp MODEL PREPERATION nbsp nbsp nbsp nbsp 10514 In this section we prepare the models for training. ZONE us east1 b The name of the GCP project where you created the TPU to use on GCP. head for index row in df. This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. apply smiles_to_inchi df_1 image_id df_1 image_id_all. numpy print Levenshtein. function https www. Create a description of the features. where l END_TOKEN 0 0 p_s selfies_decoder p_s l_s selfies_decoder l_s pre_smiles_ecfp simies_to_ecfps p_s lable_ecfp simies_to_ecfps l_s pre_smiles_ecfp_batch. Embeddings represent a token in a d dimensional space where tokens encoded vectors with similar meaning feature representation will be closer to each other. This will be discussed more in the section on training further down. Yield the default distribution strategy in Tensorflow Works on CPU and single GPU. show import warnings warnings. EXAMPLE OF TRUNCATED RAW TFRECORD TFEXAMPLE FROM TRAINING DATASET TO SHOW HOW TO FIND FEATURE DESCRIPTIONS n See an examplefor raw in raw_train_ds. ", "id": "hymanli/02-decimerplus-efficientnetv2-transformer", "size": "56561", "language": "python", "html_url": "https://www.kaggle.com/code/hymanli/02-decimerplus-efficientnetv2-transformer", "git_url": "https://www.kaggle.com/code/hymanli/02-decimerplus-efficientnetv2-transformer", "script": "sklearn.metrics Encoder(tf.keras.Model) point_wise_feed_forward_network attributes) effnetv2_configs google.colab decode efficientnetv2 get_efficientnetv1_backbone MultiHeadAttention(tf.keras.layers.Layer) efficientnet.tfkeras sklearn.metrics.pairwise collections plotly.express loss_cls StatLogger() get_efficientnetv2_backbone seed_it_all sim_tonimoto tensorflow_addons lr_schedule_fn Image decode_image cosine_similarity dist_train_step kaggle_datasets tensorflow.keras.backend np_positional_encoding_2d storage dist_val_step download_to_kaggle TransformerDecoder(tf.keras.layers.Layer) roc_curve __call__ rdkit binary_loss_fixed get_angles spatial do_interleave AllChem get_levenshtein_distance_inchi simies_to_ecfps seaborn numpy scipy.stats create_padding_mask plot_lr_schedule brain_automl create_look_ahead_mask initialize_encoder_config decoder scaled_dot_product_attention fpstolist rdkit.Chem.Draw.MolDrawing drive Config() tqdm.notebook tensorflow pandas print_last_val smiles_to_inchi matplotlib.colors Counter dense_to_sparse initialize_decoder_config tqdm; tqdm.pandas(); label_smiles_to_inchi get_lr Transformer(tf.keras.Model) encoder step DrawingOptions #Only needed if modifying defaults flatten_l_o_l rdkit.Chem load_dataset encoder as selfies_encoder matplotlib.patches list_blobs auc TransformerDecoderLayer(tf.keras.layers.Layer) distributed_test_step TransformerEncoder(tf.keras.layers.Layer) PIL get_levenshtein_distance_smiles get_counter split_heads rdkit.Chem.rdinchi google.cloud create_mask LRS() print_current_train binary_focal_loss_fixed create_bucket effnetv2_model scipy.spatial.distance scipy decoder as selfies_decoder loss_fn selfies ChargeParent get_dataset datetime rdkit.Chem.MolStandardize.rdMolStandardize glob __init__ positional_encoding_2d get_lsd print_out TransformerEncoderLayer(tf.keras.layers.Layer) RDLogger plotly.graph_objects CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule) MolDrawing Draw upload_blob test_step val_step matplotlib.pyplot call positional_encoding_1d KerasFocalLoss simies_to_ecfps_hex pearsonr Chem get_levenshtein_distance jaccard initialize_lr_config MolToInchi arr_2_smile KaggleDatasets ListedColormap prepare_for_training loss_seq tf_load_image train_step ", "entities": "(('normalization', 'd_model'), 'do') (('colors', 'ListedColormap import matplotlib'), 'import') (('appropriate mask', 'attention step'), 'use') (('shape batch_size seq_len_q num_heads batch_size CUSTOM batch_size encoder_sequence TF NATIVE INNER LAYER dff OUTPUT d_model seq_len_k batch_size seq_len_q seq_len_q returns', 'tf'), 'num_heads') (('express', 'PIL plotly import cv2 pd'), 'import') (('InvalidArgumentError exception', 'nbsp REFERENCE XLA Optimizing Machine Learning2'), 'throw') (('we', 'tf'), 'python') (('scores', '1'), 'normalized') (('we', 'caption numpy array Returns'), 'list') (('TBD Returns TBD', 'dataset dataset'), 'Dataset') (('attention weights', 'output'), 'be') (('particular following methods', 'tf'), 'be') (('policy', 'layer'), 'specify') (('you', 'python'), 'tf') (('Residual connections', 'deep networks'), 'help') (('not_equal lbls PAD_TOKEN', '0 lbls'), 'pred') (('TRAIN_CSV_PATH', 'os'), 'rsplit') (('we', 'up point'), 'TPU') (('distributed datasets', 'type tensorflow'), 'contain') (('output', 'linear layer'), 'output') (('encoding words feature So positional representations', 'd dimensional space'), 'be') (('1 1 1 Then query', 'key dot previous section'), 'be') (('less it', 'more dataset'), 'allow') (('attention', 'Linear heads'), 'head') (('DATASET 3 RAW general recipe', 'STEP'), 'PARSE') (('tensors', 'then back single tensor'), 'interpolate') (('org api_docs', 'single tensor'), 'python') (('which', 'cloud TPUs'), 'DETECTION') (('output', 'decoder'), 'be') (('0 0 p_s selfies_decoder', 'simies_to_ecfps'), 'compatible') (('experimental_distribute_dataset ds dist_ds', 'now replicas'), 'distribute') (('still replica_fn', 'argument'), 'work') (('However you', 'tf'), 'iterate') (('nbsp', 'TF Mixed Precision Overview2'), 'REFERENCE') (('dense_to_sparse lbls batch_distance', 'dense_to_sparse not_equal END_TOKEN 0 lbls_sparse'), 'lbl') (('that', 'elements'), 'False') (('Here we', 'approach'), 'call') (('w feature_dict w h feature_dict h def load_dataset False', 'True TFRecords'), 'string') (('you', 'grpc also path'), 'need') (('you', 'raw dataset'), 'do') (('nbsp REFERENCES Guide', 'TPUs Doc TPUClusterResolver2'), 'Use') (('scaled_dot_product_attention', 'efficiency'), 'apply') (('Policy', 'dtype typically policy'), 'refer') (('code above snippet', 'level replica_fn high t necessary single argument'), 'run') (('TEST_STEPS total TEST_STEPS next dist_test_ds', 'distributed_test_step pred_ids img_batch tf'), 'experimental_distribute_dataset') (('values', 'attention probabilities'), 'softmaxe') (('WE', 'INSTEAD self'), 'MultiHeadAttention') (('efficiently otherwise TPU', 'TPU'), 'determine') (('python', 'tf'), 'have') (('matmul_qk attention Calculate scaled logits', 'scaled tensor'), 'add') (('distribute Strategy tf run', 'Kaggle VM'), 'python') (('we', 'dataset'), 'parse') (('it', 'faster less memory'), 'be') (('encoding positional vector', 'embedding vector'), 'add') (('nbsp', 'Language Understanding TF Tutorial Image'), 'REFERENCE') (('confirence_loss cut_n 1 i', 'range'), 'df') (('None input_seq_len call self x training None padding_mask def enc_output2 None', 'embedding'), 'shape') (('infact', 'examples'), 'apply') (('MultiHeadAttention', 'location'), 'run') (('we', 'pooling'), 'want') (('something', 'feature d value bytes_list image value bytes_list 57 i 338ab7bac feature key value'), 'get') (('EfficientNetV2 Base Config Detect hardware', 'distribution strategy TPU appropriate detection'), 'get') (('LayerNorm normalization', 'd_model'), 'network') (('model', 'input'), 'ensure') (('embeddings', 'efficientnetv2 encoder model'), 'encode') (('model', 'different representational spaces'), 'split') (('end single model', 'specifically designed models'), 'be') (('output', 'decoder layers'), 'be') (('input self own next word', 'output'), 'attend') (('PUT 11 Transformer', 'transformer encoder transformer decoder'), 'it') (('executor', 'that'), 'have') (('model', 'same quality'), 'be') (('we', 'strategy'), 'use') (('you', 'scope'), 'include') (('test_step _ image_batch True def Forward', 'hidden_batch memory_batch False decoder'), 'lev_dist') (('which', 'positional encoding'), 'put') (('predicted char', 'shape vocab_size prediction_batch attention_weights _ image_logit decoder_pred_batch False look_ahead_mask'), 'batch_size') (('NaN when loss', 'update learning rate'), 'reset') (('Shuffling Batching', 'zip TRAINING VALIDATION TESTING'), 'drop') (('RAW TFRECORD INVESTIGATION', 'FEATURE DESCRIPTIONS'), 'start') (('bit 16 dtypes', 'memory'), 'run') (('N_PE_POS 72 101 D_FF', 'attention logits'), 'shape') (('when you', 'GCP'), 'xxx') (('simplest way', 'TFRecord files'), 'be') (('MolFromSmiles', 'None inchi 0 Chem'), 'smile') (('K key', 'inputs'), 'receive') (('i', 'PREDICTIONS n tSHAPE nOUR pred_output'), 'float') (('False 192 384 None', 'None'), 'yield') (('preds', 'zip enumerate preds'), 'experimental_distribute_dataset') (('df_1 s1 s2', 'Levenshtein'), 'apply') (('450 len', 'range'), 'take') (('all', 'TensorFlow individually executor'), 'execute') (('False def decode_image image_data 384 img_size 192 384 3 192 3 sparse tensors', 'Levenshtein distance preds'), 'sel') (('name download_to_kaggle bucket_name destination_directory file_name', 'Kaggle notebook os'), 'def') (('output', 'final linear layer'), 'be') (('that', 'only tf'), 'compile') (('that', 'sequence'), 'pass') (('look', 'sequence'), 'use') (('so we', 'only whole batches'), 'OVERALL_BATCH_SIZE') (('You', 'etc'), 'pass') (('We', 'EfficientNetV2 https arxiv'), 'understanding') (('goal', 'caption'), 'be') (('first projects', 'key'), 'query') (('Otherwise you', 'pythonexample'), 'use') (('computations', '2'), 'do') (('us', 'GCS'), 'get_gcs_path') (('express', 'PIL import cv2 df plotly pd'), 'import') (('nbsp', 'TPUs5'), 'instantiate') (('data', 'S torage directly G oogle C loud GCS'), 'read') (('dataset', 'directory'), 'be') (('Point Wise Feed Forward Neural Each', 'layer normalization'), 'network') (('we', 'validation'), 'n_stes') (('you', 'tf'), 'be') (('we', 'shuffling further bacthing etc'), 'OBJECTS') (('correct gradients', 'whole distributed batch'), 'see') (('model', 'float32'), 'say') (('you', 'gentler softmax'), 'use') (('it', 'distribution strategy'), 'define') (('we', 'replicas'), 'demonstrate') (('input', 'image encoder i.'), 'be') (('mount content', 'gs bms_test val_records bms_test bms_test gs bms_test train_tfrecords from_aws_0001'), 'drive') (('which', 'utility function'), 'provide') (('pkl wb i', 'range len image_id_all'), 'epoch') (('computation total cost', 'full dimensionality'), 'be') (('you', 'get_gcs_path function'), 'TIPS') (('MolToInchi m None treatWarningAsError', 'inchi'), 'logLevel') (('TPUs', 'local VM'), 'reduce') (('training Local path', 'print f.'), 'be') (('you', 'TPUClusterResolver'), 'need') (('where you', 'GCP'), 'b') (('all_right_num 100 len i', 'zip enumerate preds'), 'experimental_distribute_dataset') (('attention dot where products', 'sqrt d_k'), 'be') (('we', 'strategy'), 'computation') (('output', 'encoder layers'), 'be') (('RDKit get_fingerprint_type Morgan', 'T 2048 fptype'), 'fpsize') (('shuffle', 'dataset dataset'), 'shuffle_buffer_size') (('attention output', 'then tf'), 'concatenate') (('This', 'feature description'), 'give') (('you', 'https arxiv'), 'ATTENTION') (('which', 'type PerReplica https github'), 'python') (('we', 'gradients gradients tape'), 'sum') (('entries', 'other words'), 'indicate') (('entire function', 'XLA'), 'compile') (('n', 'f t t t TRUNCATED VALUE else str'), 'print') (('you', 'other notebooks'), 'Myers') (('formula', 'PE _ pos sin 2i d _ Large 2i pos 10000 model'), 'be') (('smile strings IDs', 'byte string just tensors'), 'leave') (('replica', 'loss values'), 'python') (('TFRecordDataset N_PARALLEL', 'dataset'), 'filenames') (('We', 'warmup phase'), 'utilize') (('We', 'strategy'), 'have') (('i', 'image'), 'contain') (('replica_fn', 'arguments'), 'in') (('it', 'inputs'), 'python') (('Q query', 'head attention masked multi sublayer'), 'receive') (('this', 'When TPU'), 'be') (('it', 'PerReplica objects'), 'run') (('2 1 EPOCHS', 'weights'), 'epoch') (('fit', 'automatically computation'), 'distribute') (('mask', 'immediately softmax'), 'do') (('Masked Multi Head Attention', 'ahead mask'), 'mask') (('matrix multiplication', 'dk'), 'have') (('which', 'positional encoding'), 'decoder') (('i', 'smiles_dic'), 'logLevel') (('you', 'stability numeric float32'), 'allow') (('format destination_blob_name list_blobs bucket_name', 'bucket'), 'source_file_name') (('It', 'right order'), 'require') (('This', 'GCP project dashboard page'), 'find') (('jaccard_all', 'euclidean_all euclidean_all'), 'df') (('we', 'training anyway dataset'), 'matter') (('as soon it', 'rather original order'), 'ensure') (('str str tokens 0 smiles tokens 1 selfies', 'str 2 selfies_dic'), 'split') (('uniform BATCH_SIZE_DEBUG', 'D_MODEL dtype'), 'int') (('intelligence challenging artificial where textual description', 'given photograph'), 'define') (('print f 1 selfies_label_1 selfies', 'LSD df'), 'pre') (('recurrence positional encoding', 'sentence'), 'encoding') (('preds', '0 all_pred_ids'), 'axis') (('p_li fpstolist C C ON C C C pattern_2 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 OC', 'simies_to_ecfps smil'), 'return') (('we', 'BMS tfrecord dataset'), 'map') (('dot product attention', 'depth'), 'take') (('input', 'daily val_lsd_confidence_auc_4'), 'result') (('We', 'partial batch'), 'calculate') (('that', 'individual replicas'), 'class') (('this', 'tfrecord automatically multiple files'), 'return') (('Client project gleaming glass', 'create_bucket 315115 def new bucket'), 'create') (('so values', 'equally first key'), '3') (('which', 'memory'), 'use') (('results', 'speed usage'), 'be') (('we', 'accumulation https gradient arxiv'), 'EDIT') (('goal', 'output'), 'be') (('return predictions pred_ids axis 0 all_pred_arr', '_'), 'gather') (('they', 'optimization'), 'be') (('100 i', 'i'), 'df') (('False', 'Draw'), 'logLevel') (('so associated values', 'repeated key third'), '3') (('MolToInchi m1', 'None treatWarningAsError None inchi Chem'), 'loglevel') (('readlines', 'lines'), 'ls') (('only first tokens', 'third token'), 'mean') (('s', 'MultiHeadAttention layer'), 'let') (('that', 'source code potentially changes'), 'be') (('that', 'strategy'), 'have') (('training target_vocab_size _ img_logit enc_output2 tar_seq_len SAMPLE_LBLS', 'print n.'), 't_tar') (('probably DEBUG', 'batch smaller size'), 'print') (('include_lowest 3 True', 'res df'), 'bin') (('we', 'update size'), '02368') (('we', 'Architecture 380x380x3 Input'), 'use') (('we', 'training'), 'dataset') (('each', 'batch'), 'python') (('we', 'feature maps'), 'NOTE') (('i', '_ auc fpr tpr'), 'thredhold') (('we', 'two values'), 'get') (('data Dataset we', 'strategy'), 'python') (('We', 'training later 1 epoch'), 'determine') (('precision Therefore lower dtypes', 'whenever devices'), 'run') (('TRANSFORMER POINT WISE 5 FEED FORWARD NEURAL NETWORK Point wise forward network', 'ReLU activation'), 'feed') (('each', 'TPU TWO cores'), 'consist') (('you', 'Project actually that'), 'WARNING') (('more steps', 'existing weights'), 'n') (('network outputs', 'IMG_EMB_DIM'), 'encoder_config') (('we', 'example'), 'execute') (('argmax prediction_batch', 'output_type 1 tf'), 'axis') (('model We', 'whole distributed dataset'), 'use') (('init_hidden_state image_batch_embedding', 'False decoder_input_batch'), 'training') (('we', 'tf'), 'prepare') (('learning Recently deep methods', 'problem'), 'achieve') (('learning initial rate', 'first few epochs steps'), 'use') (('input', 'daily val_lsd_confidence_auc_5'), 'result') (('_ get_levenshtein_distance', 'lbls image_id_all'), 'experimental_distribute_dataset') (('description caption', 'smile molecule'), 'be') (('output', 'attention weights'), 'decide') (('100 \u6e05\u6d17\u957f\u5ea6\u8d85\u8fc747 print len df_1 def 1 5 False df_1 print smiles_to_inchi', 'm Chem'), 'smile') (('This', 'usually pretrained weights'), 'prevent') (('Adapting', 'training time'), 'CREATE') (('we', 'encoder model'), 'create') (('second value', 'second key'), 'input') (('we', 'competition7'), 'smile') (('only first second third tokens', 'Similarly fourth token'), 'predict') (('edit_distance preds_sparse lbls_sparse', 'print len False np'), 'normalize') (('Dataset', 'later raw_test_ds'), 'tf') (('we', 'also python'), 'use') (('expand_dims pred_ids', 'arr 1 axis 0 def i'), 'axis') (('decoder', 'own output'), 'predict') (('model', 'such accuracy'), 'have') (('optimal performance', 'False'), 'for') (('which', 'strategy'), 'be') (('mask', 'close negative infinity'), 'multiply') (('final graident', 'respective replicas'), 'be') (('SECONDARY TASK notebook we', 'custom way'), 'DESCRIPTIONIn') (('jit_compile API', 'semantics i.'), 'compile') (('transformer decoder layer', 'sublayers'), 'component') (('EfficientNetV2B0', 'feature instead 1280 that'), 'have') (('where replica_fn', 'arugment'), 'run') (('when batch', 'https replicas www'), 'during') (('how quality', 'precision lower dtype'), 'DEFINITION') (('which', 'execution'), 'dist_ds') (('print inchi inchi print f', 'inchi lable_inchi plt'), 'draw') (('it', 'specifically given model'), 'provide') (('default value', 'TPU'), 'limited') (('VAL_STEPS VAL_STEPS preds', 'zip enumerate preds'), 'experimental_distribute_dataset') (('configuration which', 'later respective datasets'), 'create') (('It', 'decoder'), 'use') (('we', 'which'), 'be') (('Here we', 'DATASET RAW S'), 'CREATE') (('python', 'replica tf'), 'have') (('rate', 'annealing'), 'call') (('precision However two lower which', 'memory'), 'be') (('defaults', 'pd'), 'moldrawe') (('value_dim', 'linear projection'), 'tensor') (('also optimizers', 'gradients'), 'allow') (('print f t KEY k 1 image', 'print int print f t t t TRUNCATED VALUE'), 'print') (('Q', '1'), 'consider') (('test_records', 'Individual TFRecord Files TEST_TFREC_PATHS'), 'join') (('Teacher', 'input next predictions'), 'get') (('we', 'string scalar tensors'), 'get') (('we', 'training'), 'Dataset') (('which', 'network'), 'be') (('s', 'tf'), 'let') (('learning Deep methods', 'caption generation problems'), 'demonstrate') (('transformer model', 'attention model nmt_with_attention'), 'TRANSFORMER') (('TEST_DIR', 'None Respective Image Directories'), 'call') (('print f 1 selfies_label_1 selfies', 'selfies_dic image_id_1 print inchi_LSD DrawingOptions opts opts'), 'pre') (('True False True True None', 'tf'), 'lambda') (('output', 'sublayer'), 'be') (('it', '0'), 'indicate') (('TRANSFORMER ENCODER 9 TransformerEncoder', '1'), 'component') (('gather', 'pred_ids 0 strategy'), 'axis') (('These', 'multiple heads'), 'get') (('LDS all_right_num 2 get_levenshtein_distance_smiles', 'lbls LDS_ALL'), 'Instantiate') (('where tokens', 'other'), 'represent') (('This', 'training'), 'discuss') (('Therefore it', 'replicas'), 'be') (('where it', 'very hard softmax'), 'do') (('pythonfeature_description feature0', 'example'), 'tf') (('We', 'Research Paper https arxiv'), 'use') (('encoder layer', 'sublayers'), 'ENCODER') (('that', 'base distributed values'), 'python') ", "extra": "['test', 'procedure']"}
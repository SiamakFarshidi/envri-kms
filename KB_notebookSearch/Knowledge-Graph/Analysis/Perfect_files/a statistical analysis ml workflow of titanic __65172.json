{"name": "a statistical analysis ml workflow of titanic ", "full_name": " h1 Need to paraphrase this section h2 Feature Selection h3 Feature selection is an important part of machine learning models There are many reasons why we use feature selection h3 Before Scaling h3 After Scaling h1 Evaluating a classification model h1 AUC ROC Curve h4 Let s look at the feature importance from decision tree grid h3 Why Random Forest Pros and Cons h2 Introducing Ensemble Learning h4 Source GA h4 Resampling from original dataset to bootstrapped datasets h4 Source https uc r github io h4 Source https prachimjoshi files wordpress com h3 Why use Bagging Pros and cons h4 Random Forest VS Bagging Classifier h3 Resources h3 Resources h3 Resources h1 Resources h1 Credits h4 If you like to discuss any other projects or just have a chat about data science topics I ll be more than happy to connect with you on h1 If you have come this far Congratulations h1 If this notebook helped you in any way or you liked it please upvote and or leave a comment ", "stargazers_count": 0, "forks_count": 0, "description": "55 Pclass and Survived 0. Instead bagging reduces overfitting since a lot of the sample training data are repeated and used to create base estimators. This can be quite correlated with Pclass. It is important to remember that we will create new features in such ways that will not cause multicollinearity when there is a relationship among independent variables to occur. I will discuss more on that in a different kernel. When the error rate is high let s say close to 1 then the amount of say will be negative which means if the stump outputs a value as survived the included weight will turn that value into not survived. This KDE plot is pretty self explanatory with all the labels and colors. If you like to review logistic regression please click here https www. setting the number of runs r and or loops n leg_1 ax1. Separating dependent and independent variables Before we apply any machine learning models It is important to separate dependent and independent variables. When the stump does a reasonably good job and the total error is minimal then the amount of say Alpha is relatively large and the alpha value is positive. Random Forest ClassifierI admire working with decision trees because of the potential and basics they provide towards building a more complex model like Random Forest RF. estimator knn param_grid param n_jobs 1 to instruct scikit learn to use all available processors. We will take a different approach since 20 data in the Age column is missing in both train and test dataset. Onc thing we can do is try to set up the Null and Alternative Hypothesis in such way that when we do our t test we can choose to do one tailed test. Source GAResource Ensemble methods bagging boosting and stacking 7g. Finally we put together the combined classifier which is AdaBoost X sign left sum_ t 1 T alpha_t h_t X right Here AdaBoost X is the classification predictions for y using predictor matrix X T is the set of weak learners alpha_t is the contribution weight for weak learner t h_t X is the prediction of weak learner t and y is binary with values 1 and 1 P. If you are reading this on github I recommend you read this on kaggle. Passenger who traveled in big groups with parents children had less survival rate than other passengers. We have found some moderately strong relationships between different features. Fare Feature If you have paid attention so far you know that there is only one missing value in the fare column. However for the sake of learning and practicing we will try something else. In order to feed data in a machine learning model we ageAs I promised before we are going to use Random forest regressor in this section to predict the missing age values. Cannot be parallelized like bagging bad scalability when huge amounts of data. We withhold part of the data where we know the output result of each datapoints and we use this data to test the trained models. org wp content uploads fittings. alpha_t Amount of Say epsilon_t Total errorWe can draw a graph to determine the amount of say using the value of total error 0 to 1 Source Chris McCormick The blue line tells us the amount of say for Total Error Error rate between 0 and 1. Pclass and Survived It looks like. Enhanced generalisation by reducing overfitting. Use more training data. the test data new data then go through this averaged classifier combined classifier and predict the output. Why use Bagging Pros and cons Bagging works best with strong and complex models for example fully developed decision trees. We then compare the outcomes to determine the performance of the algorithms. Let s apply some of these methods and see how we are doing with our predictions. Bagging Averaging Methods In averaging methods the driving principle is to build several estimators independently and then to average their predictions. Let s see how we can rewrite this. The idea is to unmix the labels by asking fewer questions necessary. The idea of using sample set is that if we take multiple samples of the same population and take the mean of them and put them in a distribution eventually the distribution start to look more like a normal distribution. Source Diogo Medium Let s dive into each one of the nitty gritty stuff about AdaBoost First we determine the best feature to split the dataset using Gini index basics from decision tree. is done without making any changes including Null values to any features of the dataset. I will try my best to illustrate most of the feature relations. alpha_t Amount of Say alpha value this is the coefficient that gets updated in each iteration and y_i h_t x_i place holder for 1 if stump correctly classified 1 if misclassified. If you like to discuss any other projects or just have a chat about data science topics I ll be more than happy to connect with you on LinkedIn Github masumrumi. 55 statistically this is called the point estimate of the male population mean and female population mean. set_title PClass legs leg_1. Simplify the model by changing the hyperparameters. D_ t 1 i D_t i e alpha_t y_i h_t x_i Here D_ t 1 i New Sample Weight. While passenger who traveled in small groups with sibilings spouses had better changes of survivint than other passengers. The first stump starts with uniformly distributed weight which means in the beginning every datapoint have an equal amount of weights. This can further help our cause. Part 5 Feature Engineering Feature Engineering is exactly what its sounds like. Please check back again for future updates. Statistical Test for Correlation Statistical tests are the scientific way to prove the validation of theories. If we were to think about this interms of column and raw we could see that. When we set out to experiment we form the null hypothesis by saying that there is no difference between the means of the control group and the experimental group. Missing values in test set. Can be used for classification and regression equally well. We use the total error to determine the amount of say a stump has in the final classification using the following formula alpha_t frac 1 2 ln left frac 1 epsilon_t epsilon_t right text where epsilon_t 1 Where epsilon_t is the misclassification rate for the current classifier epsilon_t frac text misclassifications _t text observations _t Here. The age distribution chart on top provides us with some more info such as what was the age range of those three unlucky females as the red color give away the unsurvived once. We learn how much say a stump has in the final classification by calculating how well it classified the samples aka calculate the total error of the weight. It is good to have an understanding of what going on in the background. However machines do not understand the value of categorical values for example in this dataset we have gender male or female algorithms do not accept categorical variables as input. com masumrumi a stats analysis and ml workflow of house pricing edit run 9585160. This is where bias variance tradeoff comes in. While among male passengers 110 survived and 480 did not survive. name_length Creating a new feature name_length that will take the count of letters of each name title Getting the title of each name as a new feature. Grid Search on Logistic Regression What is grid search What are the pros and cons Gridsearch is a simple concept but effective technique in Machine Learning. Confusion Matrix tells us how many our model predicted correctly and incorrectly in terms of binary multiple outcome classes by comparing actual and predicted cases. Pclass A proxy for socio economic status SES 1 Upper 2 Middle 3 Lower Numeric Discrete Passenger ID Unique identifing for each passenger SibSp Parch Survived Our outcome or dependent variable 0 1 Continous Age Fare Text Variable Ticket Ticket number for passenger. com en us minitab 18 help and how to statistics basic statistics supporting topics basics null and alternative hypotheses article one tailed tests are more powerful than two tailed test. Here is an image to show how bootstrapped dataset works. 6 Sex and Survived 0. Formulate a well developed research problem or question The hypothesis test usually starts with a concrete and well developed researched problem. aspx article is pretty good as well. As the model gets complex bias decreases variance increases. We will use machine learning model Random Forest Regressor to impute missing value instead of Null value. let s take 50 random sample of male and female from our train data. Lets analyze and see what we have here. However let s dig a little deeper. Gatter more data and gather better quality data. As I go on in this journey and learn new topics I will incorporate them with each new updates. For example in terms of this dataset our model is a binary one and we are trying to classify whether the passenger survived or not survived. 7435897435897436 False Positive Rate How often the model predicts yes survived when it s actually no not survived FP FP TN 28 28 149 0. Let s stop for a second here and think through how we can take advantage of some of the other features here. Let s again look at a the sample of the train dataset below. We know our sample is selected from a broader population trainning set. Cons Difficult and time consuming to properly tune hyper parameters. Hypothesis testing for Titanic Formulating a well developed researched question Regarding this dataset we can formulate the null hypothesis and alternative hypothesis by asking the following questions. These are the top 10 features determined by Decision Tree helped classifing the fates of many passenger on Titanic on that night. The test set does not provide passengers survival status. In an alternative theory the observations show a real effect combined with a component of chance variation. The smaller the P value the stronger the evidence against the null hypothesis. Once that is done we will separate our train and test to continue towards machine learning modeling. We know we could have totally ended up with a different random sample of males and females. So I am going to introduce a few necessary libraries for now and as we go on we will keep unboxing new libraries when it seems appropriate. We do not want to use any part of the test data in any way to modify our algorithms Which are the reasons why we clean our test data and train data separately. with this in mind we can update modify our null and alternative hypothesis. TP TP FP 87 87 28 0. fit X y y_pred XGBClassifier. For now I will get rid off the ticket feature. With a lot of equally likely training data bagging is not very susceptible to overfitting with noisy data therefore reduces variance. Resampling from original dataset to bootstrapped datasetsSource https uc r. Gender and Survived This bar plot above shows the distribution of female and male survived. Visualization and Feature Relations Before we dive into finding relations between independent variables and our dependent variable survivor let us create some assumptions about how the relations may turn out among features. 26 Negative Correlation Features Fare and Pclass 0. Is there a significant difference in the mean sex between the passenger who survived and passenger who did not survive. It is the status quo. This relationship can be explained by saying that first class passenger 1 paid more for fare then second class passenger 2 similarly second class passenger paid more than the third class passenger 3. It looks like the features have unequal amount of data entries for every column and they have many different types of variables. Once we train our algorithm using 2 3 of the train data we start to test our algorithms using the remaining data. Squaring the correlation feature not only gives on positive correlations but also amplifies the relationships. True Negative TN values that model predicted as no not survived and is actually no not survived False Positive or Type I error values that model predicted as yes survived but actually no not survived False Negative or Type II error values that model predicted as no not survived but actually yes survived For this dataset whenever the model is predicting something as yes it means the model is predicting that the passenger survived and for cases when the model predicting no it means the passenger did not survive. How about we give it a little more character. We randomly select 50 people to be in the male group and 50 people to be in the female group. com max 400 1 hFJ LI7IXcWpxSLtaC0dfg. However this process makes this kernel too lengthy to sit and read at one go. Ideally we want to configure a model that performs well not only in the training data but also in the test data. On the other hand Overfitting is when the model performs too well on the training data but does poorly in the validation set or test sets. Let s take a look at sample datasets. set_text Lower adding saved target variable with train. Print them out Creating a new colomn with a separating our independent and dependent variable Feature Scaling import LogisticRegression model in python. The null hypothesis H_0 and Alternating hypothesis H_1 The null hypothesis H_0 is something that is assumed to be true. 63 first class passengers survived while only 24 lower class passenger survived. Here we get 1 10 1 10 2 10 or 1 5. We can take the average of the values where Pclass is 3 Sex is male and Embarked is S Age Feature We know that the feature Age is the one with most missing values let s see it in terms of percentage. 19 True Positive Rate Recall Sensitivity How often the model predicts yes survived when it s actually yes survived TP TP FN 87 87 30 0. A Glimpse of the Datasets. So check for them and please leave a comment if you have any suggestions to make this kernel better Going back to the topics of this kernel I will do more in depth visualizations to explain the data and the machine learning classifiers will be used to predict passenger survival status. If you want to learn more about regression models try this kernel https www. This breaking down process is done by asking questions about the features of the datasets. Part 1 Importing Necessary Libraries and datasets 1a. Feature ImportanceWhy Random Forest Pros and Cons Introducing Ensemble LearningIn statistics and machine learning ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. Name Name of the passenger. When fare is approximately more than 280 dollars there is no gray shade which means either everyone passed that fare point survived or maybe there is an outlier that clouds our judgment. com masumrumi logistic regression with titanic dataset. For now we are going to work with a less complicated and quite popular machine learning dataset. com masumrumi bagging with titanic dataset kernel if you want to find out more about bagging classifier. n is the sample size. For this competition when we train the machine learning algorithms we use part of the training set usually two thirds of the train data. Therefore we say Null Hypothesis H_0 There is no difference in the survival rate between the male and female passengers. The motivation is to combine several weak models to produce a powerful ensemble. Let s do some statistics to see how statistically significant this correlation is. Before ScalingAfter ScalingYou can see how the features have transformed above. The only difference is that we replace our hypothesis mean with another sample mean and the two sample sizes repalce one sample size. Shorter training times. Evaluating a classification modelThere are multiple ways to evaluate a classification model. In order words it is basically the measure of signal over noise. If you have any idea suggestions about this notebook please let me know. For example if we say our significance level is 5 then our confidence interval would be 1 0. The population mean is a statistical term statistician uses to indicate the actual average of the entire group. Null Hypothesis H0 male mean is greater or equal to female mean. We are to predict that using machine learning models. Age Younger passenger survived more than other passengers. This is where Central limit theory comes from. Pretty much every male that boarded on Queenstown Q did not survive. rumi Part 2 Overview and Cleaning the Data 2a. The age variable seems to be promising for determining survival rate. Assumptions Gender More female survived than male Pclass Higher socio economic status passenger survived more than others. As we ask questions we are breaking down the dataset into more subsets. MinMaxScaler Scales the data using the max and min values so that it fits between 0 and 1. After each iteration weights gets re calculated in order to take the errors misclassifications from the last stump into consideration. Often times a dataset contain features highly varying in magnitude and unit. Which means each data point will have 1 10 weight. the first column is of data points that the machine predicted as not survived. I will discuss more on that. com watch v 5NcMFlrnYp8 list PLIeGtxpvyG LrjxQ60pxZaimkaKKs0zGF video is also quite helpful understanding these topics. The following equation help us to do this calculation. Features engineering is the simple word for doing all those. Using this method the RF model creates 100 s 1000 s the amount can be menually determined of a wide variety of decision trees. This https stattrek. This kernel https www. StandardScaler Scales the data so that it has mean 0 and variance of 1. Summary The first class passengers had the upper hand during the tragedy. An Alternative hypothesis H_A is a claim and the opposite of the null hypothesis. Reduced risk of data errors during model use Data redundancy Part 6 Pre Modeling Tasks 6a. Lets find out a bit more about the train and test dataset. RF is an ensemble method combination of many decision trees which is where the forest part comes in. com docs docs BiasVariance biasvariance. The grid above clearly demonstrates the three outliers with Fare of over 500. Secondly we need to determine how much say a stump will have in the final classification and how we can calculate that. Computing T statistics and P value Let s take a random sample and see the difference. n_M and n_F are the sample number of observations in each group. AUC ROC Curve Using Cross validation Pros Helps reduce variance. More risk of overfitting compared to bagging. In a supervised machine learning process we are giving machine computer models specific inputs or data text number image audio to learn from aka we are training the machine to learn certain aspects based on the data and the output. When we use cross validation it is important to remember not to use X_train X_test y_train and y_test rather we will use X and y. This bar plot shows that 74 female passenger survived while only 19 male passenger survived. com hypothesis test hypothesis testing. Missclassification is equivalent to 1 minus Accuracy. However the most critical part is the error rates. Also the following chart gives us a mental picture of where we want our models to be. Misclassification Rate is also known as Error Rate. There is a definite positive correlation between Fare and Survived rated. Feature Scaling Feature scaling is an important concept of machine learning models. this can be a good exercise for beginners to try to write simple functions like this. com dansbecker underfitting and overfitting explains this topic well. com watch v 8Oog7TXHvFY Under fitting Over fitting So we have our first model and its score. Print classification report for y_test Gradient Boosting Classifier from xgboost import XGBClassifier XGBClassifier XGBClassifier XGBClassifier. For example lets say we start a stump with 10 datasets. Once we have a subgroup with only the unique type of labels we end the tree in that node. GridSearch finds the optimal value of alpha among a range of values provided by us and then we go on and use that optimal value to fit the model and get sweet results. The pseducode for calculating the new sample weight is as follows. We can also think about it epsilon_t frac text misclassifications _t text observations _t Since the weight is uniformly distributed all add up to 1 among all data points the total error will always be between 0 perfect stump and 1 horrible stump. predict X_test XGBClassifier_accy round accuracy_score y_pred y_test 3 print XGBClassifier_accy XGB_Classifier XGBClassifier models pd. I am showing a sample of both before and after so that you can see how scaling changes the dataset. I am not a big fan of importing everything at once for the newcomers. Depending on the standard deviation we either use t statistics or z statistics. 54 which points towards some undeniable insights. It seems about right since females and children were the priority. then X_test is used in that trained algorithms to predict outcomes. Let s make an effort to fill these missing values starting with Embarked feature. Therefore I have decided to break this kernel down and explain each algorithm in a different kernel and add the links here. The feature with the lowest Gini index becomes the first stump in the AdaBoost stump chain the lower the Gini index is the better unmixed the label is therefore better split. To GA where I started my data science journey. For example if we click on upper and Female tab we would see that green color dominates the bar with a ratio of 91 3 survived and non survived female passengers a 97 survival rate for females. Now let s go through the features and describe a little. X_train and y_train first used to train the algorithm. Compute the T Statistics Z Statistics Computing the t statistics follows a simple equation. Khan Academy has a set of videos that I think are intuative and helped me understand conceptually. Therefore It would be unwise to replace the missing values with median mean or mode. OverviewDatasets in the real world are often messy However this dataset is almost clean. According to this https support. This equation slightly differs depending on one sample test or two sample test 6. The group can be any gathering of multiple numbers such as animal human plants money stocks. Age and Survived There is nothing out of the ordinary about this plot except the very left part of the distribution. jpg As you see in the chart above. These penalties require specific alpha the strength of the regularization technique to set beforehand. Therefore It is impossible for us at this point to know the population means of survival for male and females. Therefore we need to do feature scaling to get a better result. Often times Categorical variables are an important features which can be the difference between a good model and a great model. Do a statistical analysis of how some group of people was survived more than others. Underfitting is when the model fails to capture important aspects of the data and therefore introduces more bias and performs poorly. This is our total error. Now that we know what we want in terms of under fitting and over fitting let s talk about how to combat them. They are Embarked Age Survived Sex. I think this video https www. com masumrumi decision tree with titanic dataset kernel. So why do we still have to split our training data If you are curious about that I have the answer. These models are built to deal with the bias variance tradeoff. 74 female passenger survived while only 19 male passenger survived. Writing pythonic code Six steps to more professional data science code Creating a Good Analytics Report Code Smell Python style guides The Best of the Best Practices BOBP Guide for Python PEP 20 The Zen of Python The Hitchiker s Guide to Python Python Best Practice Patterns Pythonic Sensibilities Why Scikit Learn Introduction to Scikit Learn Six reasons why I recommend scikit learn Why you should learn Scikit learn A Deep Dive Into Sklearn Pipelines Sklearn pipelines tutorial Managing Machine Learning workflows with Sklearn pipelines A simple example of pipeline in Machine Learning using SKlearn Credits To Brandon Foltz for his youtube channel and for being an amazing teacher. We may have alphanumerical or and text features. The word GridSearch stands for the fact that we are searching for optimal parameter parameters over a grid. To Kaggle community for inspiring me over and over again with all the resources I need. Each stump is made by talking the previous stump s mistakes into account. It is going against the status quo. Here Age and Calculated_fare is much higher in magnitude compared to others machine learning features. We can reset the filters by clicking anywhere in the whilte space. This part of the kernel is a working progress. get_legend leg_1. Now these means can help us determine the unknown cabins if we compare each unknown cabin rows with the given mean s above. Compare P value with alpha It looks like the p value is very small compared to our significance level alpha of 0. If the Total Error is 1 or 0 then this equation will freak out. Determine the test statistic test statistic can be used to assess the truth of the null hypothesis. However as the chain of stumps continues and at the end of the process AdaBoost becomes a strong tree and reduces both bias and variance. This theory can also be supported by mentioning another Pclass correlation with our dependent variable Survived. Resources Statquest Principles of Machine Learning AdaBoost Video Pros and cons of boosting Pros Achieves higher performance than bagging when hyper parameters tuned properly. Using RandomizedSearchCVRandomized search is a close cousin of grid search. or the mean difference in the survival rate between male and female is not zero. Let s point out the core concepts. One particular tactic for this task is regularization models Ridge Lasso Elastic Net. Cabin Embarked Port of Embarkation C Cherbourg Q Queenstown S Southampton Dichotomous Nominal variable with only two categories Sex Female Male Ordinal variables that have two or more categories just like nominal variables. In addition to that we want to identify whether the test is a one tailed test or two tailed test. Here our dependent variable or target variable is Survived. FP FN Total 28 30 294 0. In our test dataset we do not have a dependent variable feature. TN TN FP 149 149 28 0. com watch v E4KCfcVwzyw explains the p value well. For some machine learning models it is not a problem. The final prediction is typically constructed by a weighted vote where weights for each base model depends on their training errors or misclassification rates. Let s get a better perspective of the dataset through this visualization. However they all seem to book under the same letter followed by different numbers. It is essential to understand those model parameters are different from models outcomes for example coefficients or model evaluation metrics such as accuracy score or mean squared error are model outcomes and different than hyperparameters. We never accept the null hypothesis just because we are doing the statistical test with sample data points. We sure can delete this point. Something I have noticed that some readers might find questionable is that the lower class passengers have survived more than second class passengers. So now we will use a confusion matrix to compare between y_test and y_pred. People who acts according to model results have a better understanding of the model. com blog statistics and quality data analysis what is a t test and why is it like telling a kid to clean up that mess in the kitchen as reference to describe the t statistics here. Samples with higher weight have a higher influence on the total error of the next model and gets more priority. We have two choices we can either get rid of the whole feature or we can brainstorm a little and find an appropriate way to put them in use. Let s see what they are True Positive TP values that the model predicted as yes survived and is actually yes survived. Embarked feature It looks like there are only two null values 0. I have used and modified some of the code from this course to help making the learning process intuitive. We will discuss more in depth about those in another lesson. The color illustrates passengers survival status green represents survived gray represents not survived The column represents Sex left being male right stands for female The row represents Embarked from top to bottom S C Q Now that I have steered out the apparent let s see if we can get some insights that are not so obvious as we look at the data. There were very few females boarded on Queenstown however most of them survived. Specify a Significance level and Confidence Interval The significance level alpha is the probability of rejecting a null hypothesis when it is true. Part 4 Statistical Overview title https cdn images 1. More than 60 of the passengers lived boarded on Cherbourg C. For now we will use Standard Scaler to feature scale our dataset. stats to find the t statistics. Combined Feature Relations In this section we are going to discover more than two feature relations in a single graph. The more samples we take and the more sample means will be added and the closer the normal distribution will reach towards population mean. We have separated dependent and independent features We have separated train and test data. In any case when we look at the data we seem to have an intuitive understanding of where data is leading us. where we calculate the difference between hypothesized mean and sample mean. After all it is a matrix and we have some terminologies to call these statistics more specifically. Can use robust loss functions that make the model resistant to outliers. Train Set Test SetThis is a sample of train and test dataset. I will explain more as we keep reading. Let s apply cabin_estimator function in each unknown cabins cabin with null values. or the mean difference between male and female passenger in the survival rate is zero. However we will use scipy. D_t i Current Sample weight. Here S is standard deviation which tells us how much variation is there in the data. RobustScaler Scales the data similary to Standard Scaler but makes use of the median and scales using the interquertile range so as to aviod issues with large outliers. The test set should be used to see how well our model performs on unseen data. For now we have decided to make our significance level alpha 0. age_groupWe can create a new feature by grouping the Age columnNeed to paraphrase this sectionFeature SelectionFeature selection is an important part of machine learning models. The code below basically splits the train data into 4 parts X_train X_test y_train y_test. png Ideally we want to pick a sweet spot where the model performs well in training set validation set and test set. However in order to calculate between two sample population mean or in our case we will use the follow equation. Let s write a functin to print the total percentage of the missing values. Our dependent variable or target variable is something that we are trying to find and our independent variable is the features we use to find the dependent variable. Let s determine the value of all these terminologies above. As we assumed it looks like an outlier with a fare of 512. Our model may be overfitting or underfitting. There are multiple ways to do feature scaling. Let s do a quick review Bagging classifier uses a process called bootstrapped dataset to create multiple datasets from one original dataset and runs algorithm on each one of them. We need to ask the right question that can be answered using statistical analysis. There are many reasons why we use feature selection. com This kernel will always be a work in progress. is for us to have an overview and play around with the dataset. Now we have to understand that those two means are not the population mean bar mu. 7565217391304347we have our confusion matrix. It doesn t always provide the best result but its fast. We will have a detailed statistical analysis of Titanic data set along with Machine learning model implementation. While working with a dataset having meaningful value for example male or female instead of 0 s and 1 s is more intuitive for us. The models use weights that are assigned to each data point raw indicating their importance. This situation is also known as having less bias but more variation and perform poorly as well. fare_groupFare group was calculated based on calculated_fare. In fact for those of you don t know what overfitting and underfitting is Let s find out. Nothing more and nothing less. DataFrame Model Support Vector Machines KNN Logistic Regression Random Forest Naive Bayes Decision Tree Gradient Boosting Classifier Voting Classifier XGB Classifier ExtraTrees Classifier Bagging Classifier Score svc_accy knn_accy logreg_accy random_accy gaussian_accy dectree_accy gradient_accy voting_accy XGBClassifier_accy extraTree_accy bagging_accy. Easily handles mixed data types. So let s fill in the missing values as C Cabin Feature Approximately 77 of Cabin feature is missing in the training data and 78 missing on the test data. Resources Confusion Matrix https www. Some stumps get more say in the final classifications than others. True Positive TP 87 True Negative TN 149 False Positive FP 28 False Negative FN 30From these four terminologies we can compute many other rates that are used to evaluate a binary classifier. I am going to use this post http blog. Now how can we determine that machine is actually learning what we are try to teach That is where the test set comes to play. Alternative Hypothesis H_A There is a difference in the survival rate between the male and female passengers. we have fit the model using X_train and y_train and predicted the outcome of X_test in the variable y_pred. This base model fitting is an iterative process where each stump is chained one after the other It cannot run in parallel. Bagging Classifier Bagging Classifier Bootstrap Aggregating is the ensemble method that involves manipulating the training set by resampling and running algorithms on it. S is the standard deviation. You are probably wondering why two datasets Also Why have I named it train and test To explain that I am going to give you an overall picture of the supervised machine learning process. In addition to that Significance level is one minus our Confidence interval. Easier to implement by software developers model production. Let s do the confusion matrix. The correlation between Pclass and Survived is 0. com en us minitab 18 help and how to statistics basic statistics supporting topics basics null and alternative hypotheses article explains it pretty well. When we have a model that overfits meaning less biased and more of variance we introduce some bias in exchange of having much less variance. We want our models to be at the bottom of that U shape where the error rate is the least. When the stump does an average job similar to a coin flip the ratio of getting correct and incorrect 50 50 then the total error is 0. Loading Datasets After loading the necessary modules we need to import the datasets. More than 60 of the passengers died boarded on Southampton. Now let s see how the features are related to each other by creating some visualizations. Since we do not know the standard deviation sigma and n is small we will use the t distribution. Fare and Survived This plot shows something impressive. Since the stump barely captures essential specs about the dataset the model is highly biased in the beginning. AdaBoost combines a lot of weak learners they are also called stump a tree with only one node and two leaves to make classifications. PassengerIdIt seems like PassengerId column only works as an id in this dataset without any significant effect on the dataset. To illustrate what we have talked about so far let s look at the following visualization. Predict Use machine learning classification models to predict the chances of passengers survival. Third We need to learn how to modify the weights so that the next stump will take the errors that the current stump made into account. Misclassification Rate Misclassification Rate is the measure of how often the model is wrong Misclassification Rate and Accuracy are opposite of each other. Expends models predictability. Part 7 Modeling the Data In the previous versions of this kernel I thought about explaining each model before applying it. printing confision matrix Compute confusion matrix Only use the labels that appear in the data We want to show all ticks. You can probably agree with me more on this in the next section of visualizations where we look at the distribution of ticket fare and survived column. At this point I think we are quite confident that these outliers should be deleted. To Udemy Course Deployment of Machine Learning. Voting Classifier Part 8 Submit test predictions Resources Statistics Types of Standard Deviation What Is a t test And Why Is It Like Telling a Kid to Clean Up that Mess in the Kitchen What Are T Values and P Values in Statistics What is p value How we decide on our confidence level. To specify them we need to separate them from each other and the code below does just that. set_text Middle legs 2. Now the denominator of this fraction bar x mu is basically the strength of the signal. So according to the explanation above the t value or t statistics is basically measures the strength of the signal the difference to the amount of noise the variation in the data and that is how we calculate the t value in one sample t test. This negative correlation with a magnitude of 0. 33 So Let s analyze these correlations a bit. Introducing regularization models. In order to calculate the total erorr we add up all the misclassified weights. Our y_test has a total of 294 data points part of the original train set that we splitted in order to evaluate our model. However don t let that fool you to thinking that similar to a decision tree bagging also overfits the model. Describe the result and compare the p value with the significance value alpha If p alpha we say that we fail to reject the null hypothesis. Inversely we want to decrease the sample weight of the correctly classified samples hinting the next stump to put less emphasize on those. set_text Upper legs 1. Hypothesis Testing OutlineA hypothesis test compares the mean of a control group and experimental group and tries to find out whether the two sample means are different from each other and if they are different how significant that difference is. For example when we choose to use linear regression we may decide to add a penalty to the loss function such as Ridge or Lasso. Resources AdaBoost Tutorial Chris McCormick Explaining AdaBoost by Robert Schapire One of the original author of AdaBoost 7i. We may also say passengers with cabin record were more likely to be taken into consideration when loading into the boat. Gradient Boosting Classifier Resources Gradient Descent StatQuest Gradient Boost Regression Main Ideas StatQuest Gradient Boost Regression Calculation StatQuest Gradient Boost Classification Main Ideas StatQuest Gradient Boost Classification Calculation StatQuest Complete Machine Learning Guide to Parameter Tuning in Gradient Boosting GBM in Python 7j. However the downside is that this leads to an increase in bias. There is a couple of different type of variables They are. Tableau Visualization of the Data I have incorporated a tableau visualization below of the training data. This https support. The Hyperparameters are model parameters that are set before fitting the model and determine the behavior of the model. This variety makes the RF model more effective and accurate. We then run each test data point through all of these 100 s to 1000 s of decision trees or the RF model and take a vote on the output. It seems like Fare column kept a record of the total fare rather than the fare of individual passenger therefore calculated fare will be much handy in this situation. Most of the passengers were with in the Fare range of 100. Plot non normalized confusion matrix Plot normalized confusion matrix run model 10x with 60 30 split intentionally leaving out 10 estimator knn param_grid param n_jobs 1 to instruct scikit learn to use all available processors. We want to increase the sample weight of the misclassified samples hinting the next stump to put more emphasize on those. This count plot shows the actual distribution of male and female passengers that survived and did not survive. In a null hypothesis the observations are the result of pure chance. This kernel is for all aspiring data scientists to learn from and to review their knowledge. We can use multiple filters to see if there are any correlations among them. It seems like there is a significance with the letters rather than the numbers. Let s see how the Fare is distributed among all Pclass and Embarked feature valuesHere in both training set and test set the average fare closest to 80 are in the C Embarked values where pclass is 1. For example To find the age population mean of Bulgaria we will have to account for every single person s age and take their age. Kernel Goals There are three primary goals of this kernel. Positive Correlation Features Fare and Survived 0. We will use the sampling distribution approach to do the test. This can create problems as many machine learning models will get confused thinking Age and Calculated_fare have higher weight than other features. This relationship reveals that the passenger who paid more money for their ticket were more likely to survive. It is an ultimate balance between type 1 error and type 2 error. This theory aligns with one other correlation which is the correlation between Fare and Pclass 0. Gaussian Naive Bayes using the best found hyper paremeters to get the score. It shows that among all the females 230 survived and 70 did not survive. Both of them have the concept of signal noise. figure_format retina This is preferable for retina display. However from this facet grid we can also understand which age range groups survived more than others or were not so luckyThis is another compelling facet grid illustrating four features relationship at once. S 2 is the sample variance. So any suggestion would be truly appreciated. Accuracy Accuracy is the measure of how often the model is correct. Facetgrid is a great way to visualize multiple variables and their relationships at once. Let s look at the feature importance from decision tree grid. 63 first class passenger survived titanic tragedy while 48 second class and only 24 third class passenger survived. In other words we are comfortable confident with rejecting the null hypothesis a significant amount of times even though it is true. However when we do statistical tests we get a scientific or mathematical perspective of how significant these results are. How to combat over fitting Simplify the model by using less parameters. comPlease check out this https www. One crucial details about Random Forest is that while using a forest of decision trees RF model takes random subsets of the original dataset bootstrapped and random subsets of the variables features columns. Here We can take the average of the Fare column to fill in the NaN value. So We still haven t done any effective work to replace the null values. Situation like this calls for a statistical approach. The Total Error for a stump is the sum of the weights associated with the incorrectly classified samples. Do an exploratory data analysis EDA of titanic with visualizations and storytelling. We are going to use our model to predict passenger survival status. I will incorporate new concepts of data science as I comprehend them with each update. Sometimes we want to create extra features from with in the features that we have sometimes we want to remove features that are alike. According to the samples our male samples bar x _m and female samples bar x _f mean measured difference is 0. K Nearest Neighbor classifier KNN Manually find the best possible k value for KNN Grid search on KNN classifier Using best estimator from grid search using KNN. Loading librariesPython is a fantastic language with a vibrant community that produces many amazing libraries. We can use the average of the fare column We can use pythons groupby function to get the mean fare of each cabin letter. It seems like there are some passengers that had booked multiple cabin rooms in their name. Fare Passenger with higher fare survived more that other passengers. Let s combine train and test data first and for now will assign all the null values as N All the cabin names start with an English alphabet following by multiple digits. https cdncontribute. For example We may say passengers with cabin record had a higher socio economic status then others. Categorical Nominal variables that have two or more categories but which do not have an intrinsic order. Let s see what they are. When we say unseen data we mean that the algorithm or machine learning models have no relation to the test data. 8418079096045198 Precision How often is it correct when the model predicts yes. Now you can see that the predicted not survived and predicted survived sort of overlap with actual survived and actual not survived. Let s write a simple function so that we can give cabin names based on the means. Gaussian Process Classifier 7m. Let s say once the weight is distributed we run the model and find 2 incorrect predicitons. The spike in the plot under 100 dollar represents that a lot of passengers who bought the ticket within that range did not survive. This considerable amount is our Significant level. Compute the P value P value is the probability that a test statistic at least as significant as the one observed would be obtained assuming that the null hypothesis is correct. However the most significant correlation with our dependent variable is the Sex variable which is the info on whether the passenger was male or female. Our observation sample is statistically significant. A small amount of error is added to prevent this from happening. Let us describe the previous sentence a bit more for clarification. Dealing with Missing values Missing values in train dataset. This may hint on the posibility that children and infants were the priority. Most passengers seem to be boarded on Southampton S. bar x _M is the mean of our male group sample measurements. Once we get the outcomes we compare it with y_test By comparing the outcome of the model with y_test we can determine whether our algorithms are performing well or not. Now let s look at the value counts of the cabin features and see how it looks. keeping in mind that. t frac bar x _M bar x _F sqrt s 2 frac 1 n_M frac 1 n_F This equation may seem too complex however the idea behind these two are similar. 8027We can also calculate accuracy score using scikit learn. NOTE If you want to learn more about Advanced Regression models please check out this kernel. Overview Survived vs non survied Generate a mask for the upper triangle taken from seaborn example gallery separating male and female dataframe. From the chart in section 3a we have a intuation that female passengers had better prority than males during the tragedy. It is true since there were a lot more third class passengers than first and second. Going back to our dataset like we are saying these means above are part of the whole story. If you are a bit confused thats okay. We may have missing values in our features. However there is a fundamental difference between these two which is Random Forests ability to pick subsets of features in each node. Even though this sentence is grammatically wrong it is logically right. As Data Scientists we need to remember no to creating models with too many variables since it might overwhelm production engineers. Only the categories can also be ordered or ranked. However for many other ones its quite a problem. Summary As we suspected female passengers have survived at a much better rate than male passengers. In this case the amount of say is 0. Boosting Methods The other family of ensemble methods are boosting methods where base estimators are built sequentially and one tries to reduce the bias of the combined estimator. We see that in both train and test dataset have missing values. That sweet spot is also known as Optimum Model Complexity OMC. Simple models are easier to interpret. If you would like to check out some of my other tableau charts please click here. and label them with the respective list entries Rotate the tick labels and set their alignment. New Sample Weight Sample Weight e alpha_t Here the alpha_t AmountOfSay can be positive or negative depending whether the sample was correctly classified or misclassified by the current stump. We will keep the age column unchanged for now and work on that in the feature engineering section. In addition to that this https www. These optimal parameters are also known as Hyperparameters. If the model performs well we dump our test data in the algorithms to predict and submit the competition. Any feedback about further improvements would be genuinely appreciated. png Train info I have gathered a small summary from the statistical overview above. Creating dummy variablesYou might be wondering what is a dummy variable Dummy variable is an important prepocessing machine learning step. Which is almost impossible and if we were to go that route there is no point of doing statistics in the first place. The first stump will uniformly distribute an weight amoung all the datapoints. However we will keep it for now. Machine Learning is simply Machine and Learning. So our confidence interval or non rejection region would be 1 alpha 1 0. I will elaborate on this in a future update. Many of the business problems usually come with a tremendous amount of messy data. We may have categorical features. A hypothesis test usually consists of multiple parts 1. calculated_fareSome people have travelled in groups like family or friends. The t statistics is the measure of a degree to which our groups differ standardized by the variance of our measurements. Each number here represents certain details about our model. 15819209039548024 True Negative Rate Specificity How often the model predicts no not survived when it s actually no not survived True Negative Rate is equivalent to 1 minus False Positive Rate. As we compare we use confusion matrix to determine different aspects of model performance. I am hoping to write about that in a different kernel. We will follow each of these steps above to do your hypothesis testing below. Many machine learning algorithms uses euclidian distances to calculate the distance between two points it is quite a problem. AdaBoost Classifier AdaBoost is another ensemble model and is quite different than Bagging. This train data set has 891 raw and 9 columns. We will go more in depth of this topic later on. bar x is the sample mean. If the mean difference is higher then the signal is stronger. However it is essential to understand what our end goal is. Determine the test statistics This will be a two tailed test since the difference between male and female passenger in the survival rate could be higher or lower than 0. the numerator of this fraction S sqrt n calculates the amount of variation or noise of the data set. There are two types of ensemple learnings. Here is an image to make it clear on how bagging works Source https prachimjoshi. If you have come this far Congratulations If this notebook helped you in any way or you liked it please upvote and or leave a comment Import necessary modules config InlineBackend. Specify the significance level Specifying a significance level is an important step of the hypothesis test. This can also be explained by saying that first class passenger had a better chance of surviving than the second or the third and so on. The p value is known to be unintuitive and even many professors are known to explain it wrong. The way we use machine learning algorithm in a dataset is that we train our machine learning model by specifying independent variables and dependent variable. Therefore our null hypothesis is ruled out and our alternative hypothesis is valid which is There is a significant difference in the survival rate between the male and female passengers. Extra Trees Classifier 7l. TP TN total 87 149 294. bar x _F is the mean of female group samples. I am super excited to share my first kernel with the Kaggle community. In terms of raws the first raw indexed as Not survived means that the value in that raw are actual statistics of not survived once. Let s see what are those two null values We may be able to solve these two missing values by looking at other independent variables of the two raws. 22 in the Embarked feature we can replace these with the mode value S. Therefore we approach this problem using sample sets. is_alone ticketI have yet to figureout how to best manage ticket feature. Alternative Hypothesis H1 male mean is less than female mean. Confusion MatrixConfusion matrix a table that describes the performance of a classification model. Correlation Matrix and Heatmap Correlations Sex is the most important correlated feature with Survived dependent variable feature followed by Pclass. csv The training set includes our target variable dependent variable passenger survival status also known as the ground truth from the Titanic tragedy along with other independent features like gender class fare and Pclass. The x_label represents Sex feature while the y_label represents the of passenger survived. Let s do itLet s take a look at the histogram of the age column. XGBClassifier 7k. This can happen for the following reasons. Loop over data dimensions and create text annotations. Bagging ClassifierIf some of you are like me you may find Random Forest to be similar to Bagging Classifier. About This Dataset The data has split into two groups training set train. family_size Creating a new feature called family_size. Splitting the training data There are multiple ways of splitting data. Calculating the t statistics t frac bar x mu frac S sqrt n Here. With all three points above in mind how confident are we that the measured difference is real or statistically significant we can perform a t test to evaluate that. If you would like to get a detailed understanding of Decision tree classifier please take a look at this https www. This facet grid unveils a couple of interesting insights. We extract those data from many sources. Gaussian Naive Bayes Support Vector Machines SVM Decision Tree ClassifierDecision tree works by breaking down the dataset into small subsets. ROC Curve AUC Curve. Therefore we can group these cabins according to the letter of the cabin name. This is because many of them travelled with family. We were given part of the data to train our machine learning models and the other part of the data was held back for testing. Create green Bars Create orange Bars Custom x axis Show graphic Kernel Density Plot Kernel Density Plot Kernel Density Plot Placing 0 for female and 1 for male in the Sex column. only 38 passenger survived during that tragedy. the second column is of the statistics that the model predicted as survievd. But how do we make sure that our model is performing well. io After running a learning algorithm on each one of the bootstrapped datasets all models are combined by taking their average. Is there a substantial difference in the survival rate between the male and female passengers The Null Hypothesis and The Alternative Hypothesis We can formulate our hypothesis by asking questions differently. When we perform a t test we are usually trying to find out an evidence of significant difference between population mean with hypothesized mean 1 sample t test or in our case difference between two population means 2 sample t test. H0 male mean is greater or equal to female meanH1 male mean is less than female mean. The higher the value of alpha the more penalty is being added. On average the combined estimator is usually better than any of the single base estimator because its variance is reduced. Both passengers paid a fare of 80 are of Pclass 1 and female Sex. We want to see how the left vertical bar changes when we filter out unique values of certain features. Using the best parameters from the grid search. mu is the hypothesized mean. and the Survived indexed raw are values that actually survived. ", "id": "masumrumi/a-statistical-analysis-ml-workflow-of-titanic", "size": "65172", "language": "python", "html_url": "https://www.kaggle.com/code/masumrumi/a-statistical-analysis-ml-workflow-of-titanic", "git_url": "https://www.kaggle.com/code/masumrumi/a-statistical-analysis-ml-workflow-of-titanic", "script": "sklearn.metrics percent_value_counts cross_val_score sklearn.naive_bayes sklearn.tree pyplot as plt missing_percentage BaggingClassifier AdaBoostClassifier StratifiedShuffleSplit sklearn.gaussian_process recall_score precision_score KNeighborsClassifier fare_group unique_labels DecisionTreeClassifier pyplot numpy seaborn age_group_fun RandomForestRegressor auc plot_confusion_matrix cabin_estimator XGBClassifier balanced_accuracy_score ExtraTreesClassifier GradientBoostingClassifier family_group VotingClassifier sklearn.ensemble sklearn.model_selection name_converted confusion_matrix RandomForestClassifier matplotlib.pyplot sklearn.utils.multiclass completing_age pandas classification_report GaussianProcessClassifier StandardScaler LogisticRegression accuracy_score precision_recall_curve mean_absolute_error GridSearchCV sklearn.neighbors SVC sklearn.linear_model matplotlib sklearn.preprocessing roc_curve StratifiedKFold RandomizedSearchCV GaussianNB name_length_group sklearn.svm xgboost train_test_split ", "entities": "(('Gridsearch', 'Machine simple effective Learning'), 'Search') (('Many', 'messy data'), 'come') (('where we', 'column'), 'agree') (('before you', 'how dataset'), 'show') (('Most', '100'), 'be') (('we', 'means'), 'let') (('that', 'test also data'), 'want') (('that', 'features'), 'want') (('we', 'machine learning less complicated quite dataset'), 'go') (('we', 'machine learning modeling'), 'separate') (('that', 'also model'), 'let') (('which', 'undeniable insights'), '54') (('Evaluating', 'classification modelThere multiple model'), 'be') (('sample', 'population broader trainning'), 'know') (('however most', 'them'), 'be') (('data point', '1 10 weight'), 'mean') (('SibSp Parch', 'Continous Age Fare Text Variable Ticket Ticket 0 1 passenger'), 'proxy') (('better label', 'AdaBoost stump first chain'), 'become') (('Features engineering', 'simple those'), 'be') (('alpha relatively value', 'reasonably good job'), 'do') (('model', 'outliers'), 'use') (('two tailed difference', '0'), 'be') (('These', 'night'), 'be') (('Bagging classifier', 'them'), 'let') (('how well model', 'unseen data'), 'use') (('class class then second passenger 2 similarly second passenger', 'class third passenger'), 'explain') (('calculated_fareSome people', 'family'), 'travel') (('s', 'percentage'), 'take') (('plot', 'something'), 'Fare') (('green color', 'females'), 'see') (('iteration weights', 'consideration'), 'calculate') (('s', 'missing values'), 'let') (('we', 'statistics'), 'be') (('We', 'hypothesis above testing'), 'follow') (('the', 'sort of actual survived'), 'see') (('s', 'how them'), 'let') (('female passengers', 'tragedy'), 'have') (('dataset contain', 'magnitude'), 'feature') (('hypothesis Alternative H_A', 'null hypothesis'), 'be') (('learning process', 'course'), 'use') (('I', 'machine learning supervised process'), 'wonder') (('quite outliers', 'point'), 'think') (('it', 'two points'), 'use') (('age_groupWe', 'machine learning important models'), 'create') (('who', 'other passengers'), 'have') (('sweet spot', 'Optimum Model Complexity also OMC'), 'know') (('models', 'bias variance tradeoff'), 'build') (('t', 'always best result'), 'doesn') (('Fare Passenger', 'more other passengers'), 'survive') (('I', 'update'), 'incorporate') (('data', 'groups training set two train'), 'about') (('children', 'posibility'), 'hint') (('Here Age', 'others machine learning features'), 'be') (('number', 'model'), 'represent') (('Random Forest', 'Bagging Classifier'), 'ClassifierIf') (('where data', 'us'), 'in') (('com dansbecker underfitting', 'topic'), 'explain') (('passenger', 'dependent variable'), 'be') (('measured difference', 'samples'), 'accord') (('eventually distribution', 'more normal distribution'), 'be') (('we', 'dependent variable feature'), 'have') (('We', 'ticks'), 'use') (('some', 'click'), 'like') (('t why it', 't statistics'), 'statistic') (('observations', 'chance variation'), 'show') (('often However dataset', 'real world'), 'be') (('when model', 'poorly validation'), 'be') (('it', 'production engineers'), 'need') (('when model', 'yes'), 'be') (('theory', 'dependent variable Survived'), 'support') (('How about we', 'little more character'), 'give') (('Feature Scaling Feature scaling', 'machine learning important models'), 'be') (('we', 'node'), 'end') (('We', 'test values'), 'see') (('AdaBoost Classifier AdaBoost', 'ensemble quite Bagging'), 'be') (('mean difference', 'survival rate'), 'be') (('s', 'age column'), 'let') (('rather we', 'X'), 'be') (('Specify', 'hypothesis important test'), 'be') (('It', 'dependent variables'), 'separate') (('We', 'train'), 'separate') (('code', '4 parts'), 'split') (('therefore calculated', 'much situation'), 'seem') (('P s', 'difference'), 'let') (('It', 'parallel'), 'be') (('where I', 'data science journey'), 'to') (('I', 'different kernel'), 'hope') (('it', '1'), 'scale') (('that', 'hypothesis hypothesis null H_1'), 'H_0') (('us', 'dataset'), 'be') (('we', 'something'), 'try') (('I', 'at once newcomers'), 'be') (('Therefore we', 'male passengers'), 'say') (('we', '10 datasets'), 'say') (('equation', 'sample slightly one test'), 'differ') (('so far s', 'following visualization'), 'let') (('idea', 'fewer questions'), 'be') (('50 people', 'female group'), 'select') (('part', 'kernel'), 'be') (('test set', 'passengers survival status'), 'provide') (('we', 'control group'), 'form') (('Samples', 'more priority'), 'have') (('Pclass Higher socio status male economic passenger', 'more others'), 'Gender') (('p value', '0'), 'value') (('Sklearn Pipelines Sklearn pipelines tutorial Managing Machine Learning', 'youtube channel'), 'write') (('respective list', 'alignment'), 'label') (('we', 'single graph'), 'Relations') (('We', 'passenger survival status'), 'go') (('60 30 split', 'available processors'), 'normalize') (('how difference', 'other'), 'compare') (('s', 'you'), 'let') (('8027We', 'scikit learn'), 'calculate') (('that', 'when independent variables'), 'be') (('bar how left vertical when we', 'certain features'), 'want') (('we', '2 incorrect predicitons'), 'let') (('kernel', 'always progress'), 'com') (('groups', 'measurements'), 'be') (('So now we', 'y_test'), 'use') (('situation', 'also less bias'), 'know') (('we', 'datasets'), 'load') (('data aspiring scientists', 'knowledge'), 'be') (('here how we', 'other features'), 'let') (('class lower passengers', 'class more second passengers'), 'be') (('AdaBoost', 'strong bias'), 'continue') (('we', 'use'), 'have') (('error where rate', 'shape'), 'want') (('when it', 'FP FP actually TN'), '7435897435897436') (('Facetgrid', 'great multiple variables'), 'be') (('it', 'machine learning models'), 'be') (('We', 'topic'), 'go') (('passengers', 'Pclass'), 'pay') (('I', 'LinkedIn Github masumrumi'), 'be') (('So s', 'correlations'), '33') (('you', 'bagging classifier'), 'bag') (('how features', 'visualizations'), 'let') (('code', 'below just that'), 'need') (('feedback', 'further improvements'), 'appreciate') (('Determine', 'null hypothesis'), 'use') (('when it', 'null hypothesis'), 'specify') (('population', 'mean'), 'add') (('who', 'ticket'), 'reveal') (('machine', 'data points'), 'be') (('that', 'many amazing libraries'), 'be') (('so we', 'data'), 'illustrate') (('grid', 'over 500'), 'demonstrate') (('when model', 'therefore more bias'), 'be') (('The smaller P', 'null hypothesis'), 'value') (('We', 'them'), 'use') (('How we', 'confidence level'), 'type') (('Therefore It', 'median mean'), 'be') (('I', 'answer'), 'have') (('hypothesis test', 'usually multiple parts'), 'consist') (('We', 'Null instead value'), 'use') (('good beginners', 'this'), 'be') (('I', 'it'), 'part') (('how we', 'sample t one test'), 'measure') (('null hypothesis', 'at least as significant one'), 'be') (('we', 'grid'), 'word') (('bar _ F', 'group female samples'), 'be') (('ensemble methods', 'constituent learning algorithms'), 'introduce') (('I', 'new updates'), 'incorporate') (('We', 'those'), 'want') (('RF model', 'columns'), 'be') (('us', 'bit more clarification'), 'let') (('We', 'whilte anywhere space'), 'reset') (('this', 'bias'), 'be') (('important which', 'good model'), 'be') (('They', 'variables'), 'be') (('Feature Engineering Feature Part 5 Engineering', 'exactly what'), 'be') (('Age', 'other features'), 'create') (('we', 'such Ridge'), 'decide') (('where model', 'well training'), 'want') (('they', 'variables'), 'look') (('We', 'different features'), 'find') (('we', 'above whole story'), 'be') (('you', 'kernel https www'), 'try') (('test', 'that'), 'want') (('then total error', '50 50'), 'do') (('stump', 'account'), 'make') (('Null Hypothesis H0 male mean', 'female mean'), 'be') (('you', 'https here www'), 'click') (('which', 'node'), 'be') (('we', 'given mean'), 'help') (('that', 'new feature'), 'create') (('that', 'name'), 'seem') (('it', 'modules Import necessary InlineBackend'), 'come') (('Now denominator', 'basically signal'), 'be') (('we', 'males'), 'know') (('I', 'over over resources'), 'to') (('where weights', 'training errors'), 'construct') (('KDE plot', 'pretty self labels'), 'be') (('We', 'feature engineering section'), 'keep') (('we', 'competition'), 'dump') (('small amount', 'this'), 'add') (('then X_test', 'outcomes'), 'use') (('We', 'alphanumerical features'), 'have') (('480', 'male passengers'), 'survive') (('how it', 'cabin features'), 'let') (('However they', 'different numbers'), 'seem') (('I', 'training data'), 'visualization') (('More than 60', 'Southampton'), 'die') (('Missclassification', 'minus 1 Accuracy'), 'be') (('Alternative Hypothesis H1 male mean', 'female mean'), 'be') (('78', 'test data'), 'let') (('Sex Female Male Ordinal that', 'just nominal variables'), 'Embarked') (('how well it', 'weight'), 'learn') (('I', 'Kaggle community'), 'be') (('k best possible value', 'KNN'), 'find') (('too however idea', 'two'), 'sqrt') (('is', 'dummy variablesYou'), 'wonder') (('Null Alternative We', 'questions'), 'be') (('which', 'Fare'), 'align') (('kernel', 'too one go'), 'make') (('s', 'visualization'), 'let') (('that', 'classification model'), 'matrix') (('we', 'that'), 'see') (('we', 'more subsets'), 'break') (('1000 amount', 'decision trees'), 'create') (('AdaBoost First we', 'decision tree'), 'let') (('which', 'male passengers'), 'rule') (('This', 'quite Pclass'), 'correlate') (('Most passengers', 'Southampton S.'), 'seem') (('they', 'Random Forest RF'), 'admire') (('s', 'null values'), 'let') (('AUC ROC Curve Using Cross Pros Helps', 'variance'), 'validation') (('they', 'two classifications'), 'combine') (('variance', 'base single estimator'), 'be') (('learning algorithm models', 'test data'), 'mean') (('s', 'decision tree grid'), 'let') (('hypothesis test', 'usually concrete well researched problem'), 'formulate') (('which', 'intrinsic order'), 'variable') (('Train Set Test SetThis', 'train'), 'be') (('we', 'follow equation'), 'in') (('we', 't statistics'), 'use') (('model', 'variance increases'), 'decrease') (('fare_groupFare group', 'calculated_fare'), 'calculate') (('70', 'females'), 'show') (('We', 'machine learning models'), 'be') (('data text number image we', 'data'), 'give') (('Age Younger passenger', 'more other passengers'), 'survive') (('confidence then interval', 'example'), 'be') (('group', 'animal plants money such human stocks'), 'be') (('it', '512'), 'look') (('Gender', 'female survived'), 'show') (('current stump', 'account'), 'need') (('sample two sizes', 'sample one size'), 'be') (('s', 'terminologies'), 'let') (('S sqrt n', 'data set'), 'numerator') (('I', 'feature relations'), 'try') (('red color', 'away unsurvived'), 'provide') (('png Train I', 'statistical overview'), 'info') (('algorithms', 'y_test'), 'determine') (('Using', 'grid close search'), 'be') (('PLIeGtxpvyG LrjxQ60pxZaimkaKKs0zGF video', 'also quite topics'), 'watch') (('I', 'different kernel'), 'discuss') (('y', 'values'), 'put') (('how we', 'predictions'), 'let') (('model', 'survievd'), 'be') (('statistically we', 'that'), 'with') (('Correlation Matrix', 'Pclass'), 'be') (('it', 'noise'), 'be') (('how results', 'scientific perspective'), 'get') (('I', 'future update'), 'elaborate') (('you', 'kernel'), 'NOTE') (('Therefore we', 'better result'), 'need') (('True Negative actually Rate', 'Positive 1 False Rate'), '15819209039548024') (('sequentially one', 'combined estimator'), 'boost') (('who', 'range'), 'represent') (('ensemble that', 'it'), 'be') (('passenger', 'dataset'), 'be') (('we', 'age'), 'have') (('how relations', 'features'), 'visualization') (('com watch E4KCfcVwzyw', 'p value'), 'v') (('forest where part', 'method decision ensemble many trees'), 'be') (('value', 'raw'), 'mean') (('_ bar M', 'group sample male measurements'), 'be') (('We', 'Machine model learning implementation'), 'have') (('who', 'passenger'), 'be') (('figure_format This', 'retina display'), 'retina') (('many', 'family'), 'be') (('Both', 'signal noise'), 'have') (('We', 'features'), 'miss') (('We', 'cabin letter'), 'use') (('that', 'binary classifier'), '30from') (('models', 'average'), 'dataset') (('model', 'highly beginning'), 'capture') (('that', 'importance'), 'use') (('also passengers', 'when boat'), 'say') (('facet grid', 'couple interesting insights'), 'unveil') (('even it', 'times'), 'be') (('how group', 'more others'), 'do') (('So we', 'first model'), 'v') (('following equation', 'calculation'), 'help') (('Statistical Test', 'theories'), 'be') (('model parameters', 'model mean squared hyperparameters'), 'be') (('passenger', 'no'), 'value') (('stump', 'correctly 1'), 'Amount') (('More than 60', 'Cherbourg C.'), 'live') (('we', 'null hypothesis'), 'describe') (('optimal parameters', 'also Hyperparameters'), 'know') (('passengers', 'then others'), 'say') (('we', 't distribution'), 'use') (('test data new data', 'output'), 'go') (('we', 'much less variance'), 'introduce') (('stumps', 'others'), 'get') (('just we', 'sample data points'), 'accept') (('Inversely we', 'those'), 'want') (('first stump', 'datapoints'), 'distribute') (('so far you', 'only one missing fare column'), 'feature') (('we', 'sample t 2 test'), 'mean') (('population', 'bar mu'), 'have') (('we', 'model'), 'have') (('Lets', 'bit more train'), 'find') (('RobustScaler', 'large outliers'), 'scale') (('female population', 'point population male mean'), 'call') (('breaking process', 'datasets'), 'do') (('the', 'passenger'), 'represent') (('Total Error', 'incorrectly classified samples'), 'be') (('when it', 'new libraries'), 'go') (('statistical statistician', 'entire group'), 'mean') (('why we', 'test data'), 'want') (('who', 'model'), 'have') (('standard which', 'how much there data'), 'be') (('48 second class', 'titanic tragedy'), 'survive') (('age variable', 'survival rate'), 'seem') (('that', 'statistical analysis'), 'need') (('pseducode', 'sample new weight'), 'be') (('Summary we', 'male passengers'), 'survive') (('we', 'mode value'), '22') (('more penalty', 'alpha'), 'add') (('you', 'https www'), 'take') (('Overview', 'male dataframe'), 'survied') (('We', 'back testing'), 'give') (('me', 'videos'), 'have') (('mean difference', 'male'), 'be') (('we', 'variable y_pred'), 'fit') (('cabin names', 'multiple digits'), 'let') (('two null We', 'two raws'), 'let') (('sample', 'correctly current stump'), 'alpha_t') (('motivation', 'powerful ensemble'), 'be') (('com', 'one tailed more two tailed test'), 'be') (('it', '0'), 'Scales') (('we', 'model performance'), 'use') (('Squaring', 'also relationships'), 'give') (('we', 'remaining data'), 'train') (('This', 'following reasons'), 'happen') (('that', 'Queenstown Q'), 'survive') (('test where set', 'actually what'), 'determine') (('Bagging Why Pros', 'decision fully developed trees'), 'use') (('me', 'notebook'), 'let') (('we', 'trained models'), 'withhold') (('that', 'male passengers'), 'show') (('I', 'ticket feature'), 'rid') (('class Summary first passengers', 'tragedy'), 'have') (('We', 'algorithms'), 'compare') (('Therefore I', 'links'), 'decide') (('where pclass', 'C Embarked values'), 'let') (('Now s', 'little'), 'let') (('even many professors', 'it'), 'know') (('We', 'lesson'), 'discuss') (('almost we', 'first place'), 'be') (('still t', 'null values'), 'haven') (('s', 'Embarked feature'), 'let') (('then we', 'sweet results'), 'find') (('20 data', 'train'), 'take') (('we', 'dependent variable'), 'be') (('H0 male mean', 'female mean'), 'be') (('how bagging', 'Source https prachimjoshi'), 'be') (('total error', 'perfect stump'), 'think') (('PassengerId column', 'dataset'), 'seem') (('maybe that', 'judgment'), 'be') (('us', 'male'), 'be') (('Age', 'distribution'), 'be') (('only 38 passenger', 'tragedy'), 'survive') (('We', 'output'), 'run') (('included weight', 'value'), 'be') (('Naive Bayes Support Vector Machines SVM Decision Tree ClassifierDecision Gaussian tree', 'small subsets'), 'work') (('train data set', '891 raw columns'), 'have') (('model that', 'model'), 'be') (('how we', 'that'), 'need') (('hyper when parameters', 'bagging'), 'achieve') (('you', 'kaggle'), 'read') (('so luckyThis', 'facet features compelling four relationship'), 'understand') (('s', 'train dataset'), 'let') (('Therefore we', 'sample sets'), 'approach') (('correlation', 'Pclass'), 'be') (('Therefore we', 'cabin name'), 'group') (('how statistically correlation', 'statistics'), 'let') (('class also first passenger', 'second'), 'explain') (('we', 'age missing values'), 'in') (('driving principle', 'independently then predictions'), 'method') (('7565217391304347we', 'confusion matrix'), 'have') (('observations', 'pure chance'), 'be') (('Here image', 'dataset how bootstrapped works'), 'be') (('Here We', 'NaN value'), 'take') (('models', 'mental picture'), 'give') (('com', 'it'), 'explain') (('sample', 'hypothesized mean'), 'calculate') (('data', 'machine learning passenger survival status'), 'check') (('model', 'cases'), 'tell') (('we', 'one tailed test'), 'be') (('Misclassification Rate', 'Error also Rate'), 'know') (('datapoint', 'weights'), 'start') (('we', 'input'), 'understand') (('lot', 'base estimators'), 'reduce') (('model', 'TP True Positive that'), 'let') (('s', 'train data'), 'let') (('we', 'dataset'), 'use') (('Chris blue line', '0'), 'epsilon_t') (('we', 'independent variables'), 'be') (('we', 'misclassified weights'), 'in') (('It', 'letters'), 'seem') (('penalties', 'regularization technique'), 'require') (('Compute', 'simple equation'), 'follow') (('is_alone ticketI', 'ticket yet how best feature'), 'have') (('Misclassification wrong Rate', 'other'), 'be') (('estimator knn param_grid instruct 1 scikit', 'available processors'), 'param') (('we', 'alternative following questions'), 'testing') (('We', 'test'), 'use') (('we', 'null hypothesis'), 'update') (('StatQuest Gradient', 'Python 7j'), 'boost') (('One particular tactic', 'task'), 'be') (('limit Central theory', 'where'), 'be') (('many why we', 'feature selection'), 'be') (('It', 'ultimate type 1 error'), 'be') (('training set', 'gender class fare'), 'csv') (('1 Where epsilon_t', '_ t'), 'use') (('what', 'background'), 'be') (('we', 'train data'), 'use') (('X_train', 'first algorithm'), 'use') ", "extra": "['annotation', 'gender', 'outcome', 'test', 'bag']"}
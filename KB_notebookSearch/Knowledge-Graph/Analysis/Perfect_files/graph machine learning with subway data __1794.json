{"name": "graph machine learning with subway data ", "full_name": " h1 Network Graph Representation Learning tutorial h2 Preprocess h2 Unspervised Learning h3 PageRank h3 DeepWalk KDD 2014 h3 role2vec h2 Semi supervised Learning h3 Graph Convolutional Network ", "stargazers_count": 0, "forks_count": 0, "description": "com pengchenghu428 GraphTools blob master experiment pytorch gcn. We highlly recomend to confirm which version of networkx you are going to import and use the corresponding documentation or online articles. Next we re gonna try some well known graph embedding algorithms e. Let s look at the graph with simple code. com shenweichen GraphEmbedding. The ge package which stands for graph embedding implemented the following algorithms are distributed via the GitHub repo https github. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. com en Centrality for more details about centrality. calculate posisions in which the nodes are to be placed. This computes a batch of message called msg using the source node s feature h. The second layer transforms the hidden layer and produces output features of size 5 corresponding to the five colors of the representative nodes. For example running this by clicking run or pressing Shift Enter will list all files under the input directory Any results you write to the current directory are saved as output. supervisers or labels which Choice a representative node for each color as follows red 60 47 38 brown 20 77 35 purple 76 80 green 31 69 orange 78 61 Define a more sophisticated GCN model. detach https github. See the Wikipedia page https www. Unspervised Learning PageRank PageRank PR is one of the most famous algorithms in network analysis and was invented by Google to estimate importances of online pages. Define the GCNLayer module g is the graph and the inputs is the input node features first set the node features trigger message passing on all edges trigger aggregation at all nodes get the result node features perform linear transformation Define a 2 layer GCN model The first layer transforms input features of size of nodes to a hidden size of 10. More advanced GCN This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. This computes the new h features by summing received msg in each node s mailbox. read_csv Input data files are available in the. DeepWalk KDD 2014 LINE WWW 2015 node2vec KDD 2016 SDNE KDD 2016 struc2vec KDD 2017 DeepWalk KDD 2014 role2vec Semi supervised Learning Graph Convolutional NetworkDefine graph convolutional layer and GCN model. draw edges draw nodes draw edges draw nodes parameter default parameter 10 40 5 draw edges draw nodes draw edges draw nodes You can revert this convertion with the to_networkx function. png attachment image. Now we consider correct labels corresponding to nodes a. Graph so let s look dive into how machine learning algorithms on graphs can deal with this type input data. The argument is a batch of edges. to_undirected For example the feature vector of the 4th node goes like Define the message reduce function NOTE we ignore the GCN s normalization constant c_ij for this tutorial. The argument is a batch of nodes. py GCN layer MLP layer GCN MLP. png Well done Now we ve done pre processing and cleaned graph data as networkx. Network Graph Representation Learning tutorial Preprocess networkx allows you to handle graph data on Python in a simple way but one thing you have to keep in mind about networkx is that the APIs are not publicly compatible with the old one. PR can be used to evaluate centralities. only the instructor and the president nodes are labeled their labels are different Options for learning we save the logits for visualization later we only compute loss for labeled nodes input layer hidden layers output layer output logits cuda option normalization term hyper parameters feature and target class supervise data all_logits. ", "id": "openjny/graph-machine-learning-with-subway-data", "size": "1794", "language": "python", "html_url": "https://www.kaggle.com/code/openjny/graph-machine-learning-with-subway-data", "git_url": "https://www.kaggle.com/code/openjny/graph-machine-learning-with-subway-data", "script": "__init__ gcn_reduce GCN(nn.Module) graph deepwalk forward torch.nn BasicGCN(nn.Module) TSNE gensim.models numpy Word2Vec SumPooling GCNLayer(nn.Module) plot_predictions networkx MaxPooling matplotlib.pyplot progressbar sklearn.manifold pandas _get_flatten_size torch.nn.functional GraphConv plot_loss gcn_message dgl.nn.pytorch to_dgl AdvancedGCN(nn.Module) ", "entities": "(('It', 'python docker image https kaggle github'), 'GCN') (('Unspervised Learning PageRank PageRank PR', 'online pages'), 'be') (('Now we', 'networkx'), 'png') (('nodes', 'which'), 'calculate') (('Now we', 'a.'), 'consider') (('APIs', 'publicly old one'), 'allow') (('This', 'feature h.'), 'compute') (('DeepWalk LINE SDNE DeepWalk 2014 2015 KDD 2016 2016 struc2vec 2017 2014 Semi', 'Learning Graph Convolutional NetworkDefine graph convolutional layer'), 'KDD') (('how machine learning algorithms', 'type input data'), 'let') (('You', 'to_networkx function'), 'draw') (('second layer', 'representative nodes'), 'transform') (('you', 'output'), 'list') (('This', 'mailbox'), 'compute') (('layers output output logits cuda option normalization term hidden hyper', 'target data all_logits'), 'label') (('first layer', '10'), 'define') (('s', 'simple code'), 'let') (('read_csv Input data files', 'the'), 'be') (('Choice', 'color'), 'red') (('Next we', 'algorithms e.'), 'go') (('following algorithms', 'GitHub repo https github'), 'implement') (('we', 'tutorial'), 'to_undirecte') (('you', 'corresponding documentation'), 'recomend') ", "extra": "[]"}
{"name": "mushroom classification and exploration ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "1 1 10 100 1000 gamma 1 0. If spore_print_color is brown n mushrooms are mostly edible 89 1744 samples. If habitat is path p mushroom are mostly poisonous 88 1008 samples. best_score_ Output tuned hyperparameters best parameters C 1 gamma 1 accuracy 1. gill_color is buff b colored mushrooms are exactly poisonous 1728 sample. Because I will use in visualizations with for loops. The top is the most common value. In spore_print_color values are 0 1 2 3 4 8 and if odor is 5 none mushrooms are edible. shape 1 is for scaling backward propagation x_train. So I will apply K Fold Cross Validation to avoid overfitting. I don t need to use columns dtypes isnull and shape methods because info method already contains all of them. The data contains attributes are class cap shape cap surface cap color bruises odor gill attachment gill spacing gill size gill color stalk shape stalk root stalk surface above ring stalk surface below ring stalk color above ring stalk color below ring veil type veil color ring number ring type spore print color population habitat. But I detected best parameter values with this code. Inferences If gill_spacing is crowded w mushrooms mostly edible 91. 90 the correlation is positively correlated. Two comment code cells in below comment row because I don t want take up a lot of space in my kernel I learnt counts of values in each features and counts of poisonous and edible mushrooms in each features. fit_transform Fit label encoder and return encoded labelsChecking the values. 5 IQR OUTLIER Q3 1. In habitat value is 0 woods 1 grasses 3 meadows 4 paths and odor is 3 anise mushrooms are edible. model_selection import GridSearchCV grid C np. And it is misleading too with same reason. fit x_train y_train print tuned hyperparameters best parameters rf_cv. Hold the unique values in list. The Mushroom s dataset contains 8124 mushrooms both edible and poisonous in several species. I want to stop Pandas showing Future Warning messages again and again so used import warnings Logistic Regression With Grid Search Cross Validation I run below code before and found the best C and penalty values but I removed the code because it take a long time during running. best_score_ Output tuned hyperparameters best parameters C 1000. In all values of population if odor is 5 none and population isn t 1 clustered or 4 several mushrooms are edible. But if I calculate detailed I write below codes. And after this code cells I visualized them to be understandable usually six by six. 5 our prediction is sign zero y_head 0 initialize do not change learning rate Print test Errors K fold CV K 10 find k value K fold CV K 10 Naive bayes K fold CV K 10 K fold CV K 10 K fold CV K 10 K fold CV K 10 K fold CV K 10 whitten normalize. I copied data to df2 just a precaution. Let s look at our data what percentage of mushrooms are poisonous p and what percentage of mushrooms are edible e. All of features are non null object so I have not missing values for this dataset. Histogram is about frequency of data with visualization. Inferences If bruises t true mushrooms are edible overwhelmingly 82 edible Mushrooms have almond a and anise l odors are completely edible with 400 sample Mushrooms that hasn t an odor n are mostly edible Only 3 are poisonous Foul f 2160 fishy y 576 spicy s 576 creosote c 192 odor types completely poisonous. gill_color is brown n 89 936 sample or purple u 90 444 sample mushrooms are mostly edible. Let s some comments about mushrooms over relplots. And class is a keyword in python if I don t change it it will cause some problems. 16553877 I can protect my datas 0. 0 SVM With Grid Search Cross Validation and K Fold NAIVE BAYES CLASSIFICATION Confusion Matrix of Naive Bayes Naive Bayes With K Fold Crosss Validation Naive Bayes With Grid Search Cross Validation Confusion Matrix of Naive Bayes With Grid Search Cross Validation Naive Bayes With Grid Search Cross Validation and K Fold DECISION TREE CLASSIFICATION Confusion Matrix of Decision Tree Classification Decision Tree Classification With K Fold Cross Validation Decision Tree Classification With Grid Search Cross Validation Decision Tree Classification With Grid Search Cross Validation and K Fold RANDOM FOREST CLASSIFICATION Confusion Matrix of Random Forest Classification Random Forest Classification With K Fold Cross Validation Random Forest Classification With Grid Search Cross Validation from sklearn. If spore_print_color is chocolate h mushrooms are mostly poisonous 97 1584 samples. Feature names had seperated with hyphen this situation cause some syntax error later so I changed hyphen with underscore _ below code line. LOGISTIC REGRESSION CLASSIFICATION I stored m_class values in y variable and other features in x_df variable. format i fontsize 15 plt. CONTENT OF THE NOTEBOOK EXPLORATORY DATA ANALYS\u0130S AND FEATURE ENGINEERING CLASSIFICATION ALGORITHMS LOGISTIC REGRESSION CLASSIFICATION Confusion Matrix of Logistic Regression Logistic Regression with K Fold Cross Validation Logistic Regression With Grid Search Cross Validation Confusion Matrix of Logistic Regression With Grid Search CV KNN K Nearest Neighbour CLASSIFICATION Confusion Matrix of KNN KNN With K Fold Cross Validation SVM Support Vector Machine Confusion Matrix of SVM SVM With K Fold Cross Validation SVM With Grid Search Cross Validation SVM With Grid Search Cross Validation and K Fold NAIVE BAYES CLASSIFICATION Confusion Matrix of Naive Bayes Naive Bayes With K Fold Cross Validation Naive Bayes With Grid Search Cross Validation Confusion Matrix of Naive Bayes With Grid Search Cross Validation Naive Bayes With Grid Search Cross Validation and K Fold DECISION TREE CLASSIFICATION Confusion Matrix of Decision Tree Classification Decision Tree Classification With K Fold Cross Validation Decision Tree Classification With Grid Search Cross Validation Decision Tree Classification With Grid Search CV and K Fold RANDOM FOREST CLASSIFICATION Confusion Matrix of Random Forest Classification Random Forest Classification With K Fold Cross Validation Random Forest Classification With Grid Search Cross Validation Random Forest Classification With Grid Search CV and K Fold PCA PRINCIPAL COMPONENT ANALYSIS Dataset s path is put csv file. If gill_size is narrow n moshrooms are mostly poisonous 88. I step up the accuracy to 95. I compared unique values between with label encoder and without label encoder in columns to make interpretation easy. 0001 svm SVC svm_cv GridSearchCV svm grid cv 10 svm_cv. 33699013 second component 0. I create new dataframe that includes only color features in df. get_dummies I used this method to convert all values into 1 and 0. If df gets out of hand I will use df2. So we can not generalize. best_params_ print accuracy rf_cv. I can say that if there isn t bruises 0 and odor is not anise 3 or pungent 6 mushrooms are mostly poisonous. After that time my works will be easier. Because I try to find next mushroom is poisonous or edible and I ll show step by step. plot kind hist bins 20 figsize 5 5 color red grid True plt. number of edible or poisonous mushroom in every odor types number of mushrooms in every odor types total poisonous mushroom number total edible mushroom number K fold CV K 10 parameter initialize and sigmoid function forward propagation x_train. figsize magnitude of boxes annot visibility of numbers on boxes lineWidth distance between boxes fmt determine how many number will show in fractional partI see that veil color and gill attachment are directly proportional 0. value_counts n for i in df print df. 6 percent difference equal to 292 sample. best_params_ print accuracy svm_cv. I found variety of values in features And I noticed that all mushrooms have the same veil type which is p partial none of them are u universal. number of poisonous mushroom in every odor types. Describe method is useful now because of the label encoder. bins thinness of graphic columns and number of bar figsize magnitude of graphic framefor i in df df i. I calculated poisonous mushroom ratio according to cap shapes. fit x_train y_train print tuned hyperparameters best parameters svm_cv. And following visualize them. And all values in habitat except 3 meadows 6 waste if odor is 2 foul mushrooms are poisonous. The freq is the most common value s frequency. 5 our prediction is sign one y_head 1 if z is smaller than 0. 95 KNN K Neirest Neighbour CLASSIFICATION p poisonous mushroom e edible mushromm Confusion Matrix of KNN There is overfitting algorithm memorized my datas. 0 penalty l1 accuracy 0. 5 IQR OUTLIER describe already calculate these automaticallyFor object data the result s index will include count unique top and freq. Hold the df_color feature names in list. It isn t necessary sometimes it makes easier normalization but I prefer different method instead of this. For example above histogram 4 musty odor type count s is too few but below it seem 100 poisonous. axis 0 represents rows and axis 1 represents columns. Preparer RUNLIYIn this research it is tried to learn which features are mostly indicative of a poisonous mushroom and what types of machine learning models perform best on this dataset. groupby i m_class m_class. model_selection import GridSearchCVgrid n_estimators 100 300 500 criterion gini entropy bootstrap True False rf RandomForestClassifier rf_cv GridSearchCV rf grid cv 10 rf_cv. best_params_ print accuracy lr_cv. I want to show visualization about correlation. If spore_print_color is black k mushrooms are mostly edible 88 1584 samples. for i in df print df i. And some classification models used to categorize the mushroom type is edible or poisonous to identify the class to which a new data will fall under. Counts of poisonous and edible mushrooms in each features. Confusion Matrix of Logistic Regression Logistic Regression With K Fold Cross Validation cv Determines the cross validation splitting strategy. If stalk_surface_below_ring is silky k mushrooms are mostly poisonous with 93 rate 2160 sample. According to these attributes it was found out which factors are effective on whether the mushroom is poisonous or not. best_score_ Output tuned hyperparameters best parameters bootstrap True criterion gini n_estimators 100 accuracy 1. 5025289008187602 ratio. I used LabelEncoder method to transform non numerical labels to numerical labels. 576 sample If stalk_color_above_ring and stalk_color_below_ring are buff b colored mushrooms are completely poisonous 432 sample Inferences If ring_type is large l mushrooms are poisonous with 1296 samples. Hold the feature names in list. shape 1 is for scaling updating learning parameters is number_of_iterarion times make forward and backward propagation and find cost and gradients lets update we update learn parameters weights and bias prediction x_test is a input for forward propagation if z is bigger than 0. Confusion Matrix of Logistic Regression With Grid Search Cross Validation For logistic regression above codes enough. And if odor is 0 almond and 3 anise and population is 2 numerous 3 scattered 4 several or 5 solitary mushrooms are edible. Inferences If stalk_surface_above_ring is silky k mushrooms are mostly poisonous with 94 rate 2228 sample. If stalk_color_above_ring and stalk_color_below_ring are gray g colored muhrooms are completely edible. corr method uses to show the correlation between the values. fit x_train y_train print tuned hyperparameters best parameters lr_cv. So I changed with m_class that s mean mushroom classReview dataset. Rate of edible mushrooms are much more than ratio of poisonous by 3. Converting Object Types Into Integer Types and Label Encoder I need numeric values for thoroughly analyze my data but all features are in object form. model_selection import GridSearchCVgrid C 0. KNN With K Fold Cross Validation SVM Support Vector Machine Confusion Matrix of SVM SVM With K Fold Cross Validation SVM With Grid Search Cross Validation I removed the below code because it take a long time during running. count Counts of values in each features descending from ascending. 9663025080481659Then I apply C and penalty parameters for logistic regression. show I can use above codes for histogram to learn counts of values in each features but I prefer other technique. 0 Random Forest Classification With Grid Search Cross Validation and K Fold PCA PRINCIPAL COMPONENT ANALYSIS principle component 0. logspace 3 3 7 penalty l1 l2 l1 lasso ve l2 ridge lr LogisticRegression lr_cv GridSearchCV lr grid cv 10 lr_cv. So I can drop this feature it is unnecessary. Mushroom analysing according to only odor types I calculated poisonous mushroom ratio according to odors. shape 1 is for scaling x_train. xtick olarak atamak i\u00e7in ratio of poisonous and edible mushrooms. ", "id": "nurefsan/mushroom-classification-and-exploration", "size": "12362", "language": "python", "html_url": "https://www.kaggle.com/code/nurefsan/mushroom-classification-and-exploration", "git_url": "https://www.kaggle.com/code/nurefsan/mushroom-classification-and-exploration", "script": "sklearn.metrics cross_val_score PCA sklearn.naive_bayes sklearn.tree predict KNeighborsClassifier DecisionTreeClassifier collections seaborn numpy initialize_weights_and_bias sklearn.decomposition sklearn.ensemble logistic_regression sklearn.model_selection confusion_matrix LabelEncoder KFold RandomForestClassifier matplotlib.pyplot pandas LogisticRegression Counter sigmoid GridSearchCV sklearn.neighbors SVC sklearn.linear_model sklearn.preprocessing update sklearn.svm GaussianNB forward_backward_propagation train_test_split ", "entities": "(('shape', 'propagation 1 backward x_train'), 'be') (('fit_transform Fit label encoder', 'values'), 'encode') (('Describe method', 'label now encoder'), 'be') (('6 odor', '3 meadows'), 'be') (('get_dummies I', '1'), 'use') (('info method', 'them'), 'don') (('GridSearchCV rf grid', 'True rf False RandomForestClassifier'), 'bootstrap') (('fit y_train print', 'hyperparameters'), 'tune') (('best_score _ Output', 'hyperparameters'), 'tune') (('I', 'codes'), 'write') (('I', 'code'), 'detect') (('it', 'running'), 'want') (('I', 'features'), 'cell') (('later so I', 'code line'), 'seperate') (('comments', 'relplots'), 'let') (('interpretation', 'columns'), 'compare') (('corr method', 'values'), 'use') (('stalk_surface_above_ring', 'k silky mostly 94 rate'), 'inference') (('I', 'instead this'), 'make') (('I', 'loops'), 'use') (('anise 3 mushrooms', 'habitat value'), 'be') (('which', 'partial them'), 'find') (('axis', '0 rows'), 'represent') (('I', 'numerical labels'), 'use') (('10 K', 'whitten CV K 10 normalize'), '5') (('K DECISION TREE CLASSIFICATION Confusion Matrix', 'sklearn'), 'SVM') (('K', 'parameter CV K 10 initialize'), 'fold') (('best parameters', 'hyperparameters'), 'rf_cv') (('5 none', 'population'), 'be') (('I', 'logistic regression'), '9663025080481659then') (('types', 'best dataset'), 'RUNLIYIn') (('I', 'usually six six'), 'visualize') (('3 pungent 6 mushrooms', '0'), 'say') (('one y_head 1 z', '0'), '5') (('mushroom', 'attributes'), 'find') (('best parameters', 'hyperparameters'), 'lr_cv') (('it', 'problems'), 'be') (('poisonous percentage', 'mushrooms'), 'let') (('index', 'unique top'), 'calculate') (('Foul creosote c odor f 2160 576 576 192 types', 'that'), 'inference') (('mushroom classReview', 'dataset'), 'change') (('I', 'other x_df'), 'classification') (('I', 'cap shapes'), 'calculate') (('Random Forest Classification', 'K Fold PCA PRINCIPAL principle component'), '0') (('I', 'odors'), 'mushroom') (('gill attachment gill odor gill spacing size', 'veil type veil color ring number ring type spore print color population habitat'), 'contain') (('that', 'df'), 'create') (('veil color', 'fractional partI'), 'determine') (('it', 'too same reason'), 'be') (('KNN K Neirest 95 Neighbour', 'datas'), 'classification') (('I', 'step'), 'try') (('I', 'other technique'), 'show') (('stalk_surface_below_ring', 'k silky mostly 93 rate'), 'be') (('l large mushrooms', '1296 samples'), 'sample') (('null so I', 'dataset'), 'be') (('Rate', '3'), 'be') (('it', 'feature'), 'drop') (('xtick olarak', 'poisonous mushrooms'), 'atamak') (('z', '0'), 'make') (('kind hist', '20 figsize 5 5 color red grid True plt'), 'bin') (('features', 'object form'), 'need') (('it', 'running'), 'KNN') (('path', 'csv file'), 'classification') (('GridSearchCV lr grid', 've l2 ridge'), 'logspace') (('count Counts', 'features'), 'descend') (('dataset', 'several species'), 'contain') (('I', 'correlation'), 'want') (('new data', 'which'), 'be') (('Confusion Matrix', 'K Fold Cross Validation'), 'cv') (('best parameters', 'criterion gini True 100 accuracy'), 'tune') (('none 5 mushrooms', 'spore_print_color values'), 'be') (('too it', '100'), 'be') (('So I', 'overfitting'), 'apply') (('Histogram', 'visualization'), 'be') ", "extra": "['test']"}
{"name": "pokemon images autoencoder and gan in tensorflow ", "full_name": " h1 Pokemon Images Autoencoder and GAN h1 Importing the data as an array h1 Creating a supervised learning problem out of an unlabeled dataset h1 Convolutional Autoencoder h1 Application to image denoising h1 GANs h2 Define and Train the Discriminator Model h2 Create generator to generate real samples h2 Create generator to generate fake samples h2 Training the Generator Model h2 Evaluating GAN Model Performance ", "stargazers_count": 0, "forks_count": 0, "description": "Below I can see that in this case the loss remains stable over the course of training. Below I can see the original images compared with the images fed through the autoencoder. I m going to do this by creating a new model that combines the generator and discriminator models. Then it is reconstructed back to its original sizeFor this first autoencoder I m using a series of dense layers to encode and decode the images. The discriminator is only concerned with distinguishing between real and fake samples so it can be trained in a standalone manner on examples of each. The latent space is an arbitrarily defined vector space of Gaussian distributed values. Below I m going to create a dataset of images with gaussian noise. In this case the image which contains 12288 is fed through a bottleneck which contains only 32 neurons. These fake samples will be createdThe generator model is responsible for creating new fake but plausible images by taking a point from the latent space as input and outputting a square grayscale image. Importing the data as an arrayFirst I set up the base directory and find the number of pictures that I have. The array of random numbers can then be reshaped into samples which is n rows with 100 elements per row. Pokemon Images Autoencoder and GANIn this project I experiment with creating autoencoders using dense layers and convolutional pooling layers. This is a binary classification task so the output layer will be composed of a single neuron with a sigmoid activation function. The images are fuzzy and some of the color has been removed but the autoencoder is able to pick up on the main features. Create generator to generate real samplesNow I m going to write a function that will take the training dataset as an argument and will select a random subsample of images. In order to improve the quality of the reconstructed I m going to use a slightly different model with more filters per layer GANsA Generative Adversarial Network GAN is an algorithmic architecture that uses two neural networks putting one against the other in order to generate new synthetic instances of data that can pass for real data. I feed the original image through two Conv2D MaxPooling2D layers in order to encode the image down to 32 neurons. I m setting the input shape as 64 64 3 so I will need to reshape my x_train and x_test back to a shape of 64 64 3. In order to compare different runs I m going to use tensorboard and the tensorboard_callback. It will also return class labels for the sample specifically a class label of 1 to indicate real images. Therefore autoencoders are good at removing noise from images. The discriminator model is updated once per batch by combining one half of a batch of fake and real examples into a single batch. The first step is to generate new points in the latent space. Therefore when the generator is trained as part of the GAN model I will mark the generated samples as real class 1 Here I can see the model expects the pokemon images as input and predicts a single value as output Evaluating GAN Model PerformanceCurrently there are no objective ways to evaluate the performance of a GAN model so the images must be subjectively evaluated for quality by a human operator. One neural network called the generator generates new data instances. Then I use two Conv2D UpSampling2D layers to decode the image back to its original size. The generator model is not compiled and does not specify a loss function or optimization algorithm. The generator model is only concerned with the discriminator s performance on fake samples. When training the generator in this GAN model I want the discriminator to think that the samples output by the generator are real not fake. Finally I will report the loss each batch so I can keep an eye on the loss over batches. I ll be doing this via the train_discriminator function and then the train_gan function. randn for generating arrays of random numbers drawn from a standard Gaussian. Then I m going to feed those images through a convolutional autoencoder to train it. Therefore I will mark all of the layers in the discriminator as not trainable when it is part of the GAN model so that they can not be updated and overtrained on fake examples. This will take the 64 64 3 images and feed them through a neural network. I will do this with the generate_latent_points functionNext I will define a generate_fake_samples function that returns both the generated samples and the associated class labelsI can then plot the generated samples by calling the imshow function. Then I use the autoencoder in order to remove gaussian noise from images. Since the model is not trained the generated images are complately random pixel values Training the Generator ModelThe weights in the generator model are updated based on the performance of the discriminator model. Creating a supervised learning problem out of an unlabeled datasetI can take an unlabeled dataset and frame it as a supervised learning problem tasked with outputting x a reconstruction of the original input x. Application to image denoisingSince the aim of an autoencoder is to learn a representation for a set of data the autoencoder needs to focus on the main features of the data. In order to handle this complex training situation I will periodically evaluate the classification accuracy of the discriminator on real and fake imagesperiodically generate many images and save them for subjective reviewperiodically save the generator modelFirst I will update the discriminator model with real and fake samples then update the generator via the composite model. Next I m going to fit the model. Feed the test images which have never been seen before through the autoencoder. This is because the generator is not trained directly. Then I iterate through all of the images open them resize them to be 64x64x3 divide the pixel density by 255 so every pixel is in the range of 0 1 add them to an array of arrays and then split into the training and test set. This network can be trained by minimizing the reconstruction error L x x which measures the differences between the original input and the consequent reconstruction. So once good enough images can be generated the subjective quality of the images may then begin to vary improve or degrade with subsequent updates. A bottleneck constrains the amount of information that can traverse the full network forcing a learned compression of the input data. It has no meaning but by drawing points from this space randomly and providing them to the generator model during training the generator model will assign meaning to the latent points until at the end of training the latent vector space represents a compressed representation of the output space of pokemon images that only the generator knows how to turn into plausible pokemon images. Create generator to generate fake samplesNext I want to write a function that will generate fake samples. I ll do this by stacking the generator and discriminator so that the generator receives as input random points in the latent space and generates samples that are fed into the discriminator model directly and then are classified and the output of this larger model can be used to update the model weights of the generator. So I cannot know when to stop training without looking at examples of generated images. The reason for this is that a crash in the discriminator loss indicates that the generator model has started generating bad examples that the discriminator can easily discriminate. The other neural network called the discriminator evaluates them for authenticity Define and Train the Discriminator ModelFirst I m going to create a neural network that can discriminate between the real images and the fake images. I m going to use convolutions because they perform better. When the discriminator model is good at detecting fake samples teh generator is updated more and when the discriminator model is relatively poor or confused when detecting fake samples the generator model is updated less. The input is x_train and the output is also x_train since the goal is for the autoencoder to encode the images feed them through a bottleneck and then decode them to be as close as possible to the original image. Also I m going to use dropout for regularization. Convolutional AutoencoderNext I m going to test how a convolutional autoencoder will perform. Finally I m going to test how well the autoencoder performed. This can be done by calling np. After that I build and train a GAN. Due to the adversarial nature of the training process the generator is changing after every batch. ", "id": "lukemonington/pokemon-images-autoencoder-and-gan-in-tensorflow", "size": "8789", "language": "python", "html_url": "https://www.kaggle.com/code/lukemonington/pokemon-images-autoencoder-and-gan-in-tensorflow", "git_url": "https://www.kaggle.com/code/lukemonington/pokemon-images-autoencoder-and-gan-in-tensorflow", "script": "generate_real_samples train pyplot numpy train_discriminator generate_fake_samples PIL define_gan train_gan Image matplotlib.pyplot ImageOps tensorflow pandas summarize_performance tensorflow.keras define_generator generate_latent_points regularizers define_discriminator keras matplotlib.image ", "entities": "(('Then I', 'images'), 'use') (('only generator', 'pokemon how plausible images'), 'have') (('L which', 'original input'), 'train') (('images', 'human operator'), 'mark') (('Then I', 'back original size'), 'use') (('so I', 'batches'), 'report') (('It', 'real images'), 'return') (('that', 'generator models'), 'm') (('loss', 'training'), 'see') (('Creating', 'original input'), 'take') (('discriminator model', 'single batch'), 'update') (('discriminator', 'that'), 'be') (('Below I', 'autoencoder'), 'see') (('generator model', 'relatively when fake samples'), 'update') (('pixel complately random Training', 'discriminator model'), 'be') (('it', 'each'), 'be') (('Then I', 'it'), 'go') (('that', 'input data'), 'constrain') (('I', 'composite model'), 'evaluate') (('autoencoder', 'data'), 'application') (('m', 'gaussian noise'), 'go') (('which', 'before autoencoder'), 'feed') (('autoencoder', 'as possible original image'), 'be') (('autoencoder', 'main features'), 'be') (('createdThe generator model', 'grayscale square image'), 'be') (('Therefore autoencoders', 'images'), 'be') (('that', 'images'), 'create') (('I', '64 64 3'), 'm') (('they', 'fake examples'), 'mark') (('I', 'train_discriminator function'), 'do') (('generator model', 'loss function'), 'compile') (('they', 'convolutions'), 'm') (('generator model', 'fake samples'), 'be') (('samples output', 'generator'), 'want') (('that', 'fake samples'), 'want') (('directly then output', 'generator'), 'do') (('subjective quality', 'subsequent updates'), 'generate') (('I', 'that'), 'import') (('which', 'only 32 neurons'), 'feed') (('latent space', 'vector arbitrarily defined Gaussian distributed values'), 'be') (('which', 'row'), 'reshape') (('that', 'real images'), 'call') (('first step', 'latent space'), 'be') (('One neural network', 'data new instances'), 'generate') (('generated samples', 'imshow function'), 'do') (('classification output binary layer', 'activation sigmoid function'), 'be') (('so pixel', 'then training'), 'iterate') (('Also I', 'regularization'), 'm') (('I', 'dense layers'), 'Images') (('So I', 'generated images'), 'know') (('that', 'real data'), 'be') (('I', '32 neurons'), 'feed') (('This', 'neural network'), 'take') (('first I', 'images'), 'reconstruct') (('generator', 'batch'), 'due') ", "extra": "['test']"}
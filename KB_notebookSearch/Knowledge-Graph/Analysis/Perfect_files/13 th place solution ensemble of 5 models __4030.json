{"name": "13 th place solution ensemble of 5 models ", "full_name": " h2 13 th place solution 0 44091 on private LB h3 Model h3 External dataset h3 Library h3 External dataset h2 Chainer Chemistry h2 utils for this task h3 optimized rounder h3 Glove text feature embedding extraction h2 Start script code h3 Densenet image feature extraction h2 Main for GBT training h1 Xlearn h1 Chainer xDeepFM h1 ensemble h1 calculate threshold for target histogram ", "stargazers_count": 0, "forks_count": 0, "description": "com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. configs import pet_dir is_kaggle_kernel vgg16_dir base_model. print row row debug breeds breeds. User ridge regression ridge Ridge if same with train histogram. input seresnext50 chainercv base_model SEResNeXt50 pretrained_model os. test dataset predict_y numpy. extend breed_cols is_mixed_cols all_cat_id Breed1 Breed2. This affects a lot Quantity max was 20 but most of them are 10. simply take linear it will reshape h_bert self. mlp import MLP from src. 1 create submission train_predictions r 0 for r in results train train_predictions optr. shape indices indices. schedule_value Infer attr name optimized rounder X_p calc_threshold_label X coef print X X. optimizer optimizers. gpu_device_id 0 Additional parameters early_stop 500 train_x_numeric x_numeric train_indices val_x_numeric x_numeric val_indices print X_tr shape dtypes. save load is necessary for future prediction. noise_ratio_list 0. read_csv Input data files are available in the. average feats axis 2 3. org wiki List_of_Malaysian_states_by_GDP state population https en. drop temp_size axis 1 agg_imgs pd. 010558 if image_encode print y y. Breed target encoding breed1 train. cat_cols Age MaturitySize Quantity Fee VideoAmt PhotoAmt FurLength Health Vaccinated Dewormed Sterilized Gender Color1 Color2 Color3 Type Breed1 Breed2 State cutoff TODO hyperparameter tuning. com fiancheto petfinder simple lgbm baseline lb 0 399 to align prediction data to specified histogram Final submission is aligned with train dataset label histogram calculate QWK score during NN training as extensionBlendConverter for data augmentation during NN training. mlp import MLP self. txt pred_y1_rank optr. 3 dataset if use_bert print preprocess bert feature. values pred_y1_rank optr. drop temp_size axis 1 test_df_imgs temp_size test_df_imgs image_filename. TODO process these features properly later. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. max feats axis 2 3 TODO investigate why it sometimes contains nan. sn_linear import SNLinear len num_cat_id if use_bn self. train test pp. VideoAmt max was 8 but most of them are 1. mean train breed1_median breed1. RMSprop Set up the updater. cat_cols self. train_x_image numpy. TODO mottodora use better name or infer metrics_value self. reshape test_x_image_array len test_x_image_array num_image num_hidden preprocessing image import cv2 from chainer. com Kaggle docker python pull 447. train Description. 00001 2 10 25 45 50 55 0. resize im new_size 1 new_size 0 delta_w img_size new_size 1 delta_h img_size new_size 0 top bottom delta_h 2 delta_h delta_h 2 left right delta_w 2 delta_w delta_w 2 color 0 0 0 new_im cv2. get_labels remove. train_x_sent Parallel n_jobs backend threading delayed process_sentiment check_pickle False petid train for petid in train PetID. Until then the reported values will be converted to numpy arrays. append h_num_embed x_bert bs num_extract_seq hdim 1. return result num_examples concat num_examples as feature. float32 preprocessing image feature x AveragePooling1D 4 x Remove feature reduction local kaggle kernel train_x_image_feat xp. feature_predictor import FeaturePredictor from chainercv. 001 2 10 25 45 50 55 0. print DEBUG rescuer_id rescuer_id target_indices target_indices if __name__ __main__ debug False train test breeds colors states prepare_df debug dummy_dataset NumpyTupleDataset train Age MaturitySize. pardir from src. 0 breed_ones b1r 0. cut all_data Fee 0 1 10 50 100 500 labels False Scaling. values TODO update feature engineering and its name. Just take mean 2. shape load from cache prepare pretrained model n_jobs 8 print n_jobs n_jobs extract pet id iterator MultiprocessIterator image_dataset batch_size repeat False shuffle False feats F. optimized rounderI added some implementation from public kernel https www. com Kaggle docker python pull 486. groupby Breed1 AdoptionSpeed train breed1_mean breed1. matmul X feat_array filepath. txt Training data Validation data self. embed 1st step predict target_mean h_mean self. format n_components test_x_image_array svd_. float32 TODO subtract by scatter_max for computation stability Currently just use overall max of a. asarray float x score for x in file_annots. inplace True smp. MinMax scaling Non zero indices Category value processing TODO numeric cols append for lgbm cat_cols override for nn. But above is the library code scripts. bn1 h len num_cat_id if use_bn self. sum age high low high 1 high df. values https stackoverflow. calc test_x_image_array extract_hidden True with timer svd image fit n_components. Assign new minor breed id 308 for minor breeds. TODO check it was best value. shape hk_dims m. com questions 45006341 xgboost how to use mae as objective function d preds dtrain. format filepath it works but very slow. pardir from chainercv. Feature engineering GDP population Scaling. org wiki Malaysia TF IDF value tfv TfidfVectorizer min_df 3 max_features 10000 strip_accents unicode analyzer word token_pattern r w 1 ngram_range 1 3 use_idf 1 smooth_idf 1 sublinear_tf 1 stop_words english https www. At first calculate image feature and save it with DataFrame using feather. bn1 h blendnet regressor from chainer_chemistry. apply getDimensions test_df_imgs width test_df_imgs temp_size. Summary of the approach is written at 13 th place solution summary 0. This affects a lot TODO hyperparameter tuning. mean_predictor x_numeric x_cat x_bert h_image calc softmax mean h_mean_agg self. Setup CV kfold_method stratified num_split 5 random_state 1337 kfold_method stratified fold_splits kf. max value must be calculated beforehand TODO check which is better. shape 1 2 0 sometimes this does not guaranteed. Start script codeIt is already very long. abs pearson_arr 1 print pearson_arr pearson_arr inds n_components train_x_image train_x_image inds n_components test_x_image test_x_image inds n_components pet image dataset print image type image image. apply extract_rating_feature thresh 60 67 is big threshold for dog cat consider chinese char as same. nn is_first_time feature TODO check create name feature 1. com c petfinder adoption prediction discussion 87037 train counter Counter 4. bn1 h set sn blendnet from src. com ranjoranjan single xgboost model train_df_ids train PetID test_df_ids test PetID train_df_imgs temp_size train_df_imgs image_filename. extend QuadraticWeightedKappaEvaluator train_iter regressor device device trainer. ImageEncoder loss 2. reshape num_mixup 1 num_mixup lam. 3 metric huber rmse rmse learning_rate 0. photo_amt_cutoff 12 Fee max was 3000 but most of them are 300 or 500 300 or 500 Neural Network preprocessing. convert category value to one hot vector or other values. mlp3 SetMLPBlock out_dim hidden_dim hidden_dim n_layers 2 activation activation use_bn use_bn use_sn use_sn use_gamma use_gamma use_residual use_residual h self. predict predict_y_test coefficients_ https www. ignore_labels valid_ind numpy. readline num_vocab hdim a. create submission print feat_cols feat_cols 0. utils for this taskCodes from pfnet research sngan_projection https github. std_list i None self. cat_cols Type Breed1 Breed2 Gender Color1 Color2 Color3 Vaccinated Dewormed Sterilized State FurLength Health nn self. reset current state update the model to specified device id Copy the model to the GPU Init NOQA Move the model to CPU for saving Revert the model to original device Revert the model to specified device NOQA initialize must be called after init_scope. dtype print X_p X_p. rescuer_id_index_list val_y valid. blendnet mean regressor from chainer_chemistry. com wrosinski baselinemodeling It is necessary to fillna after df merged because some PetID is missing. 0 color1_onehot 0. datasets import NumpyTupleDataset predictor SNBlendNet num_cat_id kwargs Set up the iterators. t loss Note self. sn_embed_id import SNEmbedID from src. ignore_labels _to_list ignore_labels self. pick pool5 fc6 fc6 def resize_to_square im img_size 256 old_size im. se_resnext import SEResNeXt50 from chainercv. com dmlc xgboost issues 3045 pred_y1_rank optr. shape 1 2 0 scatter attention by softmax part alpha self. 2nd step predict t h_numeric_agg F. breed deal Unspecified and Unknown as same for 2nd breed all_data Breed2 all_data Breed2 0 307 all_data. apply lambda x x 1 train_df_imgs train_df_imgs. read_image import read_image from chainer_chemistry. b1 all_data Breed1. Linear None x_numeric_dim self. com pfnet research sngan_projection under MIT license. my this competition s dataset Glove embedding feature text embedding extraction Keras DenseNet Weights image feature extraction Cat and dog breeds parameters breed feature extraction xlearn to install xlearn library Malaysia GDP population hard coded. train cb train xgb train xlearn from chainer_chemistry. values added version 2 Combine all extracted features Concatenate with main DF embedding_type_list fasttext glove200d embedding_type fasttext fasttext out_dim_list 64 16 fasttext_columns metadata_annots_top_desc sentiment_entities Description out_dim_list 64 16 16 fasttext_columns metadata_annots_top_desc sentiment_entities Description Description Description fasttext_columns metadata_annots_top_desc sentiment_entities Description Description Initialize decomposition methods Concatenate with main DF nan handling. During inference do not return label During training return label as well During inference do not return label During training return label as well fasttext print line line print all_lines all_lines from joblib import Parallel delayed n_jobs 16 results Parallel n_jobs backend threading verbose 1 delayed extract_line line i vec_array for i line in enumerate all_lines sparse matrix min_df 2 ngram_range 1 3 sparse matrix num_text num_vocab unknown word index print f unknown word name unknown_count unknown_count X num_sentence num_feat feat_array num_feat hdim h_sent numpy. transform train_x_image_array. predict train_predictions coefficients_. Please refer it for the detailed explanation. validation all coefficients 3. TODO we may need to deal with 255 as special I think this is unknown age_cutoff 54 TODO hyperparameter tuning. format out_dim scatter part ones self. feature_index_ name print col_type. utils preprocessing Only train dog or cat. result arch arch scaler StandardScaler Make a specified GPU current train_h_image mlp. target_mean DEBUG this is answer. pos_labels _to_list pos_labels self. predict predict_y_test coefficients_. Linear None x_numeric_dim TODO remove hard coding. values 3 species remain rare breed major non rare breed return x breed_array 1. remove_cols Breed1 Breed2 3. add_pred xlearn nn xgb Neural Network preprocessing. Singlethreading 63 sec. shape h_bert h_bert. reshape num_mixup 1 x_mix lam2 x ind1 1 lam2 x ind2 batch_list i numpy. append indices Gaussian noise augmentation noise numpy. split num_vocab hdim int num_vocab int hdim print num_vocab num_vocab hdim hdim print all_lines all_lines from joblib import Parallel delayed n_jobs 16 results Parallel n_jobs backend threading verbose 1 delayed extract_line line i vec_array for i line in enumerate all_lines filepath. utils import timer save_npz load_npz from src. npz base_model. is_xxx flag Cutoff nn Age max was 255. dummy no internal parameter ensemble_archs lgbm xgb cb xlearn ensemble_archs nn lgbm xgb cb ensemble_archs lgbm xgb cb ensemble_archs xgb cb Train validation check 1. This affects a lot age_cutoff 72 TODO hyperparameter tuning. append h_image_embed CIN part DNN part if self. ignore_labels invert True y_total y_total valid_ind t_total t_total valid_ind blend converter num_mixup lam. standard_scaler import StandardScaler from src. pet_image_dataset import PetImageDataset from src. float32 print after train_x_image_array. snapshot trigger epoch epoch 2 10 20 40 0. create_ffm_series df filepath Prediction task Test data param 0. Multithreading 10 sec. split train target kf. Mixup ref http wazalabo. groupby Breed1 Breed2. lossfun y_mean target_mean 3. h_bert bs bert_hidden_dim print x_bert x_bert. numeric_cols return train_x_numeric train_x_cat target test_x_numeric test_x_cat num_cat_id debug add numerical features and assign values to df. 44091 65 th on public LB 0. shape 2 old_size is in height width format ratio float img_size max old_size new_size tuple int x ratio for x in old_size im cv2. astype category all_cat_id all_cat. fillna none inplace True test Description. evaluation metric accuracy epoch 100 stop_window 5 adagrad Start to predict The output result will be stored in output. best_score_ learn metric valid_rmse model. MinMax scaling Non zero indices Multiprocessing around 2 sec. raise_value_error raise_value_error ignore labels if specified if self. Only check first image. noise_ratio_list i noise numpy. BatchNormalization x_bert bs num_extract_seq hdim 1. reshape num_mixup 1 1 x_mix lam3 x ind1 1 lam3 x ind2 batch_list i numpy. target_mean loss reg_loss_mean self. values for i in range train_x_image. mean Helper function for parallel data processing version 1 is from baselinemodeling kernel version 2 is from simple xgboost model kernel Unique IDs from train and test Train set Parallel processing of data Extract processed data and format them as DFs Test set Parallel processing of data Extract processed data and format them as DFs Group extracted features by PetID Extend aggregates and improve column naming Train Test return train_dfs_sentiment train_dfs_metadata test_dfs_sentiment test_dfs_metadata rating eda return all df s mean. numeric_cols for col in self. It seems now supported https github. feature engineering in https www. fillna inplace True test. transform lambda x np. concatenate train_x_image_array test_x_image_array axis 0 with timer svd image train feature n_components. astype int Counter train_predictions 0. metrics_fun is dict which is different from original chainer implementation if len args 0 print args len args import IPython IPython. rating_eda import load_json from src. The saved files extracted image feature are loaded every time I train different models. 05170 External dataset LibraryI used some library which is was not supported in the kaggle default docker. loc condition Age high print quantize_age train quantize_age train print quantize_age test quantize_age test Cutoff Age max was 255. array y_list axis 0 coefficients_ coefficients. reshape num_mixup 1 1 Permute augmentation If True num_cols is calculated as choice if False always permute_col_ratio is used. TODO how to return label_description label_description Copied from https www. cat2num True arch lgbm train_xlearn data processing CSV file I O e. remove_cols Color1 Color2 Color3 self. isnan train_x_cat axis 0 train_x_numeric train_x_cat target test_x_numeric test_x_cat num_cat_id preprocessing train test breeds colors states debug debug use_tfidf use_tfidf use_metadata True cat2num cat2num animal_type animal_type use_tfidf_cache True tfidf_svd_components 128 num_sentiment_text 0 clf_arch vgg16 clf_arch seresnext50 n_components None if debug else 506 n_components 512 n_components 256 n_components 16 fpn50 n_components None 506 was worse. mlp import MLP dog and cat TODO compare with MLP self. is_xxx flag def quantize_age df age df Age. values minor_breeds 178 201 for threshold 100. In this kernel I copied some of the module code from the library to use it. minor_breeds 123 201 for threshold 10. configs import is_kaggle_kernel from src. category to one hot vector checked include State or not include State seems better. shape 0 1 dtype self. quantity_cutoff 11 VideoAmt max was 8 but most of them are 1. weired name or not 3. color_array 1. set_mlp_block SetMLPBlock out_dim hdim hidden_dim hdim n_layers 0 use_sn use_sn 1. utils import save_npz load_npz timer from src. Xlearn Chainer xDeepFM ensemble calculate threshold for target histogram This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. It includes permutation augmentation used in final submission mixup data augmentation not used in final submission gaussian noise data augmentation not used in final submission Glove text feature embedding extractionFeature extraction of rating. iterator MultiprocessIterator image_dataset batch_size repeat False shuffle False train lgbm subsample 0. shape 1 pearson_arr np. float32 num_examples F. is_first_time feature create name feature 1. This affects a lot age_cutoff 60 TODO hyperparameter tuning. 0 breed_ones b1r 1. take linear for each element and sum it. max_sv sn_linear sn_mlp from src. float32 batch_list i x noise self. fasttext_exp import calc_fasttext_feature extract_line a f. l_bert x_bert 2. puppy puppies kitten kitty baby flag. util function to tune optimizer s learning rate during NN training. size for col in self. numpy_tuple_dataset_feature_indexer import NumpyTupleDatasetFeatureIndexer NOQA self. Language feature extractionVarious kinds of people are lived in Malaysia Malay Chinese thus I thought it is important feature. embed cat mlp2 blendnet len num_cat_id if use_bn self. Chainer ChemistryCodes copied from chainer_chemistry https github. scatter_softmax a indices assert out_dim 2 0 out_dim is. float32 Counter y_count i returns i th count. pfnet research sngan_projection https github. Set up the trainer. apply lambda x x 1 test_df_imgs test_df_imgs. val_y val_y list chain. dtypes print test breed_feat_cols. mean inplace True unspecified black brown golden yellow cream gray white self. values train AdoptionSpeed. iterators import SerialIterator sys. scatter attention by softmax part alpha self. 44091 on private LBI will share my 13 th place solution. coef_ x X_p calc_threshold_label X np. copy pred_y1_rank optr. format n_components train_x_image_array svd_. cat_cols Type Breed1 Breed2 Gender Color1 Color2 Color3 Vaccinated Dewormed Sterilized State FurLength Health all_cat all_data cat_cols. isnan train_x_image 0. same histgram with train. 13 th place solution 0. we should treat different way is_mixed all_data Breed2 0 all_data Breed2 307 Becareful must assign. concat agg_train_imgs agg_test_imgs axis 0. shape h_cat_list. expected to be list or some iterable class self. 023249633 permute_col_ratio_list 0. field_index_ col self. BatchNormalization h_cat_list. feature_index_ col val tmp model. calc_agg h indices self. 8 colsample_bylevel 0. max_sv import max_singular_value mlp dog and cat if i 0 h h h_cat if i 0 h h h_cat h_cat self. I hope it is supported in kaggle default docker PR to support it in default docker https github. best_score_ validation_0 metric train lgbm use_fasttext takes time. values quantize_list 19 24 25 30 31 36 37 48 49 60 61 72 73 84 85 96 for low high in quantize_list condition age low age matched for age between to. ascontiguousarray lam. float32 assert y. 4 Additional parameters num_rounds 10000 early_stop 500 num_rounds 60000 train_x_numeric x_numeric train_indices val_x_numeric x_numeric val_indices print X_tr shape dtypes. 0 color2_onehot 1. float32 num_examples self. State target encoding Assign values into train and test. com pfnet research chainer chemistry MIT license. apply lambda x x 0 train_df_imgs height train_df_imgs temp_size. shape print h_numeric h_numeric. scatter_softmax a indices sn blendnet from src. coef_ print coef_ x self. models import Regressor from src. align to same dtypes. 7 color2_onehot 0. float32 retain_dim 6 for detection model num_person num_animal bbox features are remain. Becareful it makes info leak and only fits validation data but not in test data 1. 0 410 coefficients_ coefficients. values Category value processing convert category value to one hot vector or other values. cut all_data Age 0 1 2 3 4 5 6 7 8 9 10 11 12 18 24 30 36 48 60 72 84 labels False all_data. com yu4u items 70aa007346ec73b7ff05 Gaussian Noise concat in CPU at first batch_list x_num x_cat x_bert x_image target batch_list. train_x_image_array test_x_image_array contraction_by_mlp train_x_image_array test_x_image_array model_dir. numeric_cols PhotoAmt Type Breed1 Breed2 Gender Color1 Color2 Color3 Vaccinated Dewormed Sterilized State FurLength Health Age MaturitySize Quantity Fee VideoAmt self. calc_agg h_mean indices t is target_mean in this case. mlp2 import MLP2 from src. metrics_fun y_total t_total from chainer_chemistry. append is_kitty self. PhotoAmt max was 30 but most of them are 11. copy train mode train valid RescuerIDMeanDataset train_df. Let s start actual calculation with some scripts from here Densenet image feature extraction. random_state 42 method differential_evolution target is num_rows 1 predict_y is num_rows std_list calc_std_list train_x_numeric train_x_cat train_x_bert train_x_image convert to dataframe to series. float32 scatter attention by softmax part Add second axis which is same shape with target_mean. mean_squared_error metrics_fun metrics_fun device device batch_eval_func predictor Set up the optimizer. copy valid mode eval Set up the regressor. test_x_image numpy. TODO remove hard coding. dtype print coef coef y y X_p X_p ll ll ll quadratic_weighted_kappa y X_p print coef_ self. copyMakeBorder im top bottom left right cv2. n_components 5 version 1 text_methods svd nmf version 1 n_components 16 version 2 text_methods svd version 2 version 3 self customized version 2 Generate text features Initialize decomposition methods train. 01 noise_ratio_list 0. Multiprocessing around 2 sec. vec pet finder parser Does not have to be extracted because main DF already contains description version 1 is from baselinemodeling kernel version 2 is from simple xgboost model kernel file_top_score np. isnan test_x_image 0. shape 0 lam2 numpy. com c petfinder adoption prediction discussion 78040 state GDP https en. Setup CV kfold_method stratified fold_splits kf. mlp3 h indices len num_cat_id if use_bn self. optuna https github. format n_components print before train_x_image_array. com aksnzhy xlearn As explained in https www. sn_linear import SNLinear TODO subtract by scatter_max for computation stability Currently just use overall max of a. Fee max was 3000 but most of them are 300 or 500 300 or 500 Numeric value processing There is no nan value but this is just for make sure no nan exist. array pearson_list inds np. fc MLP out_dim hidden_dim 16 n_layers 2 x bs hdim D num_field m sum pooling print DEBUG h. To check the total kernel running time in detail 2 hours limit for GPU kernel for petfinder. calc train_x_image_array extract_hidden True test_h_image mlp. 0 color1_onehot 1. Refer xDeepFM Combining Explicit and Implicit Feature Interactions for Recommender Systems https arxiv. loc all_data Breed2 0 Breed2 307 is_mixed all_data Breed2 0 all_data Breed2 307 18 species remain major_breeds b1 b1 1000. pick conv5_3 seresnext50_dir. I am sending PR to support it in default docker https github. concat h h_embed axis 1 rescuer id mean dataset from chainer_chemistry. Linear None 64 self. Separate args and t When the reported data is a numpy array the loss and metrics values are scalars. preprocessing 2 self. reset_index drop True return agg_imgs nan handling. apply getDimensions train_df_imgs width train_df_imgs temp_size. pick fc7 fc6 base_model. BORDER_CONSTANT value color return new_im print image type image image. print breed_feat_cols breed_feat_cols print train breed_feat_cols. com c petfinder adoption prediction discussion 87733. shape with timer svd image test feature n_components. json from external dataset for Breed feature. random_state 42 differential_evolution permute_col_ratio_list 0. values otherwise index does not match and nan is inserted for test dtypes does not match due to nan existent. com bminixhofer xlearn we can install library as an external dataset. External dataset Petfinder. minor_breeds 80 201 for threshold 5. shape print DEBUG not exist. video_amt_cutoff 4 PhotoAmt max was 30 but most of them are 11. apply lambda x x 0 test_df_imgs height test_df_imgs temp_size. std_list i None None self. preprocess_image_cute device 0 arch vgg16 cosine distance experiment. numeric_cols Age MaturitySize Quantity Fee VideoAmt PhotoAmt self. 3 log training_rmse model. use_bn h self. _features_indexer NumpyTupleDatasetFeatureIndexer self Hacking. activation lrelu20 cat_hidden_dim 64 image_hidden_dim 32 mlp_n_layers 6 mlp_hidden_dim 512 numeric_hidden_dim 96 activation lrelu20 cat_hidden_dim 64 image_hidden_dim 66 mlp_n_layers 4 mlp_hidden_dim 557 numeric_hidden_dim 96 activation lrelu20 cat_hidden_dim 38 image_hidden_dim 66 mlp_n_layers 3 mlp_hidden_dim 557 numeric_hidden_dim 86 lam_image_recon 0. When the reported data is a cupy array sometimes the same values become arrays instead. append is_kitten self. isnan train_x_numeric axis 0 print num nan in cat numpy. noise_ratio_list i mixup Need to mixup labels as well. concatenate x x_mix axis 0 permutation augmentation x_num x_cat x_bert x_image batch_list 4 num_cols 1 n_image for image or n_sentence for bert feature num_cols 1 print skip augmentation. vec glove_exp sys. 001 optimizer optimizers. This seems to be a bug inside the reporter class which needs to be addressed and fixed. max indices 1 1 dtype self. mean_absolute_error F. bn1 h FC h self. color 0 unspecified 1 black. cutoff_count 1 not cutoff it for now. metrics_fun is dict which is different from original chainer implementation TODO support when num_image 1 TODO support when num_sentence 1 TODO subtract by scatter_max for computation stability Currently just use overall max of a. preprocess_bert train test num_extract_sentence 2 layer_indices 1 device device use_cache True animal_type animal_type else print skip bert feature clf_arch vgg16 clf_arch seresnext50 fpn50 506 was worse. sn_linear import SNLinear hk_dims m. fillna inplace True tfv TfidfVectorizer tfidf_col TfidfVectorizer. 25 all_data breed2_median breed2. Some of the codes are copied from this repository to use spectral normalization for regularization of Neural Network. loc 3 Type BreedName. if arch nn smp. inplace True nan handling. scatter_add num_examples indices ones Take mean of features. 01 1 9 early stopping print X_tr shape dtypes. dtypes rating. numeric_cols Age self. Numeric value processing There is no nan value but this is just for make sure no nan exist. com pfnet optuna I used it for hyper parameter tuning during local development not used in the final code. preprocessing import prepare_df list of str unique rescuer_id list list of list each element is rescuer s index list sample datasets from index_list. 3 use_cat not cat2num dataset print num nan in numeric numpy. At first sorry but the code is not so organized quite messy it contains all my effort during 3 months. mean coefficients 2. cat_cols Fee MaturitySize Quantity PhotoAmt VideoAmt FurLength Health Vaccinated Dewormed Sterilized Gender Color1 Color2 Color3 Type Breed1 Breed2 State lgbm cb TODO process these features properly later. join seresnext50_dir vgg16_imagenet_converted_2017_07_18. metrics_fun is dict which is different from original chainer implementation models. append is_puppy self. Install xlearn it takes several minutes. com pfnet research chainer chemistry I used it as an extension of Chainer for writing neural network part. train_x_dists process_cosine_distance train_x_image_full train_type x_cute_image_array labels_df test_x_dists process_cosine_distance test_x_image_full test_type x_cute_image_array labels_df pearson_list pearson_corr train_x_image i train. train RescuerIDMeanDataset train_df. permute_col_ratio_list 0. shape h_numeric x_numeric TODO subtract by scatter_max for computation stability Currently just use overall max of a. transform test_x_image_array. AdaDelta optimizer optimizers. shape len num_cat_id num image if num_cat_id is not None h0_dim 10 10 if use_bn self. hk x bs hdim D num_field m sum pooling print DEBUG h. shape 0 lam3 numpy. json How to fillna mean is better try both way. iloc 5 print row type row a breeds. send to device. append is_puppies Breed preprocessing deal Unspecified and Unknown as same for 2nd breed seems 307 is for mixed type and 0 is for unspecified. Neural Network model definition. shape image not exist print pred pred 0. photo_amt_cutoff 12 Fee max was 3000 but most of them are 300 or 500 300 or 500 discretize to bin all_data. asarray coef dtype np. reshape train_x_image_array len train_x_image_array num_image num_hidden test_x_image_feat xp. com pfnet research sngan_projection Some of the codes are copied from this repository to use spectral normalization for regularization of Neural Network. n_components 32 506 was worse. mlp import MLP ProjectionMLP from src. concat h_mean_agg y_mean axis 1 bs 1 hdim print h_numeric_agg h_numeric_agg. get_labels for sklearn h is delta in the graphic obj huber_approx_obj To release GPU memory we need to delete object. AdaGrad optimizer optimizers. Main for GBT training. fillna none inplace True self. extend num_color Do not cutoff here it will be cutoff later. 3 dog and cat TODO compare with MLP self. ModelThis is ensemble of these 5 models XGBoost LightGBM CatBoost xlearn Neural Network xDeepFM based model xDeepFM is a network for sparse categorical dataset. minor_breeds 101 201 for threshold 7. no name or not 2. chainer_chemistry https github. median all_data breed1_q1 breed1. binary classification 1. vgg import VGG16 from chainercv. raw float predictions 1. breed deal Unspecified and Unknown as same for 2nd breed is_mixed all_data Breed2 0 all_data Breed2 307 18 species remain major_breeds b1 b1 1000. mean_squared_error lossfun_huber else regressor Regressor predictor lossfun F. values d RescuerIDMeanDataset train dummy_dataset data0 t0 d 0 import IPython IPython. append h_bert_embed h_cat_list. kind f append. pred_y1_rank optr. xlearn https github. concatenate x x_mix axis 0 lam3 lam. 00001 check_error True from biggest error descending order Top 3 error for both side optr HACKING scatter operations. 3 metric huber rmse device gpu need to compile. datasets import NumpyTupleDataset sys. ", "id": "corochann/13-th-place-solution-ensemble-of-5-models", "size": "4030", "language": "python", "html_url": "https://www.kaggle.com/code/corochann/13-th-place-solution-ensemble-of-5-models", "git_url": "https://www.kaggle.com/code/corochann/13-th-place-solution-ensemble-of-5-models", "script": "remove_cols PetImageDataset(chainer.dataset.DatasetMixin) _convert_to_scalar relu itertools MeanPredictor(object) preprocess_image_cosine chainer_chemistry.models reset_state lrelu20 contextmanager chainer.dataset chainer.initializers Regressor BaseForwardModel(link.Chain) chainer.functions.connection _l2normalize link _forward src.preprocessing_image_keras main_gbm perf_counter MultithreadIterator TfidfVectorizer chain joblib calc_threshold_label_numba add_noise_3d permute_cols_3d pooling save_pickle calc_x_image_array time src.configs coefficients schedule_optimizer_value differential_evolution functions chainer.links.connection.linear chainer_chemistry.models.prediction.base sklearn.linear_model src.models.sn.max_sv preprocessing lrelu extensions as E read_image forward DenseNet121 load_image fit_xlearn main_nn SerialIterator add_gdp fit _to_list to_device linear SNEmbedID(link.Link) __init__ NumpyTupleDataset(object) GlobalAveragePooling2D links src.models.sn.sn_linear FeaturePredictor quadratic_weighted_kappa pet_dir fit_xgb keras.applications.densenet src.fasttext.fasttext_exp chainer_chemistry.dataset.indexers.numpy_tuple_dataset_feature_indexer StandardScaler BlendNetRegressor(Regressor) _extract_numpy load_pickle Ridge chainer.functions Preprocessor(object) preprocess_sentiment_and_metadata observe_lr save fit_lgbm GroupKFold sklearn.model_selection chainer CIN(chainer.Chain) chainercv.utils.image.read_image BlendConverter(object) ProjectionMLP(chainer.Chain) open_sentiment_file src.utils timer NMF preprocessing_target_mean preprocess CINBlock(chainer.Chain) numpy src.models.mlp logging _to_ndarray fit_and_predict_by_histgram CountVectorizer construct_glove_vocab_list vgg16_dir tensorflow Counter cuda huber_approx_obj keras.models FFMFormatPandas extract_additional_features DummyForwardModel(BaseForwardModel) _get_1d_numpy_array chainer_chemistry.links.scaler.standard_scaler sklearn.feature_extraction.text detect lossfun_custom BlendNetMeanRegressor(Regressor) BatchEvaluator  # NOQA calc_threshold_label MLP2 MLP2(chainer.Chain) SetSNBlendNet(chainer.Chain) concat_examples WeightDecay save_npz get_device open_image_file glob normal deepcopy fit_cb SetMLP(chainer.Chain) chainercv.links.model.vgg Linear training QuadraticWeightedKappaEvaluator(BatchEvaluator) keras.backend chainer.links parse_image_size open_metadata_file src.models.sn.sn_embed_id matplotlib.pyplot _check_path_exist getSize partial calc_valid_mean SparsePCA convert tqdm detect_wrapper fit_nn prepare_model calc_agg xgboost XlearnModel(object) chainer_chemistry.datasets sklearn.metrics process_metadata quantize_age collections permute_cols_2d optimizers sklearn.decomposition calc_image_features process_lang_df Image calc_std_list get_example reporter __len__ chainer_chemistry.training.extensions.batch_evaluator calc_num_examples broadcast_to functions as F BaseForwardModel parse_sentiment_file __call__ max_singular_value Trainer chainercv.links.model.senet.se_resnext pearson_corr Regressor(BaseForwardModel) CINTying(chainer.Chain) numba OptimizedRounder(object) seaborn calc_breed_rating_feat getLogger calc_attention_mean chainer.functions.array.broadcast pandas SetBlendNet(chainer.Chain) scatter_softmax_2d Evaluator get_initial_coef NumpyTupleDatasetFeatureIndexer  # NOQA transform contextlib BatchEvaluator(Evaluator) chainer.dataset.convert initialize is_kaggle_kernel extract_line BlendNetXDeepFM(chainer.Chain) preprocess_image scatter_softmax_1d MultiprocessIterator load_json copy permutation_augmentation get_train getDimensions extract_rating_feature langdetect update_device scipy RescuerIDMeanDataset(chainer.dataset.DatasetMixin) W_bar PetFinderParser(object) process_sentiment Variable  # NOQA parse_metadata_file lrelu05 SNLinear __getitem__ evaluate Parallel contraction breed_onehot Lambda strtobool chainer.training.extensions AveragePooling1D SNLinear(Linear) _to_tuple StratifiedKFold catboost calc_histogram_coef prepare_df PCA SNBlendNet(chainer.Chain) add_tfidf variable VGG16 src.preprocessing read_image_keras embed_id chainer.functions.activation NumpyTupleDataset prepare_model_densenet src.pet_image_dataset functools preprocess_image_densenet SEResNeXt50 distutils.util max_singular_value_fully_differentiable xlearn ProjectionMLP SNEmbedID fit_transform cohen_kappa_score contraction_by_mlp BlendNet(chainer.Chain) Input src.rating_eda lossfun_huber Model read_feather batch_converter transform_row_ add_noise_2d _kappa_loss load setup_predictor SentimentMetadataPreprocessor(object) PIL mixup_3d set_value extensions _initialize_params chainercv.links.model.feature_predictor MLP calc_fasttext_feature chainer.optimizer_hooks chainer.iterators preprocess_input mixup_2d permute_cols_2d_int delayed scatter_softmax iterators _extract_rating_feature keras.layers lightgbm preprocess_bert predict calc MLP(chainer.Chain) chainer.training SetMLPBlock(chainer.Chain) load_npz PetImageDataset construct_fasttext_vocab_list XlearnDataset(object) schedule_target_value TruncatedSVD LatentDirichletAllocation resize_to_square features src.models.mlp2 scipy.optimize get_datasets preprocess_image_det ", "entities": "(('result arch arch scaler StandardScaler', 'train_h_image specified GPU current mlp'), 'Make') (('concatenate train_x_image_array test_x_image_array', 'timer svd image train 0 feature'), 'axis') (('it', 'default docker https github'), 'hope') (('max_sv import max_singular_value mlp i', 'h i'), 'dog') (('embed 1st step', 'target_mean h_mean self'), 'predict') (('com fiancheto petfinder', 'NN training'), 'lb') (('reshape test_x_image_array len test_x_image_array num_image num_hidden', 'chainer'), 'preprocesse') (('x_numeric 10000 500 60000 x_numeric val_indices', 'shape X_tr dtypes'), 'parameter') (('most', 'them'), 'photo_amt_cutoff') (('Chainer ChemistryCodes', 'chainer_chemistry https github'), 'copy') (('60 thresh 67', 'chinese char'), 'apply') (('append', 'noise augmentation noise Gaussian numpy'), 'indice') (('time I', 'different models'), 'extract') (('com bminixhofer xlearn we', 'external dataset'), 'install') (('s', 'Densenet image feature extraction'), 'let') (('test_x_image test_x_image', 'image dataset print image type image pet image'), 'ind') (('which', 'same target_mean'), 'Add') (('you', 'output'), 'list') (('why it', 'sometimes nan'), 'axis') (('com pfnet I', 'final code'), 'optuna') (('best_score _', 'valid_rmse metric model'), 'learn') (('It', 'python docker image https kaggle github'), 'Chainer') (('TODO mottodora', 'better name'), 'use') (('values', 'to'), 'quantize_list') (('most', 'them'), 'video_amt_cutoff') (('nan', 'just make'), 'be') (('I', 'it'), 'copy') (('xDeepFM', 'sparse categorical dataset'), 'be') (('i', 'labels'), 'noise_ratio_list') (('category', 'State'), 'include') (('User ridge regression ridge Ridge', 'train histogram'), 'same') (('State target', 'train'), 'encode') (('cat_cols', 'nn'), 'scale') (('TODO age_cutoff 54 hyperparameter', '255'), 'need') (('save load', 'future prediction'), 'be') (('nan', 'nan existent'), 'match') (('which', 'len print args len args import IPython args 0 IPython'), 'be') (('animal_type True vgg16 clf_arch 128 0 clf_arch else 506 n_components 512 n_components 256 n_components 16 None', 'debug use_tfidf use_tfidf use_metadata debug True'), 'axis') (('values', '178 201 threshold'), 'minor_breeds') (('json', 'How mean'), 'be') (('which', 'reporter class'), 'seem') (('lam3 ind2 1 i', '1 1 ind1'), 'reshape') (('ones', 'features'), 'indice') (('output result', 'output'), 'epoch') (('most', 'them'), 'affect') (('Non zero', 'around 2 sec'), 'scale') (('std_list train_x_cat train_x_bert train_x_image', 'series'), 'random_state') (('it', 'test data'), 'make') (('Setup CV kfold_method', 'fold_splits kf'), 'stratified') (('most', 'bin 300 all_data'), 'photo_amt_cutoff') (('Parallel backend', 'enumerate all_lines filepath'), 'split') (('shape 2 old_size', 'old_size i m cv2'), 'be') (('indices calc_agg t', 'case'), 'be') (('resize_to_square 256 old_size i', 'pool5 fc6 fc6 def'), 'pick') (('DataFrame', 'feather'), 'at') (('embedding_type fasttext fasttext_columns metadata_annots_top_desc sentiment_entities Description metadata_annots_top_desc Description Description Description fasttext_columns metadata_annots_top_desc sentiment_entities Description Description Initialize decomposition 64 16 64 16 16 fasttext_columns methods', 'DF nan main handling'), 'add') (('0', 'mixed type'), 'append') (('com pfnet research Some', 'Neural Network'), 'sngan_projection') (('False always permute_col_ratio', 'choice'), 'reshape') (('it', '3 months'), 'sorry') (('Summary', 'place solution summary'), 'write') (('iterator MultiprocessIterator image_dataset batch_size', 'False shuffle'), 'repeat') (('TODO', 'MLP self'), 'compare') (('Malaysia GDP population', 'xlearn library'), 'breed') (('True arch lgbm', 'data CSV file'), 'cat2num') (('mode valid eval', 'regressor'), 'copy') (('word index print word unknown_count unknown_count X num_feat unknown f unknown feat_array', 'enumerate'), 'delay') (('all_data all_data 307 0 Breed2 18 species', '2nd breed'), 'deal') (('num_examples', 'feature'), 'result') (('fillna', 'test True Description'), 'inplace') (('m top bottom', 'right cv2'), 'leave') (('i d iterator MultiprocessIterator image_dataset pet batch_size', 'shuffle False False feats'), 'model') (('SNLinear TODO', 'a.'), 'import') (('TODO', 'feature engineering'), 'value') (('which', 'TODO beforehand check'), 'calculate') (('device batch_eval_func metrics_fun device predictor', 'optimizer'), 'mean_squared_error') (('which', 'chainer implementation original models'), 'be') (('TODO hyperparameter', 'tuning'), 'affect') (('create_ffm_series', 'filepath Prediction task Test data param'), 'df') (('Some', 'Neural Network'), 'copy') (('TODO', 'create name feature'), 'feature') (('inplace True unspecified black brown golden yellow cream', 'gray white self'), 'mean') (('most', 'them'), 'be') (('schedule_value Infer attr name', 'rounder'), 'optimize') (('com aksnzhy', 'https www'), 'xlearn') (('x_numeric x_numeric 0 Additional 500 val_indices', 'shape X_tr dtypes'), 'gpu_device_id') (('we', 'object'), 'be') (('vgg16 fpn50', 'use_cache True animal_type print skip bert animal_type else clf_arch'), 'test') (('xgb cb ensemble_archs nn lgbm xgb cb ensemble_archs xgb cb xgb cb Train ensemble_archs validation', 'parameter ensemble_archs internal lgbm'), 'dummy') (('TODO', 'features'), 'process') (('it', 'Malaysia Malay Chinese'), 'feature') (('values', 'one hot vector'), 'convert') (('process_sentiment check_pickle delayed False', 'train PetID'), 'train') (('check_error True', 'HACKING scatter side operations'), '00001') (('all_data Breed2 0 all_data 307 Becareful', 'different way'), 'treat') (('num_split 5 1337 kfold_method', 'fold_splits kf'), 'stratify') (('which', 'default kaggle docker'), 'use') (('debug', 'numerical features'), 'return') (('scatter_softmax', 'indices sn src'), 'blendnet') (('main DF', 'xgboost model 2 simple kernel'), 'have') (('I', 'default docker https github'), 'send') (('Counter i', 'count'), 'float32') (('float32 TODO', 'a.'), 'subtract') (('index list sample', 'index_list'), 'be') (('mean', 'self'), 'x_cat') (('44091', 'th place 13 solution'), 'share') (('blendnet', 'chainer_chemistry'), 'mean') (('Revert', 'init_scope'), 'update') (('nan', 'just make'), 'processing') (('TODO when num_image 1 when num_sentence 1 TODO', 'a.'), 'be') (('use_fasttext', 'time'), 'take') (('optimized rounderI', 'kernel https public www'), 'add') (('Generate 2 text', 'Initialize decomposition methods train'), 'n_components') (('delta_h img_size m new_size 1 0 img_size 1 0 top bottom', 'i'), 'resize') (('reported values', 'numpy arrays'), 'convert') (('x_numeric_dim TODO', 'hard coding'), 'Linear') (('cat_cols Fee MaturitySize PhotoAmt VideoAmt FurLength Vaccinated Dewormed Sterilized Gender Color1 Color2 Type Breed1 State lgbm cb TODO', 'features'), 'Quantity') (('com pfnet research chainer I', 'network neural part'), 'chemistry') (('It', 'rating'), 'include') (('fc MLP', '16 2'), 'hidden_dim') (('read_csv Input data files', 'the'), 'be') (('copy train mode', 'RescuerIDMeanDataset valid train_df'), 'train') (('s', 'return'), 'mean') (('it', 'h_bert self'), 'take') (('i', 'lam2 1 ind1'), 'reshape') (('TODO', 'a.'), 'shape') ", "extra": "['gender', 'test']"}
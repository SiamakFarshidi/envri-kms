{"name": "breast cancer classification ", "full_name": " h1 Problem Statement h1 Objective h1 Importing the Packages h1 Loading the dataset h1 About the dataset h1 classify cells to whether the samples are benign mild state 2 or malignant evil state 4 h1 Dropping the unwanted columns h1 Checking for missing values h1 Checking for Categorical variables h1 Checking whether the dataset is a balanced or not h1 Summary h1 Data Visualisation h1 Taking out the predictors and predicted variables seperately h1 Splitting the dataset h1 Training My Models h1 Logistic Regression Model h1 Naive Bayes Model h1 SVM Model h1 Kernal SVM Kernal taken is polynomial kernal h1 KNN Model h1 Decision tree h1 Random forest h1 XGBoost h1 Model Evaluation Metrics h1 Prediction using trained model h1 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "It is a balanced dataset. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. My xg boost model is also predicting the same as benign. Kernal taken is polynomial kernal. Fitting the XGBoost to the training set Predicting the test results Confusion Matrix Accuracy of our model. Training My Models Logistic Regression ModelThe metrics for this model are as followsAccuracy 97. the proportion of benign and malignant is almost 2 1. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. Accuracy of our model. Objective To Build a breast cancer classifier on the dataset that can be accurately classify as benign and malignant. so square root of 699 rounds of to 26. The metrics for this model are as followsAccuracy 98. The most successful way to reducecancer deaths is to detect it earlier. This is the description of the features of the dataset. The minimum and maximum value of all input variables are 1 and 10 respectively. modelling SVM Confusion matrix and Accuracy of our model. read_csv Input data files are available in the. Missing Or Null data points Let us check whether the dataset is a balanced or imbalanced one. Decision treeThe metrics for this model are as followsAccuracy 96. Many people avoid cancer screening due to the cost involved in taking numeroustests for diagnosis. Problem StatementBreast Cancer is one of the leading cancer developed in many countries including India. BareNuc variable is an object data type so need to convert it into integer data type. The mean of class is closer to 2 indicating there are more benign cases. The predicted value of class is 2 which suggests it is a benign tumor. Clump Thickness 1 103. Statistically the death toll due to this disease has increased drastically in last few decades. Divide the data as train and test dataset Accuracy of our model. When pathologists examine FNA fine needle aspirate tissues samples in breast cancer diagnosis they consider the nine attributes. So we cannot apply mathematical operations on this column. Prediction using trained modelThe trained models is used to predict a particular case clump thickness 1 uniformity of cell size 2 uniformity of cell shape 2 marginal adhesion 5 single epithelial cell size 3 bare nuclei 4 bland chromatin 6 normal nucleoli 4 mitosis 8. modelling Knn Classifier nothing but we are using euclidean distance lets see the best value of k for which the model is predicting with high accuracy. Bare Buc is an object type which is not a numeric value. Checking for missing valuesNo Missing values found in the dataset. For example running this by clicking run or pressing Shift Enter will list all files under the input directory Any results you write to the current directory are saved as output. Bare Nuclei 1 108. The metrics for this model are as followsAccuracy 97. So BareNuc is converted to integer data type. Identify the unwanted rows Taking out the predictors and predicted variables seperately for the further. Uniformity of Cell Size 1 104. we are using a dataset that has a 9 predictors in each record 699 records Let us drop the ID column as it doesnot influence the output class. Data Visualisation clump thickness is evenly distributed to some extent. Naive Bayes ModelThe metrics for this model are as followsAccuracy 94. Single Epithelial Cell Size 1 107. Here we have taken the loop iteration till 27 as per thumb rule optimum k value is always Square root of number of records. The data frame is of shape 699 10 suggesting there are 699 training cases. We could simply remove it as synthetic data would not contribute to right decisions. Uniformity of Cell Shape 1 105. The count of each column is 699 which suggests there are no missing values. 35 Precision 95 Recall 97 F1 Score 96. no single measurement can be used to determine whether it is benign or malignant. the larger the number thegreater the likelihood of malignancy. Taking out the predictors and predicted variables seperately Splitting the dataset. If we recognise early we can take the necesaary action which results in less death toll. 948905109489051 Predicting the Test set results Accuracy of our model. KNN ModelLet us find the optimum value for K. Checking whether the dataset is a balanced or not. Normal Nucleoli 1 1010. For measuring the cell shape area is measured bycounting the number of pixels in the interior of the nuclear border and adding one half of the pixels on the perimeter. For cell size perimeter was measured as the distancearound the nuclear border which is considered to be uniform. All other variables are skewed to the right. SummaryThe output variable class is discrete and takes two values 2 Benign and 4 Malignant. Marginal Adhesion 1 106. Random forestThe metrics for this model are as followsAccuracy 97. XGBoostThe metrics for this model are as followsAccuracy 97. Public Source https s3 api. My random forest model is also predicting the same as benign. 08 Precision 96 Recall 98 F1 Score 97. ConclusionBreast Cancer has become the foremost cause of death worldwide for womens. Checking for Categorical variablesAll the variables are Categorical variables. 35 Precision 96 Recall 96 F1 Score 96. Sample code number id number2. SVM ModelThe metrics for this model are as followsAccuracy 96. 89 Precision 94 Recall 96 F1 Score 95. 81 Precision 97 Recall 98 F1 Score 98. So that is why it is taken. Importing the Packages Loading the dataset. There are 699 records and for each record we have multiple parameters that is measured. Model Evaluation MetricsWe can see KNN performing well and then comes random forest and XGBoost which have more accuracy and F1 Score as well. Class 2 for benign 4 for malignant Clump thickness indicates that radius was computed by averaging the length of radial line segments from the center ofthe nuclear mass to each of the points of the nuclear border. each of the attribute is assigned to number from 1 10 by the pathologists. Dropping the unwanted columns. Fitting Random Forest Classification to the Training set Predicting the Test set results Accuracy of our model. Fitting Decision Tree Classification to the Training set for gini 0. Hence apart from medicinal solutions some Data Science solution needs to be integrated for resolving the death causing issue. 54 Precision 98 Recall 99 F1 Score 98. For a particular row and in that row a particular column BareNuc if values are non numeric. With early diagnosis 97 women can survive for more than 5 years. Bland Chromatin 1 109. So Here lets simply removethe non numeric data. This prediction system may provide easy and a cost effective way for screening cancer and may playa significant role in earlier diagnosis process for different types of cancer and provide effective preventiveapproach. Marginal adhesion is measured bycombining the perimeter and area to give a measure of the compactness of the cellnuclei classify cells to whether the samples are benign mild state 2 or malignant evil state 4 id clump thickness uniformity of cell size uniformity of cell shape marginal adhesion single epithelial cell size bare nuclei bland chromatin normal nucleoli mitosis are the variables used to predict the output class. ", "id": "karteek93/breast-cancer-classification", "size": "6131", "language": "python", "html_url": "https://www.kaggle.com/code/karteek93/breast-cancer-classification", "git_url": "https://www.kaggle.com/code/karteek93/breast-cancer-classification", "script": "sklearn.metrics sklearn.naive_bayes sklearn.tree KNeighborsClassifier DecisionTreeClassifier numpy XGBClassifier sklearn.ensemble sklearn.model_selection confusion_matrix sklearn RandomForestClassifier matplotlib.pyplot pandas classification_report LogisticRegression svm sklearn.neighbors sklearn.linear_model GaussianNB xgboost train_test_split ", "entities": "(('data frame', 'shape'), 'be') (('output variable class', 'two values'), 'be') (('values', 'column particular BareNuc'), 'for') (('SVM ModelThe metrics', 'followsAccuracy'), 'be') (('death Statistically toll', 'drastically last few decades'), 'increase') (('Decision treeThe metrics', 'followsAccuracy'), 'be') (('ConclusionBreast Cancer', 'worldwide womens'), 'become') (('that', 'dataset'), 'objective') (('which', 'more accuracy'), 'see') (('minimum value', 'input variables'), 'be') (('Problem StatementBreast Cancer', 'India'), 'be') (('This', 'dataset'), 'be') (('it', 'class'), 'be') (('particular case', 'cell 5 single epithelial 3 bare 4 6 normal nucleoli'), 'use') (('model', 'high accuracy'), 'model') (('other variables', 'right'), 'be') (('clump', 'evenly extent'), 'distribute') (('forest random model', 'benign'), 'predict') (('that', 'multiple parameters'), 'be') (('they', 'nine attributes'), 'consider') (('proportion', 'benign'), 'be') (('mean', '2'), 'be') (('97 women', 'more than 5 years'), 'survive') (('xg boost model', 'benign'), 'predict') (('forestThe Random metrics', 'followsAccuracy'), 'be') (('data object type', 'data integer type'), 'be') (('prediction system', 'effective preventiveapproach'), 'provide') (('Training Models Logistic Regression ModelThe metrics', 'followsAccuracy'), '-PRON-') (('which', 'column'), 'be') (('Naive Bayes ModelThe metrics', 'followsAccuracy'), 'be') (('synthetic data', 'right decisions'), 'remove') (('Data Science solution', 'issue'), 'need') (('So BareNuc', 'integer data type'), 'convert') (('k optimum value', 'records'), 'take') (('you', 'output'), 'list') (('Fitting Decision Tree Classification', 'gini'), 'set') (('the larger number', 'malignancy'), 'thegreater') (('which', 'death less toll'), 'take') (('which', 'nuclear border'), 'measure') (('variables', 'Categorical variablesAll'), 'check') (('read_csv Input data files', 'the'), 'be') (('radius', 'nuclear border'), 'indicate') (('each', 'pathologists'), 'assign') (('KNN ModelLet us', 'K.'), 'find') (('it', 'output class'), 'use') (('most successful way', 'it'), 'be') (('So we', 'column'), 'apply') (('It', 'python docker image https kaggle github'), 'come') (('valuesNo Missing values', 'dataset'), 'check') (('nuclei bare bland', 'output class'), 'measure') (('Many people', 'diagnosis'), 'avoid') (('metrics', 'followsAccuracy'), 'be') ", "extra": "['biopsy of the greater curvature', 'disease', 'test', 'diagnosis']"}
{"name": "3d convolutional neural network w o programming ", "full_name": " h2 Step 1 Get Access h2 Step 2 Enable Cached Dataset h2 Step 3 Create and Open a New Project h2 Step 4 Select Dataset and do training validation set division h2 Step 5 Build model h2 Step 6 Training and Results h1 3 Pre processing Code h1 Summary ", "stargazers_count": 0, "forks_count": 0, "description": "Please refer to that Guido Zuidhof notebook to understand these steps in detail. Select GPU K80 as instance and click on Start Instance. ai 2 https s3 us west 2. My aim will be to transfer my knowledge and make it easy for others to follow along. com deepcognition 3dconvnet_dataset_selection. Welcome everyone to my post that will describe my experiments to get good scores for this problem. 5 MaxPooling3D_14 Convolution3D_12 Convolution3D kernel_dim1 2 nb_filter 40 activation relu kernel_dim3 2 kernel_dim2 2 SpatialDropout3D_4 Convolution3D_13 Convolution3D kernel_dim1 2 nb_filter 40 activation relu kernel_dim3 2 kernel_dim2 2 Convolution3D_12 MaxPooling3D_23 MaxPooling3D pool_size 2 2 2 Convolution3D_13 BatchNormalization_23 BatchNormalization MaxPooling3D_23 SpatialDropout3D_5 SpatialDropout3D p 0. You can watch following video to get gentle introduction to convolutional neural network. Once Instance has been started. Note that training is going to be very slow because of sheer size of dataset and computations needed. com deepcognition 3dconvnet_cached_dataset. Your suggestions are welcome. Open Project 4 Step 4 Select Dataset and do training validation set division We will do training with 1200 samples and we will use 197 samples for validation for this example. 5 of the width height of the figure. Step 1 Get Access Sign up and get access to Deep Learning Studio at http deepcognition. Threshold values to below 1100 to 1100 and values above 700 to 700 5. Note that by no mean this is the best architecture but I wanted to share my experiment with you guys in the hope it can help you build even better network. Training and Validation Split 5 Step 5 Build model Once dataset is selected click on Model Tab and start building model as shown below by dragging layers from left menu bar to the canvas and connecting these layer blocks. BatchNormalization layer is added to accelerate the training. Today we will try 3D Convolutional Neural Network for this problem. Hyperparameters 7 Finally you can move to Training tab. def get_model Input_1 Input shape 256 512 512 1 MaxPooling3D_27 MaxPooling3D pool_size 1 3 3 Input_1 Convolution3D_1 Convolution3D kernel_dim1 4 nb_filter 10 activation relu kernel_dim3 4 kernel_dim2 4 MaxPooling3D_27 Convolution3D_7 Convolution3D kernel_dim1 4 nb_filter 10 activation relu kernel_dim3 4 kernel_dim2 4 Convolution3D_1 BatchNormalization_28 BatchNormalization Convolution3D_7 MaxPooling3D_12 MaxPooling3D pool_size 2 2 2 BatchNormalization_28 SpatialDropout3D_1 SpatialDropout3D p 0. Instead we will use drag and drop GUI based platform Deep Learning Studio to build and train neural network. These files must be uploaded for to verify that user is infact has access to Kaggle dataset Follow markers 1 to 4 Enable Access to Cached Dataset 2 Step 3 Create and Open a New Project Let s build a new project by going to project menu on left and clicking on button. We will try different experiments as we move forward with this competition. This is useful if you do not want color to change between different scan slices. This will bring values between 1 and 1 For full preprocessing you should to set demo False. Architecture 6 You will also need to set the parameters of the layers. First Experiment 3D Convolutional Neural Networks Convolutional neural networks have been very successful in image classification and other types of imaging tasks. jpg 5 https s3 us west 2. Load and Convert DICOM file to NUMPY array. Make a figure big enough to accomodate an axis of xpixels by ypixels as well as the ticklabels etc. 5 MaxPooling3D_12 Convolution3D_9 Convolution3D kernel_dim1 2 nb_filter 20 activation relu kernel_dim3 2 kernel_dim2 2 SpatialDropout3D_1 Convolution3D_11 Convolution3D kernel_dim1 2 nb_filter 20 activation relu kernel_dim3 2 kernel_dim2 2 Convolution3D_9 BatchNormalization_9 BatchNormalization Convolution3D_11 MaxPooling3D_14 MaxPooling3D pool_size 2 2 2 BatchNormalization_9 SpatialDropout3D_4 SpatialDropout3D p 0. Optional Value range is a tuple of fixed max value and min value. Following experiment uses this preprocessed data as input. slow_slice function is designed to show scan at full resolution. Our architecture is based on stacking multiple blocks of following Conv3D Conv3D BatchNorm MaxPooling3D SpatialDropout3DPurpose of first two Conv3D layers is to extract features from input. Basic imshow only shows scaled version of scan. Which means that we must process all slices together and then let network correct itself in the end. enter image description here 3 Give a name and description to your project. 5 BatchNormalization_23 GlobalMaxPooling3D_1 GlobalMaxPooling3D SpatialDropout3D_5 Dense_1 Dense activation relu output_dim 10 GlobalMaxPooling3D_1 Dropout_14 Dropout p 0. Make the axis the right size. Step 6 Training and Results Now you can go to Hyperparameters tab and make sure batch size is set to 1. Pad or Trim slices at the end such that every scan has exactly 256 slices. I will try to documents as much details as I can on this notebook. Note that many threads will block on IO so creating more than number of CPUs. Divide all values with 1100 to bring the range between 1 and 1 You can find full source code for pre processing in section 3. Cleanup For demo reduce number of slices to 5 to save time For Convnet we will need one extra dimension representing color channel Save output file to compressed npz file for easy reading. It can accept either image_width image_height array or image_width image_height 1 numpy as input. Talking about easy we will in fact be building and training our neural networks without doing programming. Please feel free to send your suggestions and comments. Code for these steps is mostly borrowed from excellent notebook of Guido Zuidhof. jpg 3 https s3 us west 2. Currently I am working on following two more appoarches 1. Pre processing We will do following preprocessing on given CT Scans to make our life easier. Click on Start Training. I hope to share more details about these experiments with you in coming days. Now open the project by clicking on box arrow icon on project bar. At the end of convolutional network we do Global max pooling to pool the features which then go into three dense layers to bring the final dimension to 2 which is the size of our output label cancer or no cancer. Load the scans in given folder path Convert to int16 from sometimes int16 should be possible as values should always be low enough 32k Set outside of scan pixels to 0 The intercept is usually 1024 so air is approximately 0 Convert to Hounsfield units HU make total 256 slices fill in 1100 as exterme value Ignore all slices later than 255 if required. Summary In this post we built a working convolutional 3D neural network without programming. com watch v JiN9p5vWHDY ab_channel DeepLearning. For Testing feed just load one scan Multi threaded processes to utilize all available CPUs for this task. MaxPool is added to reduce spacial dimensions for future blocks. jpg 4 https s3 us west 2. Reduce dimensionality of scans using autoencoders to make it easy to process the dataset using some other neural network. Traditionally convolution neural network operate on a 2D image possibly comprising of 1 or 3 color channels. This ability comes in handy when tackling with complex real world images. Full discloure I am one of the cofounder of the company who developed Deep Learning Studio software. Deep Learning Studio has a free monthly plan and it offers 2 hours of complementary training time on best GPU available in the Cloud Nvidia K80 with 12GB RAM 1. TVOur CT scan dataset is actually comprise of set of slices each slice is 512x512 pixel image. It allows to use multi CPU to do segmentation. Below is the actual generated source code using view code button in Model tab for the model that I built and you can reference it to get parameter values. Do Lung Segmentation on these scans. jpg 8 https s3 us west 2. Here I will just list major high level preprocessing that we will do on the dataset. com deepcognition 3dconvnet_training_dashboard. If you liked this post please give it a upvote Thank you Please check excellent notebook of Guido Zuidhof for full explanation of this code For Kaggle I have added sample_image directory only fix random seed for reproducibility Simple Function to show the slice at full resolustion normal imshow would downscale this image. Creation of the internal Marker Creation of the external Marker Creation of the Watershed Marker matrix Creation of the Sobel Gradient Watershed algorithm Reducing the image created by the Watershed algorithm to its outline Performing Black Tophat Morphology for reinclusion Creation of the disk kernel and increasing its size a bit Perform the Black Hat Use the internal marker and the Outline that was just created to generate the lungfilter Close holes in the lungfilter fill_holes is not used here since in some slices the heart would be reincluded by accident Apply the lungfilter note the filtered areas being assigned 30 HU Maximum absolute value of any pixel. Convolutional networks learns to extract low level features of image automatically. Use Convolutional LSTM neural network that combines both CNN and LSTM for analyzing sequence of images. But let s make a network and give it a shot. com deepcognition 3dconvnet_model. com deepcognition 3dconvnet_new_project. jpg 7 https s3 us west 2. SpacialDropout3D is added added to make system more robust and less prone to over fitting. After trying out 2 epochs I was able to get loss of about 0. 3 Dense_1 Dense_6 Dense activation relu output_dim 10 Dropout_14 Dense_2 Dense activation softmax output_dim 2 Dense_6 return Model Input_1 Dense_2 Rationale for this architecture First MaxPooling3D layer is done to reduce size of the scan kind of downscaling because even the GPUs like K80 with 12GB RAM are not able to fit this scan with reasonable model in memory. Training Dashboard 8 1 http deepcognition. com deepcognition 3dconvnet_open_project. com deepcognition 3dconvnet_hyperparameters. Pre processing Code This notebook converts DICOM scans to Numpy array along with doing segmentation normalization etc. We have information if the CT scan contain the cancer or not as a whole. Please feel free to modify and experiment with it. ai 1 Step 2 Enable Cached Dataset Enable cached dataset in your account by uploading two small files that you must download from your Kaggle account. This is important because anything bigger will not fit GPUs memory and training will fail. 3D convolutional neural network fit the bill but they tend to consume a lots of GPU memory and are difficult to converge. jpg 6 https s3 us west 2. ", "id": "deepman/3d-convolutional-neural-network-w-o-programming", "size": "9613", "language": "python", "html_url": "https://www.kaggle.com/code/deepman/3d-convolutional-neural-network-w-o-programming", "git_url": "https://www.kaggle.com/code/deepman/3d-convolutional-neural-network-w-o-programming", "script": "sklearn.metrics display multiprocessing keras.regularizers keras.layers keras.callbacks reload keras.layers.core load_scan_as_HU_nparray morphology Sequential scipy.ndimage numpy segment_pad_and_save_ct_scan_as_npz Input sklearn sklearn.model_selection keras.layers.convolutional seperate_lungs_and_pad skimage matplotlib.pyplot stats measure tensorflow pandas keras.optimizers show_slice StandardScaler importlib scipy Pool load_model threshold_and_normalize_scan Model preprocess_all_scans_mp sklearn.preprocessing keras.layers.pooling segmentation mpl_toolkits.mplot3d.art3d keras.models train_test_split Poly3DCollection IPython.display keras.layers.normalization preprocessing ", "entities": "(('Currently I', 'two more appoarches'), 'work') (('we', 'dataset'), 'list') (('they', 'GPU memory'), 'fit') (('CT scan', 'whole'), 'have') (('I', 'notebook'), 'try') (('Instead we', 'neural network'), 'use') (('you', 'parameter values'), 'be') (('you', 'False'), 'bring') (('filtered areas', '30 HU Maximum absolute pixel'), 'Watershed') (('slow_slice function', 'full resolution'), 'design') (('that', 'problem'), 'welcome') (('color', 'different scan slices'), 'be') (('of even GPUs', 'memory'), 'output_dim') (('others', 'knowledge'), 'be') (('it', 'GB 12 RAM'), 'have') (('convolution neural Traditionally network', 'color possibly 1 channels'), 'operate') (('MaxPooling3D SpatialDropout3DPurpose', 'input'), 'base') (('notebook', 'etc'), 'pre') (('LSTM neural that', 'images'), 'network') (('I', 'about 0'), 'be') (('we', 'programming'), 'Summary') (('Architecture 6 You', 'layers'), 'need') (('we', 'example'), 'Dataset') (('It', 'segmentation'), 'allow') (('which', 'output label cancer'), 'do') (('s', 'shot'), 'let') (('here 3', 'project'), 'enter') (('Optional Value range', 'max fixed value'), 'be') (('figure', 'ypixels'), 'make') (('together then network', 'end'), 'mean') (('Following', 'input'), 'use') (('Basic imshow', 'scan'), 'show') (('Code', 'Guido Zuidhof'), 'borrow') (('who', 'Deep Learning Studio software'), 'discloure') (('I', 'image'), 'give') (('Today we', 'problem'), 'try') (('Convolutional networks', 'image'), 'learn') (('life', 'CT Scans'), 'process') (('You', 'neural convolutional network'), 'watch') (('anything', 'GPUs bigger memory'), 'be') (('we', 'easy reading'), 'reduce') (('we', 'programming'), 'build') (('total 256 slices', 'value exterme slices later 255'), 'be') (('dataset', 'layer blocks'), 'Split') (('batch sure size', '1'), 'training') (('s', 'button'), 'have') (('ability', 'world handy when complex real images'), 'come') (('MaxPool', 'future blocks'), 'add') (('def get_model', 'Input_1 Convolution3D_1 Convolution3D activation 1 3 3 4 10 kernel_dim3'), 'shape') (('I', 'coming days'), 'hope') (('it', 'other neural network'), 'reduce') (('slice', 'slices'), 'be') (('7 Finally you', 'Training tab'), 'hyperparameter') (('we', 'forward competition'), 'try') (('Multi', 'task'), 'load') (('you', 'even better network'), 'note') (('Experiment 3D Neural Networks First Convolutional Convolutional neural networks', 'other imaging tasks'), 'be') (('Step', 'http deepcognition'), 'get') (('training', 'dataset'), 'note') (('many threads', 'CPUs'), 'note') (('you', 'Kaggle account'), 'ai') (('system', 'more less fitting'), 'add') (('It', 'image_width 1 input'), 'accept') (('such scan', 'exactly 256 slices'), 'slice') (('You', 'section'), 'find') (('BatchNormalization layer', 'training'), 'add') ", "extra": "['test', 'lung']"}
{"name": "birdclef2021 model training ", "full_name": " h1 Model training h1 1 Settings and imports h1 2 Data preparation h1 3 Extract training samples h1 4 Load training samples h1 5 Build a simple model h1 6 Soundscape analysis ", "stargazers_count": 0, "forks_count": 0, "description": "Ok that leaves us with 27 species and 8 548 audio files. Ok we found a few bird species with a score above the threshold. Ok we have 1 500 audio files that cover 27 species let s extract spectrograms this might take a while. Let s use a soundscape that actually contains some of the species that we trained our model for. Next we need to specify an optimzer initial learning rate a loss function and a metric. This is a good example for the difficulties we re facing when analyzing soundscapes. Alright we got 4 157 training spectrograms. If we want to train a model we have to load them into memory. In this tutorial we ll use a very simplistic AlexNet like design with four convolutional layers and three dense layers. So we keep it simple and build our own model. We actually got some of these Song Sparrow sonspa vocalizations. This is not a bad selection to start experimenting. We ll have to check ourselves luckily we have some validation soundscapes. Notice how some of them only contain a fraction of a bird call That s an issue we won t deal with in this tutorial. Now it s your turn to find better strategies to cope with this shift in acoustic domains. That s something you should always double check Add channel axis to 2D array Add new dimension for batch size Predict Get highest scoring species Prepare submission entry Decide if it s a nocall or a species by applying a threshold Add the confidence score as well Make a new data frame Merge with ground truth so we can inspect Let s look at the first 50 entries. Well and we missed others. Please don t hesitate to leave a comment or start a new forum thread if you have any questions. This is not a huge CNN it only has 200 000 parameters. 0 and exclude samples with nan Add channel axis to 2D array Add new dimension for batch size Add to train data Add to label data Make sure your experiments are reproducible Build a simple model as a sequence of convolutional blocks. the resolution of our spectrograms to fit the external model. Settings and importsLet s begin with imports and a few basic settings. But remember we re training on focal recordings and validate on focal recordings. Model trainingIn this notebook we will train our first model and apply this model to a soundscape. We ll use 20 of our training data for validation and we ll stop after 25 epochs. Well it s a multi label task so sigmoid might actually be a better choice First conv block Second conv block Third conv block Fourth conv block Global pooling instead of flatten Dense block Classification layer Compile the model and specify optimizer loss and metric Add callbacks to reduce the learning rate if needed early stopping and checkpoint saving Let s train the model for a few epochs Load the best checkpoint Pick a soundscape Open it with librosa Store results so that we can analyze them later Split signal into 5 second chunks Just like we did before well this could actually be a seperate function End of signal Get the spectrograms and run inference on each of them This should be the exact same process as we used to generate training samples Keep track of the end time of each chunk Get the spectrogram Normalize to match the value range we used during training. Let s make sure the spectrograms look right and show the first 12. We will simply ignore the fact that samples might not contain any bird sounds. The last layer is our classification layer and is softmax activated. Here we go everything is in place let s train a model. It might make sense to choose an off the shelve TF model that was pre trained on audio data but we would need to adjust the inputs i. Ok that s not too bad. And again we have to load a file with Librosa extract spectrograms for 5 second chunks pass each chunk through the model and eventually assign a label to the 5 second audio chunk. Extract training samplesWe need to define a function that extracts spectrograms for a given audio file. It s the easiest way to use these data for training with Keras. Nice These are good samples. That s way too much for this tutorial so we will limit our species selection to species that have at least 200 recordings with a rating of 4 or better. But for now loading samples from disk and combining them into a large NumPy array is fine. Data preparationThe training data for this competition contains tens of thousands of audio files for 397 species. This function needs to load a file with Librosa we only use the first 15 seconds in this tutorial extract mel spectrograms and save each spectrogram as PNG image in a working directory for later access. Soundscape analysisIn this tutorial we will simply pick a soundscape from the training data but the overall process can easily be automated and then applied to all soundscape files. Finally perform global average pooling and add 2 dense layers. The species list includes very common species like the House Sparrow houspa Blue Jay blujay or Song Sparrow sonspa. Not too bad we got into the 60s of our validation accuracy. ogg seems to contain a lot of Song Sparrow sonspa vocalizations let s try this one then. Remember this is only a sample implementation feel free to explore your own workflow. Yet with potentially hundreds of thousands of extracted spectrograms an in memory dataset is not a good idea. Global vars seconds height x width Code adapted from https www. We will keep the amount of training samples species and soundscapes to a minimum to keep the execution time as short as possible. Yet we also only have a very small dataset with just 27 classes. These are the steps that we will cover select audio files we want to use for training extract spectrograms from those files and save them in a working directory load selected samples into a large in memory dataset build a simple beginners CNN train the model apply the model to a selected soundscape and look at the results 1. Let s look at the results and see how well we re actually doing. The scores might not tell us much about how well we will perform on soundscape data. We also didn t detect the Northern Cardinal norcar and Red winged Blackbird rewbla even though we had them in our training data. The file 28933_SSW_20170408. Focal recordings as training data can be misleading and soundscapes have much higher noise levels and also contain very faint bird calls. Each block has the sequence CONV RELU BNORM MAXPOOL. Load metadata file Limit the number of training samples and classes First only use high quality samples Second assume that birds with the most training samples are also the most common A species needs at least 200 recordings with a rating above 4 to be considered common Let s see how many species and samples we have left Shuffle the training data and limit the number of audio files to MAX_AUDIO_FILES Define a function that splits an audio file extracts spectrograms and saves them in a working directory Open the file with librosa limited to the first 15 seconds Split signal into five second chunks End of signal Extract mel spectrograms for each audio chunk Normalize Save as image file Parse audio files and extract training samples Plot the first 12 spectrograms of TRAIN_SPECS Parse all samples and add spectrograms into train data primary_labels into label data Open image Convert to numpy array Normalize between 0. com frlemarchand bird song classification using an efficientnet Make sure to check out the entire notebook. Build a simple modelAlright our dataset is ready now we need to define a model architecture. That s roughly 150 for each species which is not too bad. Callbacks make our life easier the three that we re adding will take care of saving the best checkpoint they will reduce the learning rate whenever the training process stalls and they will stop the training if the model is overfitting. Load training samplesFor now our spectrograms reside in a working directory. ", "id": "stefankahl/birdclef2021-model-training", "size": "5253", "language": "python", "html_url": "https://www.kaggle.com/code/stefankahl/birdclef2021-model-training", "git_url": "https://www.kaggle.com/code/stefankahl/birdclef2021-model-training", "script": "sklearn.utils shuffle get_spectrograms numpy Image matplotlib.pyplot tensorflow pandas PIL tqdm ", "entities": "(('s', 'one'), 'seem') (('now we', 'model architecture'), 'need') (('model', 'training'), 'make') (('this', 'while'), 'have') (('we', 'focal recordings'), 'remember') (('how well we', 'soundscape data'), 'tell') (('soundscapes', 'bird also very faint calls'), 'be') (('too we', 'validation accuracy'), 'get') (('huge it', '200 only 000 parameters'), 'have') (('Data training preparationThe data', '397 species'), 'contain') (('now spectrograms', 'working directory'), 'samplesFor') (('we', 'when soundscapes'), 'be') (('we', 'tutorial'), 'notice') (('even we', 'training data'), 'detect') (('s', 'model'), 'go') (('We', 'Song Sparrow sonspa vocalizations'), 'get') (('an', 'memory dataset'), 'be') (('So we', 'own model'), 'keep') (('species list', 'House Sparrow houspa Blue Jay blujay'), 'include') (('experiments', 'convolutional blocks'), 'exclude') (('sample only implementation', 'own workflow'), 'remember') (('we', 'model'), 'let') (('spectrograms', 'first 12'), 'let') (('we', 'memory'), 'want') (('model', 'results'), 'be') (('again we', 'audio 5 second chunk'), 'have') (('we', 'inputs'), 'make') (('height width Code', 'https www'), 'second') (('how well we', 'results'), 'let') (('that', '0'), 'limit') (('Now it', 'acoustic domains'), 's') (('we', 'four convolutional layers'), 'use') (('you', 'questions'), 'hesitate') (('that', '4'), 's') (('we', 'training 4 157 spectrograms'), 'get') (('Next we', 'loss function'), 'need') (('block', 'sequence'), 'have') (('which', 'roughly species'), 's') (('We', 'execution time'), 'keep') (('Settings', 'imports'), 'begin') (('we', 'training'), 's') (('overall process', 'soundscape easily then files'), 'pick') (('samples', 'bird sounds'), 'ignore') (('s', 'first 50 entries'), 's') (('we', 'just 27 classes'), 'have') (('It', 'Keras'), 's') (('loading samples', 'NumPy large array'), 'be') (('we', '25 epochs'), 'use') (('that', 'given audio file'), 'need') (('com frlemarchand bird song classification', 'entire notebook'), 'make') (('we', 'threshold'), 'find') (('trainingIn notebook we', 'soundscape'), 'model') (('luckily we', 'validation soundscapes'), 'have') (('that', '27 species'), 'leave') (('we', 'later access'), 'use') ", "extra": "[]"}
{"name": "a cluster of colors principal component analysis ", "full_name": " h1 A CLUSTER OF COLORS h4 PCA APPROACH h1 1 Introduction h1 2 Extracting only the color features h3 Encoding categorical values h1 3 Correlation of color features h1 4 Principal Component Analysis with KMeans Clustering h1 CLOSING REMARKS ", "stargazers_count": 0, "forks_count": 0, "description": "stalk color below ring 5. Therefore we need to encode. Inspecting the data we see that there are 6 columns features that allude to colors 1. Please feel free to leave comments and thoughts on how I could improve this notebook from a data science point of view or plotting point of view or organisational point of view or views from any other point. Not really sure if there is an easier way to do this. Extracting only the color features The first step is to extract all the features in the dataset that point to the colors of the mushroom. Since the color s categorical value correspond to one another across columns I want to ensure that the encoding provides the same output across all columns. spore print colorTherefore let s extract these 6 color columns into its own dataframe data_color Encoding categorical valuesWe see that the colors are all categorical values. Therefore this notebook is organized as follows Label encoding the categorical values Pearson Correlation to investigate any linear dependence on the color features PCA and KMeans clustering for visualization 2. htmlWe also import the KMeans method so that we can use KMeans clustering to extract our PCA components. Principal Component Analysis with KMeans ClusteringThankfully the immense power of the sklearn module can be utilized to implement Principal Component Analysis conveniently. From the code below since I am going to look at PCA with 3 components therefore I assign the PCA parameter n_components to be equal to 3. Simple visualisation of the 3 clusters with a pre defined color map CLOSING REMARKSSince I m only starting out and am still very green behind the ears around data science I will stop my notebook at this juncture. org stable modules generated sklearn. With this 2D plot of the PCA projections let s try to apply a simple KMeans and see if we can identify any clusters from the projections. Let s plot some hexplots for visualisationJust some pretty visuals but let s delve deeper into the meat of the data by looking at Pearson Correlation. IntroductionThis notebook is not meant to be an exhaustive EDA nor will it attempt to run fancy stuff like XGBoosting or Ensembling methods. Correlation of color featuresNow let s look at the Pearson correlation of the color features as a sort of first attempt to identify how linearly related they are to one another. However this PCA decomposition coupled with KMeans clustering or other clustering methods can be quite powerful especially when you imagine that your dataset features contain 100s or 1000s of columns you are able to scale it down by an order of magnitude via this method. The chief focus of this script will simply be to try out sklearn s PCA Principal Decomposition Analysis method on a small dataset hence the choice to only look at mushroom colors. Importing the usual libraries Read in the mushroom data into a dataframe called data what a creative name I use a list color_features to store the color column names. Check out the official sklearn link for a more detailed explanation http scikit learn. Therefore my idea was to create a dictionary that contains the encoding for the unique values across the dataframe. Seems that from this heatmap we identify about 2 or 3 features that have some weakly to medium positive linear correlation with one another. stalk color above ring 4. A CLUSTER OF COLORS PCA APPROACH 1. To take this further from a qualitative point of view one would then extract the KMeans clusters and use those as new features in training the Machine Learning model should the effect of this dimensionality reduction clustering prove helpful. The method of fit_transform fits the model with X mushroom color values and then reduces the dimensions of X to our stated 3 dimensions. Do let me know if there is create our color dataframe and inspect first 5 rows with head List to store all unique categories Use sklearn Labelencoder for transformation Define a dictionary encodedict to store our encoding Finally use dictionary to generate encoded dataframe correlation matrix using the corr method used the astype or else I get empty results Set up the matplotlib figure Draw the heatmap using seaborn import the relevant modules calling sklearn PCA fit X and apply the reduction to X Let s see how it looks like in 2D could do a 3D plot as well Set a 3 KMeans clustering Compute cluster centers and predict cluster indices. Therefore as a rough heuristic let s look at PCA ing the features into 3 components. And to visualize this with a more swanky heatmap that everyone is using these days. ", "id": "arthurtok/a-cluster-of-colors-principal-component-analysis", "size": "3863", "language": "python", "html_url": "https://www.kaggle.com/code/arthurtok/a-cluster-of-colors-principal-component-analysis", "git_url": "https://www.kaggle.com/code/arthurtok/a-cluster-of-colors-principal-component-analysis", "script": "PCA LabelEncoder seaborn numpy matplotlib.pyplot sklearn.cluster sklearn.preprocessing KMeans pandas sklearn.decomposition ", "entities": "(('looks', 'cluster indices'), 'let') (('therefore I', '3'), 'assign') (('choice', 'mushroom only colors'), 'be') (('immense power', 'Principal Component Analysis'), 'utilize') (('columns 6 that', 'colors'), 'inspect') (('s', 'Pearson Correlation'), 'let') (('effect', 'dimensionality reduction clustering'), 'prove') (('everyone', 'days'), 'visualize') (('how linearly they', 'one'), 'let') (('how I', 'other point'), 'feel') (('we', 'PCA components'), 'import') (('exhaustive it', 'XGBoosting methods'), 'mean') (('that', 'one'), 'seem') (('we', 'projections'), 'let') (('explanation http more detailed scikit', 'sklearn official link'), 'check') (('encoding', 'columns'), 'correspond') (('creative I', 'color column names'), 'import') (('I', 'juncture'), 'stop') (('method', 'stated 3 dimensions'), 'fit') (('that', 'dataframe'), 'be') (('colors', 'Encoding categorical own dataframe data_color valuesWe'), 'let') (('you', 'method'), 'be') (('first step', 'mushroom'), 'feature') (('s', '3 components'), 'therefore') (('PCA', 'visualization'), 'organize') ", "extra": "[]"}
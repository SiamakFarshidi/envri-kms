{"name": "fashion ac gan with keras ", "full_name": " h2 Introduction h2 AC GAN implementation h2 Sample images from the final trained AC GAN h2 Generated images analysis h3 Samples between interpolated points h3 L1 distance evaluation ", "stargazers_count": 0, "forks_count": 0, "description": "GAN diagram taken from https www. if it is a fake image or not and in the AC GAN scenario it also has to predict the label of the image. There are already many types of GANs in general a GAN consists of a discriminator and a generator in which the generator makes new fake samples and feed them to the discriminator that has to detect whether if the sample is fake or if it comes from the training dataset. The loss for the generator decreases after some epochs arriving to a stable point after epoch 700. In the good side it can also be seen intra class variability which is a good sign that the ac gan is performing well. It can also be seen better quality outputs for the first second fifth and sixth columns. There are no abrupt changes at first sight either. One of the implemented architectures is the AC GAN https github. com eriklindernoren Keras GAN nice repo where there many GAN architectures implemented in Keras. The discriminator also has to predict the source of the image i. Generated images analysisTwo different tests will be done to the AC GAN to asses the quality of the generated images Draw samples from interpolated points between two arbitrary points Check the distance between generated images and training imagesGANs that have overfit show abrupt changes when there are small changes in the input noise. 0 9 if image is valid or 10 if it is generated fake Train the discriminator Train Generator Train the generator show the final losses If at save interval save generated image samples Plot the progress do not save model row cols to be sampled Rescale images 0 1 Rescale images 0 1 label dictionary input dimensions load the data with the format needed in the AC GAN implementation read the csv data extract the image pixels extract the labels the instance of the ACGAN class we can see the Discriminator and Generator architecture Train the AC GAN with the fashion mnist data Show the Generator Descriminator loss for every epoch draw interpolated samples between two arbitrary points pick N_samples_interp 2 points one is the start noise_1 and the other the end noise_2 fit a line between point1 and point2 for every label draw N_samples_interp_all samples from the fitted line get a random point draw samples between that point and that same point with all coordinates scaled by 1 draw another arbitrary point draw samples between these two arbitrary points yet another noise sample get the images that belong to id_label_sample apply the norm between X_lab and the sampled image across all images original image. Introduction GANs are an interesting topic I have always wanted to play with. These Training labels are fed to the generator that will generate fake images using both the random noise and the input label. We can visually asses that the generated images similar to the closest ones without being an exact copy as well. com blog 2017 06 introductory generative adversarial networks gans After some reading I decided to use an AC GAN that stand for Auxiliar Classifier GAN. Well trained GANs should have more smooth output changes when are fed with slightly different input noise. Samples between interpolated pointsIn the previous image we have 10 rows one per class and 6 columns 2 for the extreme points and 4 interpolated points in the middle. It can be seen that in the first epochs first 200 the generator has huge loss values while the discriminator has lower loss values meaning that the generator is not being able to trick the discriminator yet. I made some changes in that implementation this is a short summary of what these changes intended to do being able to train with more datasets than just standard mnist showing samples of generated images during training sampling images can be shown in cells not only into filesIn the previous cell we train our AC GAN with the fashion mnist data. The second check tries to asses if the AC GAN has overfit to the training data meaning that it will output a copy of input images. The output for the sandal class is quite poor and the output or the third and fourth columns is also very poor probably because for these two colums many coordinates will be around 0 and during training the AC GAN is not fed with points following that distribution. L1 distance evaluationNow let s get another generated image and see whether if it is a copy from any training image. To fix the issue around the 0s region let s interpolate intermediate inputs from two arbitrary points. The output gets richer iteration after iteration getting convincing results in the last training iterations. For more detailed information I recommend reading these papers Generative Adversarial Networks https arxiv. We can see that in the first 200 epochs the generator is doing a poor job and outputs mainly noise. The main difference between the AC GAN and a plain GAN is that to train the AC GAN we need both training samples and training labels. pdf AC GAN implementationKeras currently has no AC GAN implementation out of the shelf so after some googling I came across this https github. com eriklindernoren Keras GAN blob master acgan acgan. Sample images from the final trained AC GANMost classes we get interesting outputs while for the 6th column sandals we get not so nice generated images. pdf Conditional Image Synthesis with Auxiliary Classifier GANs https arxiv. Input shape Build and compile the discriminator Build the generator The generator takes noise and the target label as input and generates the corresponding digit of that label For the combined model we will only train the generator The discriminator takes generated image as input and determines validity and the label of that image The combined model stacked generator and discriminator Trains the generator to fool the discriminator Extract feature representation Determine validity and label of the image Load the dataset Configure inputs Adversarial ground truths Loss output Train Discriminator Select a random batch of images Sample noise as generator input The labels of the digits that the generator tries to create an image representation of Generate a half batch of new images Image labels. ", "id": "sgamez/fashion-ac-gan-with-keras", "size": "4459", "language": "python", "html_url": "https://www.kaggle.com/code/sgamez/fashion-ac-gan-with-keras", "git_url": "https://www.kaggle.com/code/sgamez/fashion-ac-gan-with-keras", "script": "interp1d Flatten __init__ Reshape plot_gan_losses keras.layers plot_n_closest LeakyReLU multiply mnist division Embedding train show_interp_samples Dropout Sequential keras.datasets Adam keras.layers.advanced_activations load_fashion_mnist scipy.interpolate Conv2D sample_images numpy save Input build_generator print_function keras.layers.convolutional ACGAN() sample_single_image matplotlib.pyplot Activation Dense pandas keras.optimizers BatchNormalization UpSampling2D __future__ Model save_model keras.models build_discriminator ZeroPadding2D ", "entities": "(('it', 'input images'), 'try') (('trained GANs', 'input when slightly different noise'), 'have') (('One', 'implemented architectures'), 'be') (('so I', 'https github'), 'have') (('it', 'training image'), 'let') (('com eriklindernoren Keras GAN GAN nice where there many architectures', 'Keras'), 'repo') (('previous we', '4 interpolated middle'), 'sample') (('It', 'quality also better first second fifth columns'), 'see') (('that', 'sampled images original image'), '9') (('We', 'similar closest ones'), 'asses') (('I', 'papers'), 'recommend') (('we', 'column 6th sandals'), 'image') (('discriminator', 'image'), 'have') (('generator', 'poor job'), 'see') (('it', 'image'), 'have') (('AC around GAN', 'distribution'), 'be') (('generator', 'images Image new labels'), 'shape') (('that', 'Auxiliar Classifier GAN'), 'blog') (('ac good gan', 'class also intra variability'), 'see') (('s', 'two arbitrary points'), 'let') (('overfit', 'input when small noise'), 'image') (('that', 'random noise'), 'feed') (('we', 'training samples'), 'be') (('it', 'training dataset'), 'be') (('generator', 'discriminator'), 'see') (('epochs', 'epoch'), 'decrease') (('output', 'training last iterations'), 'get') (('we', 'fashion mnist data'), 'make') ", "extra": "['test']"}
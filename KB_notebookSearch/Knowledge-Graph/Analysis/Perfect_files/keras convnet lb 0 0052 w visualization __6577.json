{"name": "keras convnet lb 0 0052 w visualization ", "full_name": " h1 The Idea h1 Data Augmentation h1 Combining the Image CNN with the Pre Extracted Features MLP h2 Wait I don t know what a convolutional neural network is h2 Keras Functional API h1 Visualization h1 Conclusion h2 Thank you for reading ", "stargazers_count": 0, "forks_count": 0, "description": "The IdeaI started this competition by simply feeding the pre extracted features into a multi layer perceptron with one hidden layer and got surprisingly good results but I still had all this image data that I wasn t using. The second convolutional layer is also mainly edge detection along with some point and edge shape detection I noticed with some leaves that have particularly special shapes. But before we do that let s just get all the data loading out of the way. Since we don t really have enough data to go that deep most of our filters look pretty tame. You can find more by just googling convolutional neural network explained. format i conv_img_filt i for i in range conv_img_filt. empty len ids 1 max_dim max_dim uncomment this Turn the image into an array Get the corners of the bounding box for the image NOTE Theano users comment the two lines below and length x. We ll try to emphasize this in our dataset by randomly performing a rotation or zoom transformation to each leaf image as the image is passed to the neural network. 00520 LB score with this exact same code after running for 100 epochs though the best model occurred at the 89th epoch for me on an AWS p2. First we ll pick a few random leaves from our validation set and we ll pass each one through the neural network. VisualizationGreat So we ve got our combined model working that incorporates both the raw binary images of the leaves and the pre extracted features. Keeps under lock only the mechanism which advances the indexing of each batch see http anandology. shape 1 uncomment this. com c leaf classification forums t 24764 create gif based on leaf class on the forum containing a GIF of each training sample for each species you ll notice that for a given species most of the leaves look very similar except that the leaf is rotated slightly or is slightly larger in scale. Data AugmentationOne trick we are going to use to improve the robustness of our model is image data augmentation allowing it to perform better on the test set. If you take a look at Rhyando Anggoro Adi s post https www. It s MUCH faster to run it locally if you have a GPU or on an AWS instance with a GPU. From the last version s submission created from running this on Kaggle I got a 0. EDIT I would run this somewhere other than Kaggle locally for 150 epochs instead of 89 like I have it set to below 89 is the best I could do without the script timing out. But you might ask now what is the neural network actually learning One easy way to tell what the convolutional portion of the neural net is learning is through visualization of the hidden layers. io getting started faq how can i visualize the output of an intermediate layer. Judging by our LB score though I think we can assume what it s doing is fairly constructive. 0052 with this code but due to some randomness still in the script the score varies between 0. Instead we ll be using the Functional API. And now we create our submission. shape 1 uncomment this width x. Below is the code for the data augmentation image generator along with a slight change to the source code to help us out later on. You can think of each layer as a function and the array we give it as its argument. Instead of samples rows cols channels it should be samples channels rows cols Keras stuff A large amount of the data loading code is based on najeebkhan s kernel Check it out at https www. shape 2 uncomment this Insert into image matrix NOTE Theano users comment line below and X i 0 1 h1 h2 w1 w2 x uncomment this Scale the array values so they are between 0 and 1 Load the pre extracted features Load the image data Split them into validation and cross validation Load the pre extracted features Load the image data A little hacky piece of code to get access to the indices of the images the data augmenter is working with. Thank you for reading If you want to use Theano all you need to change is the dim ordering whenever you are dealing with the image array. Wait I don t know what a convolutional neural network is No worries I ve linked below a few great places to get an overview of convnets. This is actually pretty common with convnets. index_array The transformation of images is not under thread lock so it can be done in parallel Define the image input Pass it through the first convolutional layer Now through the second convolutional layer Flatten our array Define the pre extracted feature input Concatenate the output of our convnet with our pre extracted feature input Add a fully connected layer just like in a normal MLP Get the final output How we create models with the Functional API Get the image batch and labels This is where that change to the source code we made will come in handy. me 2016 08 11 intuitive explanation convnets http neuralnetworksanddeeplearning. You can also manually shuffle the indices set the shuffle parameter for the ImageDataGenerator to False and flow the generator from the manually shuffled images. In addition to questions I m very open to any feedback both in general about kernel writing and specifically about this kernel. 01672 LB but I had managed to get a 0. Combining the Image CNN with the Pre Extracted Features MLPNow that we ve gotten all the data preparation work out of the way we can actually construct our model. As the leaf goes through the convolutional neural net will apply many filters each looking for something in the image. com najeebkhan leaf classification neural network through keras Read data from the CSV file Since the labels are textual so we encode them categorically standardize the data by setting the mean to 0 and std to 1 standardize the data by setting the mean to 0 and std to 1 Get the axis with the larger dimension Scale both axes so the image s largest dimension is max_dim Initialize the output array NOTE Theano users comment line below and X np. autosave best Model Get the names of the column headers Converting the test predictions in a dataframe as depicted by sample submission Display the submission Function by gcalmettes from http stackoverflow. NOTE the change to the source code is not the only way to get around the problem of matching the indices of our two inputs images and pre extracted features. ConclusionFor the first convolutional layer we can sort of tell that most of the filters are doing edge detection on the leaf. If you take a look at our architecture for the neural net you ll notice we created 8 filters for the first convolutional layer and 32 for the second one. Using some form of kfold validation reduces this variance. To do this in Keras we ll build a Keras function as outlined in the Keras FAQ https keras. Well that s all If you ve made it this far that means you ve read my first kernel and I hope it helps if you re stuck and don t know how to improve your score. Keras s functional API gives us a really easy way to do this. html Keras Functional APIFor basic neural network architectures we can use Keras s Sequential API but since we need to build a model that takes two different inputs image and pre extracted features in two different locations in the model we won t be able to use the Sequential API. com blog using iterators and generators We changed index_array to self. This variance in the results could definitely be improved upon with some k fold validation but I ll leave the implementation up to the reader. That actually makes a lot of sense since pretty much all of the species specific information of a leaf is stored in the shape of its edge. My immediate thought then was to simply combine a convolutional neural network on the images with the pre extracted features MLP and train the entire model end to end. com questions 11159436 multiple figures in a single window Load the best model Get the convolutional layers Pick random images to visualize Use a keras function to extract the conv layer data Also get the prediction so we know what we predicted Loop through each image disply relevant info Get top 3 predictions Get the actual leaf species Display the top 3 predictions and the actual species Show the original image For Theano users comment the line below and imshow X_img_val img_to_visualize 0 cmap gray uncomment this Plot the filter images Get it ready for the plot_figures function For Theano users comment the line below and fig_dict flt 0. Thus for each leaf image we should get a set of 8 and another set of 32 new images. Once the filter is applied we ll grab the new image of the leaf and the white portions of the image will tell us where the filter activated and the black will tell us where it didn t. I did set the random seeds but there is still randomness somewhere. We can now access the indicies of the images that imgen gave us. Click here https keras. io convolutional networks https ujjwalkarn. Below I ll outline the process of getting this model working along point out some nice resources to learning about convolutional nets and do some visualization of what the neural network is actually doing. This API is just as straightforward but instead of having a model we add layers to we ll instead be passing an array through a layer and passing that output through another layer and so on. Now we re finally ready to actually train the model Running on Kaggle will take a while. The first few layers will do really simple stuff like edge and shape detection but the deeper you go the more abstract it gets. NOTE I managed to get an LB of 0. io getting started functional api guide for more info about the functional API. ", "id": "abhmul/keras-convnet-lb-0-0052-w-visualization", "size": "6577", "language": "python", "html_url": "https://www.kaggle.com/code/abhmul/keras-convnet-lb-0-0052-w-visualization", "git_url": "https://www.kaggle.com/code/abhmul/keras-convnet-lb-0-0052-w-visualization", "script": "ImageDataGenerator2(ImageDataGenerator) Flatten keras.preprocessing.image NumpyArrayIterator2(NumpyArrayIterator) get_dim keras.layers keras.callbacks load_test_data StratifiedShuffleSplit Dropout keras.utils.np_utils numpy sqrt array_to_img load_train_data Input img_to_array flow merge ModelCheckpoint sklearn.model_selection ImageDataGenerator LabelEncoder load_image_data plot_figures load_img load_numeric_test next matplotlib.pyplot Activation Dense pandas StandardScaler to_categorical NumpyArrayIterator combined_generator combined_model load_model Model MaxPooling2D load_numeric_training sklearn.preprocessing backend backend as K keras keras.models math resize_img Convolution2D ", "entities": "(('I', 'specifically kernel'), 'in') (('which', 'http anandology'), 'see') (('image', 'neural network'), 'try') (('Below code', 'us'), 'be') (('image NOTE Theano users', 'two lines'), 'ids') (('don t', 'how score'), 's') (('I', 'convnets'), 'wait') (('we', '32 new images'), 'get') (('neural network', 'what'), 'outline') (('it', 'line'), 'question') (('image data it', 'test better set'), 'go') (('best model', 'AWS p2'), '00520') (('we', 'Sequential API'), 'architecture') (('just data', 'way'), 'let') (('You', 'manually shuffled images'), 'shuffle') (('sort of most', 'leaf'), 'ConclusionFor') (('we', 'second one'), 'notice') (('more it', 'edge detection'), 'do') (('we', 'actually model'), 'get') (('we', 'neural network'), 'pick') (('data augmenter', 'images'), 'comment') (('I', 'reader'), 'improve') (('best Model', 'http stackoverflow'), 'autosave') (('specific information', 'edge'), 'make') (('immediate thought', 'end'), 'be') (('Using', 'variance'), 'reduce') (('pre', 'leaves'), 'VisualizationGreat') (('each', 'image'), 'apply') (('very leaf', 'slightly slightly scale'), 'create') (('we', 'layer'), 'be') (('Running', 'while'), 're') (('script', 'below 89'), 'run') (('neural just convolutional network', 'more'), 'find') (('that', 'particularly special shapes'), 'edge') (('I', 't using'), 'start') (('where it', 't.'), 'grab') (('large amount', 'https www'), 'row') (('doing', 'what'), 'judge') (('we', 'argument'), 'think') (('we', 'Keras FAQ https keras'), 'build') (('We', 'index_array'), 'blog') (('I', 'random seeds'), 'set') (('learning', 'hidden layers'), 'ask') (('This', 'actually pretty convnets'), 'be') (('locally you', 'GPU'), 's') (('how i', 'intermediate layer'), 'faq') (('Instead we', 'Functional API'), 'use') (('dim whenever you', 'image array'), 'be') (('change', 'features'), 'NOTE') (('imgen', 'us'), 'access') (('score', '0'), 'vary') (('we', 'source code'), 'index_array') (('functional API', 'this'), 'give') (('deep most', 'filters'), 'have') (('NOTE Theano users', 'line'), 'network') (('I', '0'), 'from') (('you', 'Rhyando Anggoro'), 'take') ", "extra": "['test']"}
{"name": "tps june weights and biases ", "full_name": " h1 Tabular Playground Series June 2021 h2 Introduction h3 Problem Statement h3 Metric h2 Libraries h2 Data Description h4 W B Artifacts h4 W B Tables h4 Missing Data h3 Observations h4 Scatter Plot of Features h4 Target Class h4 Density Plot of Features h4 Distribution of mean values h4 Distribution of Standard Deviation h4 Distribution of min values h4 Distribution of max values h4 Distribution of Skewness h4 Distribution of Kurtosis h4 Correlation of Features h4 Checking for Duplicate Values ", "stargazers_count": 0, "forks_count": 0, "description": "Although the features are anonymized they have properties relating to real world features. Each row in the dataset has been labeled with one true Class. The formula is text log loss frac 1 N sum_ i 1 N sum_ j 1 My_ ij log p_ ij where N is the number of rows in the test set M is the number of class labels text log is the natural logarithm y_ ij is 1 if observation i is in class j and 0 otherwise and p_ ij is the predicted probability that observation i belongs to class j. Tables are great for storing understanding and sharing any form of data critical to your ML workflow from datasets to model predictions and everything in between. MetricSubmissions are evaluated using multi class logarithmic loss. Source https docs. com dwin183287 tps june 2021 edahttps www. csv a sample submission file in the correct format The train dataset contains 200000 rows and 77 features and test dataset contains 100000 rows and 76 features. Train dataset is twice that of test dataset. The columns in the train data are as following id The id of the product one per row features_ The various attribute of the product starting from Feature_0 to Feature_75 target Class labels 0 to 9 The test dataset has same columns except the target value W B Artifacts Use W B Artifacts for dataset versioning model versioning and tracking dependencies and results across machine learning pipelines. Table is a two dimensional grid of data where each column has a single type of data think of this as a more powerful DataFrame. Think of an artifact as a versioned folder of data. You can store entire datasets directly in artifacts or use artifact references to point to data in other systems like S3 GCP or your own system. For each row you must submit the predicted probabilities that the product belongs to each class label. LibrariesData Description train the training data one product id per row with the associated features feature_ and class label target test the test data you must predict the probability the id belongs to each class sample_submission. com bhuvanchennoju data storytelling auc focus on strokeshttps www. ai guides data vis Lets explore first five rows of train datasetLets explore first five rows of test dataset Missing Data Observations There are no missing rows in both test and train dataset Scatter Plot of Features Target Class Density Plot of Features Distribution of mean values Distribution of Standard Deviation Distribution of min values Distribution of max values Distribution of Skewness Distribution of Kurtosis Correlation of Features Checking for Duplicate Values Work in progress References https www. com c santander value prediction challenge Load csv data of this competition. Tabular Playground Series June 2021 Introduction Problem StatementFor Tabular Playground Series June 2021 we have a synthetic dataset generated using CTGAN and the dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Initialize a new W B run. Tables support primitive and numeric types as well as nested lists dictionaries and rich media types. Log a Table to W B then query compare and analyze results in the UI. ai guides artifacts W B Tables A W B Table wandb. ", "id": "usharengaraju/tps-june-weights-and-biases", "size": "6986", "language": "python", "html_url": "https://www.kaggle.com/code/usharengaraju/tps-june-weights-and-biases", "git_url": "https://www.kaggle.com/code/usharengaraju/tps-june-weights-and-biases", "script": "sklearn.metrics lightgbm plotly.offline tqdm_notebook UserSecretsClient missing_data mean_squared_error seaborn numpy plotly.graph_objs sklearn.model_selection plotly.tools matplotlib.pyplot pandas tqdm plot_feature_scatter plot_feature_distribution roc_auc_score StratifiedKFold roc_curve kaggle_secrets ", "entities": "(('com bhuvanchennoju storytelling data auc', 'strokeshttps www'), 'focus') (('Distribution', 'progress References https www'), 'guide') (('they', 'world real features'), 'have') (('i d', 'class sample_submission'), 'train') (('train dataset', 'test 77 100000 rows'), 'csv') (('You', 'S3 GCP'), 'store') (('ai', 'W B Tables A W B Table wandb'), 'guide') (('Playground Introduction StatementFor Tabular Playground Tabular June 2021 June 2021 we', 'listing'), 'Series') (('MetricSubmissions', 'multi class logarithmic loss'), 'evaluate') (('Train dataset', 'test dataset'), 'be') (('Tables', 'predictions'), 'be') (('where column', 'more powerful DataFrame'), 'be') (('test dataset', 'machine learning pipelines'), 'be') (('row', 'one true Class'), 'label') (('predicted i', 'j.'), 'be') (('com', 'dwin183287 june 2021 www'), 'edahttps') (('product', 'class label'), 'submit') ", "extra": "['test']"}
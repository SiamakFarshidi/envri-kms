{"name": "students performance eda and prediction ", "full_name": " h4 Descriptive Analytics h3 Checking for missing values h3 Feature Classification h4 KDE plot h4 Scatterplots for the numerical variables h4 Group with most number of people h3 Categorical Scatterplots h4 Education level of Parents h4 Gender Lunch and Test preperation h4 The group of people who scored the highest number of total marks h4 Parents educational levels and students performance h4 How does gender effect the students performance individually h3 Which subject has the most number of failures h4 Grading the Students h4 Male and Female Students Grades h4 Relationship between grades and lunch h4 Test Preperation Course and Grades h3 Creating dummy variables h3 Training the Models h4 Evaluating the performance of our regression models h4 Linear Regression h4 Decision Tree Regression h4 RandomForest Regression h4 Feature Importance Plot for Random Forest h4 Comparing the performance h4 My other notebooks h3 References h3 Do upvote the kernel if you find it useful Feedback is highly appreciated Thank You ", "stargazers_count": 0, "forks_count": 0, "description": "Scatterplots for the numerical variablesWe can see from the above figure that 1. KDE plotAs a general rule of thumb If skewness is less than 1 or greater than 1 the distribution is highly skewed. Grading the StudentsMost of the students achieved a B Grade followed by Grade C. Feedback is highly appreciated. So dividing by 3 gives the. Education level of ParentsMost of the parents attended some college 226 and almost the same amount of people have an associate s degree. Descriptive Analytics Checking for missing valuesThere are no missing values present in our dataset. Feature ClassificationIt is good practice to categorize the numerical and categorical variables. Categorical ScatterplotsAs we cannot see the parental level of education clearly I will plot it again. The info method gives the summary of our data. MAE Gives us the difference between the actual value and predicted value. The R squared value of Decision Tree Regression is negative. com subinium kaggle 2020 visualization analysis4. Gender Lunch and Test preperationWe can observe from the above figures that 1. If skewness is between 0. Females students are more than male students. Parents educational levels and students performance How does gender effect the students performance individually Which subject has the most number of failures 1. If skewness is between 1 and 0. com what are the best metrics to evaluate your regression model 418ca481755b If squared True then its MSE if squared False then its RMSE https towardsdatascience. Skewness and kurtosis Math and reading scores Mathematics and Writing Scores Reading and writing Scores color highlight color highlight color highlight color highlight Number of students who passed in math Number of students who passed in reading Number of students who passed in writing. com ruthvikpvs stroke data eda and prediction2 https www. com josephchan524 studentperformanceregressor rmse 12 26 r2 0 26 Do upvote the kernel if you find it useful. Male and Female Students Grades Relationship between grades and lunch Test Preperation Course and Grades Creating dummy variablesWe use One Hot Encoding to encode categorical variables. 5 the distribution is approximately symmetric. The number of people who failed in mathematics are more than other subjects. We can observe that 1. Random Forest performs better than Decision Trees but not as good as Linear Regression. The group of people who scored the highest number of total marksThe students in Group C scored the most number of marks among all the groups followed by groups D B E and group A. Even though Linear Regression performs better than these models the r_squared value is only 0. We can observe from the above graphs that most of the students score above 150 marks. The students who have completed any course are less than the students who did not prepare. Importing the libraries Adding a column for the total marks. My other notebooks 1 https www. Only a small portion of students scored less than 40. Eg If the actual value is 10000 and the predicted value is 5000 then we can say that the actual value is 5000 more than the predicted value. Encoding is necessary because machine learning models do not work with categorical variables. Linear regression performed far better than Decision Trees and Random Forest algorithms. com spscientist student performance in exams2. Most of the scores fall between 40 100 range. For One Hot Encoding we use pd. The scores increases linearly with each other. R squared Measures how much of variability in dependent variable can be explained by the model. We can see that our numerical data follows the normal distribution. 5 and 1 the distribution is moderately skewed. The Mean Square Error value of Linear Regression is 1436 on average the predictions have 1436 difference from the actual values 3. Linear Regression Decision Tree Regression RandomForest Regression Feature Importance Plot for Random Forest Comparing the performanceIf we compare the three models we used for predictions. 24 and the predictions are not accurate most of the time. This us useful as we can check if there are any missing values present or not. R squared values less than 0 means a horizontal line fits the data better than our model. We use histograms to observe how the scores of students are distributed. Importing the libraries Splitting the data into training and testing sets https towardsdatascience. com running random forests inspect the feature importances with this code 2b00dd72b92e. So decision tree regression is not suitable for our data. There are 1000 rows and 8 columns in our dataset. MSE Mean Square Error is an absolute measure of the goodness for the fit. Use the shape method to see the number of rows and columns in our dataset. Group with most number of peopleGroup C has the most number of people and Group A has the least amount of people. Students who prefer standard lunch are more in number than students who prefer free reduced lunch. Students percentage Percentage number 100 here the highest marks 300. com ruthvikpvs heart attack analysis eda and prediction References1. Overall the number of students who failed are significantly less than the students who passed. Parents who hold a master s degree are very few in number. get_dummies Training the Models Evaluating the performance of our regression models. com subinium simple matplotlib visualization tips3. ", "id": "ruthvikpvs/students-performance-eda-and-prediction", "size": "4911", "language": "python", "html_url": "https://www.kaggle.com/code/ruthvikpvs/students-performance-eda-and-prediction", "git_url": "https://www.kaggle.com/code/ruthvikpvs/students-performance-eda-and-prediction", "script": "sklearn.metrics sklearn.tree DecisionTreeRegressor r2_score GetGrade seaborn numpy mean_squared_error RandomForestRegressor scipy.stats EvaluatingModels sklearn.ensemble sklearn.model_selection matplotlib.pyplot stats pandas norm scipy mean_absolute_error sklearn.linear_model matplotlib train_test_split LinearRegression ", "entities": "(('Random Forest', 'Linear as Regression'), 'perform') (('how scores', 'students'), 'use') (('it', '12 26 r2 0 26 kernel'), 'rmse') (('com running random forests', 'code'), 'inspect') (('decision tree So regression', 'data'), 'be') (('less than 1 than 1 distribution', 'KDE general thumb'), 'rule') (('Descriptive Analytics Checking', 'valuesThere missing present dataset'), 'be') (('MAE', 'actual value'), 'give') (('r_squared value', 'better models'), 'be') (('value', 'Decision Tree Regression'), 'square') (('actual value', '5000 predicted value'), 'say') (('who', 'very number'), 'be') (('info method', 'data'), 'give') (('who', 'other subjects'), 'be') (('we', 'predictions'), 'Plot') (('best metrics', 'RMSE https then towardsdatascience'), 'com') (('who', 'groups D B E'), 'score') (('most', '150 marks'), 'observe') (('that', '1'), 'observe') (('who', 'writing'), 'skewness') (('clearly I', 'it'), 'ScatterplotsAs') (('who', 'significantly students'), 'be') (('scores', 'linearly other'), 'increase') (('predictions', 'time'), 'be') (('individually subject', 'failures'), 'level') (('average predictions', 'actual values'), 'be') (('who', 'free reduced lunch'), 'be') (('Only small portion', 'less than 40'), 'score') (('226 almost same amount', 'degree'), 'attend') (('less than 0 horizontal line', 'better model'), 'square') (('Grading', 'Grade C.'), 'achieve') (('who', 'students'), 'be') (('how much', 'model'), 'square') (('Feature ClassificationIt', 'good numerical variables'), 'be') (('lunch Test Preperation Grades Creating', 'categorical variables'), 'Relationship') (('Most', '40 100 range'), 'fall') (('Females students', 'male students'), 'be') (('Scatterplots', '1'), 'see') (('MSE Mean Square Error', 'fit'), 'be') (('numerical data', 'normal distribution'), 'see') (('Linear regression', 'Decision far better Trees'), 'perform') (('Group', 'people'), 'have') (('machine learning models', 'categorical variables'), 'be') ", "extra": "['biopsy of the greater curvature', 'gender', 'test']"}
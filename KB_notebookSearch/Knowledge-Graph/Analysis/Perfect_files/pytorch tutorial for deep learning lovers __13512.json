{"name": "pytorch tutorial for deep learning lovers ", "full_name": " h2 INTRODUCTION h2 Basics of Pytorch h3 Matrices h3 Basic Math with Pytorch h3 Variables h3 Linear Regression h3 Logistic Regression h3 Artificial Neural Network ANN h3 Convolutional Neural Network CNN h3 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "com kanncaa1 recurrent neural network with pytorch1. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. In order to split data we use train_test_split method from sklearn library Size of train data is 80 and size of test data is 20. Size of train data is 80 and size of test data is 20. Basics of Pytorch 1 Matrices Math Variable1. Import Libraries In order to show you I import again but we actually imported them at previous parts. While usign trained model lets predict car prices. create LinearRegression class 1. Prepare Dataset We use MNIST dataset. We use ReLU Tanh and ELU activation functions for diversity. Module Linear function. Also we decide epoch is 29 accuracy achieves almost highest value when epoch is 29. Convolutional layer Create feature maps with filters kernels. Create feature and target tensors. DataLoader It combines dataset and sample. com kanncaa1 long short term memory with pytorch If you have any question or suggest I will be happy to hear it This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. Therefore usually convert result of neural network that is tensor to numpy array to visualize or examine. If you do not know check my tutorial. Tensor method type type of the array. If you learn these parts very well implementing remaining parts like CNN or RNN will be very easy. Pooling size is 2 2 1. As you remember we need to define variable for accumulation of gradients. Lets look at array example with numpy that we already know. define model input and output size are 1 MSE Optimization find parameters that minimize error how fast we reach best parameters train model optimization Forward to get output Calculate Loss backward propagation Updating parameters store loss print loss predict our car price predict if car price is 10 what will be the number of car sell Import Libraries Prepare Dataset load data split data into features pixels and labels numbers from 0 to 9 normalization train test split. I will not explain it in here detailed. We use same batch size epoch and iteration numbers. read_csv Input data files are available in the. numpy method Type type of the array. We will use pytorch in neural network. Traning the Model 1. ConclusionIn this tutorial we learn 1. Now we have a trained model. Clean support for dynamic graphs Organizational backing from Facebook Blend of high level and low level APIs cons Much less mature than alternatives Limited references resources outside of the official documentation I accept you know neural network basics. Convolutional neural network with pytorch1. Finally we train 33600 sample one time. Actually hidden layer dimension is hyperparameter and it should be chosen and tuned. Linear Regression tutorial https www. com kanncaa1 deep learning tutorial for beginners Steps of Logistic Regression 1. For example running this by clicking run or pressing Shift Enter will list the files in the input directory Any results you write to the current directory are saved as output. Create ANN Cross Entropy Loss SGD Optimizer ANN model training Clear gradients Forward propagation Calculate softmax and ross entropy loss Calculating gradients Update parameters Calculate Accuracy Predict test dataset Forward propagation Get predictions from the maximum value Total number of labels Total correct predictions store loss and iteration Print Loss visualization loss visualization accuracy Import Libraries Create CNN Model Convolution 1 Max pool 1 Convolution 2 Max pool 2 Fully connected 1 Convolution 1 Max pool 1 Convolution 2 Max pool 2 flatten Linear function readout batch_size epoch and iteration Pytorch train and test sets data loader Create CNN Cross Entropy Loss SGD Optimizer CNN model training Clear gradients Forward propagation Calculate softmax and ross entropy loss Calculating gradients Update parameters Calculate Accuracy Iterate through test dataset Forward propagation Get predictions from the maximum value Total number of labels store loss and iteration Print Loss visualization loss visualization accuracy. epoch 1 epoch means training all samples one time. grad As a car company we collect this data from previous selling lets define car prices lets define number of car sell lets visualize our data Linear Regression with Pytorch libraries create class super function. In this part there is only one variable x. We combine convolutional part and logistic regression to create our CNN model. com kanncaa1 deep learning tutorial for beginners Difference between variables and tensor is variable accumulates gradients. For now I only say 150 there is no reason. Batch size is the group size. Number of feature map is out_channels 16 Filter kernel size is 5 5 1. This is the fact that we know and we have data set about this fact. Steps of ANN 1. Deep learning tutorial https www. Instantiate Model input_dim 28 28 size of image px px output_dim 10 labels 0 1 2 3 4 5 6 7 8 9 create model 1. We can train 1000 sample in a same time or we can divide it 10 groups which include 100 sample and train 10 groups in order. You can learn CNN basics https www. Artificial Neural Network ANN 4 1. We use same dataset so we only need train_loader and test_loader. Linear Regression 2 1. Instantiate Model Class input_dim 28 28 size of image px px output_dim 10 labels 0 1 2 3 4 5 6 7 8 9 Hidden layer dimension is 150. batch_size batch size means is that for example we have data and it includes 1000 sample. In order to learn compare numpy and tensor np. from_numpy from numpy to tensor numpy from tensor to numpy Basic Math with Pytorch Resize view a and b are tensor. If the car price is high we sell less car. At the next parts we create variable from these tensors. Logistic Regression Linear regression is not good at classification. Prediction Lets implement it with Pytorch Number of iteration is 1001. Linear regression with pytorch1. As you remember we need variable to accumulate gradients. In order to make backward propagation we need variables Assume we have equation y x 2 Define x 2 4 variable After calculation we find that y 4 16 y x 2 Recap o equation is that o 1 2 sum y 1 2 sum x 2 deriavative of o x Result is equal to x so gradients are 2 4 Lets implement Linear Regression Detailed linear regression tutorial is in my machine learning tutorial in part Regression. data type is long batch_size epoch and iteration Pytorch train and test sets data loader visualize one of the images in data set Create Logistic Regression Model Linear part There should be logistic function right However logistic function in pytorch is in loss function So actually we do not forget to put it it is only at next parts Instantiate Model Class size of image px px labels 0 1 2 3 4 5 6 7 8 9 create logistic regression model Cross Entropy Loss SGD Optimizer Traning the Model Define variables Clear gradients Forward propagation Calculate softmax and cross entropy loss Calculate gradients Update parameters Prediction Calculate Accuracy Predict test dataset Forward propagation Get predictions from the maximum value Total number of labels Total correct predictions store loss and iteration Print Loss visualization Import Libraries Create ANN Model Linear function 1 784 150 Non linearity 1 Linear function 2 150 150 Non linearity 2 Linear function 3 150 150 Non linearity 3 Linear function 4 readout 150 10 Linear function 1 Non linearity 1 Linear function 2 Non linearity 2 Linear function 2 Non linearity 2 Linear function 4 readout instantiate ANN hidden layer dim is one of the hyper parameter and it should be chosen and tuned. You can try different values for hidden layer dimension and observe the results. Instantiate Optimizer SGD Optimizer 1. linear regression logistic function softmax logistic regression Check my deep learning tutorial. You can think that our fully connected layer is logistic regression. The question is that what will be number of car sell if the car price is 100. Create Logistic Regression Model Same with linear regression. create model 1. Actually while tuning hyperparameters increase in iteration and expanding convolutional neural network can increase accuracy but it takes too much running time that we do not want at kaggle. And as you know in neural network we have backpropagation where gradients are calculated. Now examine how we implement tensor pytorch array import pytorch library with import torch We create tensor with torch. Padding After applying filter dimensions of original image decreases. Convolutional Neural Network CNN CNN is well adapted to classify images. In this example it is tensor shape shape of the array. Therefore lets learn how to make it with pytorch. define model from this LinearRegression class 1. I only choose it as 150 there is no reason. Module and we can access everythink in nn. We train each groups 336 that have batch_size quota 100. Instantiate Loss Cross entropy loss It calculates loss that is not surprise It also has softmax logistic function in it. Long Short Term Memory LSTM https www. add a b a b Subtraction a. Recurrent neural network with pytorch https www. We need to line fit into this data. We will not use activation function in fully connected layer. div a b a b Mean a. Logistic Regression 3 1. Now this plot is our collected data We have a question that is what will be number of car sell if the car price is 100 In order to solve this question we need to use linear regression. import numpy library numpy array 2x3 array type shape import pytorch library pytorch array type shape numpy ones pytorch ones numpy random pytorch random random numpy array from numpy to tensor from tensor to numpy create tensor Resize Addition Subtraction Element wise multiplication Element wise division Mean Standart deviation std import variable from pytorch library define variable lets make basic backward propagation we have an equation that is y x 2 recap o equation o 1 2 sum y backward calculates gradients As I defined variables accumulates gradients. Backpropagation 1. Therefore we need to increase complexity of model. Loss is almost zero that you can see from plot or loss in epoch number 1000. com kanncaa1 deep learning tutorial for beginners What we expect from artificial neural network is that when complexity increases we use more hidden layers and our model can adapt better. Concolutional Neural Network CNN 5 1. I am saying again that if you do not know what is artificial neural network check my deep learning tutorial because I will not explain neural network detailed here only explain pytorch. In this example it is numpy np. com kanncaa1 machine learning tutorial for beginners y Ax B. Artificial Neural Network ANN Logistic regression is good at classification but when complexity non linearity increases the accuracy of model decreases. Thanks to convolutional layer model learnt better and accuracy almost 98 is better than accuracy of ANN. Fully Connected Layer Artificial Neural Network that we learnt at previous part. Artificial Neural Network tutorial https www. In our example we have 33600 sample to train and we decide our batch_size is 100. We can make math operations with variables too. It also provides multi process iterators over the dataset. Pooling layer Prepares a condensed feature map from output of convolutional layer feature map 2 pooling layer that we will use max pooling. Many users who have used both frameworks would argue that makes pytorch significantly easier to debug and visualize. Because I will not explain neural network concepts detailed I only explain how to use pytorch for neural network Neural Network tutorial https www. std Variables It accumulates gradients. Lets look at conversion between tensor and numpy arrays. shape shape of the array. There are 28 28 images and 10 labels from 0 to 9 Data is not normalized so we divide each image to 255 that is basic normalization for images. Question is that how many iteration do I need Lets calculate training data 1 times training 33600 sample because data includes 33600 sample But we split our data 336 groups group_size batch_size 100 our data Therefore 1 epoch training data only once takes 336 iteration We have 29 epoch so total iterarion is 9744 that is almost 10000 which I used TensorDataset Data set wrapping tensors. Or it can be only linear like logistic regression but at the end there is always softmax function. Optimization SGD stochastic gradient descent 1. Prediction As a result as you can see from plot while loss decreasing accuracy almost 85 is increasing and our model is learning training. com kanncaa1 deep learning tutorial for beginners The most important parts of this tutorial from matrices to ANN. As a result accuracy increase. Flattening Flats the features map 1. If the car price is low we sell more car. Prepare Dataset Totally same with previous part logistic regression. However as you expect there should be logistic function in model right In pytorch logistic function is in the loss function where we will use at next parts. mul a b a b Element wise division torch. Therefore first we create tensor then we will create variable data type is long create feature and targets tensor for test set. Each sample is retrieved by indexing tensors along the first dimension. Visualize one of the images in dataset 1. Create ANN Model We add 3 hidden layers. However we want to preserve as much as information about the original image. mean Standart Deviation std a. Therefore variable x should be have gradients Lets look at gradients with x. MSE Mean squared error 1. INTRODUCTION It s a Python based scientific computing package targeted at two sets of audiences A replacement for NumPy to use the power of GPUs Deep learning research platform that provides maximum flexibility and speed pros Interactively debugging PyTorch. Recurrent Neural Network RNN https www. There is detailed explanation of logistic regression. Row x Column Allocation is one of the most used technique in coding. We can apply padding to increase dimension of feature map after convolutional layer. Therefore we need to handle gradients. Data is trained 29 times. We use logistic regression for classification. create feature and targets tensor for train set. com kanncaa1 convolutional neural network cnn tutorial Steps of CNN 1. Artificial neural network with with pytorch1. In order to increase complexity of model we need to add more non linear functions as hidden layer. com kanncaa1 long short term memory with pytorch Basics of Pytorch Matrices In pytorch matrix array is called tensors. For example I choose batch_size 100 that means in order to train all data only once we have 336 groups. sub b a b Element wise multiplication torch. Aim is fitting line with minimum error. We create numpy array with np. rand Even if when I use pytorch for neural networks I feel better if I use numpy. If you do not know neural network check my deep learning tutorial first because I will not explain detailed the concepts like optimization loss function or backpropagation. Prediction As a result as you can see from plot while loss decreasing accuracy is increasing and our model is learning training. Logistic regression with pytorch1. A slope of curve B bias point that intersect y axis For example we have car company. Import Libraries 1. Instantiate Loss Cross entropy loss It also has softmax logistic function in it. Instantiate Model Class create model 1. We use 2 convolutional layer. Row x Column We looked at numpy array. Steps of Linear Regression 1. Thanks to hidden layers model learnt better and accuracy almost 95 is better than accuracy of logistic regression model. Prepare Dataset Totally same with previous parts. ", "id": "kanncaa1/pytorch-tutorial-for-deep-learning-lovers", "size": "13512", "language": "python", "html_url": "https://www.kaggle.com/code/kanncaa1/pytorch-tutorial-for-deep-learning-lovers", "git_url": "https://www.kaggle.com/code/kanncaa1/pytorch-tutorial-for-deep-learning-lovers", "script": "LinearRegression(nn.Module) __init__ torch.utils.data forward sklearn.model_selection torch.nn CNNModel(nn.Module) ANNModel(nn.Module) numpy torch.autograd matplotlib.pyplot pandas LogisticRegressionModel(nn.Module) train_test_split DataLoader Variable ", "entities": "(('we', 'kaggle'), 'increase') (('You', 'results'), 'try') (('It', 'it'), 'loss') (('first I', 'optimization loss function'), 'know') (('more hidden layers', 'artificial neural network'), 'com') (('car price', 'car'), 'be') (('We', 'CNN logistic model'), 'combine') (('neural network', 'here only pytorch'), 'say') (('Lets', 'x.'), 'have') (('336 that', 'quota'), 'train') (('it', 'tensor shape array'), 'be') (('we', 'more car'), 'sell') (('We', 'convolutional layer'), 'apply') (('you', 'network neural basics'), 'con') (('you', 'output'), 'list') (('Lets', 'tensor'), 'look') (('almost you', 'epoch number'), 'be') (('we', 'less car'), 'sell') (('we', 'linear regression'), 'be') (('80', 'test data'), 'use') (('we', 'hidden layer'), 'need') (('better almost 98', 'ANN'), 'thank') (('that', 'array'), 'convert') (('Forward propagation', 'labels store Total loss'), 'train') (('batch_size', '33600 sample'), 'have') (('epoch 1 epoch', 'samples'), 'mean') (('linear regression Detailed tutorial', 'part Regression'), 'need') (('which', 'order'), 'train') (('almost 85 model', 'training'), 'prediction') (('px px 8 layer 10 0 1 2 5 7 9 Hidden dimension', 'Instantiate Model Class 28 28 image'), 'input_dim') (('where gradients', 'backpropagation'), 'have') (('linear regression logistic function softmax logistic regression', 'learning deep tutorial'), 'check') (('Row Column Allocation', 'coding'), 'be') (('I', 'network Neural Network tutorial https neural www'), 'explain') (('we', 'max pooling'), 'prepare') (('pytorch matrix array', 'Pytorch Matrices'), 'com') (('It', 'dataset'), 'DataLoader') (('I', '150'), 'choose') (('com', 'variables'), 'be') (('I', 'variables accumulates gradients'), 'numpy') (('I', 'only 150'), 'say') (('model', 'training'), 'prediction') (('it', '1000 sample'), 'be') (('again we', 'previous parts'), 'library') (('We', 'variables'), 'make') (('Convolutional layer', 'filters kernels'), 'create') (('I', 'wrapping tensors'), 'be') (('we', 'car company'), 'slope') (('parts', 'CNN'), 'be') (('that', 'maximum flexibility'), 'introduction') (('It', 'python docker image https kaggle github'), 'com') (('80', 'test data'), 'be') (('Convolutional Neural CNN CNN', 'well images'), 'Network') (('from_numpy', 'a'), 'numpy') (('We', 'fully connected layer'), 'use') (('we', 'fact'), 'be') (('Logistic Regression Linear regression', 'classification'), 'be') (('it', 'hyper parameter'), 'be') (('that', 'basic images'), 'be') (('However we', 'original image'), 'want') (('then we', 'test set'), 'create') (('Prediction Lets', 'iteration'), 'implement') (('when epoch', 'almost highest value'), 'achieve') (('we', 'gradients'), 'need') (('we', 'numpy'), 'look') (('We', 'classification'), 'use') (('Prepare load Dataset data', 'labels normalization train test 0 to 9 split'), 'be') (('we', 'nn'), 'everythink') (('Therefore we', 'model'), 'need') (('sample', 'first dimension'), 'retrieve') (('model lets', 'car prices'), 'predict') (('only we', '336 groups'), 'choose') (('I', 'numpy'), 'rand') (('Linear Pytorch libraries', 'class super function'), 'collect') (('pytorch', 'significantly debug'), 'argue') (('we', 'previous part'), 'Network') (('it', 'end'), 'be') (('We', 'torch'), 'examine') (('Therefore lets', 'pytorch'), 'learn') (('Filter kernel out_channels 16 size', 'feature map'), 'be') (('we', 'only train_loader'), 'use') (('non when complexity linearity', 'model decreases'), 'be') (('where we', 'next parts'), 'be') (('We', 'ELU activation diversity'), 'use') (('better almost 95', 'regression logistic model'), 'thank') (('read_csv Input data files', 'the'), 'be') (('Instantiate Loss Cross entropy It', 'it'), 'loss') (('We', 'batch same size epoch numbers'), 'use') (('we', 'tensors'), 'create') (('It', 'dataset'), 'provide') ", "extra": "['organization', 'test']"}
{"name": "image super resolution ", "full_name": " h1 Contents h3 1 Introduction h3 2 Problem Statement h3 3 Data h3 4 Analysis h3 5 Implementation h3 6 FSRCNN Implementation h3 7 Results h3 8 Conclusion h1 Introduction h3 1 1 SPOT VEGETATION h3 1 2 PROBA V h3 1 3 Super Resolution h1 Problem Statement h2 Utility Code h1 Data h4 Origin of the data h4 Changes in landscape h4 Image registration h3 Exploratory Data Analysis h1 Analysis h4 FSRCNN h1 Implementation h1 FSRCNN Implementation h1 Results h1 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "The payload consists of 3 identical cameras each with a very compact Three Mirror Anastigmat TMA telescope. We expect you to submit a 384x384 image for each of the 290 test scenes for which we will not provide a high resolution image. com watch v WovbLx8C0yA An Introduction to Super Resolution using Deep Learning https medium. com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. In my implementation I have used the method on right i. com watch v MJ2FOFqr7hw t 12s There are mainly two different types of methods of super resolution that can be performed they are 1. The model then perform multiple convolutions on the image stack and learn features from all the channels images which eventually removes all the artifacts and faults in the image. While the mean geolocation accuracy of PROBA V is about 61m sub pixelshifts in the content occur and are in a sense necessary to perform super resolution. Thus the super resolution can already be included in the final product of these satellites during post processing on the ground. Utility Code Data Origin of the dataWe collected satellite data from the PROBA V mission of the European Space Agency from 74 hand selected regions around the globe at different points in time. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. walk kaggle input for filename in filenames print os. Used for normalizing scores. com watch v Xk7myx9_OmU Deconvolutional Microscopy https www. To compensate for pixel shifts the submitted images are cropped by a 3 pixel border resulting in a 378x378 format. Each image comes with a quality map indicating which pixels in the image are concealed i. csv using which we have to normalize our cPSNR score to get the final cPSNR score. int proba v super resolution data https kelvins. org api _as_gen matplotlib. Create DataFrame Call the get_cpsnr function to calculate the model cpsnr score We define a scene images iterator We set it to cycle so that its never exhausted and never returns an error to StopIteration Get the images from the generator for the next scene Get the next batch of 16 images Reshape the image batch to feed it as input to the neuural network Convert the image batches into tensors Transfer the data to CUDA device Perform the forward pass of the model PLOT SOME OF THE EXAMPLES FROM THE DATASET THE SUPER RESOLVED IMAGE AND HIGH RESOLUTION IMAGE SIDE BY SIDE. There is so much of old low resolution data available that be used by performing super resolution and finding new insights from the data which will save cost. For every scene we are also given a high Resolution image our target image HR. keep track of the values at obscured pixels replace values at obscured pixels with NaNs aggregate the images suppress the warnings that originate when only_clear True but some pixels are never clear in any of the images from. specific warnings we wish to ignore Baseline cPSNR values for the dataset s images. Since our models cPSNR score is less than 1 we can say for sure that this model performs good at creating super resolution images using multiple low resolution images and it also beats the baseline method. log10 cMSE normalized cPSNR t t tcrop_scores. The Proba V mission provides multispectral images to study the evolution of the vegetation cover on a daily and global basis. warp All scenes are divided in two folders namely RED and NIR save the train images directory which is all we will be using for our model as we don t have high resolution images for the images present in test dataset Extract all the scenes paths and make a list Get the high resolution image and its mask for the scene 0348 HR image HR image mask Extract the low resolution images and their masks and display only the low resolution images Eight images are plotted We define an iterator for getting images from the directory create an object of the generator get_scene_images create a cycle iterator so that it never gets exhausted Get the images from the generator for the next scene Perform all the imports required for our implementation Check if GPU is available in the system or not set device to GPU if available otherwise set device to cpu only save checkpoint print summary super_model 9 128 128 Print the summary of all layers and parameters in the model print We got a better loss value Create an object of the SuperResolution class we have defined the neural net model class Call the train function on super_model object with learning_rate 0. AnalysisFirst I needed some domain knowledge of how super resolution works. To address this time problem FSRCNN came into existance FSRCNN doesn t upscale the input image initally and input the low resolution image to the network as it is then multiple convolutions are done on the image Feature Exraction Shrinking Mapping Expanding and finally a Deconvolution is performed on the image Transpose Convolution actually to upscale the image by the given factor. 3 Super ResolutionSuper resolution is the process of upscaling and or improving the details within an image. Image registrationThe images are delivered as recorded by PROBA V and have not been modified to align with each other. int proba v super resolution home Problem StatementPROBA V payload sensors allow for an almost global coverage 90 per day providing 300m resolution images. So below we score our model with cPSNR score. In case of SRCNN the input images need to be upscaled by the required factor before feeding it to the neural network and then consecutive convolutions are done to enhance the image quality to match the target high resolution image. join dirname filename Any results you write to the current directory are saved as output. They re required by baseline_upscale. score import score_image_fast hr_crops from. Often a low resolution image is taken as an input and the same image is upscaled to a higher resolution which is the output. It was initiated by the Space and Aeronautics department of the BELgian Science Policy Office launched into space from ELA 1 Ensemble de Lancement Ariane 1 at Guiana Space Centre on board Vega flight VV02 on 7 May 2013. The 300m resolution data is delivered as 128x128 grey scale pixel images the 100m resolution data as 384x384 grey scale pixel images. Although I knew about what super resolution is and have thought about how low resoltuion images can be converted to high resolution images I needed some technical details on how super resolution can be performed and does it match with my previous hypothesis that I have maintained in my head and therefore first I watched some videos on super resolution to understand the technical details better and I also read some blogs on the topic. ResultsWe have our model loss MSE in the model_loss variable and we have the bicubic interpolation MSE loss stored in bicubic_loss variable Bicubic interpolation is the baseline method for super resolution defined by the challenge posters. We will be constructing a model based on FSRCNN with some minor changes. Although we combined multiple images by taking their median and forming a single image and then creating a super resolution image it is not truly a multi image super resolution algorithm which the challenge demanded. It is built by QinetiQ Space N. Introduction Introduction Spot Vegetation Spot V Proba V Proba V Super Resolution Super Resolution 2. Conclusion The model we trained above gave us better results than the baseline bicubic interpolation method. HR image HR image mask. For example running this by clicking run or pressing Shift Enter will list all files under the input directory for dirname _ filenames in os. Any improvements on this data set might be transferable to larger collections of remote sensing data without the need to deploy more expensive sensors or satellites as resolution enhancement can happen post acquisition. png format which makes them look relatively dark if opened in typical image viewers. append N cPSNR The individual score for image SR is tsr_score min crop_scores t t tscore_image i NOTE Don t change these options. read_csv progress bar reading multiple files at once opencv Input data files are available in the. The train function returns the best loss value it acquired while training and saves the model to local diskNext we define some of the methods and calculate the MSE for bicubic upsampling method. I tried to create a model for multi image super resolution as I have explained in my analysis above 1 MultiISR but unfortunately due to time and system capability contraints I was to not able to make it succesfully work although I believe that that the method will work given some more in depth study and experimenting. The images provided for this challenge are not artificially degraded but are real images recorded from the very same scene just at different resolutions and different times. int proba v super resolution data Exploratory Data AnalysisThere are atmost 19 low resolution images and atleast 9 low resolution images available for every given scene in the dataset along with their clearance mask which tells us which pixels in the image are obscured due to some artifact or some glitch. The bit depth of the images is 14 but they are saved in a 16 bit. com beyondminds an introduction to super resolution using deep learning f60aff9a499d Deconvolution youtube. Super resolution has wide scope in so many different fields including satellite imagery microscopes and telescopes. If our final cPSNR value is less than 1 then we can say for sure that our model is better than baseline bicubic interpolation method. These two below models are the one I studied in deep because they covered two different aspects and methods of doing super resolution. The method is like this Instead of using a median image as input I tried to use multiple low resolution images 9 because atleast 9 images in each scene are available by stacking them on top of each other as channels and then feeding it to the model. The details in the high resolution output are filled in where the details are essentially unknown. html img as float64 safeguard against unwanted conversions to values outside the 0. org docs dev api skimage. This process which is known as Multi image Super resolution has already been applied to satellite before some of these satellites such as SPOT VGT or ZY 3 TLC have payloads that are able to take multiple images of the same area during a single satellite pass which creates a most favorable condition for the use of super resolution algorithms as images are taken simultaneously. com watch v ppsqbOL073U t 61s Enhance Super Resolution From Google Two Minute Papers 124 https www. On average each scene comes with 19 different low resolution images and always with at least 9. FSRCNN Implementation FSRCNN 7. HR_ u v which results in a clear Peak Signal to Noise Ratio of t t tcPSNR 10. In total the dataset contains 1450 scenes which are split into 1160 scenes for training and 290 scenes for testing. The V stands for Vegetation. We plot a graph below of both the losses to compare their values. int proba v super resolution problem. Thus the dataset itself is not corrected for these shifts and none of the images are registered to each other. Also I think GAN s are good for this kind of tasks and if we go in that direction and do some kind to gradual increase in the resolution of the low resolution image to high resolution image we might be able to get even better results than state of the art techniques as GANs are very good at creating synthetic data and that is the requirement of super resolution as we need to fill in those pixel in super resolution images which were not actually present. io import highres_image scene_id additional options at https matplotlib. Implementation Implementation 6. append cMSE The individual score for image SR is tsr_score N 10. The image shown below depicts the task that we need to perform. provided by the competition s organizers t tscore_image i We assume that the pixel intensities are represented as real numbers 0 1 for any given image. Therefore this task of super resolution can have great impact on a lot of industries and hence this needs to be studied and more researched upon. Single Image Super Resolution1. The main PROBA V payload is the Vegetation sensor a multispectral pushbroom spectrometer with 4 spectral bands and with a very large swath of 2285 km to guarantee daily coverage above 35 latitude. Conclusion Conclusion Introduction 1. The goal of this challenge is to construct such high resolution images by fusion of the more frequent 300m images. Below we display some examples of all low resolution high resolution images and their clearance masks. Multi Image Super ResolutionAfter my analysis to understand the problem and techniques to solve it I went through some of the latest research papers in the domain. Deep Learning for Image Super Resolution https www. clouds cloud shadows ice water missing etc and which should be considered clear. take all the images that have the same maximum clearance Images were given by the caller rather than loaded here. and operated by European Space Agency and uses a PROBA platform. As such the scenes are not always permanent but can change marginally. Let N HR be the baseline cPSNR of image HR as found in the file norm. Results Results 8. Each TMA having a FOV of 34 contains 4 spectral bands 3 bands in the visible range Blue Red and NIR and one band in the SWIR spectral range. Implementation FSRCNN ImplementationNow we create an object of our model class SuperResolution and transfer the models parameters to the CUDA deviceNext we call the train function to start training the model with our passed parameters as shown below. Because only_clear True we generate copies of all lr images so the function will have no unintended side effects on the caller s side. FSRCNNFast Super Resolution CNN is an advanced method to speed up the SRCNN super resolution method. Each data point consists of exactly one 100m resolution image and several 300m resolution images from the same scene. NOTE I also tried a different method shown on the left side in the image below for super resolution that is purely multi image but unfortunately I was not able to get expected results due to time contraints and system constraints which made me stop doing other experiments. They have provided the baseline bicubic interpolation cPSNR score in a file named norm. Analysis Analysis 5. HR_ u v which results in a clear Peak Signal to Noise Ratio of normalized cPSNR t tcrop_scores. aggregate import central_tendency from. create a copy of hr with NaNs at obscured pixels flatten used to bypass numba s indexing limitations tcrop_scores We denote the cropped 378x378 images as follows for all u v 0 6 HR_ u v is the subimage of HR with its upper left corner at coordinates u v and its lower right corner at 378 u 378 v we first compute the bias in brightness b Next we compute the corrected clear mean square error cMSE of SR w. The swath Total FOV is 103. It was launched to support applications such as land use worldwide vegetation classification crop monitoring famine prediction food security disaster monitoring and biosphere studies. add_subplot image registration display the scene s id to the left of the image https scikit image. The scoring will take pixel shifts of the high resolution image into account as registration cannot be computed by the participant for the test set. 2 PROBA V PROBA V Project for On Board Autonomy Vegetation is an ESA European SpaceAgency mission developed within the framework of the Agency s General SupportTechnology Programme GSTP devoted to the observation of the Earth s vegetation. Changes in landscapeThe images have been recorded within a time window of 30 days. This upscaling method and then enhancing the quality takes high amount of time. For an image to be included in the dataset at least 75 of its pixels have to be clear for 100m resolution images and 60 for 300m resolution images. However this is not the case for PROBA V or other satellites which could benefit from a post acquisition enhancement. 0 range would happen if img had signed values. In those cases multiple images from the same patch are still available but originate from successive revisits over longer periods of time. Data Data Exploratory Data Analysis EDA 4. Thus PROBA Vs products represent a convenient way to explore super resolution in a relevant setting. Model Technique Date Released FSRCNN Fast Super Resolution Convolutional Neural Network 2016 SRGAN Super Resolution Generative Adversarial Network 2017 These two above methods are single image super resolution methods which we modify a little bit to work for completing our task. It is a miniaturised satellite tasked with a full scale mission to map land cover and vegetation growth across the entire planet every two days. I have combined all the low resolution in a single image by taking median of each pixel in the image which gave us a cloud artifacts free image. http scikit image. rescale http scikit image. Then we combine all the channels into a single channel image. http The image below shows two different methods I thought I could follow to get our task done. 1 SPOT VEGETATIONThe overall objectives of the VEGETATION systems is to provide accurate measurements of basic characteristics of vegetation canopies on an operational basis Either for scientific studies involving both regional and global scales experiments over long time periods for example development of models of the biosphere dynamics interacting with climate models Or for systems designed to monitor important vegetation resources like crops pastures and forests. We see from the above plot that the MSE of our model is less than the bicubic interpolation MSE and as we know that MSE is the value of average of difference between each pixel value between two images the smaller the better therefore we can say that our model performs better than the bicubic interpolation method which is ouur baseline method in estimating the target image as its MSE is lower than bicubic interpolation MSE which means the difference between the pixels of super resolution image predicted by the model and the and original high resolution image is very less. log10 min crop_scores We assume that the pixel intensities are represented as real numbers 0 1 for any given image. Source Kelvins PROBA V Challenge https kelvins. Problem Statement Problem 3. values at the cropped versions of each image that fall in clear pixels of the cropped hr image we first compute the bias in brightness b Next we compute the corrected clear mean square error cMSE of SR w. Below we show some of the predicted images alongside with the original images. PROBA V also provides 100m high resolution images but at a lower frequency of roughly every 5 days dependent on the location. FSRCNN SRGAN CSFM and the winning model of the Kelvin PROBA V Challenge DeepSUM. The data is composed of radiometrically and geometrically corrected Top Of Atmosphere TOA reflectances for the RED and NIR spectral bands at 300m and 100m resolution in Plate Carr\u00e9e projection. Hence we can say that our model performs better and beats the baseline method which is the aim of this challenge. 001 number_of_epochs 200 batch_size 16 the train function return the final loss of the model Calculate the median of all low resolution images to combine it into a single image Find the maximum value in the mask and divide the whole array by that value for normalisation Multiply both output image and target image by the mask so as to ignore those pixels for calculating MSE Average the MSE loss for all the scenes Call the get_bicubic_loss to calculate the bicubic interpolation MSE loss intialise data of lists with loss values. But the challenge website tells us that they have defined another scoring technique named cPSNR clear Peak Signal Noise Ratio which we have use for scoring our model. DeepSUM is large and difficult to implement in the given timeframe and hence I didn t dig deep into it. Source https kelvins. png and a clearance map for the high resolution image. Finally we perform a deconvolution on the single channel image we obtained from the previous layer to scale the image by the erquired factor. The below image is taken from kelvins proba v challenge website. ", "id": "pranavpandey2511/image-super-resolution", "size": "15832", "language": "python", "html_url": "https://www.kaggle.com/code/pranavpandey2511/image-super-resolution", "git_url": "https://www.kaggle.com/code/pranavpandey2511/image-super-resolution", "script": "torch.optim torch.utils.data __init__ glob make_grid .aggregate torch.autograd mse get_bicubic_loss .score central_tendency lowres_image_iterator train scenes_paths DataLoader defaultdict itertools baseline_upscale forward torch.nn highres_image collections .io seaborn numpy cdf_plot compare_images get_hr_image scipy.stats check_img_as_float torchvision get_next_test_batch bicubic_upscaling SuperResolution(nn.Module) score_image tqdm # progress bar scene_id score_images lr_scheduler compare_to_hr torchvision.utils Image matplotlib.pyplot describe save_checkpoint prepare_submission pandas hr_crops Dataset Counter tqdm Variable all_scenes_paths glob # reading multiple files at once torch.nn.functional score_against_hr scorer(object) transforms create_panel compare_aggregates get_model_cpsnr get_optimizer get_scene_images score_summary get_next_batch __call__ get_lr_images percentileofscore IPython.display cycle score_image_fast ", "entities": "(('average scene', 'always at least 9'), 'come') (('upscaling method', 'time'), 'take') (('specific we', 'images'), 'warning') (('we', 'erquired factor'), 'perform') (('Don t', 'options'), 'cpsnr') (('we', 'baseline bicubic interpolation method'), 'conclusion') (('PROBA V PROBA V 2 Project', 'vegetation'), 'be') (('I', 'model'), 'be') (('FOV', 'Blue one SWIR spectral range'), 'have') (('then consecutive convolutions', 'resolution target high image'), 'need') (('we', 'that'), 'depict') (('at least 75', 'm resolution 300 images'), 'have') (('Super resolution', 'satellite imagery microscopes'), 'have') (('which', 'cost'), 'be') (('Then we', 'channel single image'), 'combine') (('clearance same maximum Images', 'caller'), 'take') (('It', 'famine prediction food security disaster monitoring'), 'launch') (('none', 'other'), 'correct') (('difference', 'model'), 'say') (('We', 'values'), 'plot') (('we', 'model'), 'tell') (('them', 'image relatively typical viewers'), 'format') (('we', 'resolution high image'), 'expect') (('It', 'python docker image https kaggle github'), 'come') (('It', 'vegetation entire planet'), 'be') (('which', '290 testing'), 'contain') (('Next we', 'SR w.'), 'compute') (('it', 'baseline also method'), 'beat') (('they', '16 bit'), 'be') (('hence I', 't deep it'), 'be') (('We', 'minor changes'), 'construct') (('They', 'file'), 'provide') (('hence this', 'industries'), 'have') (('we', 'cPSNR final score'), 'csv') (('Super Resolution CNN', 'resolution advanced SRCNN super method'), 'fsrcnnfast') (('resolution enhancement', 'post acquisition'), 'be') (('HR', 'file norm'), 'let') (('we', 'target image HR'), 'give') (('m resolution 300 data', 'grey scale pixel images'), 'deliver') (('data', 'Plate Carr\u00e9e projection'), 'compose') (('PROBA Vs Thus products', 'relevant setting'), 'represent') (('we', 'little bit task'), 'release') (('Super ResolutionSuper 3 resolution', 'image'), 'be') (('which', 'challenge'), 'say') (('Image registrationThe images', 'other'), 'deliver') (('which', 'higher resolution'), 'take') (('below image', 'kelvins proba v challenge website'), 'take') (('other which', 'post acquisition enhancement'), 'be') (('me', 'other experiments'), 'NOTE') (('how super resolution', 'domain knowledge'), 'need') (('you', 'output'), 'join') (('task', 'two different methods'), 'show') (('Transpose Convolution', 'given factor'), 'come') (('goal', 'm more frequent 300 images'), 'be') (('HR _ u which', 't t'), 'v') (('we', 'passed parameters'), 'FSRCNN') (('function', 'side'), 'have') (('Proba V mission', 'daily basis'), 'provide') (('Input data at once files', 'the'), 'opencv') (('HR _ u which', 'cPSNR t normalized tcrop_scores'), 'v') (('img', 'values'), 'happen') (('Next we', 'SR w.'), 'create') (('we', 'upsampling bicubic method'), 'return') (('challenge', 'resolution truly multi image super which'), 'combine') (('better I', 'topic'), 'know') (('pixel intensities', '0 1 given image'), 'crop_scores') (('pixels', 'image'), 'come') (('sure model', 'bicubic interpolation baseline method'), 'be') (('submitted images', '378x378 format'), 'crop') (('Thus super resolution', 'ground'), 'include') (('FSRCNN', 'Kelvin PROBA V Challenge winning DeepSUM'), 'SRGAN') (('Below we', 'resolution resolution low high images'), 'display') (('It', '7 May'), 'initiate') (('SUPER', 'RESOLUTION IMAGE HIGH SIDE'), 'call') (('pixel intensities', '0 1 given image'), 'provide') (('I', 'right i.'), 'use') (('Problem StatementPROBA V payload home sensors', 'm resolution 300 images'), 'allow') (('overall objectives', 'crops pastures'), 'be') (('Vegetation', '35 latitude'), 'be') (('multiple images', 'time'), 'be') (('Below we', 'original images'), 'show') (('registration', 'test set'), 'take') (('deep they', 'super resolution'), 'be') (('i', 'image https scikit image'), 'display') (('which', 'resolution super images'), 'think') (('pixels', 'images'), 'keep') (('I', 'domain'), 'ResolutionAfter') (('payload', 'Mirror Anastigmat TMA very compact Three telescope'), 'consist') (('Changes', '30 days'), 'record') (('SR', 'individual image'), 'append') (('which', 'cloud artifacts free image'), 'combine') (('method', 'depth more study'), 'try') (('where details', 'resolution high output'), 'fill') (('most favorable condition', 'images'), 'apply') (('PROBA V', 'roughly every 5 days location'), 'provide') (('images', 'just different resolutions'), 'degrade') (('bicubic interpolation MSE loss', 'challenge posters'), 'have') (('which', 'image'), 'perform') (('m sub about 61 pixelshifts', 'necessary super resolution'), 'occur') (('they', 'super resolution'), 'v') (('we', 'learning_rate'), 'warp') (('So below we', 'cPSNR score'), 'score') (('which', 'clouds cloud shadows ice etc'), 'water') (('data point', 'm resolution several 300 same scene'), 'consist') (('pixels', 'artifact'), 'be') (('train number_of_epochs 200 16 function', 'loss values'), '001') ", "extra": "['test']"}
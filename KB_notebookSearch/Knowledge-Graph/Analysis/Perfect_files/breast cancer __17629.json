{"name": "breast cancer ", "full_name": " h1 Predicting invasive ductal carcinoma in tissue slices h2 Motivation h2 Our goal h2 Methods presented in the paper h2 Table of contents h2 What is meant by invasive ductal carcinoma h1 Preparation peek at the data structure h2 Loading packages and setting h3 Settings h2 Exploring the data structure h3 How many patients do we have h3 How many patches do we have in total h3 Storing the image path patient id and the target h1 Exploratory analysis h2 What do we know about our data h3 Insights h2 Looking at healthy and cancer patches h3 Cancer patches h3 Healthy patches h3 Insights h2 Visualising the breast tissue h3 Binary target visualisation per tissue slice h3 Insights h3 Visualising the breast tissue images h3 Insights h1 Setting up the machine learning workflow h2 Settings h2 Validation strategy h2 Target distributions h2 Creating pytorch image datasets h2 Creating pytorch dataloaders h2 Defining the model structure h2 Setting up the loss function h2 Selecting an evaluation metric h3 The f1 score h3 Precision and recall h2 Building the training loop h2 Searching for an optimal cyclical learning rate h3 Insights h2 Performing the training or loading results h1 Exploring results and errors h2 Loss convergence h2 The probability landscape of invasive ductal carcinoma h2 Going into details h3 TODO h1 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "Visualising the breast tissue This part is a bit tricky We have to extract all coordinates of image patches that are stored in the image names. Using it we could only use one single output neuron to make predictions. Exploratory analysis What do we know about our data Insights1. This way we can load batches of images only one by one without storing the pixel values of all images. 6 f_ 1 frac 2 frac 1 0. This way we prevent to build up models that are likely overfitted to the available data and we can find out useful ideas in a strategic manner instead of trying out every idea at random. As we are not looking at the whole tissue we are not loosing spatial connections between patches and it s not important that some neighboring patches are rotated in different directions. This way we benefit from the fact that the first layers of a pretrained CNN extract basic features like edges for example and only last layers contain very problem specific features. Nonetheless it s a very good exercise to practice or develop own deep learning and data science skills. The simplest transformations we can do for each image are resizing the images to the desired input shape performing horizontal and vertical flipsIn our case the patches are of shape 50x50x3 and we could set this as our input shape. Then a pathologist has to decide whether a patient has IDC another type of breast cancer or is healthy. For validation and training we drop the last batch that often consists less images than the batch size. Precision and recallTo fully understand the f1 score we first need to grasp precision and recall. Conclusion conclusion What is meant by invasive ductal carcinoma This illustration created Mikael H\u00e4ggstr\u00f6m https commons. To deal with this imbalance we like to increase the impact of the gradients of positive cases during training and we can do so with a higher weight than for the negative cases. Now it s 70 train and 15 for dev and test. Hence if either the recall or the precision is small the f1 score will then tend towards the smaller value. The classes of IDC versus no IDC are imbalanced. Does a tissue slice per patient cover the whole region of interest 3. Setting up the machine learning workflow workflow Settings ml_settings Validation strategy validation Target distributions target_dists Creating pytorch image datasets image_datasets Creating pytorch dataloaders dataloaders Defining the model structure model_structure Setting up the loss function loss_eva Selecting an evaluation metric e_metric Building the training loop train_loop Searching for an optimal cyclical learning rate lr_cycle_optima Performing the training or loading results run 5. For each patient we have an individual subfolder that contains image patches. Preparation peek at the data structure prep Loading packages and settings setup Exploring the data structure explorestructure 3. As I like to compute the f1 score during training and prediction and I need to compute false and true positives negatives in a simple manner I will use the cross entropy loss with K 2 output neurons or 2 classes that can be hot 1 or cold 0 with sum_ k y_ nk 1 L sum_ n 1 N sum_ k 1 K 2 w_ k cdot t_ n k cdot ln y_ nk The w_ k are used to weight the positive and negative classes such that we are able to deal with the class imbalance. 6 frac 2 frac 10 1 frac 10 6 frac 2 cdot 6 70 frac 12 70 0. Comparing both images it seems that darker more violet colored tissue has a higher chance to be cancer than those with rose color. What is meant by invasive ductal carcinoma intro 2. Performing the training or loading results Exploring results and errors Loss convergence The probability landscape of invasive ductal carcinoma Going into details TODO Number of correct classifications per patient compared to cancer tissue size. Our goalAs we started with this analysis we asked ourselves if we would be able to improve the results that were presented 2014 in the paper Automatic detection of invasive ductal carcinoma in whole slide images with Convolutional Neural Networks http citeseerx. Let s take a look at the augmentations For validation we have only used the image resizing. This has to be done manually and is a time consuming process. This way we can also explore how diseased tissue looks like compared to healthy ones. Conclusion linear algebra data processing CSV file I O e. These are patient ids. Defining the model structure Our dataset is very small and we should be afraid of overfitting to our patients. We have to check this again after setting up a validation strategy and find a strategy to deal with class weights if we like to apply them. Patches with cancer look more violet and crowded than healthy ones. Target distributions Let s take a look at the target distribution difference of the datasets We can see that the test data has more cancer patches compared to healthy tissue patches than train or dev. This seems arbitrary and we should rethink this strategy in the next cycle of our datascience workflow. It s malicious and able to form metastases which makes it especially dangerous. For this reason it can be a good idea to use transfer learning with a pretrained CNN. You can see that class 1 positive cancer has a higher weight. Methods presented in the paperCollecting information. In contrast if our model would always predict no cancer we would have no true positives and our recall equals zero. But in our case we were able to load them all Setting up the machine learning workflow Settings Validation strategy Let s start very simple by selecting 30 of the patients as test data and the remaining 70 for training and developing. A common loss for this problem is the binary cross entropy function. So far we can t stratify on the targets as we are splitting on patient ids. edu medicine ccir faculty anant madabhushi and his group. Furthermore the decision depends on the expertise of the pathologist and his or her equipment. In our case we have much more negative healthy patches than those with cancer. This way each batch is composed differently and we don t start to learn for specific sequences of images. This way one would be able to overcome the dependence on the pathologist which would be especially useful in regions where no experts are available. Creating pytorch dataloaders As the gradients for each learning step are computed over batches we benefit from shuffling the training data after each epoch. Then we would have the maximum number of true positives but also a very high number of false positives that decreases the recall to some baseline value. Many years have passed by since then and it s very likely that all methods used in the paper have already been changed improved and that new research has already been done. If we would like to include some target information we would need to create a feature that allows us to generate some balance. org wiki File Lobules_and_ducts_of_the_breast. Reading the paper link that seems to be related to this data this could also be part of the preprocessing. 1714 is then shifted towards the smaller value of the recall and not close to the arithmetic mean of mu 0. If it s too small the learning process is too slow and will probably stop too early in the case we have defined a minimum required loss change. Consequently overfitting to this specific patient distribution is very likely and we need to take care about the generalization performance of our model. Take a look at the paper Cyclical Learning Rates for Training Neural Networks https arxiv. But as one can see it s not always the case. The goal is to assist with an automatic detection of tumors not expert dependent. Only then we can measure something like a generalisation performance. How many patients do we have Almost 280 patients. How many patches do we have in total Our algorithm needs to decide whether an image patch contains IDC or not. A better idea could be to cluster patients with dependence on the size of the tumor the number of total patches and statistical quantities of area coverd by the patches. I always have to look it up recall frac TruePositives TruePositives FalsePositives Imagine our model would predict cancer all the time. Our model might start to learn that mammary ducts are always related to cancer Sometimes it s not possible to load an image patch as the path is ill defined. Table of contents1. For this reason one can say that the recall answers How many selected cases are positive precision frac TruePositives TruePositives FalseNegatives How many positive cases are selected Building the training loop Searching for an optimal cyclical learning rate The learning rate is one of the most important hyperparameters for tuning neural networks. Ductal carcinoma starts to develop in the ducts whereas lobular carcinoma has its origin in the lobules. One can see the lobules the glands that can produce milk which flews through the milk ducts. This matches the total number of patches. Storing the image_path patient_id and the targetOk now for each patient we know the path for each patch as well as if it contains IDC or not the target. Confusion matrix Exploring very bad results. This way we increase the variety of our data in a meaningful way as each patch could be rotated as well on the tissue slice. It seems that tissue patches have been discarded or lost during preparation. Often a biopsy is done to remove small tissue samples. To feed the algorithm with image patches it would be nice to store the path of each image. Again our policy is to start simple by using a small network like resnet18 Setting up the loss function The task to predict the presence of inasive ductal carcinoma given a tissue patch is a binary classification. 4294 rep rep1 type pdf of professor Anant Madabhushi https case. To simplify this task let s write a method that takes a patient and outcomes a dataframe with coordinates and targets. 5 and we have no further insights. So we need to ask ourselves if violet tissue patches have more mammary ducts than rose ones. A rate that is too high will lead to jumps to higher values in the training loss during optimization. Consequently we can set the minimum learning rate to 1e 6 and the maximum to 0. Therefor deep learning could be of great help to automatically detect and locate tumor tissue cells and to speed up the process. Predicting invasive ductal carcinoma in tissue slices MotivationInasive ductal carcinoma IDC is with 80 of cases one of the most common types of breast cancer. The reason behind that is that we would like to have test patients that cover a broad range of possible variations. The image on the right shows the same tissue but cancer is stained with intensive red color. parameters cyclical lr schedule is invoked after each batch statistics deep copy the model load best model weights max_iterations should be the number of steps within num_epochs_ epoch_iterations this way the learning rate increases linearily within the period num_epochs epoch_iterations suggested_stepsize 2 num_iterations_within_epoch. Is this really typical for cancer or is it more typical for ductal cells and tissue Though some of the healthy patches are very violet colored too Would be very interesting to hear what criteria are important for a pathologist. Visualising the breast tissue images Ok now it s time to go one step deeper with our EDA. If this is true we have to be careful. Imagine our model would predict no cancer for all patches. Invasive carcinoma is able to leave its initial tissue compartment and can form metastases. Consequently not the whole patient tissue slice but the single patches have to be considered as input to our algorithm. Selecting an evaluation metric The percentage of correct predictions accuracy score is not a good evaluation metric for imbalanced target distributions. Given the coordinates of image patches we could try to reconstruct the whole tissue image not only the targets. Furthermore we need to create a dataset that loads an image patch of a patient converts it to RGB performs the augmentation if it s desired and returns the image the target the patient id and the image coordinates. read_csv zero the parameter gradients forward track history if only in train backward optimize only if in training phase for param in model. That s a small number compared to the expected number of patients one would like to analyse with our algorithm after deployment. The number of image patches per patient varies a lot This leads to the questions whether all images show the same resolution of tissue cells of if this varies between patients. Even then we still obtain a accuracy score higher than 0. Binary target visualisation per tissue slice Before we will take a look at the whole tissue let s keep it a bit simpler by looking at the target structure in the x y space for a handful of patients Insights Sometimes we don t have the full tissue information. Insights The loss drops right from the start but increases after values higher than 0. edu viewdoc download doi 10. As CNNs are translational but not rotational invariant it s a good idea to add flips during training. Exploratory analysis eda What do we know about our data data Looking at healthy and invasive ductal carcinoma patches patches Visualising the breast tissue tissue 4. 3 possibilities healthy tissue IDC another subtype of breast cancer business case prediction so far is done manually by pathologists and varies from expert to expert. Let s use an example patient with id 13616 Insights The tissue on the left is shown without target information. We should keep this in mind Creating pytorch image datasets It s often a good idea to start as simple as possible and to grow more complex while iterating through the solution. Let s pick an example with recall 0. jpg shows the anatomy of a healthy breast. How many of them do we have in total Ok roughly 280000 images. In order to exploit the full potential one could build a pipeline using massive amounts of tissue image data of various hospitals that were evaluated by different experts. Exploring results and errors error_analysis Loss convergence losses The probability landscape of invasive ductal carcinoma landscape Going into details details 7. Then we can use the coordinates to reconstruct the whole breast tissue of a patient. In addition sick cells need to be located to find out how advanced the disease is and which grade should be assigned. The f1 scoreA better choice is the f1 score that is defined as the harmonic mean of precision and recall f_ 1 frac 2 frac 1 recall frac 1 precision In contrast to the arithmetic mean it is shifted towards small outiers but not influenced strongly by large ones. Some patients have more than 80 patches that show IDC Consequently the tissue is full of cancer or only a part of the breast was covered by the tissue slice that is focused on the IDC cancer. 1714 You can see that the f1 score 0. Preparation peek at the data structure Loading packages and setting Settings Exploring the data structure Ok in this folder we should find several images or a further substructure of folders. Looking at healthy and cancer patches Cancer patches Healthy patches Insights Sometimes we can find artifacts or incomplete patches that have smaller size than 50x50 pixels. In the paper tissue slices of 162 patients were used all having IDC 113 used for training and 49 for validation One pathologist was used to determine regions of IDC given a tissue slice evaluation metric F1 score and balanced accuracy Our goal Given a patient and a patch of a tissue slice predict wheather it contains IDC or not. I assume that the wholes in the tissue belong to the mammary ducts where the milk can flow through. Ok now we have the coordinates for each patch its path to load the image and its target information. ", "id": "allunia/breast-cancer", "size": "17629", "language": "python", "html_url": "https://www.kaggle.com/code/allunia/breast-cancer", "git_url": "https://www.kaggle.com/code/allunia/breast-cancer", "script": "torch.optim torch.utils.data __init__ glob sklearn.metrics get_patient_dataframe tqdm_notebook my_transform get_lr_search_scheduler DataLoader imread listdir torch.nn seaborn numpy torch.optim.lr_scheduler models tqdm_notebook as tqdm visualise_breast_tissue __getitem__ get_cancer_dataframe ReduceLROnPlateau get_confusion_matrix PIL torchvision get_scheduler sklearn.model_selection f1_score confusion_matrix compute_class_weight BreastCancerDataset(Dataset) Image matplotlib.pyplot os pandas extract_coords Dataset __len__ evaluate_model tqdm StepLR torch.nn.functional sklearn.utils.class_weight init_weights transforms sigmoid StratifiedKFold datasets CyclicLR train_test_split train_loop skimage.io ", "entities": "(('that', 'batch size'), 'drop') (('Nonetheless it', 'data science very good own deep learning skills'), 's') (('Even then we', 'higher 0'), 'obtain') (('we', 'loss minimum required change'), 'be') (('we', 'instead idea'), 'prevent') (('very too very criteria', 'pathologist'), 'be') (('we', 'further folders'), 'peek') (('healthy subtype', 'expert'), 'IDC') (('image patch', 'IDC'), 'have') (('it', 'pretrained CNN'), 'be') (('that', 'IDC cancer'), 'have') (('we', 'cancer'), 'have') (('Methods', 'paperCollecting information'), 'present') (('Sometimes it', 'path'), 'start') (('we', 'input shape'), 'resize') (('we', 'data'), 'analysis') (('it', 'metastases'), 's') (('way we', 'images'), 'load') (('Performing', '5'), 'set') (('one', 'deployment'), 's') (('error_analysis Loss convergence probability landscape', 'details details'), 'losse') (('incomplete that', '50x50 pixels'), 'look') (('we', 'epoch'), 'create') (('that', 'optimization'), 'lead') (('percentage', 'evaluation target good imbalanced distributions'), 'select') (('patch', 'tissue as well slice'), 'increase') (('grade', 'addition'), 'need') (('that', 'image patches'), 'have') (('this', 'patients'), 'vary') (('What', 'ductal carcinoma invasive intro'), 'mean') (('also how diseased tissue', 'healthy ones'), 'explore') (('num_epochs epoch_iterations', '2 num_iterations_within_epoch'), 'invoke') (('we', 'first precision'), 'understand') (('patient', 'breast cancer'), 'have') (('classes', 'IDC'), 'imbalanced') (('where experts', 'especially regions'), 'be') (('common loss', 'problem'), 'be') (('only last layers', 'very problem specific features'), 'benefit') (('jpg', 'healthy breast'), 'show') (('that', 'different experts'), 'build') (('f1 score', 'then smaller value'), 'tend') (('violet tissue patches', 'rose ones'), 'need') (('this', 'also preprocessing'), 'be') (('tissue patches', 'preparation'), 'seem') (('we', 'negative cases'), 'like') (('Then we', 'patient'), 'use') (('model', 'patches'), 'imagine') (('that', 'coordinates'), 'let') (('illustration', 'Mikael H\u00e4ggstr\u00f6m https commons'), 'conclusion') (('already new research', 'paper'), 'pass') (('TODO Number', 'cancer tissue size'), 'perform') (('read_csv parameter', 'model'), 'zero') (('Furthermore decision', 'pathologist'), 'depend') (('we', 'them'), 'have') (('class 1 positive cancer', 'higher weight'), 'see') (('it', 'IDC'), 'use') (('goal', 'tumors'), 'be') (('learning rate', 'neural networks'), 'say') (('recall', 'zero'), 'have') (('single patches', 'algorithm'), 'tissue') (('better idea', 'patches'), 'be') (('it', 'training'), 'be') (('that', 'image names'), 'be') (('Invasive carcinoma', 'metastases'), 'be') (('Patches', 'healthy ones'), 'look') (('Only then we', 'generalisation performance'), 'measure') (('very we', 'patients'), 'be') (('such we', 'class imbalance'), 'need') (('very we', 'model'), 'be') (('Confusion matrix', 'very bad results'), 'explore') (('tissue', 'target information'), 'let') (('Often biopsy', 'tissue small samples'), 'do') (('now it', 'one step deeper EDA'), 'visualise') (('It', 'often good as simple possible more solution'), 'keep') (('TruePositives model', 'cancer'), 'have') (('milk', 'where'), 'assume') (('it', 'image'), 'be') (('now we', 'image'), 'have') (('edu medicine ccir', 'anant madabhushi'), 'faculty') (('it', 'target patient'), 'need') (('1714', 'mu'), 'shift') (('we', 'image only resizing'), 'let') (('MotivationInasive ductal carcinoma IDC', 'breast cancer'), 'predict') (('Consequently we', '6 0'), 'set') (('neighboring patches', 'different directions'), 'loose') (('This', 'patches'), 'match') (('cancer', 'intensive red color'), 'show') (('we', 'only targets'), 'try') (('darker more violet colored tissue', 'rose color'), 'seem') (('as well it', 'IDC'), 'know') (('lobular carcinoma', 'lobules'), 'start') (('we', 'total Ok roughly 280000 images'), 'have') (('t', 'images'), 'compose') (('test data', 'train'), 'let') (('that', 'baseline value'), 'have') (('we', 'predictions'), 'use') (('ductal carcinoma patches healthy patches', '4'), 'eda') (('we', 'patient ids'), 'stratify') (('us', 'balance'), 'like') (('task', 'tissue patch'), 'be') (('Sometimes we', 'don tissue full information'), 'let') (('s', 'remaining training'), 'be') (('it', 'strongly large ones'), 'be') (('Now it', '70 dev'), 's') (('loss', 'higher 0'), 'insight') (('tissue slice', 'interest'), 'cover') (('which', 'milk ducts'), 'see') (('that', 'possible variations'), 'be') (('How many patients we', 'Almost 280 patients'), 'have') (('Automatic detection', 'citeseerx'), 'ask') (('we', 'datascience workflow'), 'seem') ", "extra": "['biopsy', 'biopsy of the greater curvature', 'disease', 'outcome', 'patient', 'test']"}
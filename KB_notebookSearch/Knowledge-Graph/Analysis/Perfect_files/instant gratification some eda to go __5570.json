{"name": "instant gratification some eda to go ", "full_name": " h2 Table of contents h2 Prepare to start h2 Sneak a peek h3 Take a look h3 Insights h3 Size of the data h3 Dtypes h3 A magic feature h3 Missing values h2 Basic exploratory analysis h3 Class balance h3 Feature correlation h3 Insights h3 Insights h3 Insights h3 What logistic regression wants to tell us h3 The magic turtle again h3 Insights h3 What about the column names h3 Ideas and insights h3 Duplicates h2 Diving into single datasets h3 Choosing a subset ", "stargazers_count": 0, "forks_count": 0, "description": "Table of contents1. The scatter plot of wheezy copper turtle magic and our highest class median distance feature wheezy_myrtle mandrill entropy looks indeed crazy It s not that the turtle magic spreads smoothly with lower density over the whole space of the mandrills tails. By doing so you will definitely find some spread that separates target classes What about the column names Have you asked yourself as well who had this nice phantasy to build up the column names Is there a logic behind it Can we find connections given the column names Well I don t know it and we all have to work on it but perhaps a sketch helps. Very interesting id column isn t it Size of the dataRoughly we have twice as much train data than test data. Our crazy magic turtle feature has no difference at all And it s distribution is almost uniform even though the small bin peaks look interesting just an artifact of plotting. Let s see what logistic regression tells us with its weights in the next step. This again leads to the question What role does the magic turtle play in this game What logistic regression wants to tell us. Perhaps there are some non obvious once but let s move this topic to exploratory data analysis. Let s stay curious and critical Do we know if test and train behave the same No For this reason I don t like to combine train and test right now. No It has some subsequent peak tails depending on the value of magic turtle. That looks like a further puzzle to solve. but this time it doesn t look like that. Color has a natural order. Maybe this slight values are still something fruitful. Do you see what is missing in train We have 0. The kind is a mysterium for me. This is especially interesting for some subsequent features. The correlation between the last two features in train looks strong enough to be something but in test this correlation has gone As we have already seen by the correlation distributions we can expect some differences in the feature distributions of train and test. perhaps the length of these adjectives is important or the first character or we can find a grouping given the other feature names Would be great to create a connection map. two int columns A magic feature Ohhh D Cool The wheezy copper turtle magic oooohhh magic What does that mean for the comp Missing valuesLet s start with obvious once No obvious missing values in train and test. Do we need this kind of order somewhere 4. Choosing a subset. Sneak a peek Take a look Size of the data Dtypes A magic feature Missing values3. 015 in test on both sides but only 0. By plotting two features with highest distances in class medians I wanted to see if we can see something like in don t overfit overlapping gaussians. There a lot of further goal descriptions that could be interpretable or at least leave a guess on what to try out with them. Let s follow the idea that these names indeed have some meaning. even the feature with highest difference in classes medians looks like no big deal at all. in this case what are features to discard Is there one more magic feature and what makes it magically Ideas and insightsPuhhh. Duplicates Diving into single datasetsHow many single rows do we have given a single magic turtle value Do all subsets in the data have the same amount of samples Obviously not The zick zack nature above seemed to be a plotting artifact. Basic Exploratory Analysis Feature correlations Distances between class medians What logistic regression wants to tell us The magic turtle again What about the column names Prepare to start Sneak a peek Take a look Insights Hey we are given crazy column names Can we find a meaning behind them Hmm. Can we find some sense in the way of column order This is not always true. We have already found an interesting feature by peeking at the data. Insights If you compare correlations carefully you can observe that some of the nearby features have some slight correlations in train and test. But perhaps it s not about a single animal name and we can introduce a higher level of abstraction like bird or dog instead of a specific species of dogs birds etc. Perhaps we can find some more during basic EDA. Class balanceVery balanced in train Feature correlation Insights Looks almost decorrelated. The one turtle magic is one magic. The magic turtle againCan t get enough Let s look at a 3D Scatterplot with magic turtle Insights Very cool and beautiful again Choose some other features for feat1 and feat2. As Chris already pointed out we won t get far by ignoring the pattern found with our magic turtle. o What s that Wheezy copper turtle magic. who is connected with who Can we visualize a network Could be a good timepoint to learn how to realize that. Take a look at the lower right corner. There must be some differences in feature distributions between train and test. again InsightsCrazy turtle D By taking the feature mean per target and computing distances between the classes I wanted to find features that show clear separating forces. A lot of animals only have one or two occurences. Basic exploratory analysisOk now the colorful part starts. But don t be too fast. ", "id": "allunia/instant-gratification-some-eda-to-go", "size": "5570", "language": "python", "html_url": "https://www.kaggle.com/code/allunia/instant-gratification-some-eda-to-go", "git_url": "https://www.kaggle.com/code/allunia/instant-gratification-some-eda-to-go", "script": "LogisticRegression sklearn.metrics sklearn.model_selection seaborn numpy matplotlib.pyplot RepeatedStratifiedKFold sklearn.linear_model roc_auc_score sklearn.preprocessing plotly.offline pandas plotly.graph_objs StandardScaler train_test_split ", "entities": "(('perhaps sketch', 'it'), 'find') (('Insights', 'train Feature correlation'), 'balance') (('we', 't overfit don overlapping gaussians'), 'by') (('that', 'clear separating forces'), 'd') (('already we', 'magic turtle'), 'get') (('lot', 'only one occurences'), 'have') (('we', 'train'), 'look') (('we', 'test data'), 'interesting') (('bin almost even small peaks', 'just artifact'), 'have') (('Perhaps we', 'basic EDA'), 'find') (('that', 'train'), 'column') (('Perhaps obvious once s', 'data exploratory analysis'), 'be') (('turtle magic', 'mandrills tails'), 'look') (('we', 'somewhere 4'), 'need') (('it', 'case'), 'be') (('zick zack Obviously nature', 'samples'), 'give') (('This', 'especially subsequent features'), 'be') (('grouping', 'connection map'), 'be') (('It', 'magic turtle'), 'have') (('we', 'Hmm'), 'distance') (('we', 'good how that'), 'connect') (('names', 'indeed meaning'), 'let') (('We', '0'), 'see') (('I', 'train'), 'let') (('we', 'dogs instead specific birds'), 's') (('even feature', 'big deal'), 'look') (('We', 'data'), 'find') (('Sneak', 'data'), 'take') (('That', 'further puzzle'), 'look') (('This', 'column order'), 'find') (('that', 'them'), 'lot') (('logistic regression', 'us'), 'lead') (('some', 'train'), 'observe') (('s', 'feat1'), 'get') (('logistic regression', 'next step'), 'let') ", "extra": "['test']"}
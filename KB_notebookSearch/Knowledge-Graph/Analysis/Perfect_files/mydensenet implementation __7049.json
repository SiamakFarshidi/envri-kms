{"name": "mydensenet implementation ", "full_name": " h1 CIFAR 10 Yet another DenseNet implementation h3 Data preparation and augmentation after its loading h3 Visualizing some images after transformation h2 My DenseNet implementation DenseNet class h3 My DenseNet implementation h3 Model training function h2 Training a DenseNet h3 Training Validation losses and accuracy development over the number of epochs h2 Testing the best parameters obtained h2 Conclusion h3 Acknoledgemets ", "stargazers_count": 0, "forks_count": 0, "description": "com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. disabling dropouts during the forward pass numpy array to hold all the final predictions i. I wanted to make my own implementation of DenseNet and see it working. This exercise is more about having a working implementation of DenseNet and less about finding a solution for CIFAR 10. I wanted to try differen configuration on the amount of layers and dense blocks and see if I could find a configuration that could be beat the DenseNet BC network that got the best validation loss in the forementioned comparison I did. It is interesting to see the misclassified images and intuitively see what could have led the model to a wrong prediction. My DenseNet implementation DenseNet class My DenseNet implementation. Instead a global average pooling takes place together with a fully connected network performing a softmax classifier. the name of the class an image belongs to draw batches of images from the test loader until all of them have been drawn get predictions of the classes of the iamges on this batch release the GPU memory prepare the submission of the predictions get 20 random indexes get a test image corresponding to the random index recently drawn get numpy images out of the images batch. This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. save the compression factor value needed to further build the network save the compression factor value needed to further build the network check that nLayers is either of type int or list if nLayer is of type list check that it is not empty track chane in validation loss const value. So this is my own implementation of DenseNet. same mode architecture release the GPU memory set the DenseNet model for evaluation only i. 06993v5 I was as impressionable as a beginner can be surprised by its simple architecture and its powerful performance when compared agains other very well known image classification networks. At the end I hope that by making these exercises I get to learn something beyond the readings of a paper. a linear transformation is used here as a Softmax layer. batches are built out of random sampled elements prepare loaders the following test loader is used to load all the test images into the model for their classification unnormalize the picture convert from Tensor image get a batch of training images convert images to numpy for display plot the iamges of the batch validate parameters. add the just built dense block to the main sequential module i. Previous to this notebook I did a very simple comparison of the performance of this implementation using two DenseNet BC networks and two DenseNet not BC variants networks. com armhzjz DenseNet. read_csv Input data files are available in the. pt file containing the trained parameters and that they are loaded to a similar DenseNet model as the model such parameters were trained i. Model training function Training a DenseNetWe must now build an instance of a DenseNet class specify a loss function and an optimizer to then train our network. There are two reasons behind my decision There have been other users who have tried the BC variant of a DenseNet on the Cifar 10 dataset Based on the comparison I did it seams to me that the last DenseNet network I used could yield to a better result. Next the data is loaded into numpy arrays. I liked her idea of collecting all the training and validation information to plot it later which I definitely took from her. For example running this by clicking run or pressing Shift Enter will list all files under the input directory Any results you write to the current directory are saved as output. feature maps and how they can learn different patterns from each one of those channels. For the images labels a numpy array is constructed with the corresponding index of the classes list also defined in the hidden cell. Such comparison can be found in here https github. ConclusionI am quite happy with the gotten results. First a class that takes numpy arrays that encode images and their labels is defined. Thanks for checking this kernel out and as always if there are observation and or suggestions I will be more than happy to read from you. It would be nice to see how much a DenseNet architecture needs to change to get similar results in the Cifar 100 dataset. I want to mention that I tried to write my implementation as loyal to the paper as my understanding of it allowed me. For this a transformation has also been defined to process the images. These are some of the images the densenet network will try to predict. Then I d have a much clearer idea of how powerful this network really is. So in my implementation I use the character for my own comments and I use for the paper s extracts. samples per batch number of subprocesses to use for data loading CifarDataset is a class that construct a dataset out of training images stored as numpy arrays and its corresponding training labels also stored as numpy arrays This CifarDataset class serves also to provide testing images converted Tensors in a way that they can be provided via a DataLoader specify the image classes loading the images and training labels we need to correctly transpose the numpy arrays so they can be converted to PIL images later while they are being drawn from the data loaders numpy array where the training labels are going to be stored as integer value convert data to a normalized torch. build a dense block with the number of layers according to the index indx of the nLayers list add the just built dense block to the main sequential module i. Let s get the accuracy on this model on such unseen images. Training Validation losses and accuracy development over the number of epochs Testing the best parameters obtainedThe model will try to predict the classes of data that has not been seen by it by the model. I have created a github repository as well which is found here https github. 001 we reset it to 0. This transformation is passed to the CifarDataset instance created so that when samples are taken from that dataset the returnedimages will be training ready. AcknoledgemetsDuring the comparison I performed on this implementation of the network it occured to me to check other solutions on the Cifar10 competition and I stumbled upon this network from Aleksandra Deis aleksandradeis which uses also an implementation of DenseNet which is the one I have already mentioned at the begining of this kernel. At last training and validation sub sets are prepared out of the training images together with data loaders which will be providing batches of training and validation images to the training process. densenet add a transition layer right after a dense block do not forget to explicitly add the compression factor argument update the number of input feature maps of the next Dense Block create and add the last dense block. Visualizing some images after transformationThis section serves both to demonstrate the usage of the loaders as well as to make sure the transformations are performed to the images. com weiaicunzai pytorch cifar100 blob master models densenet. This has become for sure my favorite network architecture so far. I am both glad and kind of sad to find out that most parts of my implementations were written basically identically. I checked the evaluation loss without these layer first and with these layers after and it works best wtih them. com armhzjz DenseNet tree master performance_Analysis. green backgrounds or green leaves as backgrounds. Displaying the image below is really irrelevant for this exercise but it is usefull to understand how convolutional networks see different pictures in different channels i. Those images are converted to a numpy arrays so they can be plotted. create the main sequentail module Before entering the first dense block a convolution with 16 or twice the growth rate for DenseNet BC ouput channels is performed on the input images. This last dense block was previously left aside because after this last dense block comes no transition layer. we are collect some characteristic data from the training process to check some statistics plot the train and validation losses plot the train and validation accuracies plot the train and validation top 3 accuracy get a batch of test images convert images to numpy for display plot the iamges of the batch can we move the tensors to GPU I evaluate the availability of cuda here again so that the user can use only this cell to predict the classes of the test images provided there is a. create the dense blocks according to the size of the nLayers list I define for clarity readability reasons a innerChanns variable whose value is initialized to preprocess_outmaps we skip here the creation of the last dense block. densenet With adaptive pooling the output can be reduced to any feature map size although in practice it is often choosen size 1 in which case it does the same thing as global pooling but first a batch and relu layer I included this two layers after checking the implementation I refer to at the begining of this notebook. get the number of inputs constructor of the class constructor of the class constructor of the class validate the parameters given to the main class creator to ensure a minimum degree of sane functionality check for the type of layer to be used. Here some of the test images and their classes according to the modDN DneseNet model we trained. This exercise has been very satisfying and it has proven the simplicity and the power of DenseNets. For this notebook I decided to go with a regular DenseNet network if the not BC variant can be called a standard DenseNet network. At the end I compared my implementation against this other implementation https github. start updating the learning rate at this percentage of the nEpochs epoch at which the last learning rate update will be done reaching its minimum value percentage of epochs at which the optimization will reach its minimum learning rate check if CUDA is available release the GPU memory Encapsulate the model in case the learning rate update went a bit below 0. Its average train accuracy improved in a very stable way after epoch 30 and its best training loss is just 0. 02 bigger than the best result I got using the BC variant. Once the images and its labels are loaded in numpy arrays the cifar dataset is constructed by using thedefined CifarDataset class. I liked that so I took that idea from the author. Also I am still a beginner and based much of my training code on notebooks I developed during the Deep Learning nanodegree from Udacity which I pretty much recommend if you can afford it. For example a frog could be misclassified as a bird given that the context of the frog s picture shares some commonalities with the context of a bird s pictures i. FloatTensor define transformations for the test images which means only converting them to Tensors and normalizing them creating the cifar dataset training indices to be used for validation purposes split the training dataset into a real training dataset and a validation set we take 24 percent of the training dataset for validation define samplers they sample obtain batches from a list of indices. I have no doubts I will get a good score like everybody else have already gotten but really this is more a playground to experiment with my implementation of the paper. A train loader iterator is here created to draw batches of images which have been processed by the transforms transformations. 001 to avoid an extremly slow optimization keep track of training and validation loss start counting the elapsed time clear the gradients of all optimized variables forward pass compute predicted outputs by passing inputs to the model calculate the batch loss backward pass compute gradient of the loss with respect to model parameters finally perform one optimization step an update of the parameters towards the disminution of error direction update training loss calculating train top 1 accuracy calculating train top 3 accuracy check how much time has elapsed forward pass compute predicted outputs by passing inputs to the model calculate the batch loss update average validation loss calculating validation top 1 accuracy calculating validation top 3 accuracy calculate average losses print training validation statistics save model if validation loss has decreased as loss function cross entropy loss will be used and the optimizer. Yet another DenseNet implementationAfter readeing the DenseNet paper https arxiv. Data preparation and augmentation after its loading In the following hidden cells a dataset consisting of the images and its labels is being constructed. I find my implementation in general but especially of the construction of the DenseNet to be more interesting as well as to follow in a better way the paper allowing the user to decide whether to construct DenseNet BC or just a regular DenseNet network without compression factor and without bottleneck layers. I must mentioned that I liked the way that other implementation includes extracts of the paper on the relevant corresponding code lines allowing the reader to make a direct link between the code and the paper. initialize all weights and biases for every linear layer in a model. ", "id": "ahernandez1/mydensenet-implementation", "size": "7049", "language": "python", "html_url": "https://www.kaggle.com/code/ahernandez1/mydensenet-implementation", "git_url": "https://www.kaggle.com/code/ahernandez1/mydensenet-implementation", "script": "torch.optim torch.utils.data __init__ DataLoader __Bottleneck(nn.Module) forward torch.nn numpy __getitem__ PIL torchvision __H_layer(nn.Module) __Transition_layer(nn.Module) __InitW_uniCenter TrainModel Image matplotlib.pyplot __Validate_params pandas Dataset __len__ CifarDataset(Dataset) transforms showImage torch.utils.data.sampler datasets SubsetRandomSampler DenseNet(nn.Module) ", "entities": "(('training 30 best loss', 'epoch'), 'improve') (('how much DenseNet architecture', 'Cifar'), 'be') (('always I', 'more than you'), 'be') (('I', 'implementation https other github'), 'compare') (('which', 'training process'), 'prepare') (('densenet network', 'images'), 'be') (('as well transformations', 'images'), 'visualize') (('Next data', 'numpy arrays'), 'load') (('transformation', 'also images'), 'define') (('here again user', 'test images'), 'be') (('growth 16 rate', 'input images'), 'create') (('very it', 'DenseNets'), 'be') (('corresponding', 'images batch'), 'belong') (('I', 'extracts'), 'use') (('they', 'numpy arrays'), 'convert') (('BC variant', 'DenseNet regular network'), 'decide') (('I', 'forementioned comparison'), 'want') (('learning rate update', 'bit 0'), 'start') (('Data preparation', 'images'), 'construct') (('Such comparison', 'https github'), 'find') (('we', 'last dense block'), 'create') (('encode images', 'numpy arrays'), 'class') (('pretty much you', 'it'), 'be') (('integer value', 'normalized torch'), 'be') (('minimum degree', 'layer'), 'get') (('context', 'pictures i.'), 'misclassifie') (('as beginner', 'simple architecture'), '06993v5') (('how convolutional networks', 'channels different i.'), 'be') (('I', 'DenseNet BC two networks'), 'previous') (('feature how they', 'channels'), 'map') (('when samples', 'returnedimages'), 'pass') (('such parameters', 'DenseNet similar model'), 'file') (('that', 'model'), 'try') (('I', 'kernel'), 'AcknoledgemetsDuring') (('reader', 'code'), 'mention') (('GPU memory', 'evaluation'), 'release') (('both kind of most parts', 'implementations'), 'be') (('so I', 'author'), 'like') (('how network', 'much clearer idea'), 'have') (('intuitively what', 'wrong prediction'), 'be') (('I', 'definitely her'), 'like') (('it', 'track validation loss const empty value'), 'save') (('entropy loss', 'model'), 'start') (('you', 'output'), 'list') (('So this', 'own DenseNet'), 'be') (('I', 'BC variant'), 'big') (('which', 'transforms transformations'), 'create') (('linear transformation', 'Softmax here layer'), 'use') (('Instead global average pooling', 'softmax classifier'), 'take') (('ConclusionI', 'quite gotten results'), 'be') (('numpy array', 'also hidden cell'), 'label') (('it', 'best wtih'), 'check') (('as well which', 'https here github'), 'create') (('batch', 'batch validate parameters'), 'build') (('exercise', 'CIFAR'), 'be') (('read_csv Input data files', 'the'), 'be') (('understanding', 'me'), 'want') (('number', 'last dense block'), 'add') (('we', 'DneseNet modDN model'), 'some') (('they', 'indices'), 'define') (('s', 'such unseen images'), 'let') (('else already really this', 'paper'), 'have') (('previously aside last dense block', 'transition layer'), 'leave') (('cifar arrays dataset', 'CifarDataset thedefined class'), 'load') (('user', 'bottleneck layers'), 'find') (('it', 'DenseNet'), 'want') (('It', 'python docker image https kaggle github'), 'come') (('Model training DenseNetWe', 'then network'), 'function') (('I', 'better result'), 'be') (('I', 'paper'), 'hope') (('I', 'notebook'), 'reduce') ", "extra": "['test']"}
{"name": "t2i synthesis with generative adversarial ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "append loss_T_E print right_text None. Embedding num_word 1 embeding_size padding_idx 0 1 for padding idx self. backward optimizer_T_E. shape noise torch. shape for key in models 0 models 0 key. shape right_text torch. step avg_total_loss_T_E total_loss_T_E dataloader_len loss_T_E_hist. to device text_encod text1 transforms. word_to_index 128 256 total_loss_T_E 0 D_real disc img Enc_right_text D_wrong disc img Enc_wrong_text D_wrong_img disc wrong_img Enc_right_text loss_D_real criterion D_real ones loss_D_wrong criterion D_wrong zeros loss_D_wrong_img criterion D_wrong_img zeros loss_T_E loss_D_real loss_D_wrong loss_D_wrong_img 2 optimizer_T_E. to device right_text. shape gen_image models fold generator noise enc_text. rnn text hidden hidden. squeeze Total_data np. Module def __init__ self num_word embeding_size hidden_size super. eval del check_point img img Nun. npy allow_pickle True. shape total_loss_T_E loss_T_E. state_dict for img right_text _ in d_set text1 wrong_text. eval Enc_test_sentence_numeric text_encod test_sentence_numeric print Enc_test_sentence_numeric. step print fake_image. ToPILImage image 26. cpu print gen_image. hidden_size hidden_size self. The references used are mentioned below. to device break image gen torch. input t2i synthesis with generative adversarial data. split for word in test_sentence if word in Total_data word_to_index test_sentence_numeric. tensor test_sentence_numeric device device None print test_sentence_numeric. tensor right_text device device None right_text. shape enc_text check_point models text_encoder right_text None print enc_text. shape text_encod. zero_grad loss_T_E. RNN embeding_size hidden_size batch_first True def forward self text text self. embedding text text hidden self. __init__ self. append Total_data word_to_index word print test_sentence_numeric test_sentence_numeric 0 Total_data max_sequence_length len test_sentence_numeric test_sentence_numeric test_sentence_numeric torch. data 50000 return 1000 class Text_encoder nn. item test_sentence_numeric test_sentence input. hidden_size 1 1 return hidden score batch_size max_length hidden_dim attention_weights batch_size max_length 1 we get 1 at the last axis because we are applying score to self. Please note This kernel is for practice purposes only. Reference links Paper Git repo hand written sentence to generatation list f train print text print type text t t unique text img_name self. randn 1 100 1 1 device device generated_img gen noise Enc_test_sentence_numeric transforms. shape Enc_right_text text_encod right_text noise torch. item print f loss_D loss_D loss_G loss_G scheduler_T_E. randn 1 100 1 1 device device gen_img gen noise Enc_right_text transforms. V context_vector shape after sum batch_size hidden_dim gen Generator disc Dicriminator text_encod TextEncoder len d_set. ", "id": "avikbanik/t2i-synthesis-with-generative-adversarial", "size": "190", "language": "python", "html_url": "https://www.kaggle.com/code/avikbanik/t2i-synthesis-with-generative-adversarial", "git_url": "https://www.kaggle.com/code/avikbanik/t2i-synthesis-with-generative-adversarial", "script": "__init__ torch Discriminator(nn.Module) forward numpy __getitem__ PIL torchvision nn Image matplotlib.pyplot pandas __len__ tqdm Generator(nn.Module) transforms visualize Train_dataset attention Text_encoder(nn.Module) Train TextEncoder(nn.Module) ", "entities": "(('we', 'score'), 'score') (('shape gen_image models', 'generator noise enc_text'), 'fold') (('kernel', 'practice purposes'), 'note') (('gen noise', '1 device 1 100 1 device'), 'randn') (('right_text None', 'enc_text'), 'print') (('data', 'class Text_encoder 50000 1000 nn'), 'return') ", "extra": "['test']"}
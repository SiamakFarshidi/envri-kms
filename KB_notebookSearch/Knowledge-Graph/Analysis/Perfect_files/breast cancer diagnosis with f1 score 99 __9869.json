{"name": "breast cancer diagnosis with f1 score 99 ", "full_name": " h1 Breast Cancer h2 A Problem Understanding h2 B Data Understanding h4 1 Data Description h4 2 Load The Data h4 3 Data Types h1 C Data Exploration h1 D Data Preprocessing h4 1 Data Selection h4 2 Preprocess Data h4 3 Data Transformation h1 E Data Modelling h4 1 Random Forest h4 2 KNN h4 3 SVM h1 F Evaluation ", "stargazers_count": 0, "forks_count": 0, "description": "98651 Rejected area_se is highly correlated with perimeter_se \u03c1 0. Data Description data. Ten features are computed for each nucleus area radius perimeter symmetry number and size of concavities fractal dimension of the boundary compactness smootimess local variation of radial seg ments and texture variance of gray levels inside the boundary. 93766 Rejected area_worst is highly correlated with perimeter_worst \u03c1 0. For example the third column is Mean Radius column 13 is Radius SE column 23 is Worst Radius. Clearly this not severe as the opposite situation. The fluid from the FNA is placedon a glass slide and stained to highlight the nuclei of the constituent cells. Because the FP is zero and NP is very small 1. If the data are highly correlated we then exlude it. 91204 RejectedAs on the previous test we need to keep some features and remove the other features that are unnecessary. Problem UnderstandingDespite a great deal of public awareness and scientific research breast cancer continues to be the most common cancer and the second largest cause of cancer deaths among women. It is better to scale the numeric data because every feature has different scale. If the cancer is identified as malignant there is a sort amount of time or even no time to re evaluate the patient and the wrong treatment will be taken by the doctor and make the patient in danger. 96275 RejectedFirst we will choose one out of three variables that are higly correlated From radius_mean perimeter_mean and area_mean we choose radius_mean From radius_se perimeter_se and area_se we choose radius_se From radius_worst perimeter_worst and area_worst we choose radius_worst Second due to the high correlation of the radius features radius_mean and radius_worst we need to choose one let s take the radius_mean At this step we keep 2 variables radius_mean and radius_se and will exclude 7 other variables in group_1 perimeter_mean area_mean perimeter_se area_se radius_worst perimeter_worst area_worst Group 2 Features in concave points texture and concavity Look at the pandas profile report we can witness concave points_mean is highly correlated with concavity_mean \u03c1 0. largest or worst value biggest size most irregular shape and standard error of each of these cellular features are com puted for each image resulting in a total of 30 real valued features. Let me remind you what does it mean. 7 F1 score of Optmized SVM model 99. The mean value extreme value i. Data SelectionNow we need to select the data based on the question that we want to address which is classification of the cancer. 99371 Rejected radius_worst is highly correlated with area_mean \u03c1 0. For example the patient ID and other blank features. There are 31 features now including the target Next let s explore all variables using Pandas Proiling Report. 92139 Rejected concave points_worst is highly correlated with concave points_mean \u03c1 0. From concave points_mean concavity_mean and concave points_worst we choose concave points_mean From texture_mean and texture_worse we choose texture_mean At this step we keep variables concave points_mean and texture_mean and will exclude 3 other variables in group_2 concavity_mean concave points_worst and texture_worse 2. 97279 Rejected perimeter_worst is highly correlated with radius_worst \u03c1 0. We create 3 basic models and then optimze each models using Hyperparameter Search technique. From the above warning we can see that there are 10 warning regarding the correlation of the features we can group them as 2 groups of correlation test Group 1 Features in Radius Perimeter and Area Take a look at the pandas profile report area_mean is highly correlated with perimeter_mean \u03c1 0. K Nearest Neighbours3. This is helpful to speed up our correlation test. In this case because the data are obtained using real image we assume zero values are possible and not human error so we can t exclude that. Support Vector Machine SVM 1. 3 We can conclude that SVM is the best model to classify the breast cancer with the optimum F1 score of 99. It is very dangerous because the patient will have the serious treatment consume a high dose drug category or have a serious surgery that is actually not appropriate for such patient. Xcyt uses a curve fitting program to determine the exact boundaries of the nuclei. In contrast a value in FN is the number of malignant patient who are predicted as benign. FP is the most important indicator. False positives FP We predicted yes but they don t actually have the malignant cancer. 91016 Rejected texture_worst is highly correlated with texture_mean \u03c1 0. After the diagnosis for each patient with breast cancer we classify the severity of cancers as malignant or benign in order to give them special treatments. 97758 Rejected perimeter_mean is highly correlated with radius_mean \u03c1 0. The correlation test is used to evaluate the relationship between two numerical variables. This outpatient procedure involves using a small gauge needle to take the fluid known as a fine needle aspirate FNA directly from a breast lump or mass thelump having been previously detected by self examination and or mammoaphy. There is a time to re assess the patient in order to provide better treatment. Even though the available data are seems to be relevant we need to conduct the correlation test to make sure we used the features that are must be included. In the histogram the horizontal axis is the data of the feature while the vertical axis is the frequency of occurrence. The predictive model using SVM does very well. The available data can includes independent variables and dependent variables. Data TransformationWe need to check the boundaries minimum and maximum values of each features. A breast cancer victim s chances for long term survival are improved by early detection of the disease and early detection is in turn enhanced by an accurate diagnosis. 0 concavity severity of concave portions of the contour concave points number of concave portions of the contour symmetry fractal dimension coastline approximation 1 Note Mean Etandard Error SE and Worst mean of the three largest values of these features are obtained from each image resulting in 30 features. To illustrate if there is a value in FP it means that the patient with benign cancer predicted as malignant cancer. Before go to correlation test we need to change the target of classification in the column of diagnosis to be numerical. Data Preprocessing 1. 7 F1 score of KNN model 97. Data ExplorationOn the data exploration we will see the distribution of each variable using a histogram. If two variables have a correlation coefficient then the two variables are numerical variables while the remainder are categorical variables. We also consider to remove unnecessary data that is clearly not required. An image from the FNA is transferredto a workstation by a video camera mounted on a microscope. For a typical image containing between 10 and 40 nuclei the image analysis process takes approximately two to five minutes. 9 F1 score of Optmized KNN model 97. All feature values are stored with four significant numbers. From the histograms below we can see the distributions are normal. Ten real valued features are computed for each cell nucleus radius mean of distances from center to points on the perimeter texture standard deviation of gray scale values perimeter area smoothness local variation in radius lengths compactness perimeter 2 area 1. Preprocess DataAfter we know what features to be excluded let s make the sample data for analysis or the data that we want to work with. It is also important to binarized our target because it is need to convert to 0 and 1 to calculate F1 score of our model evaluation. SVMFor the above confusion matrix we can see that the false positive 0 and the false negative 1. The annual mortality rate of approximately 28 deaths per 100 000 women has remained nearly constant over the past 20 years. women will be diagnosed with breast cancer and 3. 3 To increase the F1 score we have applied hyperparameter tuning using RandomizedSearch and obtain F1 score of Optmized Random Forest model 94. Data ModellingLet s prapare our input and output using tran test split before we create models. EvaluationOverall the model perform well to predict the class of cancer with F1 score 94 even not using hyperparameter optimization F1 score of Random Forest model 94. False negatives FN We predicted no but they actually do have the malignant cancer. The boundaries are initialized by an operator using a mouse pointer. 99786 Rejected perimeter_se is highly correlated with radius_se \u03c1 0. Approximately 12 of U. The model we used are 1. So we can also include the target to the correlation test because the correlation test can process only numerical data. 0 F1 score of SVM model 99. Data UnderstandingFirst a sample of fluid is taken from the patient s breast. Diagnosis M malignant B benign 3. From the Pandas Profiling thare are 14 warnings 4 are due to zero values. What we need is to ensure the inputs include all independent varibales and each feature doesn t make a high correlation with the target or with other input s we can identify them by evaluating through correlation test. ", "id": "busthon/breast-cancer-diagnosis-with-f1-score-99", "size": "9869", "language": "python", "html_url": "https://www.kaggle.com/code/busthon/breast-cancer-diagnosis-with-f1-score-99", "git_url": "https://www.kaggle.com/code/busthon/breast-cancer-diagnosis-with-f1-score-99", "script": "sklearn.metrics KNeighborsClassifier seaborn numpy evaluate sklearn.ensemble sklearn sklearn.model_selection f1_score confusion_matrix RandomForestClassifier matplotlib.pyplot pandas StandardScaler sklearn.neighbors SVC sklearn.preprocessing RandomizedSearchCV sklearn.svm train_test_split preprocessing ", "entities": "(('boundaries', 'mouse pointer'), 'initialize') (('human we', 't that'), 'assume') (('feature', 'different scale'), 'be') (('patient', 'malignant cancer'), 'illustrate') (('image analysis process', 'approximately two to five minutes'), 'take') (('available data', 'independent variables'), 'include') (('Worst mean', '30 features'), 'severity') (('they', 'actually malignant cancer'), 'fn') (('EvaluationOverall model', 'Random Forest model'), 'perform') (('Ten real valued features', 'radius lengths'), 'compute') (('sort malignant amount', 'danger'), 'be') (('correlation test', 'two numerical variables'), 'use') (('that', 'actually such patient'), 'be') (('Rejected perimeter_worst', '0'), '97279') (('image', 'microscope'), 'be') (('t', 'actually malignant cancer'), 'positive') (('fluid', 'mass self previously examination'), 'involve') (('mortality annual rate', 'nearly past 20 years'), 'remain') (('we', 'points_worst'), 'choose') (('feature values', 'four significant numbers'), 'store') (('We', 'Hyperparameter Search technique'), 'create') (('97758 Rejected perimeter_mean', '0'), 'correlate') (('concave points_mean', '0'), 'choose') (('Problem UnderstandingDespite', 'women'), 'continue') (('largest biggest size', '30 real valued features'), 'put') (('Data TransformationWe', 'features'), 'need') (('we', 'that'), 'DataAfter') (('that', 'other features'), 'need') (('fluid', 'constituent cells'), 'be') (('Xcyt', 'nuclei'), 'use') (('third column', 'example'), 'be') (('Rejected area_se', 'highly \u03c1'), '98651') (('we', 'confusion above matrix'), 'see') (('correlation test', 'only numerical data'), 'include') (('sample', 'breast'), 'take') (('we', 'Random Forest Optmized model'), '3') (('we', 'diagnosis'), 'need') (('highly we', 'then it'), 'exlude') (('early detection', 'accurate diagnosis'), 's') (('Rejected texture_worst', '0'), '91016') (('vertical axis', 'occurrence'), 'be') (('it', 'model evaluation'), 'be') (('we', 'special treatments'), 'classify') (('area_mean', 'perimeter_mean highly \u03c1'), 'see') (('that', 'features'), 'seem') (('we', 'correlation test'), 'be') (('distribution', 'histogram'), 'ExplorationOn') (('tran test we', 'models'), 'prapare') (('This', 'correlation test'), 'be') (('Ten features', 'boundary'), 'compute') (('Rejected perimeter_se', 'highly \u03c1'), '99786') (('numerical remainder', 'correlation coefficient'), 'be') (('concave 92139 Rejected points_worst', 'points_mean 0'), 'correlate') (('Rejected radius_worst', 'area_mean highly \u03c1'), '99371') (('which', 'cancer'), 'SelectionNow') (('Rejected area_worst', '0'), '93766') (('Next s', 'Pandas Proiling Report'), 'be') (('that', 'also unnecessary data'), 'consider') (('Clearly this', 'opposite situation'), 'severe') (('who', 'malignant patient'), 'be') (('predictive model', 'SVM'), 'do') (('women', 'breast cancer'), 'diagnose') (('distributions', 'histograms'), 'see') (('SVM', '99'), 'conclude') ", "extra": "['biopsy of the greater curvature', 'disease', 'patient', 'test', 'diagnosis', 'procedure']"}
{"name": "eda regression with statsmodels and scikit learn ", "full_name": " h1 Workflow h1 1 Load relevant libraries h1 2 Problem definition h1 3 Data Acquisition h1 4 Target variable inspection h1 5 Feature inspection h2 5 1 Feature Explanation h3 5 1 1 Cut h3 5 1 2 Color h3 5 1 3 Clarity h3 5 1 4 Carat h3 5 1 5 Depth and Table h4 5 1 5 1 Depth h4 5 1 5 2 Table h3 5 1 6 x y and z h3 What we learn h2 5 2 Data cleaning h3 Nulls h3 Data types h2 5 3 Feature engineering h1 6 Exploratory Data Analysis EDA h2 6 1 Univariate h3 Carat Weight h3 Cut h3 Color h3 Clarity h3 Depth h3 Table h3 Depth Table ratio h3 Valuable diamonds are they distributed differently h3 Conclusions What we ve learned h2 6 2 Multivariate h2 Cut vs Clarity h2 Cut vs Color h2 Clarity vs Color h2 Depth vs Cut h2 Table vs Cut h2 Depth vs Table vs Cut h2 Fixed carat how is price related to other features h3 Cut vs Color h3 Cut vs Clarity h3 Color vs Clarity h3 Conclusions what to expect from the models h1 7 Modelling h2 7 1 Statsmodels h3 7 1 1 First Model price carat h3 7 1 2 Second model log price carat h3 7 1 3 3rd model price carat carat 2 carat 3 carat 4 h3 7 1 4 4th model log price carat carat 2 carat 3 carat 4 h3 7 1 5 5th model log price ALL features h3 7 1 6 6th model log price ALL features depth table h3 7 1 7 7th model log price ALL features depth table cut h3 Statsmodels Conclusions h2 7 2 Scikit Learn h3 7 2 1 Get the data h3 7 2 2 Ridge Regression L2 norm penalization h3 7 2 3 Lasso Regression L1 norm penalization h3 7 2 4 Elastic Net Ridge Lasso h4 Coefficient comparison Ridge and Lasso h3 Scikit Learn Conclusions ", "stargazers_count": 0, "forks_count": 0, "description": "Cut cut_grading https cdn. At the lower clarities may have an effect on the diamond s durability. fit model with best paramater s 4. carat_ags https cdn. Carat is highly related to price in a non linear fashion log transforming price adding polynomial terms improved the fit visually2. The value of a finished diamond is based on this combination. Is there a relationship between the predictors and price 2. Load relevant libraries2. Two diamonds of equal weight may be unequal in value depending upon other determining factors such as Cut Color and Clarity. Let s try turning to bins discretizing Depth values balanced across bins. Cut vs ClarityInterpretation Table 13. AGS grades cut on a scale from 0 to 10 with 0 being Ideal and 10 being Poor. png AGS 0 Flawless or Internally Flawless no inclusions or blemishes visible under 10x Internally Flawless diamonds have no inclusions visible under 10x but can have very minor blemishes marks and features confined to the surface only. As most diamonds are approximately round shaped we expect x y. Carat With larger diamonds come higher prices. JPG No null entries as observed with the. png In a grading report table percentage is calculated based on the size of the table divided by the average girdle diameter of the diamond. Are there outliers 4. The following quote from the Gemological Institute of America summarizes the __ diamond quality factors https www. Inspect coefficients visually As we have observed the GridSearchCV actually dound the best value for alpha to be very low. AGS 1 or 2 VVS has minute inclusions that are difficult for a skilled grader to see under 10x magnification. inspect coefficients5. Of highly priced diamonds Three highest prices maximum grades for clarity and color Fourth highest price maximum grades for cut and color 2nd highest for clarity Between diamonds close in carat exceptionally good quality drives price up. Apparently large values above 4 are not absurds but big diamonds. edu diamond quality factor __ Diamonds with certain qualities are more rare and more valuable than diamonds that lack them. Set up GridSearchCV find best parameter s 3. Problem definitionWe want to predict diamond price continuous numerical based on certain measurements features using use prices already available. org resource resmgr images GemsJewelry 116161409755629. On the other hand I don t expect to any of the dimensions to be largely relevant as other variables already capture their importanca with them. com wp content uploads 2013 02 depthpercentagesofdiamond. On the other hand a depth of 65 percent for a round diamond would be excessive and be detrimental to its beauty. Again we trun to discretization for better visualization. 0 replace with the mean x value over the entire dataset3. html __ y Xw 2_2 alpha w 2_2 This additional term penalizes large coefficients. Is there any particular pattern for the other variables Let s arbitrarily look at diamonds above 10 000. For the remaining observations when x is absurd 15 or 0. The verbal descriptors are AGS Ideal Excellent Very Good Good Fair and Poor. Using a master set of diamonds specifically chosen based on their range of color a grader picks up the diamond and places it next to the individual diamonds in the master set. A depth percentage that may be too much for one shape might be essential for another. AS a result the coefficients are not shrinked and feature selection is not performed. This is as far as my expertise of both APIs go for now so I stop here. First Model price caratAs a first model I start with the simplest possible as a starting point. 0 aproximate using depth z average x y 100 showed in the Feature Explanation. Target variable inspection5. We then try the polynomial approach on carat. Color vs ClarityInterpretation Table 16. jpg No null entries as observed with the. png No null entries as observed with the. 200 grams or 1 5 gram and is subdivided into 100 points. Depth percentage https beyond4cs. Although some preliminary analysis found no missing values NaNs it seems that 0. ClarityAgain same overall pattern majority of cases receving low price lower grades with higher mean prices DepthAlone doesn t help predicting price. 7 7th model log price ALL features depth table cutOne last model now I will try removing cut since it seemed to display a low effect on price in the multivariate analysis cross tables want to check. We ll see with Statsmodels that this will in fact improve the model and why it is so but for now I won t do that. 850 good for a starting value Coefficients are significant as p values are low F test for regression states there is a correlation between predictors and response residuals are non normal form Omnibus and Jarque Bera Proceeding to examine residuals 1. Residuals plot displays that variance of error terms around 0 got more or less constant Studentized Residuals Plot display there are still high residuals 7. Feature engineeringI am not very skilled in this aspect but one idea comes to mind since cut is related to depth and table I combine depth and table into one variable. The modern clarity scale was invented in the 1950s by a former president of GIA Richard T. Also approximating a diamond for a prism we should expect carat to be proportional to x y z. Regarding the best model Model 5 log price polynomial carat presented the best behavior in terms of residuals. TableAnalog to depth doesn t seem to help predicting price. Table appear to have a negative correlation with price 6. For simplicity and to prevent high collinearity from affecteing the coefficient estimates of the model I ll drop x y z since carat seem toSince depth_table_ratio doesn t add information will also drop alongside epth and table bins. Below we look at the count of diamonds once again. clarity_grading https cdn. How many Depth 65 around 835 diamonds values of x y and z don t particularly stand out z just seems to be close to them probrably due to the shape of the cutDepth 58 around 581 diamonds values of x y and z don t particularly stand out z just seems to be far from them probrably due to the shape of the cutNo reason to cut out points outside Inter Quartile Range of boxplot but it s probably a good thing to verify how cut and depth interact in Exploratory Data Analysis. Feature ExplanationAs I know absilutely nothing about diamonds beforehand checking some literature is always a good idead. Are there missing values 2. A few points we may want to check 1. Data cleaningThis step is crucial. 936 a very significant increase Coefficient estimates still significant F statistic display there is high relationship between predictors and response still Omnibus and JarqueBera suggest residuals are still far from normal Skew is very close to zero suggesting more symmetrical residuals Kurtosis is somewhat large indicating more concentration of residuals around zero meanUp until now I ve only looked at the residuals plot but now we take a look at the Studentized Residuals as well the Residuals divied Residuals plot displays that variance of error terms around 0 got more or less constant LOWESS line is almost a straight line Studentized Residuals Plot display there are high residuals 7. The size and severity of these flaws determines the grade. org page diamondcolor __ of a diamond actually refers to the lack of color in a diamond with perfectly colorless diamonds considered the highest quality with the highest value and brown or yellow diamonds being the lowest quality. jpg Large diamonds are rarer than smaller ones and as the carat weight increases the value of the diamond increases as well. ColorThe __ color https www. Fit w best parameter s 4. Therefore I won t start with a simple model here and build it up rather I ll use Ridge and Lasso regressors from Scikit Learn regularized regression on the model with all features and see if I come to similar conclusions regarding feature importance and prediction capability. Exploratory Data Analysis EDA 6. Depth Aside from having less points outside the box and whiskers the distributions seem analogous. Need to look at combination between color and other quality factors and how they affect diamond prices. Depth Table ratioLike depth and table doesn t seem to be correlate with price. org stable modules generated sklearn. Table_percentage https beyond4cs. AGS 3 or 4 VS have minor inclusions. 6 weight 1 carat or less. CutThe __ cut https www. 5 Inter Quartile Range but there are too many to be outliers probrably are highly priced diamonds therefore can t lose this information. Table Continuous numerical variable check for missing values absurd values scale and possible errors. Also majority of diamonds have low carat weight. NullsNo values missing or encoded as NaN. R 2 achieved of 0. Cut Not really good to see as there are way less highly priced diamonds. build pipeline to transform the data and apply a grid search for best parameters2. z is the absolute value of depth and should be coherent with the depth x and y values. com grading depth and table values __ I got information about depth and table. After this transformation the distribution of values allows for better statistical analysis and seems to improve models performances. dtype is float64 so only numeric entries. This is my first practice Kernel in Data Science. Seems to confirm that high quality grades increase price. From this we learn that cut may help estimate depth and table but the other way around is not true. LOWESS Locally WEighted Scatterplot Smoothing curve shows a U shape suggesting a non linear relationship is present2. No data type errors or typos. In the case 3 it might be that we ll need to perform some more cleaning steps. Second model log price caratFirst just the log transformation of the response. Below I extract the features of interest for polynomial transformation and separately the feaures to go untouched in this case. info performed at the beginning of the cleaning stage we know there are no missign entries but if we didn t remember that Values highly concentrated between 50 and 65. Inspect coefficients visually And the result is very similar to the that obtained with Statsmodels carat has the biggest average weight on price followed by the 2nd order term of carat depth table and cut have very low weight on price the quality features have increasing weight with increasing quality grade as expected. Table is high or low probrably due to shape of cut. Features inspection6. Hope you ve enjoyed and that you feel like contributing commenting and upvoting basic libraries for data acquisition handling and visualization libraries for modelling check fror null values on target variable turn to categorical data type and order turn to categorical data type and order create Boolean mask to subset DataFrame compute mean value of x substitute on the dataFrame find rows where z is absurd define function to calculate z apply on dataframe create bins create column for bins create bin list create column for bins create bins list create columns for bins build polynomial carats exclude cons take quality features concatenate carat and quality features get responde DataFrame train model take quality features concatenate carat and quality features train_y_df remains as used in the previous example train model remove cut columns from DataFrame train_y_df is the same as used for the previous model train model as DataFrame as DataFrame create identifiers for polynomial features and linear features create the functions to get each subset of the data display polynomial features after transformation display first few lines of linear features in this case no other operation is performed join both pipelines into one display final resulting array s first 5 rows create identifiers for polynomial features and linear features create the functions to get each subset of the data join both pipelines into one create the regressor pipeline perform first fit and use as starting point set up grid of alphas to search set up GridSearch object to select best alpha and fit to data fit to data and print best scores and parameters predictions and actual values as arrays create the regressor pipeline perform first fit and use as starting point set up grid of alphas to search set up GridSearch object to select best alpha and fit to data fit to data and print best scores and parameters get prediction and actual values as arrays create alphas space for search prepare GridSearch arguments get prediction and actual values as arrays. We follow with a visual inspection on the distribution of prices. Depth vs CutInteresting result it seems that high cut grades tend to be found more often around 60 and 65 more concentrated. Next both approach are put to work together. Data AcquisitionI separate a DataFrame data so that the changes I perform are recorded on it but there s still one version of the data untouched. for a given carat and cut higher color grade related to increase in price. org resource resmgr images GemsJewelry 79661461782004. Residuals still ehxibit highly non linear pattern and heteroscadacity wasn t really taken care for. So a 60 percent table means that the table is 60 percent wide as the diamond s outline. Inspect coefficients visually As observed before the L1 penalty term in this particular dataset makes the alpha go very low almost turning off the regularization. Depth no very clear relationship with price 7. org page diamondcut __ of a diamond refers to how well the diamond s facets interact with light the proportions of the diamond and the overall finish of the diamond. How many Values of x y and z don t particularly stand out. How is it distributed over the range of values Does it seem to follow a particular distribution We begin by taking a look at some 10 random observations Checking the data type and some statistics. 7Visually inspecting Setting the axes limits between 0 and 15 reveals that the hypotheses that x is approximately equal to y was somewhat accurate. Target variable inspectionIt s a continuous variable. color_grading https cdn. In case we forgot that Values highly concentrated between 58 and 65 but there are observations above and below. It s a Supervised Regression task. Also I ll use some of the Scikit Learn s funcionalities to speed the preprocessing steps. Visualizaing What we ve learned so far overall higher the weight higher the price relationship between mean price and carat bin is not linear first three bins mean value increases far more than the proportional increase in carat diamonds between 2 and 3 carats and between 3 and 4 carats apporximately same mean price diamonds heavier than 3 carats the price still goes up with carat but the increase is more moderate there are lighter diamonds that were highly valued why For the last observation let s check highly priced diamonds with small carat weight. Residuals plot displays that variance of error terms around 0 got more or less constant Studentized Residuals Plot display there are some very high residuals even higher then before 7. x y and z x length in mm y width in mm z depth in mmThose are simply the dimensions of the diamonds. AGS 7 8 9 or 10 I have inclusions that are obvious at 10x magnification sometimes they can be seen with the naked eye. Carat__ Carat https www. x y and z Continuous numerical variable check for missing values absurd values scale and possible errors. Since we have confirmed that x y I propose a set of steps to deal with absurd dimension values in the following order 1. 1 was expected since we saw visually that price and carat relationship was not linear. Next when y is absurd 15 or 0. Questions we may want to answer 1. for a given carat and clarity higher cut grade doesn t necessarily mean increase in price. Regarding statistical metrics R 2 got smaller and no improvement is found. We ve visually tested both so we ll now model them to see the results. Inspect residuals Residuals plot resembles that of Ridge Regression as well. png The ideal depth percentage varies with the shape of the diamond. This is largely due to these dimensions being highly correlated with carat and between themselves. 985 one indication that depth and table didn t help much Coefficient estimates are all significant F statistic s p value suggests there is high relationship between predictors and response Omnibus and JarqueBera still high but we ll see from residuals that theyare better behaved Skew is very close to zero suggesting more symmetrical residuals Kurtosis is somewhat large indicating more concentration of residuals around zero mean Condition Number got reduced and warning is now gone indicating that collinearity is not a huge issue now would need to see VIF statistic ti be sure but for simplicity won t do that now. Clarity clarity_grading https cdn. Domain and historical knowledge would be useful here but in the absence of any I ll simplify. Residuals should be equally scattered around zero line for all fitted values constant variance of residuals or homoscedacity the plot displays a non equally distributed behavior i. cut_grading https cdn. inspect residuals 7. Notice the ouput of lin_pl pipeline is a DataFrame whereas the output of poly_pl pipeline is an array. com wp content uploads 2013 02 tableandtablepercentagesofdiamond. It just lazily treats the data on demand for the algorithms and makes it easier to change the polynomial features degree. Scikit LearnThrough Statsmodels we ve already tried out a few models and using its statistical API came to a few conclusions regarding important features. For instance a princess cut with a 75 or 77 percent depth would still be considered acceptable and can yield an attractive diamond. 1 When y is availabele but x is absurd 2 When x is absurd but y is not availableFor simplicity as this only seems to happen when both are zero I do 3 Where x is available but y is absurd 4 When z is absurd Now all values seem to be fine 5. Can we predict price with the predictors available 3. Drawing a pair plot in order to visualize as scatter plots The same kind of relationship found between price and carat is reproduced between price and the dimensional features x y and z. Lasso Regression L1 norm penalizationOn top of the Ordinary Least Squares Lasso Regression adds a penalty term that is proportional to the absolute magnitude of the coefficients of the regression. cut is receiving bad reputation for something it may be not responsible for. 2 could be solved using a non linear transformation on price such as sqrt price or log price. negative zero strings data type problems etc. Hypothesis Like with cut the overall behvior is possibly being adversily affected by the majority of diamonds being light. Coefficient comparison Ridge and LassoNotice that even with a very low alpha Lasso shrinks the coefficients even more. No null entries as observed with the. in their book Introduction to Statistical Learning. However the increase in value is not proportionate to the size increase. In practice this means regularization is almost absent. No particular relationship. Now looking at y vs carat. org resource resmgr images GemsJewelry 135781409756963. 9 very weird when maximum x is about 10. Like for depth let s try discretizing and check for patterns. In fact the Table for price seems a combination of the effects of carat and count of diamonds. Although polynomial terms tend to be somewhat collinear this value wasn t so high when only the carat terms were used Looking back at the pairplot we see that depth and table are fairly collinear. When they re put together using FeatureUnion the final output is coerced to an array. Since many inclusions and blemishes are very small and can be difficult to see with the naked eye they are graded at 10x magnification. set up and perform GridSearchCV3. On a grading report there are normally two measurements of depth the first is the actual depth measurement in millimeters and the second is the depth percentage which shows how deep the diamond is in relation to its width. Clarity vs Color Color seems to matter more for low cut grades. ColorOn the basis purely of color higher grades seem to decrease the value. for a given carat and cut higher clarity grade related to increase in price. Predict and print metrics on test set 6. 3rd model price carat carat 2 carat 3 carat 4Now the U shaped is practically gone suggesting a better fit but heteroscedacity is still present. One way to solve it would be a non linear transformation on carat. For example a 1 carat diamond will cost more than twice that of a \u00bd carat diamond assuming Color Clarity and Cut grade are the same. Mean price seems to decrease as depth to table ratio increases. Create pipelines to extract and treat differently each subset of the data. Depth and TableFrom a different __ reference https beyond4cs. AGS has a proprietary numeric and verbal descriptors for cut. Minimizes 1 2 n_ samples y Xw 2_2 alpha l1_ ratio w _1 0. Define cmap for bivariate visualization Cut vs ClarityHow does the interaction between cut and clarity affect the mean price In Table 1 for a given value of cut higher mean prices are more associated with lower clarity grades. In order to leave the whole functionality in just one cell I reproduce the complete pipeline below Now we use this union pipeline alongside other functionalities. Taking a quick glance at the distribution As expected higher carat weights linked to greater dimensions of diamonds. About the distribution highly skewed to the right 1 4 of the diamonds below 950 50 of the diamonds below 2 400 1 4 of the diamonds between 2 400 and 5 300 50 of the diamonds between 950 and 5 300Given the skewness of the distribution I ve seen in a lot of kernel authors perfoming a log transformation on the target variable. These are known as the 4Cs. 983 one indication that cut didn t help much Coefficient estimates are all significant F statistic s p value suggests there is high relationship between predictors and response Omnibus and JarqueBera still high but we ll see from residuals that theyare better behaved Skew is very close to zero suggesting more symmetrical residuals Kurtosis is somewhat large indicating more concentration of residuals around zero meanResiduals plot behaves similarly but now we see a few more high studentized residuals appearing. To reduce collinearity and increase the accuracy of the coefficient estimates we ll try next removing depth and table. Taking a look at some summary statistics The. describe method reveals that there are at least three suposedly absurd situations x 0 no sense in a diamond with zero length y 58. 4 Elastic Net Ridge Lasso Combines the concepts of L1 and L2 regularizations by letting one chose the weight of each through the l1_ratio parameter. Why would higher cut grades have lower prices Hypotheses Majority of diamonds have good cut grade. Depth vs Table vs CutAs observed better cuts tend to be more restrictive in terms of the range of depth and table values. Indeed log transforming seems to bring the data closer to fit with the help of a third order polynomial. Carat weight has positive correlation with price and relationship seems highly non linear carat distribution is different between more valuable and less valuable diamonds. It also happens to be the largest facet on a diamond and plays a vital role on brilliance and light performance of a stone. Color color_grading https cdn. Feel free to make on this Kernel better as well by comenting and suggesting. Weight does not always enhance the value of a diamond either. As expected from the feature explanation section these entries are categories written in the form of text. Fixed carat how is price related to other features How quality features fare for a fixed carat does increase in quality mean increase in price So we select carat 0. Next let s look at the other end low values. TableThe table refers to the flat facet of the diamond which can be seen when the stone is face up. info method helps analysing a lot on information regarding data preparation. What we learn From the basic reserach of the literature we expect carat clarity color and cut to play a big role diamond price depth and table are also important but not clearly how x y and z are important as they help determine carat and depth but seem to be of secondary importanceI won t assume an order of importance between the 4 Cs since for me it isn t quite clear from the previous explanations which order this should be. Machine Learning algorithms don t work with NaNs how missing values are encoded in pandas and numpy and some are very sensitive to outliers and absurd values. UnivariateHow is each predictor alone related to price Carat WeightPartiotining carat into multiple bins for visualization shows carat is positively related to price relationship seems non linearLooking at how carat changes with price seems to hint yet again that log transforming price might be a good idea because of the shape of the relationship. 9 above Very Good seems to be negatively related to price Here a non expected behavior appears. org page 4cs __ which is presented below very summarized. Diamond clarity is the presence or absence of characteristics called inclusions in the diamond. However by including categorical features like clarity and color model 7 seemed to outperform model 5 in terms of prediction as measured by the R 2 although there are high studentized residuals for all fitted values. Conclusions What we ve learned1. Next turn into category and set an order of importance. All predictors when used solely have large and small priced diamonds over the entire range of their values categories. Get the dataInstead of preparing a different complete DataFrame as I did for Statsmodels I ll use FunctionTransformer and FeatureUnion functionalities to transform the data on the fly for each model. Expect to see majority of low prices because majority of diamonds are are light. CutAbout cut 87. 06 weight more than 3 carats. Model didn t suffer much R 2 dropped to 0. 5 5th model log price ALL featuresThis time will use data as DataFrame for better interpretation of results. Both are suggested by Hastie T. In the American Gem Society there s a comprehensive explanation of the __ 4 C s of diamonds https www. Later I go from what I ve learned and build on top of that with Scikit Learn API as it s to me more friendly and more flexible. What about the values themselves Some very low and some very high. Clarity__ Clarity https www. Finally when z is absurd 15 or 0. Depth Continuous numerical variable check for missing values absurd values scale and possible errors. As in Ridge alpha term controls the regularization strength higher alpha stronger regularization smaller coefficients 1. For simplicity I ll arbitrarily establish that above 15 is absurd. This is the data type of strings text in Python. Cut vs ColorInterpretation Table 10. When turned to bins table seems to display a positive correlation with price except for depths greater than 65. Load relevant libraries 2. 985 a very significant increase Coefficient estimates are all significant F statistic s p value suggests there is high relationship between predictors and response Omnibus and JarqueBera suggest residuals are far from normal Skew is very close to zero suggesting more symmetrical residuals Kurtosis is somewhat large indicating more concentration of residuals around zero mean Condition Number is very high indicating high collinearity between terms. My main goal was to use some basic Statsmodels API to evaluate some simple regression models. When y is available but x is absurd 15 or 0. Let s try using a table normalization and some colors In the case of the top 3 cut grades Highly priced diamonds don t seem to present a different distribution across cut grades both have majority of diamonds on high grades pprobably because overall there are more good grades than bad ones. It is relavant to dig a little deeper here and understanding why might it be that these entries are encoded as strings 1. Color In the case of color highly priced diamonds seem to appear more often alongdside bad color grades than with good color grades. As a consequence Lasso is sometimes used to perform feature selection least important are left out. Data typesThree variables with object data type. The main purpose of the table facet is to refract light rays entering the diamond and to allow reflected light rays from the pavilion facets back into the observer s eye. html __ 1 2 n_ samples y Xw 2_2 alpha w _1 This additional term penalizes large coefficients but different from Ridge it actually shrinks smaller coefficients down to zero sparsity. Alone not a good predictor of price. predict on test set6. AGS 5 6 or 7 SI have noticeable inclusions that are fairly easy to see under 10x magnification sometimes these inclusions can be visible to the unaided eye. However when we look at Tables 2 and 3 we verify that the mean price is driven mainly by mean carat weight. for a given carat and color higher cut grade doesn t necessarily mean increase in price. Moreover Data Cleaning focuses on removing problematic data entries whenever possible be it for computational and or statistical reasons. 4th model log price carat carat 2 carat 3 carat 4 R 2 increased to 0. Let s check the potentially absurd values. print and store metrics R 2 Explained Variance RSME MAE7. The diamond grader then decides the color grade based on the saturation of the color compared to the master set. org page diamondclarity __ is the state of being clear or transparent. Specifically it seems to be between 55 and 63. The alpha term controls the regularization strength higher alpha stronger regularization smaller coefficients 1. From the heatmap we see that carat x y and z are highly correlated with price and between themselves. Depth don t seem to have any clear relationsip with price4. Chaging data type is good practice here for visualization and data analysis. Looking at the count of diamonds below. Feature inspection 5. As explained Dataset page depth here is the depth percentage which can be approximated by depth z average x y 100. 3 for the maximum number of diamonds with same carat. In doing so the coefficient estimate for table got a p value 0. Carat Continuous numerical variable then it s good to check for missing values absurd values scale and possible errors. org page diamondcarat __ is the unit of measurement for the physical weight of diamonds. Are there absurd values i. Thefere the next model presents only the version where I removed both depth and table. Ridge Regression L2 norm penalizationOn top of the Ordinary Least Squares Ridge Regression adds a penalty term that is proportional to the square of the coefficients from the regression. Exploratory Data Analysis 6. By default uses alpha 1 and l1_ratio 0. What we ve done used Statsmodels to build some less complex models for the price task regression evaluated some statistical aspects of each model developed some knowledge about the importane of the features got an R 2 of about 0. Again similar behavior. Seemingly high number of high values above 1. 5 meaning it became non significant. Clarity No clear difference in distributions on the basis of clarity. Table vs CutHere a very similar finding to that of table higher cut grades tend to be found around specific table values. MultivariateFirst it s better to encode quality categorical variables so they get visible. Inspect residuals As observed in the Statsmodels models although there are some very high residuals there are some good aspects to this Residuals plot Residusl resemble normality kind of Residuals seem to be equally dispersed around zero mean for all fitted values homoscedacity 7. Next we do indeed create a partition in carat weight but we split by 1. 985 on the training set a few statistics pointed out that the model used might not be the best one however the ease of interpretation is in favor of the model built. For better understanding it s good to go step by step. When used together they describe the quality of a finished diamond. org resource resmgr images GemsJewelry 164901433526626. In short inclusions are the internal or external flaws of the diamond. 5 alpha 1 l1_ ratio w 2_2 Since two parameters are going to be tested nw we use RandomizedSearchCV to reduce the workload instead of testing 6 x 9 54 combinations it sample a number of them and return the best results. However being inside this range does not guarantee a good cut. Below I summarize the entries on each column to see unique values. are they text data 2. What we do next use some powerful tools like Cross Validation in Scikit Learn to evaluate other models evaluate the generalization capacity of each model on the test set 7. From the plot in fact the coefficients resemble those of Ridge regression. Statsmodels ConclusionsWell that s pretty much as far as my knowledge in Linear Regression Statistics and Statsmodels go. Which predictors seem to have greater impact 4. Hope to be contributing to the Data Science community. If so how strong it this relationship 3. Scikit Learn ConclusionsAfter using Statsmodels to investigate linear models non linear transformation and analyse some easily available statistics we ve used Scikit Learn s API to build Pipelines to create polynomial terms on th fly and grid search for the best parameters perform regularized regressions with Ridge and Lasso investigate results on test setsBoth API s are great tools to fit and analyse models with some differences on outputs and capabilities. Conclusions what to expect from the models1. 6 6th model log price ALL features depth tableFor this model I tried first removing depth since it has weaker relationship with price. With minor modifications it has been the universal standard ever since using verbal descriptors most are now familiar with Flawless Internally Flawless VVS1 VVS2 VS1 VS2 SI1 SI2 I1 I2 and I3. Cut vs ColorSimilar behavior to the observed for cut vs clarity price is mainly affected by carat but the count of diamonds shifts towards higher grades. Valuable diamonds are they distributed differently As all boxplots displaying price display a large number of diamonds outside Inter Quartile Range I investigate a little further highly priced diamonds. Table from univariate analysis increase in table is related to decrease in price expect to see negative coefficient4. 5 weight 2 carats or less. Only three rows present values above 12. It is not to be confused with the shape like emerald or round or facet arrangement like brilliant or step cut but is instead a reference to the craftsmanship of the diamond and how it factors into the diamond s brilliance. 8 very weird when maximum x is about 10. DepthThe depth of a diamond is its height in millimeters measured from the culet to the table. Cut Color Clarity appear to have negative correlation with mean price apart from Color frequency of diamonds is very similar across all grades. Here different than what has been seen previously both color and clarity grades seem to increase price very clearly. are they categories written as text 3. are they numeric that due to errors got coerced into object It s important to differentiate case 2 from case 1 as there s a specific category data type in Python that saves memory and allows for ordering which helps in data analysis tasks. Cut Color and Clarity given a carat value we expect them to increase price as the grade is higher but Color and clarity clearly displayed that increase when combined for a fixed carat value Cut from previous literature is expected to increase price but we couldn t see it so clearly other aspects may be affecting 3. 0 encodes missing values in this dataset. The consequence is that smaller coefficients tend to produce smaller penalties and the coefficients are shrinked. Table Very similar distributions as well. most of the diamonds carat 1 on average small price most of the diamonds Ideal cutBy association Ideal cut small pricesIt should be true then that cut only drives up the price when comparing same carat diamonds when alongside other distinctive quality factorsOn Bivariate Multivariate analysis predictors relationships between themselves we wnat to check that. The numeric descriptors for the Diamond Cut Grade follow the American Gem Society s standards for how well a diamond is cut. The equation below is taken from Scikit Learn s __ documentation https scikit learn. Clarity grade is determined on a scale of decreasing clarity from the highest clarity Flawless or FL to the lowest clarity Included 3 or I3. ", "id": "alvaroacapelo/eda-regression-with-statsmodels-and-scikit-learn", "size": "38500", "language": "python", "html_url": "https://www.kaggle.com/code/alvaroacapelo/eda-regression-with-statsmodels-and-scikit-learn", "git_url": "https://www.kaggle.com/code/alvaroacapelo/eda-regression-with-statsmodels-and-scikit-learn", "script": "sklearn.metrics cross_val_score explained_variance_score Ridge FeatureUnion Lasso r2_score cross_validate mean_squared_error seaborn numpy sklearn.pipeline PolynomialFeatures FunctionTransformer sklearn.model_selection LabelEncoder matplotlib.pyplot pandas Pipeline StandardScaler ElasticNet GridSearchCV mean_absolute_error sklearn.linear_model sklearn.preprocessing RandomizedSearchCV train_test_split statsmodels.api ", "entities": "(('Ridge alpha term', 'regularization strength higher alpha stronger regularization smaller coefficients'), 'control') (('depth', 'beauty'), 'be') (('whenever it', 'computational reasons'), 'focus') (('cut high grades', 'Depth CutInteresting'), 'result') (('com grading table _ I', 'depth'), 'depth') (('I', 'following order'), 'confirm') (('carat', 'z.'), 'approximate') (('best however ease', 'model'), 'set') (('basis', 'value'), 'seem') (('Also majority', 'carat low weight'), 'have') (('We', 'carat'), 'try') (('highest quality', 'highest value'), 'refer') (('setsBoth API', 'outputs'), 'perform') (('main goal', 'regression simple models'), 'be') (('However being', 'good cut'), 'guarantee') (('carat weight', 'diamond increases'), 'be') (('com wp content', '2013 02 depthpercentagesofdiamond'), 'upload') (('I', 'target variable'), 'skewness') (('it', 'multivariate analysis cross tables'), 'feature') (('I', 'little further highly priced diamonds'), 'distribute') (('z', 'depth values'), 'be') (('which', 'this'), 'be') (('Hypothesis overall behvior', 'diamonds'), 'affect') (('Table', 'diamonds'), 'seem') (('so clearly other aspects', '3'), 'expect') (('we', 'that'), 'be') (('when x', 'remaining observations'), 'for') (('quality high grades', 'price'), 'seem') (('Depth don t', 'price4'), 'seem') (('when stone', 'diamond'), 'refer') (('2', 'sqrt such price'), 'solve') (('Below we', 'diamonds'), 'look') (('it', 'price'), 'feature') (('s', 'carat small weight'), 'visualizae') (('some', 'very outliers'), 'work') (('We', 'data type'), 'distribute') (('heteroscedacity', 'practically better fit'), 'carat') (('alpha', 'actually best value'), 'dound') (('Inter Quartile 5 too probrably highly priced therefore t', 'information'), 'Range') (('carat highly non linear distribution', 'more valuable less diamonds'), 'have') (('This', 'Python'), 'be') (('given carat', 'price'), 'mean') (('GridSearch arguments', 'actual arrays'), 'create') (('mean price', 'carat mainly mean weight'), 'verify') (('Two diamonds', 'Cut such Color'), 'be') (('continuous numerical', 'use prices'), 'want') (('so we', 'results'), 'test') (('table', '60 percent outline'), 'mean') (('sometimes inclusions', 'unaided eye'), 'have') (('Here non expected behavior', 'negatively price'), 'seem') (('clarity modern scale', 'GIA Richard T.'), 'invent') (('alpha term', 'regularization strength higher alpha stronger regularization smaller coefficients'), 'control') (('cut', 'still attractive diamond'), 'consider') (('depth', 'table'), 'be') (('AGS', 'verbal cut'), 'have') (('s', '10 000'), 'be') (('regularization', 'practice'), 'mean') (('When together they', 'finished diamond'), 'describe') (('majority', 'diamonds'), 'expect') (('much R', '0'), 'suffer') (('s', 'patterns'), 'let') (('depth', 'back pairplot'), 'tend') (('feature selection', 'result'), 'shrinked') (('plot', 'residuals'), 'scatter') (('L2 one', 'l1_ratio parameter'), 'combine') (('how well facets', 'overall diamond'), 'refer') (('s', 'bins'), 'let') (('now so I', 'APIs'), 'be') (('absilutely nothing', 'beforehand literature'), 'ExplanationAs') (('AGS grades', '0'), 'cut') (('final output', 'array'), 'put') (('t', 'price'), 'seem') (('log transforming yet again price', 'relationship'), 'relate') (('Mean price', 'table ratio increases'), 'seem') (('Inspect residuals Residuals plot', 'Ridge Regression'), 'resemble') (('distributions', 'box'), 'seem') (('I', 'still one data'), 'separate') (('we', 'more cleaning steps'), 'be') (('it', 'me'), 'go') (('skilled grader', '10x magnification'), 'have') (('didn Values', 'highly 50'), 'info') (('pattern ClarityAgain same overall majority', 'DepthAlone doesn t price'), 'help') (('alpha', 'very low almost regularization'), 'inspect') (('grader', 'master set'), 'pick') (('it', 'something'), 'receive') (('quality features', 'quality increasing grade'), 'have') (('model log price 4th carat', '2 3 4 2 0'), 'increase') (('distribution', 'models performances'), 'allow') (('pretty much as far knowledge', 'Linear Regression Statistics'), 'ConclusionsWell') (('where I', 'depth'), 'present') (('quality exceptionally good drives', 'close carat'), 'price') (('Again we', 'better visualization'), 'trun') (('same kind', 'price'), 'reproduce') (('Next s', 'other end low values'), 'let') (('org page diamondcarat _ _', 'diamonds'), 'be') (('I', 'model'), 'get') (('s', 'potentially absurd values'), 'let') (('coefficient so estimate', 'p value'), 'get') (('both', 'pprobably overall more good bad ones'), 'let') (('interaction', 'clarity more lower grades'), 'affect') (('doesn t', 'price'), 'table') (('that', 'approximately y'), '7visually') (('main purpose', 'back eye'), 'be') (('which', 'data analysis tasks'), 'be') (('Cut', 'higher grades'), 'affect') (('we', 'test'), 'use') (('it', 'Exploratory Data Analysis'), 'stand') (('sometimes they', 'naked eye'), 'AGS') (('depth here which', 'depth'), 'be') (('depth ideal percentage', 'diamond'), 'png') (('Below I', 'separately case'), 'extract') (('previously color grades', 'price'), 'seem') (('value', 'combination'), 'base') (('Residuals plot variance', 'very high even higher then 7'), 'display') (('they', 'quality categorical variables'), 's') (('it', 'best results'), '2_2') (('Now we', 'other functionalities'), 'reproduce') (('size', 'grade'), 'determine') (('2 improvement', 'metrics statistical R'), 'get') (('ti', 'that'), 'suggest') (('Lasso', 'feature sometimes selection'), 'leave') (('Scikit LearnThrough Statsmodels we', 'important features'), 'try') (('that', 'regression'), 'norm') (('Carat Continuous numerical then it', 'missing values'), 'variable') (('that', 'another'), 'be') (('following quote', '_ _ diamond quality factors https www'), 'summarize') (('how diamond', 'width'), 'be') (('they', '10x magnification'), 'grade') (('entries', 'text'), 'be') (('it', 'values missing NaNs'), 'find') (('Table', 'price'), 'appear') (('p values', 'Jarque Bera residuals'), 'good') (('Apparently large values', '4'), 'be') (('com wp content', '2013 02 tableandtablepercentagesofdiamond'), 'upload') (('more than twice that', 'Color Clarity'), 'cost') (('diamond grader', 'master set'), 'decide') (('quality other how they', 'diamond prices'), 'need') (('Carat', 'fit visually2'), 'be') (('Values', 'highly 58'), 'forget') (('I', 'arbitrarily 15'), 'establish') (('Now values', '3'), '1') (('200 grams', '1 5 100 points'), 'subdivide') (('output', 'poly_pl pipeline'), 'notice') (('predictors', 'greater impact'), 'seem') (('so I', 'that'), 'see') (('linear non relationship', 'U shape'), 'show') (('info method', 'data preparation'), 'help') (('other way', 'depth'), 'learn') (('Weight', 'diamond'), 'enhance') (('don t', 'y'), 'stand') (('Clarity', 'low cut grades'), 'seem') (('So we', 'carat'), 'increase') (('entries', 'strings'), 'be') (('it', 'step step'), 's') (('html _ _ Xw w 2_2 2_2 additional term', 'large coefficients'), 'y') (('I', 'one variable'), 'be') (('We', 'prices'), 'follow') (('Table', 'cut'), 'be') (('Hypotheses Majority', 'cut good grade'), 'have') (('equation', 'Scikit _ _ documentation https below scikit'), 'learn') (('it', 'zero sparsity'), '_') (('Also I', 'preprocessing steps'), 'use') (('I', 'any'), 'be') (('largely other variables', 'them'), 'expect') (('log Indeed transforming', 'third order'), 'seem') (('y width', 'simply diamonds'), 'be') (('largely dimensions', 'themselves'), 'be') (('we', 'predictors'), 'predict') (('However increase', 'size increase'), 'be') (('it', 'features polynomial degree'), 'treat') (('This', 'Data first Science'), 'be') (('One way', 'non linear carat'), 'be') (('Chaging', 'good here visualization'), 'be') (('we', '1'), 'create') (('It', 'light stone'), 'happen') (('Lasso', 'coefficients'), 'Ridge') (('z x y 100', 'Feature Explanation'), 'aproximate') (('Residuals plot variance', 'Studentized Residuals Plot more constant display'), 'display') (('I', 'feature importance'), 'win') (('we', 'next depth'), 'reduce') (('Residuals', 'heteroscadacity wasn really care'), 'ehxibit') (('better cuts', 'depth values'), 'observe') (('Cut Color Clarity', 'very grades'), 'appear') (('Specifically it', '55'), 'seem') (('Table', 'negative coefficient4'), 'relate') (('how it', 'brilliance'), 'be') (('Flawless Internally diamonds', 'surface'), 'AGS') (('Diamond clarity', 'diamond'), 'be') (('Condition Number', 'very high indicating high terms'), 'suggest') (('carat x y', 'themselves'), 'see') (('statistical aspects', '2 about 0'), 'use') (('LOWESS more constant line', '0'), 'estimate') (('log Model 5 price polynomial carat', 'residuals'), 'present') (('Below I', 'unique values'), 'summarize') (('a few more high studentized residuals', 'zero meanResiduals'), 'help') (('that', 'them'), 'be') (('coefficients', 'smaller penalties'), 'be') (('grading report table percentage', 'diamond'), 'png') (('coefficients', 'Ridge regression'), 'resemble') (('add', 'also epth bins'), 'for') (('Residusl normality resemble kind', 'values fitted homoscedacity'), 'be') (('Clarity grade', '3'), 'determine') (('how well diamond', 'American Gem standards'), 'follow') (('it', 'Flawless Internally Flawless VVS1 VVS2 VS1 VS2 SI1 SI2 I1 most now I2'), 'be') (('model log 5 5th time', 'results'), 'price') (('Carat', 'higher prices'), 'come') (('Model price First first I', 'starting point'), 'carata') ", "extra": "['biopsy of the greater curvature', 'test']"}
{"name": "nuclei segmentation tensorflow u net 0 327 027909 ", "full_name": " h1 1 Modules and global settings h1 2 Analyse data h1 3 Manipulate data h1 4 Score Metric h1 5 Implement the Neural Network Class h1 6 Train the Neural Network h1 7 Validate the neural network h1 8 Make Test Prediction h1 9 Submit ", "stargazers_count": 0, "forks_count": 0, "description": "Study how many objects in the masks can be identified. Save parameters tensors summaries. Make Test Prediction 8 bullet 9. Training on augmented data. Read images masks from files and resize them. Initialize summary writer. Load neural network and make prediction for masks. Python lists to store the training images masks and test images. The performance of an algorithm is evaluated on the mean average precision at different intersection over union IoU thresholds which will be referred to as the score in the following. Recursive use of function. Current number of log steps. Being constrained on kaggel hardware and running time we can train for 3 epochs which takes roughly 35 minutes. Store parameters. Type of neural network Name of neural network For storing parameters Log results in terms of epochs Count number of mini batches True use augmented data True use TensorBoard summaries True save the session Parameters that should be stored. A major reason for the score discrepancy can be explained by overlapping touching nuclei that are identified as a single nucleous by the current implementation. next mini batch Store losses and scores. Tunable hyperparameters for training. in case that no object is identified in one of the masks Returning parameters. Summary dataframe. Furthermore we implement data augmentation by making use of translations rotations horizontal vertical flipping and zoom. Each image and mask is stored as a 3 dim array where the number of channels is 3 and 1 respectively. Each model can be saved loaded and the training process can be visualized with TensorBoard. Train the Neural Network 6 bullet 7. Check one sample prediction in more detail. Assign predicted to true objects if they have any overlap. Resize predicted masks to original image size. True mask with true objects. The network achieves a score of 0. The network is written in TensorFlow. Create summary tensors for TensorBoard. On average the red green and blue channels have similar intensities for all images. Make Test Prediction 9. Transform lists into 4 dim numpy arrays. randint len x_train Create predicted mask from true mask. In case the current index is larger than one epoch. Train data used for evaluation. All summaries are written into the logs directory which is contained in the current working directory. Choosing an image size of 256x256 pixels the network requires roughly 30 training epochs before the training seems to converge. Train the Neural Network 7. Assign predicted to true background. 128 128 3 Generic tensors. Split training and validation data in the same way as was done for training the neural network. Number of different labels. Overall score on train set. Training on original data. Save summaries for TensorBoard. indices from top to down segment image and label different objects loop over each object excluding the background labeled by 0 Load neural network make prediction for test masks resize predicted masks to original image size and apply run length encoding for the submission file. There is the possibility to transform images into the grayscale sepctrum and to invert images which have a very light background. Stop after one iteration. Adam Optimizer adaptive moment estimation. Author Raoul Malm Abstract The 2018 Data Science Bowl Find the nuclei in divergent images to advance medical discovery provides in its first stage a training and test data set consisting of 670 and 65 microscopic images of varying size showing ensembles of cells and their nuclei. Analyse data 2 bullet 3. Implemented are functions to read images masks from files and to read basic properties of the train test data sets. Compute score and assign parameters. unit output layer. Mini batch size Keeping probability with dropout regularization Step size in terms of epochs Reduction of learn rate for each step Starting learning rate 1 keep_probability Set helper variables. Build U Net graph. len x_batch Valid data used for evaluation. False positives and false negatives. Use augmented data. In case you want to reload and preprocess the raw data. For the task we implement a deep neural network of the U Net type consisting of several convolutional and max pooling layers. Merge all summaries. Note that the score is better than the true score since overlapping touching nuclei can not be separately identified in this version. randint len x_test Create submission file. It should be noted that the background can be dark black as as well as light white. len x_batch Evaluate current loss and score Store losses and scores. The properties of the network Prior to training the network we resize normalize and transform the images. Each mask has at least one identified object. Default image width Default image height Default number of channels Image type Folder name including the image Folder name including the masks Folder name for TensorBoard summaries Folder name for storing network parameters Random seed for splitting train validation sets Minimal nucleous size in pixels Global variables. Create and start training of a new neural network or continue training of a pretrained model. The pixels are one indexed and numbered from top to bottom then left to right 1 is pixel 1 1 2 is pixel 2 1 etc. For the training images the nuclei are segmented by humans such that we know their number and location within each image. We use 10 of the training data for validation. save parameters of the network TensorFlow saver TensorBoard summaries default session restore session save default graph load parameters define relevant tensors as variables load parameters of network Input tensors Tensors for training and prediction. Counting unique image shapes. True mask with identified objects. Set training and validation sets. The input of the network are images of shape height width channels while the output are corresponding binary masks of shape height width 1. Plot the worst 4 predictions. This is a limiting factor for the overall performance. Implement the Neural Network class 5 bullet 6. Display working train test directories. randint len x_train Keep only objects that are large enough. Inspect a test prediction and check run length encoding. Overall score on validation set. Study the pixel intensity. Attach summaries. Manipulate data 4. For using KFold For using image generation To measure running time For resizing images For using image labeling To read and manipulate images For filepath directory handling System specific parameters and functions Use smart progress meter For pairplots Python 2D plotting library Color map Global constants. Overview of train images masks. Implement the Neural Network Class 6. Validate the neural network 8. Compute all intersections between the objects. 128 128 1 Input tensor. Show intermediate losses and scores during the training session. For example 1 3 10 5 implies pixels 1 2 3 10 11 12 13 14 are to be included in the mask. Summary of scores for training and validations sets. 4 on the validation set. Data augmentations can be used for regularization. Check the image transformation procedure resizing normalizing inverting by looking at a sample. Intersections over unions. Prediction overlap with true mask. randint len x_train Collection of methods for run length encoding. Modules and global settings 1 bullet 2. Collection of methods for data operations. Predicted mask with identified objects. Intersection over union. Start TensorBoard visualization. Looping over mini batches. Basic properties of images masks. Dice loss based on Jaccard dice score coefficent. for testing purpose Implement cross validations Start timer Split into train and validation Create and start training of a new model. Continue training of a pretrained model. Submit Import necessary modules and set global constants and variables. Invert images such that each image has a dark background. Submit 9 bullet Reference U Net Convolutional Networks for Biomedical Image Segmentation https arxiv. There is a lot of variation concerning the form size number of nuclei and the darkness lightness colorfulness of the images. Collection of methods for basic data manipulation like normalizing inverting color transformation and generating new images masks Convert pixel values from 0 255 to 0 1 by global factor Convert pixel values from 0 255 to 0 1 by local factor protect against too small pixel intensities Standardisation of each image Transformations. Furthermore we have not tuned the hyperparameters so there is still a lot of room for improvement. randint 0 len x_train Generate new images masks via transformations applied on the original images maks. Extra operations required for batch normalization. 327 on the validation test set. Manipulate data 3 bullet 4. Run length encoding of predicted test masks. Modules and global settings 2. Read and resize train images masks. Generate new set of images Normalize images and masks Remove color and transform images into grayscale spectrum. 128 128 1 Loss tensor Optimisation tensor. Start tensorflow session. Validate the Neural Network 7 bullet 8. Read and resize test images. Check the score metric for one sample. The predicted mask is simulated and can be modified in order to check the correct implementation of the score metric. Labels that are not assigned. Normalize all images and masks. Remove background. Fixed learnrate Decreasing learnrate each step by factor 1 alpha At the start of the epoch. Second version 2 class variant of dice loss dice_coeff corr offset l2_true l2_pred offset corr_inv offset l2_pred_inv l2_true_inv offset Sigmoid cross entropy. Shuffle permutation array. Adapt the learning rate. The goal is to find the correct number and location of all nuclei shown in the test images. Array of different objects and occupied area. Score Metric 4 bullet 5. Attach saver tensor. The network can achieve a score of 0. Variable initialization. Remove one object false postive Remove one object false negative Offset. Create instance of neural network. ", "id": "fabsta/nuclei-segmentation-tensorflow-u-net-0-327-027909", "size": "3053", "language": "python", "html_url": "https://www.kaggle.com/code/fabsta/nuclei-segmentation-tensorflow-u-net-0-327-027909", "git_url": "https://www.kaggle.com/code/fabsta/nuclei-segmentation-tensorflow-u-net-0-327-027909", "script": "matplotlib.cm read_mask trsf_proba_to_binary __init__ normalize_masks get_prediction imshow_args loss_tensor max_pool_2x2 read_image img_intensity_pairplot rle_of_binary leaky_relu invert_imgs get_learn_rate load_session_from_file imgs_to_grayscale attach_saver preprocess_raw_data activation get_iou seaborn numpy next_mini_batch num_of_weights NeuralNetwork() conv2d_transpose summary_variable weight_variable dropout_layer plot_generated_image_mask train_graph plot_score_summary build_graph conv2d load_parameters rle_to_mask load_tensors read_train_data_properties matplotlib.pyplot tensorflow pandas get_score attach_summary optimizer_tensor normalize_imgs img_comparison_plot generate_images_and_masks build_UNet_graph generate_images normalize get_loss read_test_data_properties load_raw_data get_labeled_mask bias_variable mask_to_rle save_model batch_norm_layer get_score_summary ", "entities": "(('we', 'several convolutional layers'), 'implement') (('output', 'shape'), 'be') (('Furthermore we', 'improvement'), 'tune') (('prediction', 'submission file'), 'loop') (('Default image width Default image height Default number', 'pixels Global variables'), 'set') (('overlapping touching nuclei', 'separately version'), 'note') (('that', 'Parameters'), 'Log') (('Implement', 'new model'), 'for') (('such we', 'image'), 'segment') (('Implemented', 'train test data sets'), 'be') (('This', 'limiting overall performance'), 'be') (('how many objects', 'masks'), 'study') (('which', 'working current directory'), 'write') (('l2_true_inv Sigmoid', 'entropy'), 'offset') (('object', 'parameters'), 'in') (('Python 2D', 'Global constants'), 'use') (('1 2 3 10 14', 'mask'), 'imply') (('average red green channels', 'images'), 'have') (('where number', 'channels'), 'store') (('training', 'training roughly 30 epochs'), 'require') (('predicted mask', 'score metric'), 'simulate') (('randint len x_train Create', 'true mask'), 'predict') (('they', 'overlap'), 'predict') (('Furthermore we', 'translations rotations'), 'implement') (('pixels', 'then right 1'), 'be') (('Read', 'them'), 'image') (('that', 'current implementation'), 'explain') (('default graph load parameters', 'training'), 'define') (('Data augmentations', 'regularization'), 'use') (('which', 'very light background'), 'be') (('Resize', 'image original size'), 'predict') (('medical discovery', 'cells'), 'Abstract') (('goal', 'test images'), 'be') (('Array', 'area'), 'occupy') (('Python', 'training images masks'), 'list') (('which', 'roughly 35 minutes'), 'train') (('training process', 'TensorBoard'), 'save') (('you', 'raw data'), 'in') (('Invert such image', 'dark background'), 'image') (('batch Mini size', 'keep_probability Set helper learning rate 1 variables'), 'keep') (('We', 'validation'), 'use') (('Extra operations', 'batch normalization'), 'require') (('mask', 'at least one identified object'), 'have') (('current index', 'one epoch'), 'be') (('which', 'following'), 'evaluate') (('we', 'images'), 'normalize') ", "extra": "['test', 'procedure']"}
{"name": "chaii muril hf keras wb ", "full_name": " h1 MURIL Multilingual Representations for Indic Languages h2 References h2 Stack h1 Table of Contents h2 Imports h2 Configuration h2 Dataset Split h2 Setting Tokenizer h2 Dataset Pipelines h2 Postprocessing Pipeline h2 Creating Dataset h2 Creating Model h2 Model Training h2 Make predictions on test set h2 Further Reading h3 If you learnt something from this kernel please don t forget to upvote ", "stargazers_count": 0, "forks_count": 0, "description": "Model Training section9 10. Hugging Face for pretrained model and tokenizer4. Use Learning Rate Scheduler If you learnt something from this kernel please don t forget to upvote Creating a logger Specify the format Create a StreamHandler Instance Create a FileHandler Instance Create a logging. com huggingface notebooks blob master examples question_answering. Imports section1 2. png attachment d3c64f59 55c8 4f4f 9eff d82c4e64779e. Creating Model section8 9. But what is MURIL MURIL Khanuja et al simrankhanuja is a multilingual LM specifically built for Indic Languages. If no answers are given set the cls_index as answer. I am going to use other postprocessing methods to improve the score. Otherwise move the token_start_index and token_end_index to the two ends of the answer. Set to None the offset_mapping that are not part of the context so it s easy to determine if a token position is part of the context or not. ipynb by HuggingFace 2. Start end character index of the answer in the text. Detect if the answer is out of span in which case this feature is labeled with the CLS index. pdf Screenshot from 2021 09 05 15 27 50. io examples nlp text_extraction_with_bert Stack1. Note we could go after the last offset if the answer is the last word edge case. Pandas for Data Preprocessing2. Generally for MURIL a goood approach would be to finetune on squad 2 first and then finetune on the competition dataset. Read the full paper here https arxiv. Creating Dataset section7 8. End token index of the current span in the text. This wonderful notebook https github. Weights and biases for experiment tracking kaggle. png attachment a91d27e6 acff 4189 abf6 24314847de65. png Table of Contents1. Configuration section2 3. Start token index of the current span in the text. We keep the example_id that gave us this feature and we will store the offset mappings. One example can give several spans this is the index of the example containing this span of text. Go through all possibilities for the n_best_size greater start and end. data from Tensorflow for Data Pipelines3. Keras Text extraction with Bert Link https keras. Dataset split section3 4. Keras for Model training6. Setting Tokenizer section4 5. Dataset Pipeline section5 6. Make Predictions on Test Set section10 Imports Configuration Dataset Split Setting Tokenizer Dataset Pipelines Postprocessing Pipeline Creating Dataset Creating Model Model Training Make predictions on test set Further Reading1. Grab the sequence corresponding to that example to know what is the context and what is the question. Don t consider answers with a length that is either max_answer_length. MURIL Multilingual Representations for Indic Languages In this notebook I try to train model using MURIL pretrained model combined with Hugging Face and Keras. MURIL as the pretrained model5. Don t consider out of scope answers either because the indices are out of bounds or correspond to part of the input_ids that are not in the context. Postprocessing Pipeline section6 7. Update minimum null prediction. Logger Instance To make this work with TPU detect TPUs TPU detection detect GPUs Intialize wandb run We will label impossible answers with the index of the CLS token. ", "id": "harveenchadha/chaii-muril-hf-keras-wb", "size": "2139", "language": "python", "html_url": "https://www.kaggle.com/code/harveenchadha/chaii-muril-hf-keras-wb", "git_url": "https://www.kaggle.com/code/harveenchadha/chaii-muril-hf-keras-wb", "script": "init_logger __init__ postprocess get_callbacks tqdm.auto UserSecretsClient JaccardScore(keras.callbacks.Callback) map_func prepare_train_features on_epoch_end transformers numpy TFAutoModel sklearn.model_selection seed_everything plot_hist matplotlib.pyplot tensorflow WandbCallback pandas tensorflow.keras.backend get_jaccard_score prepare_tf_data_pipeline wandb.keras tensorflow.keras tqdm prepare_eval_features AutoTokenizer ChaiiDataset jaccard run_tokenizer layers keras get_keras_model get_device train_test_split kaggle_secrets map_func_eval ", "entities": "(('question', 'example'), 'grab') (('I', 'Hugging Face'), 'Representations') (('that', 'context'), 'consider') (('we', 'offset mappings'), 'keep') (('answers', 'answer'), 'set') (('feature', 'CLS index'), 'detect') (('answer', 'last offset'), 'note') (('several this', 'text'), 'give') (('goood approach', 'competition 2 first then dataset'), 'be') (('that', 'length'), 'consider') (('io examples', 'text_extraction_with_bert Stack1'), 'nlp') (('We', 'CLS token'), 'Instance') (('Postprocessing Pipeline', 'Further Reading1'), 'make') (('I', 'score'), 'go') (('don t', 'logging'), 'use') (('token position', 'context'), 'set') (('MURIL MURIL Khanuja et al simrankhanuja', 'Indic multilingual specifically Languages'), 'be') ", "extra": "['test']"}
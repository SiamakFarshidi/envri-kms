{"name": "own build model ", "full_name": " ", "stargazers_count": 0, "forks_count": 0, "description": "com kaggle docker python For example here s several helpful packages to load in linear algebra data processing CSV file I O e. Also we use keras utils to convert labels into categorical labels. read_csv Input data files are available in the. 0001 cooldown 5 min_lr 0. Display Few Samples with labels Set random seed we set the random seed for numpy and tansorflow to get reproducible result each time when we run Building Model for model construction we use keras with tensorfolw backend We use the vgg16 like architecture Two convolutional layers and one maxpooling 2x2 with strides of 2x2 to extract features We create 5 blocks of feature extraction and at last 2 pooling layer we change the strides to 3x3 We apply a flatten to make vector for dense layer After that we use 2 dense layers with 512 and 64 density respectively At final layer we use softmax activation with density of 2 to pridect Model compilation we use Adam optimizer with learning rate of 1e 4 and loss categorical_crossentropy list of callbacks 1. after that we convert list to numpy array for fast processing. ReduceLROnPlateau to monitor learning rate3. Earlystopping to stop training while model not learning furthure Training we use batch size of 32 and runs for 50 epochs Plot the model history to verify model Save best Model weights and load best wieghts Evaluating of Model Model Prediction Classification Reports ROC curve and ROC AUC Score This Python 3 environment comes with many helpful analytics libraries installed It is defined by the kaggle python docker image https github. config the session Set the seed for hash based operations in python Set the numpy seed Set the random seed in tensorflow at graph level block 2 block 3 block 4 reduceLROnPlat ReduceLROnPlateau monitor val_loss factor 0. 8 patience 10 verbose 1 mode auto epsilon 0. Modelcheckpoint to save best weights of model and monitor the val_loss2. For example running this by clicking run or pressing Shift Enter will list all files under the input directory Any results you write to the current directory are saved as output. 0001 probably needs to be more patient but kaggle time is limited summarize history for accuracy summarize history for loss Original labels Get the confusion matrix Calculate Precision and Recall. Preprocessing Data The data are not well splite so we gather all data in one numpy array and then using sklearn library to split data in train and test 80 training data and 20 test data with equal distribution of each classes. we read the image using opencv labrary and then resize the image to 224x224 using inter_cubic interpolation. ", "id": "uzairshahmdn/own-build-model", "size": "1691", "language": "python", "html_url": "https://www.kaggle.com/code/uzairshahmdn/own-build-model", "git_url": "https://www.kaggle.com/code/uzairshahmdn/own-build-model", "script": "sklearn.metrics glob keras.callbacks random model EarlyStopping Adam numpy plot_confusion_matrix ReduceLROnPlateau seed ModelCheckpoint sklearn.model_selection confusion_matrix matplotlib.pyplot keras.utils tensorflow pandas classification_report keras.optimizers to_categorical mlxtend.plotting Model layers roc_auc_score backend LearningRateScheduler roc_curve keras train_test_split ", "entities": "(('read_csv Input data files', 'the'), 'be') (('we', 'inter_cubic interpolation'), 'read') (('probably more patient limited history', 'confusion matrix Calculate Precision'), 'need') (('reduceLROnPlat 2 3 block 4 ReduceLROnPlateau', 'graph level block'), 'config') (('you', 'output'), 'list') (('well so we', 'classes'), 'preprocesse') (('It', 'python docker image https kaggle github'), 'earlystoppe') (('Also we', 'categorical labels'), 'use') (('we', 'callbacks'), 'display') (('we', 'fast processing'), 'convert') ", "extra": "['patient', 'test']"}
{"name": "exploratory analysis ", "full_name": " h1 Exploratory Analysis h3 Disclaimer h2 References h2 Approach h2 Questions h3 Observations h2 Distribition of images h2 Masks h1 Processing Steps h3 Masks with holes h2 Masks with gaps h2 Very Small Nuclei h3 Anomalies h2 Conclusion ", "stargazers_count": 0, "forks_count": 0, "description": "Any suggestions to improve the code here is welcome. ConclusionSometimes mistakes help. References Adrian Rosebrock s PyImageSearch https www. I saw that some were grayscale with black background and nuclei in grayscale intensities. My approach may not be the right one but I am still going to try Most of the code here is borrowed from what others have been doing. While looking at the image extraction progression above I noticed that in some cases the masked section identified was a part of the mask and not the entire object. There are 670 training images and 65 test images making the test set less than 10 of the training set. I liked the video overview given by Dr. Most of the remaining shapes have average width between 10 30 One outlier is the 360x360 where there are groups which are generally bigger than 40 but there a re quite a few which are smaller than 20. Anne Carpenter https www. I wanted to confirm this assumption but missed out. My assumption is that the group that forms the larger cluster is probably the background coolor and the other one is the foreground color. Some have already been identified some are yet to be identified. Very Small NucleiFiltering the data set by the resulting height and width less than 10 pixels I want to look at the smaller objects to verify that the code I wrote is not incorrect and these are actually as identified by Dr Anne team. For me if I could see that something was a nucleus even behind a piece of debris like this I would annotate it. com drannecarpenter DisclaimerMy knowledge of Computer Vision Microbiology Deep Learning is very limited. 0a7d30b252359a10fd298b638b90cb9ada3acced4e0c0e5a3692013f432ee4e9. There are different methods for converting a RGB to grayscale and I can revisit this later if the average value is not good enough. My first attempt at extracting the nuclei ended up with quite a lot of faded objects so I added the contrast stretching to make the nuclei more visible. I have been trying to follow courses and learn these interesting techniques but I have realized that this is a vast field and there are too many things to learn. This was before I read the thread on modalities and zooms. Maybe it is possible to detect if the extracted nuclei image dimensions are an outlier or not. There are very few images with nuclei count less than 5Processing details where only a single nuclei is annotated. Given a mask and an image perform the following actions Identify the contours in the mask Apply mask on the image to leave only the identified objects Identify contours in the mask For each contour extract metadata about the mask Extract the nuclei and rotate it to get a clipped horizontal rectangleMasks are in the masks directory and each mask is in a different file. Such a model could be built into software that biologists use with all kinds of microscopes and eliminate the need for them to train on their individual data or provide metadata about their cell type microscope resolution etc. If yes I can exclude the child contours. I have just tweaked a few things here and there and expanded on the steps so that I can see and understand what is happening behind the scenes. Collect information about the images and save it. There are 7 out of 16 different shapes that are in Test data set only and not in the train data set. Just not sure whether that is happening in the annotations or in your code that generates the multicolor visualization I assume the former of course in which case it s definitely an error. The images consist of different modalities and magnification as mentioned in this thread https www. Single mask seems to cover two objects grab the number of different clusters and create a histogram based on the number of pixels assigned to each cluster normalize the histogram such that it sums to one return the histogram grab the dimensions of the image and then determine the center grab the rotation matrix applying the negative of the angle to rotate clockwise then grab the sine and cosine i. In these cases the process I have used has made me detect more than one contour. When width is less that 10 pixels the height also is less than 10 however there are images where height is less than 10 but the width is greater than 10 Smaller sized 5px images are mostly in the image sizes 256x256 256x360 and 360x360 Rest of the images have larger overall images with few outliers in the smaller sizesThere seem to be some extreme cases where height is less than 10pixels but the width is greater than 30Ditribution of the nuclei counts identified in images by shape of original imageOverall distribution of the number of nuclei annotated by image. These could be of different modality or magnification. There are some missing annotations also as mentioned in this Thread to post data quality issues https www. Processing StepsThe images below show the original one of the masks masked image and extracted square of the mask. For 9bb6e39d5f4415bc7554842ee5d1280403a602f2ba56122b87f453a62d37c06e indeed that object is an error. I caught many of these before the training set went out but apparently not all For 1f0008060150b5b93084ae2e4dabd160ab80a95ce8071a321b80ec4e33b58aca Those pairs of nuclei should indeed be split. So these images are interesting and I get to learn a bit more about how Deep Learning impact the medical field. I will approach this competition with the limited knowledge that I have and I will also attempt to incorporate methods that others are experimenting with if I can grasp them and can implement on my own. This means that these masks have a break between two sections and this is causing the Masks with gapsThe distribution of the number of nuclei identified by different shapes is also quite wide. com c data science bowl 2018 discussion 47640 We want a single model that just works across all kinds of image modalities no matter the size of the nuclei or the color scheme. I added a circle on the images to show the original location and to show that the nuclei on edges can be clipped based on which edge they are on. But there are still 11 images where the number of contours identified is 2. There is one example of each sample from the training set. QuestionsHere are the questions I set out to answer in this notebook. MasksExtract the masks metadata into a separate file. There seem to be issues in the data. com c data science bowl 2018 discussion 47770 This might be a case where annotators disagree. I agree b1eb0123fe2d8c825694b193efb7b923d95effac9558ee4eaf3116374c2c94fe is missing two nuclei off to the right. The distribution is certainly skewed which I guess is expected. Perform KMeans clustering on the RGB format. Overall size distribution of the nuclei The largest resolution 1040x1388 has larger nuclei width averaging around 110. Turns out that cv2 has a mode RETR_EXTERNAL which will exclude all child elements and this solves the problem above. This way we can do a comparison across all images. the rotation components of the matrix compute the new bounding dimensions of the image adjust the rotation matrix to take into account translation perform the actual rotation and return the image offset the points print box lambda function to flatten a list cv2. com which covers great tutorials on OpenCV ApproachI am a newbie to Deep Learning and Computer Vision and this competition is my playground for learning. Build the paths for the individual images ObservationsI had initially glanced through some of the sample images and there were different types of images. I think there is a way to identify whether the contour is a child or not. CV2 find contours is identifying the parent contour and the holes as child contours. How many types of images are there Are the types of images in train and test similar or vastly different How does the image segmentation and object detection compare to the masks provided for the training set Ensuring that only the folders are picked up and any junk files in the same path are ignoredCreate a pandas dataframe combining all images and marking them as train or test. The images below show the processing steps followed to extract the final nuclei. the circle shows the original center. Interesting distribution of the nuclei image sizes. I did see some very small objects which to my eye looked like black patches. There are a lot of people who have built interesting kernels which take different approaches to reach the end goal. Some of them were in color and some of them seemed to be black on white. Masks with holesLet s have a look at the mask with 14 elementsIt looks like the mask has holes and this may be intentional. There are four images sizes where the total number of nuclei identified is greater than 2000. k means color clustering https www. Using RETR_TREE was a mistake but it helped me identify masks that have holes. I also assumed that the masked sections are completely solid and would not have holes. This is missing annotations. The code below helps us cluster the image into two groups. Rotating the image so that long edge is horizontal and clipping the boundaries. com 2014 05 26 opencv python k means color clustering Given a path for an image load the image and extract the shape attributes. Bounded rotation ensures that resulting rotated image is not clipped. Create a histogram and identify the centroid of the group as the color intensity whose variations are most similar to it. The third one in the above set has already been identified an incorrect train file. Distribition of imagesTime to play around with some graphs and see how the data is spread across all images. Processing details where only two nuclei are annotated. I have calculated the grayscale value as an average of all three colors and this is marked as teh background and foreground color. You are right that in general they ought to be multi colored whereas your result indicates the masks are improperly merged. Exploratory AnalysisDuring my undergraduate studies I had biology as one of my subjects and I enjoyed preparing the slides and looking at them using a microscope. If the foreground color is darker than the background color mark the image to be inverted before processing. com drannecarpenter and I am sure I will be able to learn quite a few things by participating in this. I cannot swear to it but in general nuclei as we have annotated them should NOT have any holes For 19f0653c33982a416feed56e5d1ce6849fd83314fd19dfa1c5b23c6b66e9868a I guess it depends how you generated the image you are showing on the right. I m also disturbed that there are tiny black dots indicating holes in the nuclei which should not be there. We can pick a random sample from each image size and have a look. Since the sample itself is random every run may not give the same results. I had assumed that each mask is one nucleus. I wonder if creating combining the contours together into a single set will give me a single composite image. Thankfully debris like this is not common. Image 1 Is this supposed to be two nuclei Image 3 Is a middle one missing from the masks AnomaliesAll of these look like incorrect annotation. Original image Image after applying contrast stretch A mask for the image After converting dark on bright to bright on dark and applying the mask Extracting a square. Using this extract the background and foreground colors. Since we have the color values for different channels it would be interesting to see how these values are spread across the images. As Anne mentioned there are some image sizes in test set that are not in the training set. Now I have read that most of the CV tasks work best on grayscale images and it makes sense if all images follow a similar pattern of white on black. stage1_train 58c593bcb98386e7fd42a1d34e291db93477624b164e83ab2afa3caa90d1d921 I agree that nucleus ought to have been identified I agree that image 12aeefb1b522b283819b12e4cfaf6b13c1264c0aadac3412b4edd2ace304cb40 was badly annotated. This should include mask_id a separate index number for all the mask objects minimum bounding rectangle angle of rotation longer edge horizontal masked area length breadthBy using contour identification process individual mask objects can be extracted and rotated to a common rectangular shape and we can then get answers to more questions. ", "id": "jerrythomas/exploratory-analysis", "size": "12069", "language": "python", "html_url": "https://www.kaggle.com/code/jerrythomas/exploratory-analysis", "git_url": "https://www.kaggle.com/code/jerrythomas/exploratory-analysis", "script": "get_masks tag_anomaly show_row_col sklearn.cluster KMeans pyplot as plt show_process extract seaborn numpy pyplot show_mask rotate_bound centroid_histogram get_image_info pandas rotate_points show_image n_of_each matplotlib ", "entities": "(('Thankfully debris', 'this'), 'be') (('KMeans', 'RGB format'), 'perform') (('this', 'holes'), 'have') (('I', 'modalities'), 'be') (('I', 'it'), 'annotate') (('b1eb0123fe2d8c825694b193efb7b923d95effac9558ee4eaf3116374c2c94fe', 'off right'), 'agree') (('some', 'white'), 'be') (('which', 'black patches'), 'see') (('others', 'here what'), 'be') (('third one', 'train already incorrect file'), 'identify') (('where only single nuclei', 'less than 5Processing details'), 'be') (('I', 'own'), 'approach') (('nuclei', 'faded objects'), 'end') (('that', 'training set'), 'be') (('Computer competition', 'learning'), 'be') (('which', 'nuclei'), 'disturb') (('pairs', 'nuclei'), 'catch') (('that', 'matter nuclei'), 'bowl') (('this', 'problem'), 'turn') (('which', 'end goal'), 'be') (('images', 'white'), 'read') (('re quite a few which', 'generally 40'), 'be') (('we', 'more questions'), 'include') (('later average value', 'this'), 'be') (('what', 'scenes'), 'tweak') (('rotation components', 'list cv2'), 'adjust') (('them', 'cell type microscope resolution etc'), 'build') (('still 11 where number', 'contours'), 'be') (('long edge', 'boundaries'), 'rotate') (('it', 'case'), 'assume') (('some', 'grayscale intensities'), 'see') (('width', 'image'), 'be') (('you', 'right'), 'swear') (('images', 'thread https www'), 'consist') (('We', 'look'), 'pick') (('how data', 'images'), 'Distribition') (('junk files', 'train'), 'be') (('Processing StepsThe images', 'mask'), 'show') (('resolution largest 1040x1388', 'around 110'), 'have') (('this', 'interesting techniques'), 'try') (('that', 'holes'), 'be') (('then center', 'then sine'), 'seem') (('they', 'edge'), 'add') (('where only two nuclei', 'details'), 'processing') (('indeed object', '9bb6e39d5f4415bc7554842ee5d1280403a602f2ba56122b87f453a62d37c06e'), 'be') (('below us', 'two groups'), 'help') (('images four where total number', '2000'), 'be') (('image', 'processing'), 'be') (('I', 'this'), 'com') (('training test 670 65 test', 'training set'), 'be') (('way we', 'images'), 'do') (('variations', 'most it'), 'create') (('I', 'microscope'), 'AnalysisDuring') (('suggestions', 'code'), 'be') (('I', 'notebook'), 'be') (('this', 'teh background'), 'calculate') (('creating', 'single composite image'), 'wonder') (('masks', 'separate file'), 'metadata') (('also masked sections', 'completely holes'), 'assume') (('how values', 'images'), 'be') (('python k color', 'shape attributes'), 'mean') (('I', 'assumption'), 'want') (('this', 'different shapes'), 'mean') (('resulting', 'rotated image'), 'ensure') (('mask', 'different file'), 'perform') (('processing below steps', 'final nuclei'), 'show') (('background probably coolor', 'larger cluster'), 'be') (('Build', 'different images'), 'glance') (('com', 'Computer Vision Microbiology Deep Learning'), 'be') (('contours', 'child contours'), 'find') (('These', 'different modality'), 'be') (('two Image', 'incorrect annotation'), 'image') (('that', 'train data only set'), 'be') (('masked section', 'mask'), 'notice') (('Deep bit more how Learning', 'medical field'), 'be') (('run', 'same results'), 'give') (('me', 'more than one contour'), 'make') (('these', 'Dr Anne actually team'), 'NucleiFiltering') ", "extra": "['annotation', 'test']"}
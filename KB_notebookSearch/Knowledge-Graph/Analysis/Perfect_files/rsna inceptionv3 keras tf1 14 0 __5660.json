{"name": "rsna inceptionv3 keras tf1 14 0 ", "full_name": " h3 InceptionV3 previously ResNet50 Keras baseline model h3 0 Preprocessing brain subudral soft h4 Check with an example if the correction works visually h3 1 Helper functions h3 2 Data generators h3 3a loss function and metric h3 3b Model h3 4 Read csv files h3 5 Train model and predict h3 6 Submit test predictions h3 7 Improvements ", "stargazers_count": 0, "forks_count": 0, "description": "ImprovementsSome improvements that could possibly be made Image augmentation which can be put in _read Different learning rate and learning rate schedule Increased input size Train longer Add more dense layers and regularization e. com reppic gradient sigmoid windowing kernel by Ryan Epp Thus I m trying out the sigmoid brain subdural bone to see if it improves the log loss Number of epochs reduced to 4 increased undersampling and validation predictions removed due to limited time Update 6 did not improve from 5 Going back to raw HUs with a bit of clipping Together with a first initial conv layer with sigmoid activation epochs increased to 6 from 4 and input size increased to 256 256 from 224 224 simple average of epochs 1 for the test predictions Update 7 Trying windowing based on appian42 s repo https github. Update 1 training for 4 epochs instead of 3. 1 x callbacks train set 00 and validation set 10 lets go for the first fold only obtain model obtain test validation predictions history. com marcovasquez basic eda data visualization Nanashi https www. com appian42 kaggle rsna intracranial hemorrhage windowing Jeremy s kernel https www. batch size lowered to 16 from 32. valid_df print validation loss. 2 x x keras. ModelModel is divided into three parts REMOVED The initial layer which will transform map input image of shape _ _ 1 to another image of shape _ _ 3. The new input image is then passed through InceptionV3 which I named engine. com omission eda view dicom images with correct windowing 2. doing 5 epochs instead of 6 Update 5 Got some inspiration from this great https www. valid_predictions axis 0 weights 2 i for i in range len self. uses bsb_window from previous cell REMOVED Source for windowing although now partly removed from this kernel https www. com dcstang see like a radiologist with systematic windowing Marco https www. Train model and predict Using train validation and test set Training for 5 epochs with Adam optimizer with a learning rate of 0. Preprocessing brain subudral soft REMOVED Many thanks to Ryan Epp https www. 4f weighted_log_loss_metric self. Update 2 adding competition metric for training using custom Callback for validation and test sets instead of the run function and global epochs training with plain BCE again merging TestDataGenerator and TrainDataGenerator into one adding undersampling see inside on_epoch_end will now run 6 epochs Update 3 skipping removing windowing value clipping but the transformation to Hounsfield Units is kept removing initial layer doing np. valid_predictions here you could also save the predictions with np. com jesucristo rsna introduction eda models and Richard McKinley https www. PixelRepresentation 0 and int dcm. 0005 and decay rate of 0. test_predictions history. Not sure how much this will affect the performance of the training but it really speeded it up. resnet import ResNet50 Sanity Check Example dicoms ID_2669954a7 ID_5c8b5d701 ID_52c9913b1 ID Label 4045566 ID_5c8b5d701_epidural 0 4045567 ID_5c8b5d701_intraparenchymal 1 4045568 ID_5c8b5d701_intraventricular 0 4045569 ID_5c8b5d701_subarachnoid 1 4045570 ID_5c8b5d701_subdural 1 4045571 ID_5c8b5d701_any 1 example of a bad data point i. valid_predictions let s do a weighted average for epochs 1. Dropout before the output layer Adding some optimal windowing Feel free to comment from keras_applications. RescaleIntercept 100 True Another sanity check for training phase we undersample and shuffle keep probability of any 0 and any 1 training phase test phase Commented out to save time self. Submit test predictions 7. stack img ast 3 axis 1 instead reducing learning rate to 5e 4 and add decay increasing batch size to 32 from 16 Increasing training set to 90 of the data 10 for validation slight increase in undersampling fixed some hardcoding for input dims sizes training with weighted BCE again Update 4 Trying out InceptionV3 instead of ResNet50 undersampling without weights adding dense layers with dropout before output clipping HUs between 50 and 450 probably the most relevant value space normalization is now mapping input to 0 to 1 range instead of 1 to 1. Sequence object and thus should be safe for multiprocessing. int_shape x 1 activation relu name dense_hidden_1 x x keras. com appian42 kaggle rsna intracranial hemorrhage instead I also include some cleaning based on Jeremy s kernel https www. Helper functions read and transform dcms to 3 channel inputs for e. com omission eda view dicom images with correct windowing. com jhoward cleaning the data for rapid prototyping fastai hopefully it s correct atleast the visualization looked good weighted average of the epochs 1 for the test predictions reducing number of epochs to 5 Update 8 Removing the extra dense layer before output layer keeping everything else the same 0. values np. training without learning rate decay. Code is taken from his kernel see his kernel for more information and other peoples work for example David Tang https www. loss function and metric 3b. The validation predictions are exponentially weighted averaged over all 5 epochs not in this commit. fit_and_predict returns validation and test predictions for all epochs. valid_images_dir verbose 2 len self. append self. Data generatorsInherits from keras. com reppic gradient sigmoid windowing. NEW Based on two great kernels appian42 s repo https github. Weighted BCE instead of plain BCE training data lowered to 80 from 90. Finally the output from InceptionV3 goes through average pooling followed by two dense layers including output layer. At first I thought I couldn t use sigmoid windowing for this kernel because of how expensive it is to do but I could resize the image prior to the transformation to save a lot of computation. com jhoward cleaning the data for rapid prototyping fastai cleaning Check with an example if the correction works visually 1. save x keras. InceptionV3 previously ResNet50 Keras baseline model This notebook takes you through some important steps in building a deep convnet in Keras for multilabel classification of brain CT scans. predict_generator DataGenerator self. BitsStored 12 and dcm. InceptionV3 could be replaced by any of the available architectures in keras_application. ", "id": "akensert/rsna-inceptionv3-keras-tf1-14-0", "size": "5660", "language": "python", "html_url": "https://www.kaggle.com/code/akensert/rsna-inceptionv3-keras-tf1-14-0", "git_url": "https://www.kaggle.com/code/akensert/rsna-inceptionv3-keras-tf1-14-0", "script": "__init__ weighted_loss weighted_log_loss log window_with_correction weighted_log_loss_metric tqdm_notebook floor fit_and_predict load read_trainset DataGenerator(keras.utils.Sequence) bsb_window on_epoch_end ShuffleSplit __data_generation numpy tqdm_notebook as tqdm InceptionV3 _read __getitem__ save window_testing _normalized_weighted_average keras_applications.resnet ceil sklearn.model_selection _build matplotlib.pyplot correct_dcm tensorflow ResNet50 pandas __len__ tqdm read_testset MyDeepModel window_without_correction on_train_begin backend backend as K keras window_image keras_applications.inception_v3 math PredictionCheckpoint(keras.callbacks.Callback) datetime ", "entities": "(('correction', 'example'), 'clean') (('test 1 predictions', 'everything'), 'clean') (('I', 'computation'), 'think') (('Train model', '0'), 'set') (('InceptionV3', 'keras_application'), 'replace') (('com jesucristo rsna', 'eda models'), 'introduction') (('here you', 'np'), 'save') (('output layer', 'keras_applications'), 'dropout') (('we', 'training phase test time 1 self'), 'RescaleIntercept') (('value space probably most relevant normalization', 'to 1 range'), 'size') (('resnet import Sanity Check Example', 'data ID 4045566 0 4045567 1 4045568 0 4045569 1 4045570 ID_5c8b5d701_subdural 4045571 ID_5c8b5d701_any 1 bad point'), 'ResNet50') (('Helper functions', 'e.'), 'read') (('Finally output', 'output layer'), 'go') (('input size', 'repo https github'), 'sigmoid') (('transformation', 'np'), 'update') (('com dcstang', 'Marco https systematic windowing www'), 'see') (('00 validation', 'model obtain test validation predictions only history'), 'go') (('Keras baseline notebook', 'brain CT scans'), 'InceptionV3') (('initial which', 'shape'), 'divide') (('intracranial instead I', 'kernel https www'), 'com') (('input Increased size', 'longer more dense layers'), 'improvement') (('doing', 'https great www'), 'Got') (('I', 'engine'), 'pass') (('s', 'epochs'), 'let') (('validation predictions', 'commit'), 'weight') (('valid_predictions', 'range len self'), 'axis') (('it', 'really it'), 'sure') (('kernel', 'other example'), 'take') (('Weighted BCE', '90'), 'lower') ", "extra": "['test']"}